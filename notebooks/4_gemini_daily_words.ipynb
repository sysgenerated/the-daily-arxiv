{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "\n",
    "from typing import Union\n",
    "from dotenv import load_dotenv\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API key from environment variable\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define LLM functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "#gemini-1.0-pro\n",
    "model = genai.GenerativeModel(\"gemini-1.0-pro-001\", safety_settings={\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE})\n",
    "\n",
    "\n",
    "def get_descriptive_words_from_gemini(abstracts: list[str], word_count: int=10,\n",
    "                                               max_retries: int=3) -> list[dict[str | list]]:\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "Provide a comma separated list of <word_count> words uniquely identifying this abstract. \n",
    "The words should only be unitary words.\n",
    "Do not use hyphenated words. \n",
    "Do not use phrases.\n",
    "\n",
    "Abstract: \n",
    "<abstract>\n",
    "\"\"\"\n",
    "\n",
    "    descriptive_words = []\n",
    "\n",
    "    for abstract in abstracts:\n",
    "        prompt = prompt_template.replace(\"<word_count>\", str(word_count))\n",
    "        prompt = prompt.replace(\"<abstract>\", abstract)\n",
    "        print(f\"Prompt: {prompt}\")\n",
    "\n",
    "        retries = 0\n",
    "        while retries < max_retries:\n",
    "            try:\n",
    "                model_results = model.generate_content(prompt)\n",
    "                print(f\"Completed {model_results.text} abstracts ...\")\n",
    "                descriptive_words.append(model_results.text)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Exception occurred: {e}\")\n",
    "                retries += 1\n",
    "                print(f\"Retrying... ({retries}/{max_retries})\")\n",
    "                time.sleep(10)\n",
    "        if retries == 3:\n",
    "            return None\n",
    "        time.sleep(3)\n",
    "    return descriptive_words\n",
    "\n",
    "\n",
    "def get_most_recent_file(directory: str) -> Union[str, None]:\n",
    "    files = [os.path.join(directory, f) for f in os.listdir(directory)]\n",
    "    files = [f for f in files if os.path.isfile(f)]\n",
    "    if not files:\n",
    "        return None\n",
    "    file_ctimes = [(f, os.path.getctime(f)) for f in files]\n",
    "    most_recent_file = sorted(file_ctimes, key=lambda x: x[1], reverse=True)[0][0]\n",
    "    return most_recent_file\n",
    "\n",
    "\n",
    "def daily_processing(filename=None):\n",
    "    if filename is None:\n",
    "        filename = get_most_recent_file(\"../data\")\n",
    "    df = pd.read_json(filename, orient=\"records\")\n",
    "    if not df.empty:\n",
    "        abstracts = df[\"abstract\"].tolist()\n",
    "        descriptive_words = get_descriptive_words_from_gemini_by_chunk(abstracts)\n",
    "        descriptive_words = [{key: value} for key, value in descriptive_words.items()]\n",
    "        results = pd.DataFrame(descriptive_words, columns=[\"abstract\"])\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We study ill-conditioned positive definite matrices that are disturbed by the sum of $m$ rank-one matrices of a specific form. We provide estimates for the eigenvalues and eigenvectors. When the condition number of the initial matrix tends to infinity, we bound the values of the coordinates of the eigenvectors of the perturbed matrix. Equivalently, in the coordinate system where the initial matrix is diagonal, we bound the rate of convergence of coordinates that tend to zero.\n",
      "\n",
      "Completed ill-conditioned, positive, definite, matrices, rank-one, eigenvalues, eigenvectors, condition, number, convergence abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "To ensure that text generated by large language models (LLMs) is in an expected format, constrained decoding proposes to enforce strict formal language constraints during generation. However, as we show in this work, not only do such methods incur performance overhead during generation, but many of them also significantly impair task accuracy, if they do not correctly align the underlying LLM sub-word vocabularies with external constraints. To address this, we present a novel decoding algorithm, DOMINO, that can enforce constraints in a fully subword-aligned fashion, while leveraging pre-computation and speculative decoding to achieve virtually no overhead and in some cases even almost 2$\\times$ speedup over unconstrained decoding -- thereby outperforming existing approaches by a wide margin.\n",
      "\n",
      "Completed Constrained,Decoding,Language,Models,Subword,Vocabulary,Alignment,DOMINO,Overhead,Speedup abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Reducing the dimensionality and uncertainty of design spaces is a key prerequisite for shape optimisation in computationally intensive fluid problems. However, running these analyses at an offline stage itself poses a computationally demanding task. In this work, we propose a unique framework for the inexpensive implementation of sensitivity analyses for reducing the dimensionality of the design space in wave-resistance problems. At the heart of our approach is the formulation of a geometric operator that leverages, via high-order geometric moments, the underlying connection between geometry and physics, specifically the wave-resistance coefficient ($C_w$), of ships using the slender body theory based on the well-known Vossers' integral. The resulting geometric operator is computationally inexpensive yet physics-informed and can act as a geometry-based surrogate to drive parametric sensitivities. To analytically demonstrate the capability of the proposed approach, we use a well-known benchmark geometry, namely, the modified Wigley hull. Its simple analytical formulation allows for closed expressions of the geometric operators and exploration of computational domains that would otherwise be inaccessible. In this context, the proposed geometric operator outperforms existing similar approaches by achieving 100% similarity with $C_w$ at a fraction of the computational cost.\n",
      "\n",
      "Completed geometric operator, design space, wave-resistance, sensitivity analysis, geometric moments, physics-informed surrogate, slender body theory, Vossers' integral, modified Wigley hull, closed expressions abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "A three-dimensional model of polydisperse reactive sedimentation is developed by means of a multilayer shallow water approach. The model consists of a variety of solid particles of different sizes and densities, and substrates diluted in water, which produce biochemical reactions while the sedimentation process occurs. Based on the Masliyah-Lockett-Bassoon settling velocity, compressibility of the sediment and viscosity of the mixture, the system of governing equations is composed by non-homogeneous transport equations, coupled to a momentum equation describing the mass-average velocity. Besides, the free-surface depicted by the total height of the fluid column is incorporated and fully determined through the multilayer approach. A finite volume numerical scheme on Cartesian grids is proposed to approximate the model equations. Numerical simulations of the denitrification process exemplify the performance of the numerical scheme and model under different scenarios and bottom topographies.\n",
      "\n",
      "Completed polydisperse, sedimentation, reactive, multilayer, shallow water, Masliyah-Lockett-Bassoon, compressibility, viscosity, non-homogeneous, finite volume abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Autonomous driving technology can improve traffic safety and reduce traffic accidents. In addition, it improves traffic flow, reduces congestion, saves energy and increases travel efficiency. In the relatively mature automatic driving technology, the automatic driving function is divided into several modules: perception, decision-making, planning and control, and a reasonable division of labor can improve the stability of the system. Therefore, autonomous vehicles need to have the ability to predict the trajectory of surrounding vehicles in order to make reasonable decision planning and safety measures to improve driving safety. By using deep learning method, a safety-sensitive deep learning model based on short term memory (LSTM) network is proposed. This model can alleviate the shortcomings of current automatic driving trajectory planning, and the output trajectory not only ensures high accuracy but also improves safety. The cell state simulation algorithm simulates the trackability of the trajectory generated by this model. The research results show that compared with the traditional model-based method, the trajectory prediction method based on LSTM network has obvious advantages in predicting the trajectory in the long time domain. The intention recognition module considering interactive information has higher prediction and accuracy, and the algorithm results show that the trajectory is very smooth based on the premise of safe prediction and efficient lane change. And autonomous vehicles can efficiently and safely complete lane changes.\n",
      "\n",
      "Completed autonomous, driving, safety, traffic, LSTM, trajectory, prediction, planning, efficiency, stability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper introduces the Capacitated Covering Salesman Problem (CCSP), approaching the notion of service by coverage in capacitated vehicle routing problems. In CCSP, locations where vehicles can transit are provided, some of which have customers with demands. The objective is to service customers through a fleet of vehicles based in a depot, minimizing the total distance traversed by the vehicles. CCSP is unique in the sense that customers, to be serviced, do not need to be visited by a vehicle. Instead, they can be serviced if they are within a coverage area of the vehicle. This assumption is motivated by applications in which some customers are unreachable (e.g., forbidden access to vehicles) or visiting every customer is impractical. In this work, optimization methodologies are proposed for the CCSP based on ILP (Integer Linear Programming) and BRKGA (Biased Random-Key Genetic Algorithm) metaheuristic. Computational experiments conducted on a benchmark of instances for the CCSP evaluate the performance of the methodologies with respect to primal bounds. Furthermore, our ILP formulation is extended in order to create a novel MILP (Mixed Integer Linear Programming) for the Multi-Depot Covering Tour Vehicle Routing Problem (MDCTVRP). Computational experiments show that the extended MILP formulation outperformed the previous state-of-the-art exact approach with respect to optimality gaps. In particular, optimal solutions were obtained for several previously unsolved instances.\n",
      "\n",
      "Completed Capacitated, Covering, Salesman, Problem, Integer, MILP, BRKGA, Metaheuristic, Benchmark, MDCTVRP abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "What constitutes human creativity, and is it possible for computers to exhibit genuine creativity? We argue that achieving human-level intelligence in computers, or so-called Artificial General Intelligence, necessitates attaining also human-level creativity. We contribute to this discussion by developing a statistical representation of human creativity, incorporating prior insights from stochastic theory, psychology, philosophy, neuroscience, and chaos theory. This highlights the stochastic nature of the human creative process, which includes both a bias guided, random proposal step, and an evaluation step depending on a flexible or transformable bias structure. The acquired representation of human creativity is subsequently used to assess the creativity levels of various contemporary AI systems. Our analysis includes modern AI algorithms such as reinforcement learning, diffusion models, and large language models, addressing to what extent they measure up to human level creativity. We conclude that these technologies currently lack the capability for autonomous creative action at a human level.\n",
      "\n",
      "Completed creativity, human, artificial intelligence, stochastic, chaos theory, stochastic process, computational creativity, diffusion models, reinforcement learning, language models abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Survival analysis is essential for studying time-to-event outcomes and providing a dynamic understanding of the probability of an event occurring over time. Various survival analysis techniques, from traditional statistical models to state-of-the-art machine learning algorithms, support healthcare intervention and policy decisions. However, there remains ongoing discussion about their comparative performance. We conducted a comparative study of several survival analysis methods, including Cox proportional hazards (CoxPH), stepwise CoxPH, elastic net penalized Cox model, Random Survival Forests (RSF), Gradient Boosting machine (GBM) learning, AutoScore-Survival, DeepSurv, time-dependent Cox model based on neural network (CoxTime), and DeepHit survival neural network. We applied the concordance index (C-index) for model goodness-of-fit, and integral Brier scores (IBS) for calibration, and considered the model interpretability. As a case study, we performed a retrospective analysis of patients admitted through the emergency department of a tertiary hospital from 2017 to 2019, predicting 90-day all-cause mortality based on patient demographics, clinicopathological features, and historical data. The results of the C-index indicate that deep learning achieved comparable performance, with DeepSurv producing the best discrimination (DeepSurv: 0.893; CoxTime: 0.892; DeepHit: 0.891). The calibration of DeepSurv (IBS: 0.041) performed the best, followed by RSF (IBS: 0.042) and GBM (IBS: 0.0421), all using the full variables. Moreover, AutoScore-Survival, using a minimal variable subset, is easy to interpret, and can achieve good discrimination and calibration (C-index: 0.867; IBS: 0.044). While all models were satisfactory, DeepSurv exhibited the best discrimination and calibration. In addition, AutoScore-Survival offers a more parsimonious model and excellent interpretability.\n",
      "\n",
      "Completed survival analysis, CoxPH, Random Survival Forests, DeepSurv, CoxTime, DeepHit, C-index, integral Brier scores, AutoScore-Survival, interpretability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "When two bodies get into contact, only a small portion of the apparent area is actually involved in producing contact and friction forces, because of the surface roughnesses. It is therefore crucial to accurately describe the morphology of rough surfaces for instance by extracting the fractal dimension and the so-called Hurst exponent which is a typical signature of rough surfaces. This can be done using harmonic decomposition, which is easy for periodic and nominally flat surfaces since Fourier transforms allow fast and reliable decomposition. Yet, it remains a challenging task in the general curved and non-periodic cases, where more appropriate basis functions must be used. In this work, disk harmonics based on Fourier-Bessel basis functions are employed for decomposing open single-edge genus-0 surfaces (no holes) as a practical and fast alternative to characterise self-affine rough surfaces with the power Fourier-Bessel spectral density. An analytical relationship between the power spectrum density decay and the Hurst exponent is derived through an extension of the Wiener-Khinchin theorem, in the special case where surfaces are assumed self-affine and isotropic. Finally, this approach is demonstrated to successfully measure the fractal dimension, and the Hurst exponent, without introducing typical biases coming from basis functions boundary conditions, surface discretisation or curvature of the surface patches. This work opens the path for contact mechanics studies based on the Fourier-Bessel spectral representation of curved and rough surface morphologies. All implementation details for this method are available under GNU LGPLv3 terms and conditions.\n",
      "\n",
      "Completed surfaces, roughness, fractal dimension, Hurst exponent, harmonic decomposition, Fourier-Bessel, disk harmonics, self-affine, Wiener-Khinchin theorem, isotropic abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "A smart city solution toward future 6G network deployment allows small and medium sized enterprises (SMEs), industry, and government entities to connect with the infrastructures and play a crucial role in enhancing emergency preparedness with advanced sensors. The objective of this work is to propose a set of coordinated technological solutions to transform an existing emergency response system into an intelligent interactive system, thereby improving the public services and the quality of life for residents at home, on road, in hospitals, transport hubs, etc. In this context, we consider a city wide view from three different application scenes that are closely related to peoples daily life, to optimize the actions taken at relevant departments. Therefore, using artificial intelligence (AI) and machine learning (ML) techniques to enable the next generation connected vehicle experiences, we specifically focus on accidents happening in indoor households, urban roads, and at large public facilities. This smart interactive response system will benefit from advanced sensor fusion and AI by formulating a real time dynamic model.\n",
      "\n",
      "Completed connected, emergency, household, infrastructure, interactive, public, response, sensor, smart, vehicle abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "A popular approach to the MAP inference problem in graphical models is to minimize an upper bound obtained from a dual linear programming or Lagrangian relaxation by (block-)coordinate descent. Examples of such algorithms are max-sum diffusion and sequential tree-reweighted message passing. Convergence properties of these methods are currently not fully understood. They have been proved to converge to the set characterized by local consistency of active constraints, with unknown convergence rate; however, it was not clear if the iterates converge at all (to any single point). We prove a stronger result (which was conjectured before but never proved): the iterates converge to a fixed point of the algorithm. Moreover, we show that they achieve precision $\\varepsilon>0$ in $\\mathcal{O}(1/\\varepsilon)$ iterations.\n",
      "  We first prove this for a version of coordinate descent applied to a general piecewise-affine convex objective, using a novel proof technique. Then we demonstrate the generality of this approach by reducing some popular coordinate-descent algorithms to this problem. Finally we show that, in contrast to our main result, a similar version of coordinate descent applied to a constrained optimization problem need not converge.\n",
      "\n",
      "Completed graphical, models, MAP, inference, dual, linear, programming, coordinate, descent, fixed point abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we study the cooperative Multi-Agent Reinforcement Learning (MARL) problems using Reward Machines (RMs) to specify the reward functions such that the prior knowledge of high-level events in a task can be leveraged to facilitate the learning efficiency. Unlike the existing work that RMs have been incorporated into MARL for task decomposition and policy learning in relatively simple domains or with an assumption of independencies among the agents, we present Multi-Agent Reinforcement Learning with a Hierarchy of RMs (MAHRM) that is capable of dealing with more complex scenarios when the events among agents can occur concurrently and the agents are highly interdependent.\n",
      "  MAHRM exploits the relationship of high-level events to decompose a task into a hierarchy of simpler subtasks that are assigned to a small group of agents, so as to reduce the overall computational complexity.\n",
      "  Experimental results in three cooperative MARL domains show that MAHRM outperforms other MARL methods using the same prior knowledge of high-level events.\n",
      "\n",
      "Completed Multi-Agent, Reinforcement, Learning, Reward, Machines, Hierarchy, Cooperation, Decomposition, Complexity, Efficiency abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Wearable augmented reality (AR) offers new ways for supporting the interaction between autonomous vehicles (AVs) and pedestrians due to its ability to integrate timely and contextually relevant data into the user's field of view. This article presents novel wearable AR concepts that assist crossing pedestrians in multi-vehicle scenarios where several AVs frequent the road from both directions. Three concepts with different communication approaches for signaling responses from multiple AVs to a crossing request, as well as a conventional pedestrian push button, were simulated and tested within a virtual reality environment. The results showed that wearable AR is a promising way to reduce crossing pedestrians' cognitive load when the design offers both individual AV responses and a clear signal to cross. The willingness of pedestrians to adopt a wearable AR solution, however, is subject to different factors, including costs, data privacy, technical defects, liability risks, maintenance duties, and form factors. We further found that all participants favored sending a crossing request to AVs rather than waiting for the vehicles to detect their intentions-pointing to an important gap and opportunity in the current AV-pedestrian interaction literature.\n",
      "\n",
      "Completed Wearable, Augmented, Reality, Autonomous, Vehicles, Pedestrians, Virtual, Reality, Cognitive, Load abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Mobile users such as airplanes or ships will constitute an important segment of the future satellite communications market. Operators are now able to leverage digital payloads that allow flexible resource allocation policies that are robust against dynamic user bases. One of the key problems is managing the frequency spectrum efficiently, which has not been sufficiently explored for mobile users.\n",
      "  To address this gap, we propose a dynamic frequency management algorithm based on linear programming that assigns resources in scenarios with both fixed and mobile users by combining long-term planning with real-time operation. We propose different strategies divided into proactive strategies, which stem from robust optimization practices, and reactive strategies, which exploit a high degree of real-time control. This represents a tradeoff between how conservative long-time planning should be and how much real-time reconfiguration is needed.\n",
      "  To assess the performance of our method and to determine which proactive and reactive strategies work better under which context, we simulate operational use cases of non-geostationary constellations with different levels of dimensionality and uncertainty, showing that our method is able to serve over 99.97\\% of the fixed and mobile users in scenarios with more than 900 beams. Finally, we discuss the trade-offs between the studied strategies in terms of the number of served users, power consumption, and number of changes that need to happen during operations.\n",
      "\n",
      "Completed mobile, users, frequency, spectrum, management, dynamic, algorithm, optimization, linear, programming abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The evaluation of machine learning models using human-labeled validation data can be expensive and time-consuming. AI-labeled synthetic data can be used to decrease the number of human annotations required for this purpose in a process called autoevaluation. We suggest efficient and statistically principled algorithms for this purpose that improve sample efficiency while remaining unbiased. These algorithms increase the effective human-labeled sample size by up to 50% on experiments with GPT-4.\n",
      "\n",
      "Completed AI-labeled, synthetic, data, autoevaluation, algorithms, sample, efficiency, unbiased, GPT-4, experiments abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we give the concept of Globular T-Spherical Fuzzy (G-TSF) Sets (G-TSFSs) as an innovative extension of T-Spherical Fuzzy Sets (TSFSs) and Circular Spherical Fuzzy Sets (C-SFSs). G-TSFSs represent membership, indeterminacy, and non-membership degrees using a globular/sphere bound that can offer a more accurate portrayal of vague, ambiguous, and imprecise information. By employing a structured representation of data points on a sphere with a specific center and radius, this model enhances decision-making processes by enabling a more comprehensive evaluation of objects within a flexible region. Following the newly defined G-TSFSs, we establish some basic set operations and introduce fundamental algebraic operations for G-TSF Values (G-TSFVs). These operations expand the evaluative capabilities of decision-makers, facilitating more sensitive decision-making processes in a broader region. To quantify a similarity measure (SM) between GTSFVs, the SM is defined based on the radius of G-TSFSs. Additionally, Hamming distance and Euclidean distance are introduced for G-TSFSs. We also present theorems and examples to elucidate computational mechanisms. Furthermore, we give the G-TSF Weighted Average (G-TSFWA) and G-TSF Weighted Geometric (G-TSFWG) operators. Leveraging our proposed SM, a Multi-Criteria Group Decision-Making (MCGDM) scheme for G-TSFSs, named G-TSF MCGDM (G-TSFMCGDM), is developed to address group decision-making problems. The applicability and effectiveness of the proposed G-TSFMCGDM method are demonstrated by applying it to solve the selection problem of the best venue for professional development training sessions in a firm. The analysis results affirm the suitability and utility of the proposed method for resolving MCGDM problems, establishing its effectiveness in practical decision-making scenarios.\n",
      "\n",
      "Completed Globular, T-Spherical, Fuzzy, Sets, G-TSFS, G-TSFV, Similarity, Measure, MCGDM, G-TSFMCGDM abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "With the widespread adoption of Non-Intrusive Load Monitoring (NILM) in building energy management, ensuring the high quality of NILM data has become imperative. However, practical applications of NILM face challenges associated with data loss, significantly impacting accuracy and reliability in energy management. This paper addresses the issue of NILM data loss by introducing an innovative tensor completion(TC) model- Proportional-Integral-Derivative (PID)-incorporated Non-negative Latent Factorization of Tensors (PNLFT) with twofold ideas: 1) To tackle the issue of slow convergence in Latent Factorization of Tensors (LFT) using Stochastic Gradient Descent (SGD), a Proportional-Integral-Derivative controller is introduced during the learning process. The PID controller utilizes historical and current information to control learning residuals. 2) Considering the characteristics of NILM data, non-negative update rules are proposed in the model's learning scheme. Experimental results on three datasets demonstrate that, compared to state-of-the-art models, the proposed model exhibits noteworthy enhancements in both convergence speed and accuracy.\n",
      "\n",
      "Completed non-intrusive, load, monitoring, data, loss, tensor, completion, pid, latent, factorization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Hyperparameter selection in continual learning scenarios is a challenging and underexplored aspect, especially in practical non-stationary environments. Traditional approaches, such as grid searches with held-out validation data from all tasks, are unrealistic for building accurate lifelong learning systems. This paper aims to explore the role of hyperparameter selection in continual learning and the necessity of continually and automatically tuning them according to the complexity of the task at hand. Hence, we propose leveraging the nature of sequence task learning to improve Hyperparameter Optimization efficiency. By using the functional analysis of variance-based techniques, we identify the most crucial hyperparameters that have an impact on performance. We demonstrate empirically that this approach, agnostic to continual scenarios and strategies, allows us to speed up hyperparameters optimization continually across tasks and exhibit robustness even in the face of varying sequential task orders. We believe that our findings can contribute to the advancement of continual learning methodologies towards more efficient, robust and adaptable models for real-world applications.\n",
      "\n",
      "Completed continual, learning, hyperparameter, selection, optimization, efficiency, variance, performance, robustness, applications abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Designing secure information infrastructure is a function of design and usability. However, security is seldom given priority when systems are being developed. Secure design practices should balance between functionality (i.e., proper design) to meet minimum requirements and user-friendliness. Design recommendations such as those with a user-centric approach (i.e., inclusive of only relevant information, user liberty) and presenting information within its proper context in a clear and engaging manner has been scientifically shown to improve user response and experience.\n",
      "\n",
      "Completed Design, usability, security, functionality, user-centric, inclusive, relevant information, user liberty, proper context, user response abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Spatio-Temporal (ST) prediction is crucial for making informed decisions in urban location-based applications like ride-sharing. However, existing ST models often require region partition as a prerequisite, resulting in two main pitfalls. Firstly, location-based services necessitate ad-hoc regions for various purposes, requiring multiple ST models with varying scales and zones, which can be costly to support. Secondly, different ST models may produce conflicting outputs, resulting in confusing predictions. In this paper, we propose One4All-ST, a framework that can conduct ST prediction for arbitrary modifiable areal units using only one model. To reduce the cost of getting multi-scale predictions, we design an ST network with hierarchical spatial modeling and scale normalization modules to efficiently and equally learn multi-scale representations. To address prediction inconsistencies across scales, we propose a dynamic programming scheme to solve the formulated optimal combination problem, minimizing predicted error through theoretical analysis. Besides, we suggest using an extended quad-tree to index the optimal combinations for quick response to arbitrary modifiable areal units in practical online scenarios. Extensive experiments on two real-world datasets verify the efficiency and effectiveness of One4All-ST in ST prediction for arbitrary modifiable areal units. The source codes and data of this work are available at https://github.com/uctb/One4All-ST.\n",
      "\n",
      "Completed Spatio-Temporal, ST, arbitrary, modifiable, One4All-ST, hierarchical, normalization, dynamic, programming, quad-tree abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this contribution, we discuss the construction of Polynomial Chaos surrogates for Monte Carlo radiation transport applications via non-intrusive spectral projection. This contribution focuses on improvements with respect to the approach that we previously introduced in previous work. We focus on understanding the impact of re-sampling cost on the algorithm performance and provide algorithm refinements, which allow to obtain unbiased estimators for the variance, estimate the PC variability due to limited samples, and adapt the expansion. An attenuation-only test case is provided to illustrate and discuss the results.\n",
      "\n",
      "Completed Polynomial, Chaos, surrogates, Monte, Carlo, non-intrusive, spectral, projection, variance, variability, expansion abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Dengue fever is one of the most deadly mosquito-born tropical infectious diseases. Detailed long range forecast model is vital in controlling the spread of disease and making mitigation efforts. In this study, we examine methods used to forecast dengue cases for long range predictions. The dataset consists of local climate/weather in addition to global climate indicators of Singapore from 2000 to 2019. We utilize newly developed deep neural networks to learn the intricate relationship between the features. The baseline models in this study are in the class of recent transformers for long sequence forecasting tasks. We found that a Fourier mixed window attention (FWin) based transformer performed the best in terms of both the mean square error and the maximum absolute error on the long range dengue forecast up to 60 weeks.\n",
      "\n",
      "Completed Dengue, Forecast, Infectious, Tropical, Climate, Singapore, Neural, Transformers, Error, Long abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recently, neural networks (NN) have made great strides in combinatorial optimization. However, they face challenges when solving the capacitated arc routing problem (CARP) which is to find the minimum-cost tour covering all required edges on a graph, while within capacity constraints. In tackling CARP, NN-based approaches tend to lag behind advanced metaheuristics, since they lack directed arc modeling and efficient learning methods tailored for complex CARP. In this paper, we introduce an NN-based solver to significantly narrow the gap with advanced metaheuristics while exhibiting superior efficiency. First, we propose the direction-aware attention model (DaAM) to incorporate directionality into the embedding process, facilitating more effective one-stage decision-making. Second, we design a supervised reinforcement learning scheme that involves supervised pre-training to establish a robust initial policy for subsequent reinforcement fine-tuning. It proves particularly valuable for solving CARP that has a higher complexity than the node routing problems (NRPs). Finally, a path optimization method is proposed to adjust the depot return positions within the path generated by DaAM. Experiments illustrate that our approach surpasses heuristics and achieves decision quality comparable to state-of-the-art metaheuristics for the first time while maintaining superior efficiency.\n",
      "\n",
      "Completed neural networks, combinatorial optimization, capacitated arc routing problem, direction-aware attention model, supervised reinforcement learning, path optimization, heuristics, metaheuristics, node routing problems, decision quality abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "With the continuous development of computer technology and network technology, the scale of the network continues to expand, the network space tends to be complex, and the application of computers and networks has been deeply into politics, the military, finance, electricity, and other important fields. When security events do not occur, the vulnerability assessment of these high-risk network assets can be actively carried out to prepare for rainy days, to effectively reduce the loss caused by security events. Therefore, this paper proposes a multi-classification prediction model of network asset vulnerability based on quantum particle swarm algorithm-Lightweight Gradient Elevator (QPSO-LightGBM). In this model, based on using the Synthetic minority oversampling technique (SMOTE) to balance the data, quantum particle swarm optimization (QPSO) was used for automatic parameter optimization, and LightGBM was used for modeling. Realize multi-classification prediction of network asset vulnerability. To verify the rationality of the model, the proposed model is compared with the model constructed by other algorithms. The results show that the proposed model is better in various predictive performance indexes.\n",
      "\n",
      "Completed Quantum, particle, swarm, algorithm, LightGBM, oversampling, vulnerability, prediction, network, optimization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Due to privacy or patent concerns, a growing number of large models are released without granting access to their training data, making transferring their knowledge inefficient and problematic. In response, Data-Free Knowledge Distillation (DFKD) methods have emerged as direct solutions. However, simply adopting models derived from DFKD for real-world applications suffers significant performance degradation, due to the discrepancy between teachers' training data and real-world scenarios (student domain). The degradation stems from the portions of teachers' knowledge that are not applicable to the student domain. They are specific to the teacher domain and would undermine students' performance. Hence, selectively transferring teachers' appropriate knowledge becomes the primary challenge in DFKD. In this work, we propose a simple but effective method AuG-KD. It utilizes an uncertainty-guided and sample-specific anchor to align student-domain data with the teacher domain and leverages a generative method to progressively trade off the learning process between OOD knowledge distillation and domain-specific information learning via mixup learning. Extensive experiments in 3 datasets and 8 settings demonstrate the stability and superiority of our approach. Code available at https://github.com/IshiKura-a/AuG-KD .\n",
      "\n",
      "Completed Data-Free, Knowledge, Distillation, Uncertainty-guided, Anchor, Generative, OOD, Domain-specific, Mixup, AuG-KD abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We introduce the \"cram\" method, a general and efficient approach to simultaneous learning and evaluation using a generic machine learning (ML) algorithm. In a single pass of batched data, the proposed method repeatedly trains an ML algorithm and tests its empirical performance. Because it utilizes the entire sample for both learning and evaluation, cramming is significantly more data-efficient than sample-splitting. The cram method also naturally accommodates online learning algorithms, making its implementation computationally efficient. To demonstrate the power of the cram method, we consider the standard policy learning setting where cramming is applied to the same data to both develop an individualized treatment rule (ITR) and estimate the average outcome that would result if the learned ITR were to be deployed. We show that under a minimal set of assumptions, the resulting crammed evaluation estimator is consistent and asymptotically normal. While our asymptotic results require a relatively weak stabilization condition of ML algorithm, we develop a simple, generic method that can be used with any policy learning algorithm to satisfy this condition. Our extensive simulation studies show that, when compared to sample-splitting, cramming reduces the evaluation standard error by more than 40% while improving the performance of learned policy. We also apply the cram method to a randomized clinical trial to demonstrate its applicability to real-world problems. Finally, we briefly discuss future extensions of the cram method to other learning and evaluation settings.\n",
      "\n",
      "Completed cram, efficient, learning, evaluation, machine learning, individualized treatment rule, average outcome, consistent, asymptotically normal, simulation studies abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Scene flow prediction is a crucial underlying task in understanding dynamic scenes as it offers fundamental motion information. However, contemporary scene flow methods encounter three major challenges. Firstly, flow estimation solely based on local receptive fields lacks long-dependency matching of point pairs. To address this issue, we propose global attentive flow embedding to match all-to-all point pairs in both feature space and Euclidean space, providing global initialization before local refinement. Secondly, there are deformations existing in non-rigid objects after warping, which leads to variations in the spatiotemporal relation between the consecutive frames. For a more precise estimation of residual flow, a spatial temporal feature re-embedding module is devised to acquire the sequence features after deformation. Furthermore, previous methods perform poor generalization due to the significant domain gap between the synthesized and LiDAR-scanned datasets. We leverage novel domain adaptive losses to effectively bridge the gap of motion inference from synthetic to real-world. Experiments demonstrate that our approach achieves state-of-the-art performance across various datasets, with particularly outstanding results on real-world LiDAR-scanned datasets. Our code is available at https://github.com/O-VIGIA/StarFlow.\n",
      "\n",
      "Completed Scene, flow, prediction, motion, receptive, field, deformation, re-embedding, domain, adaptive abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Neural networks, with powerful nonlinear mapping and classification capabilities, are widely applied in mechanical fault diagnosis to ensure safety. However, being typical black-box models, their application is limited in high-reliability-required scenarios. To understand the classification logic and explain what typical fault signals look like, the prototype matching network (PMN) is proposed by combining the human-inherent prototype-matching with autoencoder (AE). The PMN matches AE-extracted feature with each prototype and selects the most similar prototype as the prediction result. It has three interpreting paths on classification logic, fault prototypes, and matching contributions. Conventional diagnosis and domain generalization experiments demonstrate its competitive diagnostic performance and distinguished advantages in representation learning. Besides, the learned typical fault signals (i.e., sample-level prototypes) showcase the ability for denoising and extracting subtle key features that experts find challenging to capture. This ability broadens human understanding and provides a promising solution from interpretability research to AI-for-Science.\n",
      "\n",
      "Completed Neural, networks, prototype, matching, network, autoencoder, interpretation, fault, signals, understanding abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The effectiveness of Evolutionary Neural Architecture Search (ENAS) is influenced by the design of the search space. Nevertheless, common methods including the global search space, scalable search space and hierarchical search space have certain limitations. Specifically, the global search space requires a significant amount of computational resources and time, the scalable search space sacrifices the diversity of network structures and the hierarchical search space increases the search cost in exchange for network diversity. To address above limitation, we propose a novel paradigm of searching neural network architectures and design the Multiple Population Alternate Evolution Neural Architecture Search (MPAE), which can achieve module diversity with a smaller search cost. MPAE converts the search space into L interconnected units and sequentially searches the units, then the above search of the entire network be cycled several times to reduce the impact of previous units on subsequent units. To accelerate the population evolution process, we also propose the the population migration mechanism establishes an excellent migration archive and transfers the excellent knowledge and experience in the migration archive to new populations. The proposed method requires only 0.3 GPU days to search a neural network on the CIFAR dataset and achieves the state-of-the-art results.\n",
      "\n",
      "Completed Evolutionary, Neural, Architecture, Search, Space, Multiple, Population, Alternate, Evolution, Migration abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Reducing inference time and energy usage while maintaining prediction accuracy has become a significant concern for deep neural networks (DNN) inference on resource-constrained edge devices. To address this problem, we propose a novel approach based on \"converting\" autoencoder and lightweight DNNs. This improves upon recent work such as early-exiting framework and DNN partitioning. Early-exiting frameworks spend different amounts of computation power for different input data depending upon their complexity. However, they can be inefficient in real-world scenarios that deal with many hard image samples. On the other hand, DNN partitioning algorithms that utilize the computation power of both the cloud and edge devices can be affected by network delays and intermittent connections between the cloud and the edge. We present CBNet, a low-latency and energy-efficient DNN inference framework tailored for edge devices. It utilizes a \"converting\" autoencoder to efficiently transform hard images into easy ones, which are subsequently processed by a lightweight DNN for inference. To the best of our knowledge, such autoencoder has not been proposed earlier. Our experimental results using three popular image-classification datasets on a Raspberry Pi 4, a Google Cloud instance, and an instance with Nvidia Tesla K80 GPU show that CBNet achieves up to 4.8x speedup in inference latency and 79% reduction in energy usage compared to competing techniques while maintaining similar or higher accuracy.\n",
      "\n",
      "Completed autoencoder, lightweight, edge devices, inference time, energy usage, CBNet, cloud, converting, DNN, partitioning abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Patient triage plays a crucial role in emergency departments, ensuring timely and appropriate care based on correctly evaluating the emergency grade of patient conditions.\n",
      "  Triage methods are generally performed by human operator based on her own experience and information that are gathered from the patient management process.\n",
      "  Thus, it is a process that can generate errors in emergency level associations. Recently, Traditional triage methods heavily rely on human decisions, which can be subjective and prone to errors.\n",
      "  Recently, a growing interest has been focused on leveraging artificial intelligence (AI) to develop algorithms able to maximize information gathering and minimize errors in patient triage processing.\n",
      "  We define and implement an AI based module to manage patients emergency code assignments in emergency departments. It uses emergency department historical data to train the medical decision process. Data containing relevant patient information, such as vital signs, symptoms, and medical history, are used to accurately classify patients into triage categories. Experimental results demonstrate that the proposed algorithm achieved high accuracy outperforming traditional triage methods. By using the proposed method we claim that healthcare professionals can predict severity index to guide patient management processing and resource allocation.\n",
      "\n",
      "Completed triage, emergency, department, artificial intelligence, algorithm, information gathering, errors, patient management, resource allocation, healthcare abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In the realm of ASIC engineering, the landscape has been significantly reshaped by the rapid development of LLM, paralleled by an increase in the complexity of modern digital circuits. This complexity has escalated the requirements for HDL coding, necessitating a higher degree of precision and sophistication. However, challenges have been faced due to the less-than-optimal performance of modern language models in generating hardware description code, a situation further exacerbated by the scarcity of the corresponding high-quality code datasets. These challenges have highlighted the gap between the potential of LLMs to revolutionize digital circuit design and their current capabilities in accurately interpreting and implementing hardware specifications. To address these challenges, a strategy focusing on the fine-tuning of the leading-edge nature language model and the reshuffling of the HDL code dataset has been developed. The fine-tuning aims to enhance models' proficiency in generating precise and efficient ASIC design, while the dataset reshuffling is intended to broaden the scope and improve the quality of training material. The model demonstrated significant improvements compared to the base model, with approximately 10% to 20% increase in accuracy across a wide range of temperature for the pass@1 metric. This approach is expected to facilitate a simplified and more efficient LLM-assisted framework for complex circuit design, leveraging their capabilities to meet the sophisticated demands of HDL coding and thus streamlining the ASIC development process.\n",
      "\n",
      "Completed ASIC, engineering, LLM, digital circuits, HDL, coding, language models, hardware description, datasets, circuit design abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper is an extended abstract of our original work published in KDD23, where we won the best research paper award (Xiangguo Sun, Hong Cheng, Jia Li, Bo Liu, and Jihong Guan. All in one: Multi-task prompting for graph neural networks. KDD 23) The paper introduces a novel approach to bridging the gap between pre-trained graph models and the diverse tasks they're applied to, inspired by the success of prompt learning in NLP. Recognizing the challenge of aligning pre-trained models with varied graph tasks (node level, edge level, and graph level), which can lead to negative transfer and poor performance, we propose a multi-task prompting method for graphs. This method involves unifying graph and language prompt formats, enabling NLP's prompting strategies to be adapted for graph tasks. By analyzing the task space of graph applications, we reformulate problems to fit graph-level tasks and apply meta-learning to improve prompt initialization for multiple tasks. Experiments show our method's effectiveness in enhancing model performance across different graph tasks.\n",
      "  Beyond the original work, in this extended abstract, we further discuss the graph prompt from a bigger picture and provide some of the latest work toward this area.\n",
      "\n",
      "Completed Graph, prompt, model, task, NLP, transfer, meta-learning, initialization, performance, applications abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper introduces the Generative Flow Ant Colony Sampler (GFACS), a novel neural-guided meta-heuristic algorithm for combinatorial optimization. GFACS integrates generative flow networks (GFlowNets) with the ant colony optimization (ACO) methodology. GFlowNets, a generative model that learns a constructive policy in combinatorial spaces, enhance ACO by providing an informed prior distribution of decision variables conditioned on input graph instances. Furthermore, we introduce a novel combination of training tricks, including search-guided local exploration, energy normalization, and energy shaping to improve GFACS. Our experimental results demonstrate that GFACS outperforms baseline ACO algorithms in seven CO tasks and is competitive with problem-specific heuristics for vehicle routing problems. The source code is available at \\url{https://github.com/ai4co/gfacs}.\n",
      "\n",
      "Completed GFACS, meta-heuristic, combinatorial optimization, GFlowNets, ant colony optimization, decision variables, generative model, energy normalization, energy shaping, vehicle routing abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This work presents a unified approach for collision avoidance using Collision-Cone Control Barrier Functions (CBFs) in both ground (UGV) and aerial (UAV) unmanned vehicles. We propose a novel CBF formulation inspired by collision cones, to ensure safety by constraining the relative velocity between the vehicle and the obstacle to always point away from each other. The efficacy of this approach is demonstrated through simulations and hardware implementations on the TurtleBot, Stoch-Jeep, and Crazyflie 2.1 quadrotor robot, showcasing its effectiveness in avoiding collisions with dynamic obstacles in both ground and aerial settings. The real-time controller is developed using CBF Quadratic Programs (CBF-QPs). Comparative analysis with the state-of-the-art CBFs highlights the less conservative nature of the proposed approach. Overall, this research contributes to a novel control formation that can give a guarantee for collision avoidance in unmanned vehicles by modifying the control inputs from existing path-planning controllers.\n",
      "\n",
      "Completed collision, avoidance, CBF, ground, aerial, velocity, relative, obstacles, quadrotor, control abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Nations around the world are conducting research into the design of central bank digital currency (CBDC), a new, digital form of money that would be issued by central banks alongside cash and central bank reserves. Retail CBDC would be used by individuals and businesses as form of money suitable for routine commerce. An important motivating factor in the development of retail CBDC is the decline of the popularity of central bank money for retail purchases and the increasing use of digital money created by the private sector for such purposes. The debate about how retail CBDC would be designed and implemented has led to many proposals, which have sparked considerable debate about business models, regulatory frameworks, and the socio-technical role of money in general. Here, we present a critical analysis of the existing proposals. We examine their motivations and themes, as well as their underlying assumptions. We also offer a reflection of the opportunity that retail CBDC represents and suggest a way forward in furtherance of the public interest.\n",
      "\n",
      "Completed Central, Bank, Digital, Currency, Retail, Private, Money, Proposals, Business, Models abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "3D object detection is one of the most important components in any Self-Driving stack, but current state-of-the-art (SOTA) lidar object detectors require costly & slow manual annotation of 3D bounding boxes to perform well. Recently, several methods emerged to generate pseudo ground truth without human supervision, however, all of these methods have various drawbacks: Some methods require sensor rigs with full camera coverage and accurate calibration, partly supplemented by an auxiliary optical flow engine. Others require expensive high-precision localization to find objects that disappeared over multiple drives. We introduce a novel self-supervised method to train SOTA lidar object detection networks which works on unlabeled sequences of lidar point clouds only, which we call trajectory-regularized self-training. It utilizes a SOTA self-supervised lidar scene flow network under the hood to generate, track, and iteratively refine pseudo ground truth. We demonstrate the effectiveness of our approach for multiple SOTA object detection networks across multiple real-world datasets. Code will be released.\n",
      "\n",
      "Completed 3D, object, detection, lidar, pseudo, ground, truth, unsupervised, self-training, scene, flow abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The field of explainable artificial intelligence (XAI) attempts to develop methods that provide insight into how complicated machine learning methods make predictions. Many methods of explanation have focused on the concept of feature attribution, a decomposition of the model's prediction into individual contributions corresponding to each input feature. In this work, we explore the problem of feature attribution in the context of Gaussian process regression (GPR). We take a principled approach to defining attributions under model uncertainty, extending the existing literature. We show that although GPR is a highly flexible and non-parametric approach, we can derive interpretable, closed-form expressions for the feature attributions. When using integrated gradients as an attribution method, we show that the attributions of a GPR model also follow a Gaussian process distribution, which quantifies the uncertainty in attribution arising from uncertainty in the model. We demonstrate, both through theory and experimentation, the versatility and robustness of this approach. We also show that, when applicable, the exact expressions for GPR attributions are both more accurate and less computationally expensive than the approximations currently used in practice. The source code for this project is freely available under MIT license at https://github.com/KurtButler/2024_attributions_paper.\n",
      "\n",
      "Completed Explainable, Artificial, Intelligence, Feature, Attribution, Gaussian, Process, Regression, Interpretable, Uncertainty abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper presents the VLEIBot^* (Very Little Eel-Inspired roBot), a 45-mg/23-mm^3 microrobotic swimmer that is propelled by a bioinspired anguilliform propulsor. The propulsor is excited by a single 6-mg high-work-density (HWD) microactuator and undulates periodically due to wave propagation phenomena generated by fluid-structure interaction (FSI) during swimming. The microactuator is composed of a carbon-fiber beam, which functions as a leaf spring, and shape-memory alloy (SMA) wires, which deform cyclically when excited periodically using Joule heating. The VLEIBot can swim at speeds as high as 15.1mm * s^{-1} (0.33 Bl * s^{-1}}) when driven with a heuristically-optimized propulsor. To improve maneuverability, we evolved the VLEIBot design into the 90-mg/47-mm^3 VLEIBot^+, which is driven by two propulsors and fully controllable in the two-dimensional (2D) space. The VLEIBot^+ can swim at speeds as high as 16.1mm * s^{-1} (0.35 Bl * s^{-1}), when driven with heuristically-optimized propulsors, and achieves turning rates as high as 0.28 rad * s^{-1}, when tracking path references. The measured root-mean-square (RMS) values of the tracking errors are as low as 4 mm.\n",
      "\n",
      "Completed VLEIBot, microrobotic, swimmer, bioinspired, anguilliform, propulsor, fluid-structure, interaction, maneuverability, controllable abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Robots require a semantic understanding of their surroundings to operate in an efficient and explainable way in human environments. In the literature, there has been an extensive focus on object labeling and exhaustive scene graph generation; less effort has been focused on the task of purely identifying and mapping large semantic regions. The present work proposes a method for semantic region mapping via embodied navigation in indoor environments, generating a high-level representation of the knowledge of the agent. To enable region identification, the method uses a vision-to-language model to provide scene information for mapping. By projecting egocentric scene understanding into the global frame, the proposed method generates a semantic map as a distribution over possible region labels at each location. This mapping procedure is paired with a trained navigation policy to enable autonomous map generation. The proposed method significantly outperforms a variety of baselines, including an object-based system and a pretrained scene classifier, in experiments in a photorealistic simulator.\n",
      "\n",
      "Completed semantic, region, mapping, embodied, navigation, indoor, representation, knowledge, language, distribution abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We review current and emerging knowledge-informed and brain-inspired cognitive systems for realizing adversarial defenses, eXplainable Artificial Intelligence (XAI), and zero-shot or few-short learning. Data-driven deep learning models have achieved remarkable performance and demonstrated capabilities surpassing human experts in many applications. Yet, their inability to exploit domain knowledge leads to serious performance limitations in practical applications. In particular, deep learning systems are exposed to adversarial attacks, which can trick them into making glaringly incorrect decisions. Moreover, complex data-driven models typically lack interpretability or explainability, i.e., their decisions cannot be understood by human subjects. Furthermore, models are usually trained on standard datasets with a closed-world assumption. Hence, they struggle to generalize to unseen cases during inference in practical open-world environments, thus, raising the zero- or few-shot generalization problem. Although many conventional solutions exist, explicit domain knowledge, brain-inspired neural network and cognitive architectures offer powerful new dimensions towards alleviating these problems. Prior knowledge is represented in appropriate forms and incorporated in deep learning frameworks to improve performance. Brain-inspired cognition methods use computational models that mimic the human mind to enhance intelligent behavior in artificial agents and autonomous robots. Ultimately, these models achieve better explainability, higher adversarial robustness and data-efficient learning, and can, in turn, provide insights for cognitive science and neuroscience-that is, to deepen human understanding on how the brain works in general, and how it handles these problems.\n",
      "\n",
      "Completed adversarial, brain-inspired, cognitive, defenses, explainable, learning, neuroscience, prior knowledge, zero-shot, generalization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The growing popularity of generative AI, particularly ChatGPT, has sparked both enthusiasm and caution among practitioners and researchers in education. To effectively harness the full potential of ChatGPT in educational contexts, it is crucial to analyze its impact and suitability for different educational purposes. This paper takes an initial step in exploring the applicability of ChatGPT in a computer-supported collaborative learning (CSCL) environment. Using statistical analysis, we validate the shifts in student interactions during an asynchronous group brainstorming session by introducing ChatGPT as an instantaneous question-answering agent.\n",
      "\n",
      "Completed Generative, AI, ChatGPT, Education, CSCL, Collaborative, Learning, Interactions, Brainstorming, Agent abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper presents an exploration of Long Short-Term Memory (LSTM) networks in the realm of text generation, focusing on the utilization of historical datasets for Shakespeare and Nietzsche. LSTMs, known for their effectiveness in handling sequential data, are applied here to model complex language patterns and structures inherent in historical texts. The study demonstrates that LSTM-based models, when trained on historical datasets, can not only generate text that is linguistically rich and contextually relevant but also provide insights into the evolution of language patterns over time. The finding presents models that are highly accurate and efficient in predicting text from works of Nietzsche, with low loss values and a training time of 100 iterations. The accuracy of the model is 0.9521, indicating high accuracy. The loss of the model is 0.2518, indicating its effectiveness. The accuracy of the model in predicting text from the work of Shakespeare is 0.9125, indicating a low error rate. The training time of the model is 100, mirroring the efficiency of the Nietzsche dataset. This efficiency demonstrates the effectiveness of the model design and training methodology, especially when handling complex literary texts. This research contributes to the field of natural language processing by showcasing the versatility of LSTM networks in text generation and offering a pathway for future explorations in historical linguistics and beyond.\n",
      "\n",
      "Completed language, generation, LSTM, historical, patterns, Shakespeare, Nietzsche, prediction, efficiency, natural abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Large language models(LLMs) have shown its outperforming ability on various tasks and question answering. However, LLMs require high computation cost and large memory cost. At the same time, LLMs may cause privacy leakage when training or prediction procedure contains sensitive information. In this paper, we propose SPA(Side Plugin Adaption), a lightweight architecture for fast on-devices inference and privacy retaining on the constraints of strict on-devices computation and memory constraints. Compared with other on-devices seq2seq generation, SPA could make a fast and stable inference on low-resource constraints, allowing it to obtain cost effiency. Our method establish an interaction between a pretrained LLMs on-cloud and additive parameters on-devices, which could provide the knowledge on both pretrained LLMs and private personal feature.Further more, SPA provides a framework to keep feature-base parameters on private guaranteed but low computational devices while leave the parameters containing general information on the high computational devices.\n",
      "\n",
      "Completed Large, language, models, privacy, lightweight, inference, devices, constraints, parameters, framework abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Social media platforms hold valuable insights, yet extracting essential information can be challenging. Traditional top-down approaches often struggle to capture critical signals in rapidly changing events. As global events evolve swiftly, social media narratives, including instances of disinformation, become significant sources of insights. To address the need for an inductive strategy, we explore a niche social media platform GAB and an established messaging service Telegram, to develop methodologies applicable on a broader scale. This study investigates narrative evolution on these platforms using quantitative corpus-based discourse analysis techniques. Our approach is a novel mode to study multiple social media domains to distil key information which may be obscured otherwise, allowing for useful and actionable insights. The paper details the technical and methodological aspects of gathering and preprocessing GAB and Telegram data for a keyness (Log Ratio) metric analysis, identifying crucial nouns and verbs for deeper exploration. Empirically, this approach is applied to a case study of a well defined event that had global impact: the 2023 Wagner mutiny. The main findings are: (1) the time line can be deconstructed to provide useful data features allowing for improved interpretation; (2) a methodology is applied which provides a basis for generalization. The key contribution is an approach, that in some cases, provides the ability to capture the dynamic narrative shifts over time with elevated confidence. The approach can augment near-real-time assessment of key social movements, allowing for informed governance choices. This research is important because it lays out a useful methodology for time series relevant info-culling, which can enable proactive modes for positive social engagement.\n",
      "\n",
      "Completed social media, narratives, disinformation, GAB, Telegram, corpus-based discourse analysis, keyness, Wagner mutiny, time-series, info-culling abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper explores policy-learning approaches in the context of sim-to-real transfer for robotic manipulation using a TIAGo mobile manipulator, focusing on two state-of-art simulators, Isaac Gym and Isaac Sim, both developed by Nvidia. Control architectures are discussed, with a particular emphasis on achieving collision-less movement in both simulation and the real environment. Presented results demonstrate successful sim-to-real transfer, showcasing similar movements executed by an RL-trained model in both simulated and real setups.\n",
      "\n",
      "Completed sim-to-real, robotic, manipulation, TIAGo, Isaac Gym, Isaac Sim, Nvidia, collision-less, RL-trained, sim-to-real transfer abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The increasing computational demands of modern neural networks present deployment challenges on resource-constrained devices. Network pruning offers a solution to reduce model size and computational cost while maintaining performance. However, most current pruning methods focus primarily on improving sparsity by reducing the number of nonzero parameters, often neglecting other deployment costs such as inference time, which are closely related to the number of floating-point operations (FLOPs). In this paper, we propose FALCON, a novel combinatorial-optimization-based framework for network pruning that jointly takes into account model accuracy (fidelity), FLOPs, and sparsity constraints. A main building block of our approach is an integer linear program (ILP) that simultaneously handles FLOP and sparsity constraints. We present a novel algorithm to approximately solve the ILP. We propose a novel first-order method for our optimization framework which makes use of our ILP solver. Using problem structure (e.g., the low-rank structure of approx. Hessian), we can address instances with millions of parameters. Our experiments demonstrate that FALCON achieves superior accuracy compared to other pruning approaches within a fixed FLOP budget. For instance, for ResNet50 with 20% of the total FLOPs retained, our approach improves the accuracy by 48% relative to state-of-the-art. Furthermore, in gradual pruning settings with re-training between pruning steps, our framework outperforms existing pruning methods, emphasizing the significance of incorporating both FLOP and sparsity constraints for effective network pruning.\n",
      "\n",
      "Completed FALCON, network pruning, combinatorial optimization, integer linear program, first-order method, Hessian, accuracy, FLOPs, sparsity, deep learning abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Training neural networks with high certified accuracy against adversarial examples remains an open problem despite significant efforts. While certification methods can effectively leverage tight convex relaxations for bound computation, in training, these methods perform worse than looser relaxations. Prior work hypothesized that this is caused by the discontinuity and perturbation sensitivity of the loss surface induced by these tighter relaxations. In this work, we show theoretically that Gaussian Loss Smoothing can alleviate both of these issues. We confirm this empirically by proposing a certified training method combining PGPE, an algorithm computing gradients of a smoothed loss, with different convex relaxations. When using this training method, we observe that tighter bounds indeed lead to strictly better networks that can outperform state-of-the-art methods on the same network. While scaling PGPE-based training remains challenging due to high computational cost, our results clearly demonstrate the promise of Gaussian Loss Smoothing for training certifiably robust neural networks.\n",
      "\n",
      "Completed Certification, Robustness, Gaussian, Loss Smoothing, Convex Relaxations, Gradients, PGPE, Neural Networks, Adversarial Examples, Perturbation Sensitivity abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We study the model of continuous chemical reaction networks (CRNs), consisting of reactions such as $A+B \\to C+D$ that can transform some continuous, nonnegative real-valued quantity (called a *concentration*) of chemical species $A$ and $B$ into equal concentrations of $C$ and $D$. Such a reaction can occur from any state in which both reactants $A$ and $B$ are present, i.e., have positive concentration. We modify the model to allow *inhibitors*, for instance, reaction $A+B \\to^{I} C+D$ can occur only if the reactants $A$ and $B$ are present and the inhibitor $I$ is absent. The computational power of non-inhibitory CRNs has been studied. For instance, the reaction $X_1+X_2 \\to Y$ can be thought to compute the function $f(x_1,x_2) = \\min(x_1,x_2)$. Under an \"adversarial\" model in which reaction rates can vary arbitrarily over time, it was found that exactly the continuous, piecewise linear functions can be computed, ruling out even simple functions such as $f(x) = x^2$. In contrast, in this paper we show that inhibitory CRNs can compute any computable function $f:\\mathbb{N}\\to\\mathbb{N}$.\n",
      "\n",
      "Completed CRNs, continuous, chemical, reaction, network, inhibitor, piecewise, linear, computable, function abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Scheduling distributed applications modeled as directed, acyclic task graphs to run on heterogeneous compute networks is a fundamental (NP-Hard) problem in distributed computing for which many heuristic algorithms have been proposed over the past decades. Many of these algorithms fall under the list-scheduling paradigm, whereby the algorithm first computes priorities for the tasks and then schedules them greedily to the compute node that minimizes some cost function. Thus, many algorithms differ from each other only in a few key components (e.g., the way they prioritize tasks, their cost functions, where the algorithms consider inserting tasks into a partially complete schedule, etc.). In this paper, we propose a generalized parametric list-scheduling algorithm that allows mixing and matching different algorithmic components to produce 72 unique algorithms. We benchmark these algorithms on four datasets to study the individual and combined effects of different algorithmic components on performance and runtime.\n",
      "\n",
      "Completed distributed, scheduling, task graphs, heterogeneous, compute networks, list-scheduling, heuristic algorithms, algorithmic components, benchmarking, performance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Object detection, a pivotal task in computer vision, is frequently hindered by dataset imbalances, particularly the under-explored issue of foreground-foreground class imbalance. This lack of attention to foreground-foreground class imbalance becomes even more pronounced in the context of single-stage detectors. This study introduces a benchmarking framework utilizing the YOLOv5 single-stage detector to address the problem of foreground-foreground class imbalance. We crafted a novel 10-class long-tailed dataset from the COCO dataset, termed COCO-ZIPF, tailored to reflect common real-world detection scenarios with a limited number of object classes. Against this backdrop, we scrutinized three established techniques: sampling, loss weighing, and data augmentation. Our comparative analysis reveals that sampling and loss reweighing methods, while shown to be beneficial in two-stage detector settings, do not translate as effectively in improving YOLOv5's performance on the COCO-ZIPF dataset. On the other hand, data augmentation methods, specifically mosaic and mixup, significantly enhance the model's mean Average Precision (mAP), by introducing more variability and complexity into the training data. (Code available: https://github.com/craston/object_detection_cib)\n",
      "\n",
      "Completed object, detection, dataset, imbalance, foreground, YOLOv5, COCO-ZIPF, sampling, loss, augmentation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The use of generative AI to create text descriptions from graphs has mostly focused on knowledge graphs, which connect concepts using facts. In this work we explore the capability of large pretrained language models to generate text from causal graphs, where salient concepts are represented as nodes and causality is represented via directed, typed edges. The causal reasoning encoded in these graphs can support applications as diverse as healthcare or marketing. Using two publicly available causal graph datasets, we empirically investigate the performance of four GPT-3 models under various settings. Our results indicate that while causal text descriptions improve with training data, compared to fact-based graphs, they are harder to generate under zero-shot settings. Results further suggest that users of generative AI can deploy future applications faster since similar performances are obtained when training a model with only a few examples as compared to fine-tuning via a large curated dataset.\n",
      "\n",
      "Completed Generative, AI, Causal, Graphs, Language, Models, GPT-3, Healthcare, Marketing, Zero-Shot abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Scheduling a task graph representing an application over a heterogeneous network of computers is a fundamental problem in distributed computing. It is known to be not only NP-hard but also not polynomial-time approximable within a constant factor. As a result, many heuristic algorithms have been proposed over the past few decades. Yet it remains largely unclear how these algorithms compare to each other in terms of the quality of schedules they produce. We identify gaps in the traditional benchmarking approach to comparing task scheduling algorithms and propose a simulated annealing-based adversarial analysis approach called PISA to help address them. We also introduce SAGA, a new open-source library for comparing task scheduling algorithms. We use SAGA to benchmark 15 algorithms on 16 datasets and PISA to compare the algorithms in a pairwise manner. Algorithms that appear to perform similarly on benchmarking datasets are shown to perform very differently on adversarially chosen problem instances. Interestingly, the results indicate that this is true even when the adversarial search is constrained to selecting among well-structured, application-specific problem instances. This work represents an important step towards a more general understanding of the performance boundaries between task scheduling algorithms on different families of problem instances.\n",
      "\n",
      "Completed task, graph, scheduling, heterogeneity, approximability, heuristic, benchmarking, adversarial, SAGA, performance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Virtual humans play a pivotal role in social virtual environments, shaping users' VR experiences. The diversity in available options and users' preferences can result in a heterogeneous mix of appearances among a group of virtual humans. The resulting variety in higher-order anthropomorphic and realistic cues introduces multiple (in)congruencies, eventually impacting the plausibility of the experience. In this work, we consider the impact of (in)congruencies in the realism of a group of virtual humans, including co-located others and one's self-avatar. In a 2 x 3 mixed design, participants embodied either (1) a personalized realistic or (2) a customized stylized self-avatar across three consecutive VR exposures in which they were accompanied by a group of virtual others being either (1) all realistic, (2) all stylized, or (3) mixed. Our results indicate groups of virtual others of higher realism, i.e., potentially more congruent with participants' real-world experiences and expectations, were considered more human-like, increasing the feeling of co-presence and the impression of interaction possibilities. (In)congruencies concerning the homogeneity of the group did not cause considerable effects. Furthermore, our results indicate that a self-avatar's congruence with the participant's real-world experiences concerning their own physical body yielded notable benefits for virtual body ownership and self-identification for realistic personalized avatars. Notably, the incongruence between a stylized self-avatar and a group of realistic virtual others resulted in diminished ratings of self-location and self-identification. We conclude on the implications of our findings and discuss our results within current theories of VR experiences, considering (in)congruent visual cues and their impact on the perception of virtual others, self-representation, and spatial presence.\n",
      "\n",
      "Completed Virtual, Humans, Anthropomorphic, Plausibility, Realism, Congruence, Self-Avatar, Body Ownership, Self-Identification, Spatial Presence abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Maneuverable tether-net systems launched from an unmanned spacecraft offer a promising solution for the active removal of large space debris. Guaranteeing the successful capture of such space debris is dependent on the ability to reliably maneuver the tether-net system -- a flexible, many-DoF (thus complex) system -- for a wide range of launch scenarios. Here, scenarios are defined by the relative location of the debris with respect to the chaser spacecraft. This paper represents and solves this problem as a hierarchically decentralized implementation of robotic trajectory planning and control and demonstrates the effectiveness of the approach when applied to two different tether-net systems, with 4 and 8 maneuverable units (MUs), respectively. Reinforcement learning (policy gradient) is used to design the centralized trajectory planner that, based on the relative location of the target debris at the launch of the net, computes the final aiming positions of each MU, from which their trajectory can be derived. Each MU then seeks to follow its assigned trajectory by using a decentralized PID controller that outputs the MU's thrust vector and is informed by noisy sensor feedback (for realism) of its relative location. System performance is assessed in terms of capture success and overall fuel consumption by the MUs. Reward shaping and surrogate models are used to respectively guide and speed up the RL process. Simulation-based experiments show that this approach allows the successful capture of debris at fuel costs that are notably lower than nominal baselines, including in scenarios where the debris is significantly off-centered compared to the approaching chaser spacecraft.\n",
      "\n",
      "Completed tether-net, space debris, trajectory planning, reinforcement learning, policy gradient, decentralized control, PID, surrogate models, system performance, simulation-based experiments abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present FAX, a JAX-based library designed to support large-scale distributed and federated computations in both data center and cross-device applications. FAX leverages JAX's sharding mechanisms to enable native targeting of TPUs and state-of-the-art JAX runtimes, including Pathways. FAX embeds building blocks for federated computations as primitives in JAX. This enables three key benefits. First, FAX computations can be translated to XLA HLO. Second, FAX provides a full implementation of federated automatic differentiation, greatly simplifying the expression of federated computations. Last, FAX computations can be interpreted out to existing production cross-device federated compute systems. We show that FAX provides an easily programmable, performant, and scalable framework for federated computations in the data center. FAX is available at https://github.com/google-research/google-research/tree/master/fax .\n",
      "\n",
      "Completed FAX, JAX, library, distributed, federated, computations, data center, cross-device, TPUs, primitives abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The interactive decision-making in multi-agent autonomous racing offers insights valuable beyond the domain of self-driving cars. Mapless online path planning is particularly of practical appeal but poses a challenge for safely overtaking opponents due to the limited planning horizon. Accordingly, this paper introduces RaceMOP, a novel method for mapless online path planning designed for multi-agent racing of F1TENTH cars. Unlike classical planners that depend on predefined racing lines, RaceMOP operates without a map, relying solely on local observations to overtake other race cars at high speed. Our approach combines an artificial potential field method as a base policy with residual policy learning to introduce long-horizon planning capabilities. We advance the field by introducing a novel approach for policy fusion with the residual policy directly in probability space. Our experiments for twelve simulated racetracks validate that RaceMOP is capable of long-horizon decision-making with robust collision avoidance during overtaking maneuvers. RaceMOP demonstrates superior handling over existing mapless planners while generalizing to unknown racetracks, paving the way for further use of our method in robotics. We make the open-source code for RaceMOP available at http://github.com/raphajaner/racemop.\n",
      "\n",
      "Completed multi-agent, autonomous, racing, mapless, overtaking, RaceMOP, potential field, residual policy learning, policy fusion, probability space abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Most real-world Multi-Robot Task Allocation (MRTA) problems require fast and efficient decision-making, which is often achieved using heuristics-aided methods such as genetic algorithms, auction-based methods, and bipartite graph matching methods. These methods often assume a form that lends better explainability compared to an end-to-end (learnt) neural network based policy for MRTA. However, deriving suitable heuristics can be tedious, risky and in some cases impractical if problems are too complex. This raises the question: can these heuristics be learned? To this end, this paper particularly develops a Graph Reinforcement Learning (GRL) framework to learn the heuristics or incentives for a bipartite graph matching approach to MRTA. Specifically a Capsule Attention policy model is used to learn how to weight task/robot pairings (edges) in the bipartite graph that connects the set of tasks to the set of robots. The original capsule attention network architecture is fundamentally modified by adding encoding of robots' state graph, and two Multihead Attention based decoders whose output are used to construct a LogNormal distribution matrix from which positive bigraph weights can be drawn. The performance of this new bigraph matching approach augmented with a GRL-derived incentive is found to be at par with the original bigraph matching approach that used expert-specified heuristics, with the former offering notable robustness benefits. During training, the learned incentive policy is found to get initially closer to the expert-specified incentive and then slightly deviate from its trend.\n",
      "\n",
      "Completed Multi-Robot, Task, Allocation, Heuristics, Graph, Reinforcement, Learning, Attention, Bigraph, Robustness abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Post-training quantization (PTQ) has emerged as a practical approach to compress large neural networks, making them highly efficient for deployment. However, effectively reducing these models to their low-bit counterparts without compromising the original accuracy remains a key challenge. In this paper, we propose an innovative PTQ algorithm termed COMQ, which sequentially conducts coordinate-wise minimization of the layer-wise reconstruction errors. We consider the widely used integer quantization, where every quantized weight can be decomposed into a shared floating-point scalar and an integer bit-code. Within a fixed layer, COMQ treats all the scaling factor(s) and bit-codes as the variables of the reconstruction error. Every iteration improves this error along a single coordinate while keeping all other variables constant. COMQ is easy to use and requires no hyper-parameter tuning. It instead involves only dot products and rounding operations. We update these variables in a carefully designed greedy order, significantly enhancing the accuracy. COMQ achieves remarkable results in quantizing 4-bit Vision Transformers, with a negligible loss of less than 1% in Top-1 accuracy. In 4-bit INT quantization of convolutional neural networks, COMQ maintains near-lossless accuracy with a minimal drop of merely 0.3% in Top-1 accuracy.\n",
      "\n",
      "Completed Post-training, Quantization, COMQ, Coordinate-wise, Minimization, Floating-point, Integer, Bit-codes, Transformers, Accuracy abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Identifying the trade-offs between model-based and model-free methods is a central question in reinforcement learning. Value-based methods offer substantial computational advantages and are sometimes just as statistically efficient as model-based methods. However, focusing on the core problem of policy evaluation, we show information about the transition dynamics may be impossible to represent in the space of value functions. We explore this through a series of case studies focused on structures that arises in many important problems. In several, there is no information loss and value-based methods are as statistically efficient as model based ones. In other closely-related examples, information loss is severe and value-based methods are severely outperformed. A deeper investigation points to the limitations of the representational power as the driver of the inefficiency, as opposed to failure in algorithm design.\n",
      "\n",
      "Completed model-based, model-free, value-based, trade-offs, representation, efficiency, transition, dynamics, policy, evaluation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The extensive amounts of data required for training deep neural networks pose significant challenges on storage and transmission fronts. Dataset distillation has emerged as a promising technique to condense the information of massive datasets into a much smaller yet representative set of synthetic samples. However, traditional dataset distillation approaches often struggle to scale effectively with high-resolution images and more complex architectures due to the limitations in bi-level optimization. Recently, several works have proposed exploiting knowledge distillation with decoupled optimization schemes to scale up dataset distillation. Although these methods effectively address the scalability issue, they rely on extensive image augmentations requiring the storage of soft labels for augmented images. In this paper, we introduce Dataset Distillation using Diffusion Models (D3M) as a novel paradigm for dataset distillation, leveraging recent advancements in generative text-to-image foundation models. Our approach utilizes textual inversion, a technique for fine-tuning text-to-image generative models, to create concise and informative representations for large datasets. By employing these learned text prompts, we can efficiently store and infer new samples for introducing data variability within a fixed memory budget. We show the effectiveness of our method through extensive experiments across various computer vision benchmark datasets with different memory budgets.\n",
      "\n",
      "Completed dataset, distillation, deep learning, optimization, scalability, generative models, text-to-image, learned text prompts, data variability, memory budget abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This work studies the repeated principal-agent problem from an online learning perspective. The principal's goal is to learn the optimal contract that maximizes her utility through repeated interactions, without prior knowledge of the agent's type (i.e., the agent's cost and production functions).\n",
      "  I study three different settings when the principal contracts with a $\\textit{single}$ agent each round: 1. The agents are heterogeneous; 2. the agents are homogenous; 3. the principal interacts with the same agent and the agent is non-myopic. I present different approaches and techniques for designing learning algorithms in each setting. For heterogeneous agent types, I identify a condition that allows the problem to be reduced to Lipschitz bandits directly. For identical agents, I give a polynomial sample complexity scheme to learn the optimal contract based on inverse game theory. For strategic non-myopic agents, I design a low strategic-regret mechanism. Also, I identify a connection between linear contracts and posted-price auctions, showing the two can be reduced to one another, and give a regret lower bound on learning the optimal linear contract based on this observation.\n",
      "  I also study a $\\textit{team production}$ model. I identify a condition under which the principal's learning problem can be reformulated as solving a family of convex programs, thereby showing the optimal contract can be found efficiently.\n",
      "\n",
      "Completed online learning, principal-agent problem, heterogeneous agents, homogenous agents, strategic agents, linear contracts, posted-price auctions, team production, convex programs, Lipschitz bandits abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present the Thought Graph as a novel framework to support complex reasoning and use gene set analysis as an example to uncover semantic relationships between biological processes. Our framework stands out for its ability to provide a deeper understanding of gene sets, significantly surpassing GSEA by 40.28% and LLM baselines by 5.38% based on cosine similarity to human annotations. Our analysis further provides insights into future directions of biological processes naming, and implications for bioinformatics and precision medicine.\n",
      "\n",
      "Completed Thought Graph, gene set analysis, semantic relationships, biological processes, GSEA, LLM baselines, human annotations, biological processes naming, bioinformatics, precision medicine abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Online social platforms allow users to filter out content they do not like. According to selective exposure theory, people tend to view content they agree with more to get more self-assurance. This causes people to live in ideological filter bubbles. We report on a user study that encourages users to break the political filter bubble of their Twitter feed by reading more diverse viewpoints through social comparison. The user study is conducted using political-bias analyzing and Twitter-mirroring tools to compare the political slant of what a user reads and what other Twitter users read about a topic, and in general. The results show that social comparison can have a great impact on users' reading behavior by motivating them to read viewpoints from the opposing political party.\n",
      "\n",
      "Completed online, social, platforms, filter, exposure, theory, ideological, filter, bubbles, social, comparison abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Federated Learning (FL) is a collaborative machine learning (ML) approach, where multiple clients participate in training an ML model without exposing the private data. Fair and accurate assessment of client contributions is an important problem in FL to facilitate incentive allocation and encouraging diverse clients to participate in a unified model training. Existing methods for assessing client contribution adopts co-operative game-theoretic concepts, such as Shapley values, but under simplified assumptions. In this paper, we propose a history-aware game-theoretic framework, called FLContrib, to assess client contributions when a subset of (potentially non-i.i.d.) clients participate in each epoch of FL training. By exploiting the FL training process and linearity of Shapley value, we develop FLContrib that yields a historical timeline of client contributions as FL training progresses over epochs. Additionally, to assess client contribution under limited computational budget, we propose a scheduling procedure that considers a two-sided fairness criteria to perform expensive Shapley value computation only in a subset of training epochs. In experiments, we demonstrate a controlled trade-off between the correctness and efficiency of client contributions assessed via FLContrib. To demonstrate the benefits of history-aware client contributions, we apply FLContrib to detect dishonest clients conducting data poisoning in FL training.\n",
      "\n",
      "Completed Federated Learning, Client Contributions, Shapley Value, History-Aware, Game-Theoretic, FLContrib, Epoch-Based, Scheduling Procedure, Fairness Criteria, Data Poisoning Detection abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This article describes the 2023 IEEE Low-Power Computer Vision Challenge (LPCVC). Since 2015, LPCVC has been an international competition devoted to tackling the challenge of computer vision (CV) on edge devices. Most CV researchers focus on improving accuracy, at the expense of ever-growing sizes of machine models. LPCVC balances accuracy with resource requirements. Winners must achieve high accuracy with short execution time when their CV solutions run on an embedded device, such as Raspberry PI or Nvidia Jetson Nano. The vision problem for 2023 LPCVC is segmentation of images acquired by Unmanned Aerial Vehicles (UAVs, also called drones) after disasters. The 2023 LPCVC attracted 60 international teams that submitted 676 solutions during the submission window of one month. This article explains the setup of the competition and highlights the winners' methods that improve accuracy and shorten execution time.\n",
      "\n",
      "Completed IEEE, Low-Power, Computer, Vision, Challenge, Segmentation, Drones, Accuracy, Execution, Time abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Smart ecosystems are the drivers of modern society. They control critical infrastructures, ensuring their stable and sustainable operation. Smart ecosystems are governed by digital twins -- real-time virtual representations of physical infrastructure. To support the open-ended and reactive traits of smart ecosystems, digital twins need to be able to evolve in reaction to changing conditions. However, digital twin evolution is particularly challenging due to the intertwined nature of physical and software components. As a consequence, software practitioners find a substantial body of knowledge on software evolution hard to apply in digital twin evolution scenarios. In this article, we provide software practitioners with tangible leads toward understanding and managing the evolutionary concerns of digital twins. By that, we aim to bridge a significant gap in leveraging software engineering practices to develop robust smart ecosystems.\n",
      "\n",
      "Completed Smart, ecosystems, digital, twins, evolution, software, virtual, physical, infrastructure, practitioners abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this work, we develop recent research on the fully mixed virtual element method (mixed-VEM) based on the Banach space for the stationary Boussinesq equation to suggest and analyze a new mixed-VEM for the stationary two-dimensional Boussinesq equation with temperature-dependent parameters in terms of the pseudostress, vorticity, velocity, pseudoheat vector and temperature fields. The well-posedness of the continuous formulation is analyzed utilizing a fixed-point strategy, a smallness assumption on the data, and some additional regularities on the solution. The discretization for the mentioned variables is based on the coupling $\\mathbb{H}(\\mathbf{div}_{6/5})$ -- and $\\mathbf{H}(\\mathrm{div}_{6/5})$ -- conforming virtual element techniques. The proposed scheme is rewritten as an equivalent fixed point operator equation, so that its existence and stability estimates have been proven. In addition, an a priori convergence analysis is established by utilizing the C\\'ea estimate and a suitable assumption on data for all variables in their natural norms showing an optimal rate of convergence. Finally, several numerical examples are presented to illustrate the performance of the proposed method.\n",
      "\n",
      "Completed virtual, mixed-VEM, Boussinesq, temperature, pseudostress, vorticity, velocity, pseudoheat, temperature, convergence abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recent work on model editing using Rank-One Model Editing (ROME), a popular model editing method, has shown that there are certain facts that the algorithm is unable to edit without breaking the model. Such edits have previously been called disabling edits. These disabling edits cause immediate model collapse and limits the use of ROME for sequential editing. In this paper, we make two main contributions. Firstly, we show that model collapse with ROME only happens when making edits using the CounterFact dataset and does not happen when using the zsRE dataset. Secondly, we find that disabling edits are an artifact of the original implementation of ROME. With this paper, we provide a more stable implementation ROME, which we call r-ROME and show that we no longer observe model collapse when making large scale sequential edits with ROME.\n",
      "\n",
      "Completed Model,Editing,Rank-One,Model,Editing,Disabling,Edits,Model,Collapse,r-ROME abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Generating molecules with desired properties is a critical task with broad applications in drug discovery and materials design. Inspired by recent advances in large language models, there is a growing interest in using natural language descriptions of molecules to generate molecules with the desired properties. Most existing methods focus on generating molecules that precisely match the text description. However, practical applications call for methods that generate diverse, and ideally novel, molecules with the desired properties. We propose 3M-Diffusion, a novel multi-modal molecular graph generation method, to address this challenge. 3M-Diffusion first encodes molecular graphs into a graph latent space aligned with text descriptions. It then reconstructs the molecular structure and atomic attributes based on the given text descriptions using the molecule decoder. It then learns a probabilistic mapping from the text space to the latent molecular graph space using a diffusion model. The results of our extensive experiments on several datasets demonstrate that 3M-Diffusion can generate high-quality, novel and diverse molecular graphs that semantically match the textual description provided.\n",
      "\n",
      "Completed molecule, generation, text, description, graph, diffusion, decoder, space, novel, diverse abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The recent advances in language-based generative models have paved the way for the orchestration of multiple generators of different artefact types (text, image, audio, etc.) into one system. Presently, many open-source pre-trained models combine text with other modalities, thus enabling shared vector embeddings to be compared across different generators. Within this context we propose a novel approach to handle multimodal creative tasks using Quality Diversity evolution. Our contribution is a variation of the MAP-Elites algorithm, MAP-Elites with Transverse Assessment (MEliTA), which is tailored for multimodal creative tasks and leverages deep learned models that assess coherence across modalities. MEliTA decouples the artefacts' modalities and promotes cross-pollination between elites. As a test bed for this algorithm, we generate text descriptions and cover images for a hypothetical video game and assign each artefact a unique modality-specific behavioural characteristic. Results indicate that MEliTA can improve text-to-image mappings within the solution space, compared to a baseline MAP-Elites algorithm that strictly treats each image-text pair as one solution. Our approach represents a significant step forward in multimodal bottom-up orchestration and lays the groundwork for more complex systems coordinating multimodal creative agents in the future.\n",
      "\n",
      "Completed Multimodal, Generative, Quality, Diversity, Evolution, MEliTA, Assessment, Cross-Pollination, Bottom-Up, Orchestration abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present an approach for estimating the fraction of text in a large corpus which is likely to be substantially modified or produced by a large language model (LLM). Our maximum likelihood model leverages expert-written and AI-generated reference texts to accurately and efficiently examine real-world LLM-use at the corpus level. We apply this approach to a case study of scientific peer review in AI conferences that took place after the release of ChatGPT: ICLR 2024, NeurIPS 2023, CoRL 2023 and EMNLP 2023. Our results suggest that between 6.5% and 16.9% of text submitted as peer reviews to these conferences could have been substantially modified by LLMs, i.e. beyond spell-checking or minor writing updates. The circumstances in which generated text occurs offer insight into user behavior: the estimated fraction of LLM-generated text is higher in reviews which report lower confidence, were submitted close to the deadline, and from reviewers who are less likely to respond to author rebuttals. We also observe corpus-level trends in generated text which may be too subtle to detect at the individual level, and discuss the implications of such trends on peer review. We call for future interdisciplinary work to examine how LLM use is changing our information and knowledge practices.\n",
      "\n",
      "Completed LLM, expert-written, AI-generated, reference, corpus, scientific, peer, review, behavior, interdisciplinary abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Graph Neural Networks (GNNs) have been extensively used in various real-world applications. However, the predictive uncertainty of GNNs stemming from diverse sources such as inherent randomness in data and model training errors can lead to unstable and erroneous predictions. Therefore, identifying, quantifying, and utilizing uncertainty are essential to enhance the performance of the model for the downstream tasks as well as the reliability of the GNN predictions. This survey aims to provide a comprehensive overview of the GNNs from the perspective of uncertainty with an emphasis on its integration in graph learning. We compare and summarize existing graph uncertainty theory and methods, alongside the corresponding downstream tasks. Thereby, we bridge the gap between theory and practice, meanwhile connecting different GNN communities. Moreover, our work provides valuable insights into promising directions in this field.\n",
      "\n",
      "Completed Graph, Neural Networks, Uncertainty, Prediction, Reliability, Theory, Methods, Learning, Community, Insights abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We introduce UPS (Unified PDE Solver), an effective and data-efficient approach to solve diverse spatiotemporal PDEs defined over various domains, dimensions, and resolutions. UPS unifies different PDEs into a consistent representation space and processes diverse collections of PDE data using a unified network architecture that combines LLMs with domain-specific neural operators. We train the network via a two-stage cross-modal adaptation process, leveraging ideas of modality alignment and multi-task learning. By adapting from pretrained LLMs and exploiting text-form meta information, we are able to use considerably fewer training samples than previous methods while obtaining strong empirical results. UPS outperforms existing baselines, often by a large margin, on a wide range of 1D and 2D datasets in PDEBench, achieving state-of-the-art results on 8 of 10 tasks considered. Meanwhile, it is capable of few-shot transfer to different PDE families, coefficients, and resolutions.\n",
      "\n",
      "Completed UPS, PDEs, Spatiotemporal, Unified, Representation, Architecture, LLMs, Cross-modal, Adaptation, Empirical abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We consider a statistical model for symmetric matrix factorization with additive Gaussian noise in the high-dimensional regime where the rank $M$ of the signal matrix to infer scales with its size $N$ as $M = o(N^{1/10})$. Allowing for a $N$-dependent rank offers new challenges and requires new methods. Working in the Bayesian-optimal setting, we show that whenever the signal has i.i.d. entries the limiting mutual information between signal and data is given by a variational formula involving a rank-one replica symmetric potential. In other words, from the information-theoretic perspective, the case of a (slowly) growing rank is the same as when $M = 1$ (namely, the standard spiked Wigner model). The proof is primarily based on a novel multiscale cavity method allowing for growing rank along with some information-theoretic identities on worst noise for the Gaussian vector channel. We believe that the cavity method developed here will play a role in the analysis of a broader class of inference and spin models where the degrees of freedom are large arrays instead of vectors.\n",
      "\n",
      "Completed Bayesian, Gaussian, information-theoretic, matrix factorization, mutual information, replica symmetric, spiked Wigner model, statistical model, worst noise, multiscale cavity method abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recent advances in reinforcement learning (RL) algorithms aim to enhance the performance of language models at scale. Yet, there is a noticeable absence of a cost-effective and standardized testbed tailored to evaluating and comparing these algorithms. To bridge this gap, we present a generalized version of the 24-Puzzle: the $(N,K)$-Puzzle, which challenges language models to reach a target value $K$ with $N$ integers. We evaluate the effectiveness of established RL algorithms such as Proximal Policy Optimization (PPO), alongside novel approaches like Identity Policy Optimization (IPO) and Direct Policy Optimization (DPO).\n",
      "\n",
      "Completed Reinforcement, Learning, Language, Models, Cost-effective, Standardized, Testbed, N-Puzzle, K-Puzzle, Policy abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Robots often need to convey information to human users. For example, robots can leverage visual, auditory, and haptic interfaces to display their intent or express their internal state. In some scenarios there are socially agreed upon conventions for what these signals mean: e.g., a red light indicates an autonomous car is slowing down. But as robots develop new capabilities and seek to convey more complex data, the meaning behind their signals is not always mutually understood: one user might think a flashing light indicates the autonomous car is an aggressive driver, while another user might think the same signal means the autonomous car is defensive. In this paper we enable robots to adapt their interfaces to the current user so that the human's personalized interpretation is aligned with the robot's meaning. We start with an information theoretic end-to-end approach, which automatically tunes the interface policy to optimize the correlation between human and robot. But to ensure that this learning policy is intuitive -- and to accelerate how quickly the interface adapts to the human -- we recognize that humans have priors over how interfaces should function. For instance, humans expect interface signals to be proportional and convex. Our approach biases the robot's interface towards these priors, resulting in signals that are adapted to the current user while still following social expectations. Our simulations and user study results across $15$ participants suggest that these priors improve robot-to-human communication. See videos here: https://youtu.be/Re3OLg57hp8\n",
      "\n",
      "Completed robot, communication, human, interface, priors, information, theory, learning, convex, proportionality abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this article, we present CuentosIE (TalesEI: chatbot of tales with a message to develop Emotional Intelligence), an educational chatbot on emotions that also provides teachers and psychologists with a tool to monitor their students/patients through indicators and data compiled by CuentosIE. The use of \"tales with a message\" is justified by their simplicity and easy understanding, thanks to their moral or associated metaphors. The main contributions of CuentosIE are the selection, collection, and classification of a set of highly specialized tales, as well as the provision of tools (searching, reading comprehension, chatting, recommending, and classifying) that are useful for both educating users about emotions and monitoring their emotional development. The preliminary evaluation of the tool has obtained encouraging results, which provides an affirmative answer to the question posed in the title of the article.\n",
      "\n",
      "Completed CuentosIE, chatbot, emotions, monitoring, indicators, data, selection, collection, tools, evaluation, encouraging abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The aim of this study was to predict university students' learning performance using different sources of data from an Intelligent Tutoring System. We collected and preprocessed data from 40 students from different multimodal sources: learning strategies from system logs, emotions from face recording videos, interaction zones from eye tracking, and test performance from final knowledge evaluation. Our objective was to test whether the prediction could be improved by using attribute selection and classification ensembles. We carried out three experiments by applying six classification algorithms to numerical and discretized preprocessed multimodal data. The results show that the best predictions were produced using ensembles and selecting the best attributes approach with numerical data.\n",
      "\n",
      "Completed Intelligent, Tutoring, System, Multimodal, Learning, Strategies, Emotions, Interaction, Zones, Classification abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We introduce a novel text-to-pose video editing method, ReimaginedAct. While existing video editing tasks are limited to changes in attributes, backgrounds, and styles, our method aims to predict open-ended human action changes in video. Moreover, our method can accept not only direct instructional text prompts but also `what if' questions to predict possible action changes. ReimaginedAct comprises video understanding, reasoning, and editing modules. First, an LLM is utilized initially to obtain a plausible answer for the instruction or question, which is then used for (1) prompting Grounded-SAM to produce bounding boxes of relevant individuals and (2) retrieving a set of pose videos that we have collected for editing human actions. The retrieved pose videos and the detected individuals are then utilized to alter the poses extracted from the original video. We also employ a timestep blending module to ensure the edited video retains its original content except where necessary modifications are needed. To facilitate research in text-to-pose video editing, we introduce a new evaluation dataset, WhatifVideo-1.0. This dataset includes videos of different scenarios spanning a range of difficulty levels, along with questions and text prompts. Experimental results demonstrate that existing video editing methods struggle with human action editing, while our approach can achieve effective action editing and even imaginary editing from counterfactual questions.\n",
      "\n",
      "Completed text-to-pose, video editing, human action, reasoning, LLM, Grounded-SAM, pose videos, timestep blending, WhatifVideo-1.0, counterfactual questions abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper introduces iRoCo (intuitive Robot Control) - a framework for ubiquitous human-robot collaboration using a single smartwatch and smartphone. By integrating probabilistic differentiable filters, iRoCo optimizes a combination of precise robot control and unrestricted user movement from ubiquitous devices. We demonstrate and evaluate the effectiveness of iRoCo in practical teleoperation and drone piloting applications. Comparative analysis shows no significant difference between task performance with iRoCo and gold-standard control systems in teleoperation tasks. Additionally, iRoCo users complete drone piloting tasks 32\\% faster than with a traditional remote control and report less frustration in a subjective load index questionnaire. Our findings strongly suggest that iRoCo is a promising new approach for intuitive robot control through smartwatches and smartphones from anywhere, at any time. The code is available at www.github.com/wearable-motion-capture\n",
      "\n",
      "Completed human-robot, collaboration, smartwatch, smartphone, probabilistic, differentiable, filters, teleoperation, drone, piloting, subjective abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recently, $p$-presentation distances for $p\\in [1,\\infty]$ were introduced for merge trees and multiparameter persistence modules as more sensitive variations of the respective interleaving distances ($p=\\infty$). It is well-known that computing the interleaving distance is NP-hard in both cases. We extend this result by showing that computing the $p$-presentation distance is NP-hard for all $p\\in [1,\\infty)$ for both merge trees and $t$-parameter persistence modules for any $t\\geq 2$. Though the details differ, both proofs follow the same novel strategy, suggesting that our approach can be adapted to proving the NP-hardness of other distances based on sums or $p$-norms.\n",
      "\n",
      "Completed p-presentation, distances, merge, trees, multiparameter, persistence, modules, interleaving, NP-hard, p-norms abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Assessing acute brain dysfunction (ABD), including delirium and coma in the intensive care unit (ICU), is a critical challenge due to its prevalence and severe implications for patient outcomes. Current diagnostic methods rely on infrequent clinical observations, which can only determine a patient's ABD status after onset. Our research attempts to solve these problems by harnessing Electronic Health Records (EHR) data to develop automated methods for ABD prediction for patients in the ICU. Existing models solely predict a single state (e.g., either delirium or coma), require at least 24 hours of observation data to make predictions, do not dynamically predict fluctuating ABD conditions during ICU stay (typically a one-time prediction), and use small sample size, proprietary single-hospital datasets. Our research fills these gaps in the existing literature by dynamically predicting delirium, coma, and mortality for 12-hour intervals throughout an ICU stay and validating on two public datasets. Our research also introduces the concept of dynamically predicting critical transitions from non-ABD to ABD and between different ABD states in real time, which could be clinically more informative for the hospital staff. We compared the predictive performance of two state-of-the-art neural network models, the MAMBA selective state space model and the Longformer Transformer model. Using the MAMBA model, we achieved a mean area under the receiving operator characteristic curve (AUROC) of 0.95 on outcome prediction of ABD for 12-hour intervals. The model achieves a mean AUROC of 0.79 when predicting transitions between ABD states. Our study uses a curated dataset from the University of Florida Health Shands Hospital for internal validation and two publicly available datasets, MIMIC-IV and eICU, for external validation, demonstrating robustness across ICU stays from 203 hospitals and 140,945 patients.\n",
      "\n",
      "Completed delirium, coma, acute brain dysfunction, EHR, prediction, ICU, dynamic, transition, neural networks, validation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Structural priming is a widely used psycholinguistic paradigm to study human sentence representations. In this work we propose a framework for using empirical priming patterns to build a theory characterizing the structural representations humans construct when processing sentences. This framework uses a new cognitively motivated parser, SPAWN, to generate quantitative priming predictions from theoretical syntax and evaluate these predictions with empirical human behavior. As a case study, we apply this framework to study reduced relative clause representations in English. We use SPAWN to generate priming predictions from two theoretical accounts which make different assumptions about the structure of relative clauses. We find that the predictions from only one of these theories (Participial-Phase) align with empirical priming patterns, thus highlighting which assumptions about relative clause better capture human sentence representations.\n",
      "\n",
      "Completed sentence, representations, priming, SPAWN, syntax, human, behavior, relative, clauses, English abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we propose a novel abstraction-aware sketch-based image retrieval framework capable of handling sketch abstraction at varied levels. Prior works had mainly focused on tackling sub-factors such as drawing style and order, we instead attempt to model abstraction as a whole, and propose feature-level and retrieval granularity-level designs so that the system builds into its DNA the necessary means to interpret abstraction. On learning abstraction-aware features, we for the first-time harness the rich semantic embedding of pre-trained StyleGAN model, together with a novel abstraction-level mapper that deciphers the level of abstraction and dynamically selects appropriate dimensions in the feature matrix correspondingly, to construct a feature matrix embedding that can be freely traversed to accommodate different levels of abstraction. For granularity-level abstraction understanding, we dictate that the retrieval model should not treat all abstraction-levels equally and introduce a differentiable surrogate Acc.@q loss to inject that understanding into the system. Different to the gold-standard triplet loss, our Acc.@q loss uniquely allows a sketch to narrow/broaden its focus in terms of how stringent the evaluation should be - the more abstract a sketch, the less stringent (higher $q$). Extensive experiments depict our method to outperform existing state-of-the-arts in standard SBIR tasks along with challenging scenarios like early retrieval, forensic sketch-photo matching, and style-invariant retrieval.\n",
      "\n",
      "Completed sketch-based, image, retrieval, abstraction, features, granularity, StyleGAN, loss, SBIR, forensic abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Entropy comparison inequalities are obtained for the differential entropy $h(X+Y)$ of the sum of two independent random vectors $X,Y$, when one is replaced by a Gaussian. For identically distributed random vectors $X,Y$, these are closely related to bounds on the entropic doubling constant, which quantifies the entropy increase when adding an independent copy of a random vector to itself. Consequences of both large and small doubling are explored. For the former, lower bounds are deduced on the entropy increase when adding an independent Gaussian, while for the latter, a qualitative stability result for the entropy power inequality is obtained. In the more general case of non-identically distributed random vectors $X,Y$, a Gaussian comparison inequality with interesting implications for channel coding is established: For additive-noise channels with a power constraint, Gaussian codebooks come within a $\\frac{{\\sf snr}}{3{\\sf snr}+2}$ factor of capacity. In the low-SNR regime this improves the half-a-bit additive bound of Zamir and Erez (2004). Analogous results are obtained for additive-noise multiple access channels, and for linear, additive-noise MIMO channels.\n",
      "\n",
      "Completed entropy, Gaussian, comparison, inequalities, doubling, capacity, half-a-bit, SNR, MIMO, channel abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present an extensive, in-depth analysis of the eye tracking capabilities of the Meta Quest Pro virtual reality headset using a dataset of eye movement recordings collected from 78 participants. In addition to presenting classical signal quality metrics--spatial accuracy, spatial precision and linearity--in ideal settings, we also study the impact of background luminance and headset slippage on device performance. We additionally present a user-centered analysis of eye tracking signal quality, where we highlight the potential differences in user experience as a function of device performance. This work contributes to a growing understanding of eye tracking signal quality in virtual reality headsets, where the performance of applications such as gaze-based interaction, foveated rendering, and social gaze are directly dependent on the quality of eye tracking signal.\n",
      "\n",
      "Completed Meta Quest Pro, virtual reality, eye tracking, signal quality, spatial accuracy, spatial precision, linearity, background luminance, headset slippage, user experience abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Web-based applications such as chatbots, search engines and news recommendations continue to grow in scale and complexity with the recent surge in the adoption of LLMs. Online model selection has thus garnered increasing attention due to the need to choose the best model among a diverse set while balancing task reward and exploration cost. Organizations faces decisions like whether to employ a costly API-based LLM or a locally finetuned small LLM, weighing cost against performance. Traditional selection methods often evaluate every candidate model before choosing one, which are becoming impractical given the rising costs of training and finetuning LLMs. Moreover, it is undesirable to allocate excessive resources towards exploring poor-performing models. While some recent works leverage online bandit algorithm to manage such exploration-exploitation trade-off in model selection, they tend to overlook the increasing-then-converging trend in model performances as the model is iteratively finetuned, leading to less accurate predictions and suboptimal model selections.\n",
      "  In this paper, we propose a time-increasing bandit algorithm TI-UCB, which effectively predicts the increase of model performances due to finetuning and efficiently balances exploration and exploitation in model selection. To further capture the converging points of models, we develop a change detection mechanism by comparing consecutive increase predictions. We theoretically prove that our algorithm achieves a logarithmic regret upper bound in a typical increasing bandit setting, which implies a fast convergence rate. The advantage of our method is also empirically validated through extensive experiments on classification model selection and online selection of LLMs. Our results highlight the importance of utilizing increasing-then-converging pattern for more efficient and economic model selection in the deployment of LLMs.\n",
      "\n",
      "Completed online, model, selection, exploration, exploitation, bandit, algorithm, finetuning, performance, regret abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper, for the first time, explores text-to-image diffusion models for Zero-Shot Sketch-based Image Retrieval (ZS-SBIR). We highlight a pivotal discovery: the capacity of text-to-image diffusion models to seamlessly bridge the gap between sketches and photos. This proficiency is underpinned by their robust cross-modal capabilities and shape bias, findings that are substantiated through our pilot studies. In order to harness pre-trained diffusion models effectively, we introduce a straightforward yet powerful strategy focused on two key aspects: selecting optimal feature layers and utilising visual and textual prompts. For the former, we identify which layers are most enriched with information and are best suited for the specific retrieval requirements (category-level or fine-grained). Then we employ visual and textual prompts to guide the model's feature extraction process, enabling it to generate more discriminative and contextually relevant cross-modal representations. Extensive experiments on several benchmark datasets validate significant performance improvements.\n",
      "\n",
      "Completed text-to-image, diffusion, models, sketch-based, image, retrieval, cross-modal, shape, bias, promp abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The paper presents a technique using reinforcement learning (RL) to adapt the control gains of a quadcopter controller. Specifically, we employed Proximal Policy Optimization (PPO) to train a policy which adapts the gains of a cascaded feedback controller in-flight. The primary goal of this controller is to minimize tracking error while following a specified trajectory. The paper's key objective is to analyze the effectiveness of the adaptive gain policy and compare it to the performance of a static gain control algorithm, where the Integral Squared Error and Integral Time Squared Error are used as metrics. The results show that the adaptive gain scheme achieves over 40$\\%$ decrease in tracking error as compared to the static gain controller.\n",
      "\n",
      "Completed quadcopter, reinforcement, learning, control, gains, adaptive, policy, optimization, tracking, error abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "While location trajectories represent a valuable data source for analyses and location-based services, they can reveal sensitive information, such as political and religious preferences. Differentially private publication mechanisms have been proposed to allow for analyses under rigorous privacy guarantees. However, the traditional protection schemes suffer from a limiting privacy-utility trade-off and are vulnerable to correlation and reconstruction attacks. Synthetic trajectory data generation and release represent a promising alternative to protection algorithms. While initial proposals achieve remarkable utility, they fail to provide rigorous privacy guarantees. This paper proposes a framework for designing a privacy-preserving trajectory publication approach by defining five design goals, particularly stressing the importance of choosing an appropriate Unit of Privacy. Based on this framework, we briefly discuss the existing trajectory protection approaches, emphasising their shortcomings. This work focuses on the systematisation of the state-of-the-art generative models for trajectories in the context of the proposed framework. We find that no existing solution satisfies all requirements. Thus, we perform an experimental study evaluating the applicability of six sequential generative models to the trajectory domain. Finally, we conclude that a generative trajectory model providing semantic guarantees remains an open research question and propose concrete next steps for future research.\n",
      "\n",
      "Completed privacy, trajectories, generative models, data generation, location data, protection algorithms, reconstruction attacks, correlation attacks, privacy-utility trade-off, unit of privacy abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "For those experiencing severe-to-profound sensorineural hearing loss, the cochlear implant (CI) is the preferred treatment. Augmented reality (AR) aided surgery can potentially improve CI procedures and hearing outcomes. Typically, AR solutions for image-guided surgery rely on optical tracking systems to register pre-operative planning information to the display so that hidden anatomy or other important information can be overlayed and co-registered with the view of the surgical scene. In this paper, our goal is to develop a method that permits direct 2D-to-3D registration of the microscope video to the pre-operative Computed Tomography (CT) scan without the need for external tracking equipment. Our proposed solution involves using surface mapping of a portion of the incus in surgical recordings and determining the pose of this structure relative to the surgical microscope by performing pose estimation via the perspective-n-point (PnP) algorithm. This registration can then be applied to pre-operative segmentations of other anatomy-of-interest, as well as the planned electrode insertion trajectory to co-register this information for the AR display. Our results demonstrate the accuracy with an average rotation error of less than 25 degrees and a translation error of less than 2 mm, 3 mm, and 0.55% for the x, y, and z axes, respectively. Our proposed method has the potential to be applicable and generalized to other surgical procedures while only needing a monocular microscope during intra-operation.\n",
      "\n",
      "Completed cochlear, implant, augmented, reality, image, guided, surgery, registration, perspective-n-point, accuracy abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "While GPU clusters are the de facto choice for training large deep neural network (DNN) models today, several reasons including ease of workflow, security and cost have led to efforts investigating whether CPUs may be viable for inference in routine use in many sectors of the industry. But the imbalance between the compute capabilities of GPUs and CPUs is huge. Motivated by these considerations, we study a module which is a workhorse within modern DNN architectures, GEMM based Feed Forward Networks (FFNs), and assess the extent to which it can be made compute- (or FLOP-) lite. Specifically, we propose an alternative formulation (we call it LookupFFN) to GEMM based FFNs inspired by the recent studies of using Locality Sensitive Hashing (LSH) to approximate FFNs. Our formulation recasts most essential operations as a memory look-up, leveraging the trade-off between the two resources on any platform: compute and memory (since CPUs offer it in abundance). For RoBERTa language model pretraining, our formulation achieves similar performance compared to GEMM based FFNs, while dramatically reducing the required FLOP. Our development is complemented with a detailed hardware profiling of strategies that will maximize efficiency -- not just on contemporary hardware but on products that will be offered in the near/medium term future. Code is avaiable at \\url{https://github.com/mlpen/LookupFFN}.\n",
      "\n",
      "Completed CPU, inference, GEMM, Feed Forward Networks, Locality Sensitive Hashing, memory look-up, RoBERTa, FLOP, hardware profiling, efficiency abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Two primary input modalities prevail in image retrieval: sketch and text. While text is widely used for inter-category retrieval tasks, sketches have been established as the sole preferred modality for fine-grained image retrieval due to their ability to capture intricate visual details. In this paper, we question the reliance on sketches alone for fine-grained image retrieval by simultaneously exploring the fine-grained representation capabilities of both sketch and text, orchestrating a duet between the two. The end result enables precise retrievals previously unattainable, allowing users to pose ever-finer queries and incorporate attributes like colour and contextual cues from text. For this purpose, we introduce a novel compositionality framework, effectively combining sketches and text using pre-trained CLIP models, while eliminating the need for extensive fine-grained textual descriptions. Last but not least, our system extends to novel applications in composite image retrieval, domain attribute transfer, and fine-grained generation, providing solutions for various real-world scenarios.\n",
      "\n",
      "Completed sketch, text, fine-grained, image, retrieval, representation, duet, compositionality, CLIP, framework abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this study, we address the challenge of constructing continuous three-dimensional (3D) models that accurately represent uncertain surfaces, derived from noisy and incomplete LiDAR scanning data. Building upon our prior work, which utilized the Gaussian Process (GP) and Gaussian Mixture Model (GMM) for structured building models, we introduce a more generalized approach tailored for complex surfaces in urban scenes, where four-dimensional (4D) GMM Regression and GP with derivative observations are applied. A Hierarchical GMM (HGMM) is employed to optimize the number of GMM components and speed up the GMM training. With the prior map obtained from HGMM, GP inference is followed for the refinement of the final map. Our approach models the implicit surface of the geo-object and enables the inference of the regions that are not completely covered by measurements. The integration of GMM and GP yields well-calibrated uncertainty estimates alongside the surface model, enhancing both accuracy and reliability. The proposed method is evaluated on the real data collected by a mobile mapping system. Compared to the performance in mapping accuracy and uncertainty quantification of other methods such as Gaussian Process Implicit Surface map (GPIS) and log-Gaussian Process Implicit Surface map (Log-GPIS), the proposed method achieves lower RMSEs, higher log-likelihood values and fewer computational costs for the evaluated datasets.\n",
      "\n",
      "Completed LiDAR, 3D, Gaussian Process, Gaussian Mixture Model, Urban Scenes, 4D GMM Regression, Derivative GP, Hierarchical GMM, Uncertainty Quantification, Real-World Data abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We propose an accurate and robust initialization approach for stereo visual-inertial SLAM systems. Unlike the current state-of-the-art method, which heavily relies on the accuracy of a pure visual SLAM system to estimate inertial variables without updating camera poses, potentially compromising accuracy and robustness, our approach offers a different solution. We realize the crucial impact of precise gyroscope bias estimation on rotation accuracy. This, in turn, affects trajectory accuracy due to the accumulation of translation errors. To address this, we first independently estimate the gyroscope bias and use it to formulate a maximum a posteriori problem for further refinement. After this refinement, we proceed to update the rotation estimation by performing IMU integration with gyroscope bias removed from gyroscope measurements. We then leverage robust and accurate rotation estimates to enhance translation estimation via 3-DoF bundle adjustment. Moreover, we introduce a novel approach for determining the success of the initialization by evaluating the residual of the normal epipolar constraint. Extensive evaluations on the EuRoC dataset illustrate that our method excels in accuracy and robustness. It outperforms ORB-SLAM3, the current leading stereo visual-inertial initialization method, in terms of absolute trajectory error and relative rotation error, while maintaining competitive computational speed. Notably, even with 5 keyframes for initialization, our method consistently surpasses the state-of-the-art approach using 10 keyframes in rotation accuracy.\n",
      "\n",
      "Completed stereo, visual-inertial, SLAM, gyroscope, bias, rotation, translation, initialization, EuRoC, ORB-SLAM3 abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Some theories on data flow security are based on order-theoretical concepts, most commonly on lattice concepts. This paper presents a correspondence between security concepts and partial order concepts, by which the former become an application of the latter. The formalization involves concepts of data flow, equivalence classes of entities that can access the same data, and labels. Efficient, well-known algorithms to obtain one of these from one of the others are presented. Security concepts such as secrecy (also called confidentiality), integrity and conflict can be expressed in this theory. Further, it is shown that complex tuple labels used in the literature to express security levels can be translated into equivalent set labels. A consequence is that any network's data flow or access control relationships can be defined by assigning simple set labels to the entities. Finally, it is shown how several partial orders can be combined when different data flows must coexist.\n",
      "\n",
      "Completed data, flow, security, order, lattice, equivalence, labels, secrecy, integrity, conflict abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Let $\\mathsf{TH}_k$ denote the $k$-out-of-$n$ threshold function: given $n$ input Boolean variables, the output is $1$ if and only if at least $k$ of the inputs are $1$. We consider the problem of computing the $\\mathsf{TH}_k$ function using noisy readings of the Boolean variables, where each reading is incorrect with some fixed and known probability $p \\in (0,1/2)$. As our main result, we show that, when $k = o(n)$, it is both sufficient and necessary to use $$(1 \\pm o(1)) \\frac{n\\log \\frac{k}{\\delta}}{D_{\\mathsf{KL}}(p || 1-p)}$$ queries in expectation to compute the $\\mathsf{TH}_k$ function with a vanishing error probability $\\delta = o(1)$, where $D_{\\mathsf{KL}}(p || 1-p)$ denotes the Kullback-Leibler divergence between $\\mathsf{Bern}(p)$ and $\\mathsf{Bern}(1-p)$ distributions. In particular, this says that $(1 \\pm o(1)) \\frac{n\\log \\frac{1}{\\delta}}{D_{\\mathsf{KL}}(p || 1-p)}$ queries in expectation are both sufficient and necessary to compute the $\\mathsf{OR}$ and $\\mathsf{AND}$ functions of $n$ Boolean variables. Compared to previous work, our result tightens the dependence on $p$ in both the upper and lower bounds.\n",
      "\n",
      "Completed threshold, noisy, query, Kullback-Leibler, divergence, expectation, error, probability, OR, AND abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Direct Preference Optimization (DPO) is an effective technique that leverages pairwise preference data (usually one chosen and rejected response pair per user prompt) to align LLMs to human preferences. In practice, multiple responses can exist for a given prompt with varying quality relative to each other. With availability of such quality ratings for multiple responses, we propose utilizing these responses to create multiple preference pairs for a given prompt. Our work focuses on systematically using the constructed multiple preference pair in DPO training via curriculum learning methodology. In particular, we order these multiple pairs of preference data from easy to hard (emulating curriculum training) according to various criteria. We show detailed comparisons of our proposed approach to the standard single-pair DPO setting. Our method, which we call Curry-DPO consistently shows increased performance gains on MTbench, Vicuna, WizardLM, and the UltraFeedback test set, highlighting its effectiveness. More specifically, Curry-DPO achieves a score of 7.43 on MT-bench with Zephy-7B model outperforming majority of existing LLMs with similar parameter size. Curry-DPO also achieves the highest adjusted win rates on Vicuna, WizardLM, and UltraFeedback test datasets (90.7%, 87.1%, and 87.9% respectively) in our experiments, with notable gains of upto 7.5% when compared to standard DPO technique.\n",
      "\n",
      "Completed Direct, Preference, Optimization, Pairwise, Quality, Curriculum, Learning, Multiple, Vicuna, WizardLM abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The rapid proliferation of digital content and the ever-growing need for precise object recognition and segmentation have driven the advancement of cutting-edge techniques in the field of object classification and segmentation. This paper introduces \"Learn and Search\", a novel approach for object lookup that leverages the power of contrastive learning to enhance the efficiency and effectiveness of retrieval systems.\n",
      "  In this study, we present an elegant and innovative methodology that integrates deep learning principles and contrastive learning to tackle the challenges of object search. Our extensive experimentation reveals compelling results, with \"Learn and Search\" achieving superior Similarity Grid Accuracy, showcasing its efficacy in discerning regions of utmost similarity within an image relative to a cropped image.\n",
      "  The seamless fusion of deep learning and contrastive learning to address the intricacies of object identification not only promises transformative applications in image recognition, recommendation systems, and content tagging but also revolutionizes content-based search and retrieval. The amalgamation of these techniques, as exemplified by \"Learn and Search,\" represents a significant stride in the ongoing evolution of methodologies in the dynamic realm of object classification and segmentation.\n",
      "\n",
      "Completed object, classification, segmentation, contrastive, learning, identification, retrieval, recognition, deep, image abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Significant progress has been made in training multimodal trajectory forecasting models for autonomous driving. However, effectively integrating these models with downstream planners and model-based control approaches is still an open problem. Although these models have conventionally been evaluated for open-loop prediction, we show that they can be used to parameterize autoregressive closed-loop models without retraining. We consider recent trajectory prediction approaches which leverage learned anchor embeddings to predict multiple trajectories, finding that these anchor embeddings can parameterize discrete and distinct modes representing high-level driving behaviors. We propose to perform fully reactive closed-loop planning over these discrete latent modes, allowing us to tractably model the causal interactions between agents at each step. We validate our approach on a suite of more dynamic merging scenarios, finding that our approach avoids the $\\textit{frozen robot problem}$ which is pervasive in conventional planners. Our approach also outperforms the previous state-of-the-art in CARLA on challenging dense traffic scenarios when evaluated at realistic speeds.\n",
      "\n",
      "Completed trajectory, forecasting, multimodal, planning, models, anchor, embeddings, closed-loop, reactive, CARLA abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper unravels the potential of sketches for diffusion models, addressing the deceptive promise of direct sketch control in generative AI. We importantly democratise the process, enabling amateur sketches to generate precise images, living up to the commitment of \"what you sketch is what you get\". A pilot study underscores the necessity, revealing that deformities in existing models stem from spatial-conditioning. To rectify this, we propose an abstraction-aware framework, utilising a sketch adapter, adaptive time-step sampling, and discriminative guidance from a pre-trained fine-grained sketch-based image retrieval model, working synergistically to reinforce fine-grained sketch-photo association. Our approach operates seamlessly during inference without the need for textual prompts; a simple, rough sketch akin to what you and I can create suffices! We welcome everyone to examine results presented in the paper and its supplementary. Contributions include democratising sketch control, introducing an abstraction-aware framework, and leveraging discriminative guidance, validated through extensive experiments.\n",
      "\n",
      "Completed sketches, diffusion models, sketch control, democratised, precise images, pilot study, spatial-conditioning, abstraction-aware framework, discriminative guidance, fine-grained abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this study we investigated the impact of image segmentation methods on the results of stress computation in the wall of abdominal aortic aneurysms (AAAs). We compared wall stress distributions and magnitudes calculated from geometry models obtained from classical semi-automated segmentation versus automated neural network-based segmentation. Ten different AAA contrast-enhanced computed tomography (CT) images were semi-automatically segmented by an analyst, taking, depending on the quality of an image, between 15 and 40 minutes of human effort per patient. The same images were automatically segmented using PRAEVAorta 2, commercial software by NUREA (https://www.nurea-soft.com/), developed based on artificial intelligence (AI) algorithms, requiring only 1-2 minutes of computer time per patient. Aneurysm wall stress calculations performed using the BioPARR software (https://bioparr.mech.uwa.edu.au/) revealed that, compared to the classical semi-automated segmentation, the automatic neural network-based segmentation leads to equivalent stress distributions, and slightly higher peak and 99th percentile maximum principal stress values. This difference is due to consistently larger lumen surface areas in automatically segmented models as compared to classical semi-automated segmentations, resulting in greater total pressure load on the wall. Our findings are a steppingstone toward a fully automated pipeline for biomechanical analysis of AAAs, starting with CT scans and concluding with wall stress assessment, while at the same time highlighting the critical importance of the repeatable and accurate segmentation of the lumen, the difficult problem often underestimated by the literature.\n",
      "\n",
      "Completed stress, computation, segmentation, aneurysm, AAA, image, automated, neural network, accuracy, biomechanical abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Motivated by the importance of dynamic programming (DP) in parameterized complexity, we consider several fine-grained questions, such as the following examples: (i) can Dominating Set be solved in time $(3-\\epsilon)^{pw}n^{O(1)}$? (where $pw$ is the pathwidth) (ii) can Coloring be solved in time $pw^{(1-\\epsilon)pw}n^{O(1)}$? (iii) can a short reconfiguration between two size-$k$ independent sets be found in time $n^{(1-\\epsilon)k}$? Such questions are well-studied: in some cases the answer is No under the SETH, while in others coarse-grained lower bounds are known under the ETH. Even though questions such as the above seem \"morally equivalent\" as they all ask if a simple DP can be improved, the problems concerned have wildly varying time complexities, ranging from single-exponential FPT to XNLP-complete.\n",
      "  This paper's main contribution is to show that, despite their varying complexities, these questions are not just morally equivalent, but in fact they are the same question in disguise. We achieve this by putting forth a natural complexity assumption which we call the Primal Pathwidth-Strong Exponential Time Hypothesis (PP-SETH) and which states that 3-SAT cannot be solved in time $(2-\\epsilon)^{pw}n^{O(1)}$, for any $\\epsilon>0$, where $pw$ is the pathwidth of the primal graph of the input. We then show that numerous fine-grained questions in parameterized complexity, including the ones above, are equivalent to the PP-SETH, and hence to each other. This allows us to obtain sharp fine-grained lower bounds for problems for which previous lower bounds left a constant in the exponent undetermined, but also to increase our confidence in bounds which were previously known under the SETH, because we show that breaking any one such bound requires breaking all (old and new) bounds; and because we show that the PP-SETH is more plausible than the SETH.\n",
      "\n",
      "Completed complexity, dynamic, programming, pathwidth, exponential, parameterized, equivalent, questions, fine-grained, assumptions abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This research addresses the challenge of developing a universal deepfake detector that can effectively identify unseen deepfake images despite limited training data. Existing frequency-based paradigms have relied on frequency-level artifacts introduced during the up-sampling in GAN pipelines to detect forgeries. However, the rapid advancements in synthesis technology have led to specific artifacts for each generation model. Consequently, these detectors have exhibited a lack of proficiency in learning the frequency domain and tend to overfit to the artifacts present in the training data, leading to suboptimal performance on unseen sources. To address this issue, we introduce a novel frequency-aware approach called FreqNet, centered around frequency domain learning, specifically designed to enhance the generalizability of deepfake detectors. Our method forces the detector to continuously focus on high-frequency information, exploiting high-frequency representation of features across spatial and channel dimensions. Additionally, we incorporate a straightforward frequency domain learning module to learn source-agnostic features. It involves convolutional layers applied to both the phase spectrum and amplitude spectrum between the Fast Fourier Transform (FFT) and Inverse Fast Fourier Transform (iFFT). Extensive experimentation involving 17 GANs demonstrates the effectiveness of our proposed method, showcasing state-of-the-art performance (+9.8\\%) while requiring fewer parameters. The code is available at {\\cred \\url{https://github.com/chuangchuangtan/FreqNet-DeepfakeDetection}}.\n",
      "\n",
      "Completed Deepfake, Detector, Universal, Frequency-aware, FreqNet, High-frequency, Generalizability, FFT, iFFT, Source-agnostic abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Fine-tuning pre-trained vision-language models, like CLIP, has yielded success on diverse downstream tasks. However, several pain points persist for this paradigm: (i) directly tuning entire pre-trained models becomes both time-intensive and computationally costly. Additionally, these tuned models tend to become highly specialized, limiting their practicality for real-world deployment; (ii) recent studies indicate that pre-trained vision-language classifiers may overly depend on spurious features -- patterns that correlate with the target in training data, but are not related to the true labeling function; and (iii) existing studies on mitigating the reliance on spurious features, largely based on the assumption that we can identify such features, does not provide definitive assurance for real-world applications. As a piloting study, this work focuses on exploring mitigating the reliance on spurious features for CLIP without using any group annotation. To this end, we systematically study the existence of spurious correlation on CLIP and CILP+ERM. We first, following recent work on Deep Feature Reweighting (DFR), verify that last-layer retraining can greatly improve group robustness on pretrained CLIP. In view of them, we advocate a lightweight representation calibration method for fine-tuning CLIP, by first generating a calibration set using the pretrained CLIP, and then calibrating representations of samples within this set through contrastive learning, all without the need for group labels. Extensive experiments and in-depth visualizations on several benchmarks validate the effectiveness of our proposals, largely reducing reliance and significantly boosting the model generalization.\n",
      "\n",
      "Completed fine-tuning, vision-language, CLIP, spurious, features, mitigation, deep, feature, reweighting, contrastive, learning abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We propose a computational imaging method for time-efficient light-field acquisition that combines a coded aperture with an event-based camera. Different from the conventional coded-aperture imaging method, our method applies a sequence of coding patterns during a single exposure for an image frame. The parallax information, which is related to the differences in coding patterns, is recorded as events. The image frame and events, all of which are measured in a single exposure, are jointly used to computationally reconstruct a light field. We also designed an algorithm pipeline for our method that is end-to-end trainable on the basis of deep optics and compatible with real camera hardware. We experimentally showed that our method can achieve more accurate reconstruction than several other imaging methods with a single exposure. We also developed a hardware prototype with the potential to complete the measurement on the camera within 22 msec and demonstrated that light fields from real 3-D scenes can be obtained with convincing visual quality. Our software and supplementary video are available from our project website.\n",
      "\n",
      "Completed computational, imaging, time-efficient, light-field, coded, aperture, event-based, camera, parallax, deep, optics abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Time series data has been demonstrated to be crucial in various research fields. The management of large quantities of time series data presents challenges in terms of deep learning tasks, particularly for training a deep neural network. Recently, a technique named \\textit{Dataset Condensation} has emerged as a solution to this problem. This technique generates a smaller synthetic dataset that has comparable performance to the full real dataset in downstream tasks such as classification. However, previous methods are primarily designed for image and graph datasets, and directly adapting them to the time series dataset leads to suboptimal performance due to their inability to effectively leverage the rich information inherent in time series data, particularly in the frequency domain. In this paper, we propose a novel framework named Dataset \\textit{\\textbf{Cond}}ensation for \\textit{\\textbf{T}}ime \\textit{\\textbf{S}}eries \\textit{\\textbf{C}}lassification via Dual Domain Matching (\\textbf{CondTSC}) which focuses on the time series classification dataset condensation task. Different from previous methods, our proposed framework aims to generate a condensed dataset that matches the surrogate objectives in both the time and frequency domains. Specifically, CondTSC incorporates multi-view data augmentation, dual domain training, and dual surrogate objectives to enhance the dataset condensation process in the time and frequency domains. Through extensive experiments, we demonstrate the effectiveness of our proposed framework, which outperforms other baselines and learns a condensed synthetic dataset that exhibits desirable characteristics such as conforming to the distribution of the original data.\n",
      "\n",
      "Completed Dataset, Condensation, Time, Series, Classification, Domain, Matching, Augmentation, Surrogate, Objectives abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Human-object interaction (HOI) detection aims to locate human-object pairs and identify their interaction categories in images. Most existing methods primarily focus on supervised learning, which relies on extensive manual HOI annotations. In this paper, we propose a novel framework, termed Knowledge Integration to HOI (KI2HOI), that effectively integrates the knowledge of visual-language model to improve zero-shot HOI detection. Specifically, the verb feature learning module is designed based on visual semantics, by employing the verb extraction decoder to convert corresponding verb queries into interaction-specific category representations. We develop an effective additive self-attention mechanism to generate more comprehensive visual representations. Moreover, the innovative interaction representation decoder effectively extracts informative regions by integrating spatial and visual feature information through a cross-attention mechanism. To deal with zero-shot learning in low-data, we leverage a priori knowledge from the CLIP text encoder to initialize the linear classifier for enhanced interaction understanding. Extensive experiments conducted on the mainstream HICO-DET and V-COCO datasets demonstrate that our model outperforms the previous methods in various zero-shot and full-supervised settings.\n",
      "\n",
      "Completed Human-object, interaction, detection, zero-shot, visual-language, knowledge, integration, cross-attention, linear classifier, CLIP abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "A blockchain facilitates secure and atomic transactions between mutually untrusting parties on that chain. Today, there are multiple blockchains with differing interfaces and security properties. Programming in this multi-blockchain world is hindered by the lack of general and convenient abstractions for cross-chain communication and computation. Current cross-chain communication bridges have varied and low-level interfaces, making it difficult to develop portable applications. Current methods for multi-chain atomic transactions are limited in scope to cryptocurrency swaps.\n",
      "  This work addresses these issues. We first define a uniform, high-level interface for communication between chains. Building on this interface, we formulate a protocol that guarantees atomicity for general transactions whose operations may span several chains. We formulate and prove the desired correctness and security properties of these protocols. Our prototype implementation is built using the LayerZero cross-chain bridge. Experience with this implementation shows that the new abstractions considerably simplify the design and implementation of multi-chain transactions. Experimental evaluation with multi-chain swap transactions demonstrates performance comparable to that of custom-built implementations.\n",
      "\n",
      "Completed blockchain, multi-chain, cross-chain, communication, computation, atomicity, abstractions, protocol, correctness, security abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Conventional approaches to grasp planning require perfect knowledge of an object's pose and geometry. Uncertainties in these quantities induce uncertainties in the quality of planned grasps, which can lead to failure. Classically, grasp robustness refers to the ability to resist external disturbances after grasping an object. In contrast, this work studies robustness to intrinsic sources of uncertainty like object pose or geometry affecting grasp planning before execution. To do so, we develop a novel analytic theory of grasping that reasons about this intrinsic robustness by characterizing the effect of friction cone uncertainty on a grasp's force closure status. As a result, we show the Ferrari-Canny metric -- which measures the size of external disturbances a grasp can reject -- bounds the friction cone uncertainty a grasp can tolerate, and thus also measures intrinsic robustness. In tandem, we show that the recently proposed min-weight metric lower bounds the Ferrari-Canny metric, justifying it as a computationally-efficient, uncertainty-aware alternative. We validate this theory on hardware experiments versus a competitive baseline and demonstrate superior performance. Finally, we use our theory to develop an analytic notion of probabilistic force closure, which we show in simulation generates grasps that can incorporate uncertainty distributions over an object's geometry.\n",
      "\n",
      "Completed grasp, robustness, uncertainty, friction, cone, Ferrari-Canny, min-weight, force, probabilistic, geometry abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Within the Electronic Design Automation (EDA) domain, AI-driven solutions have emerged as formidable tools, yet they typically augment rather than redefine existing methodologies. These solutions often repurpose deep learning models from other domains, such as vision, text, and graph analytics, applying them to circuit design without tailoring to the unique complexities of electronic circuits. Such an AI4EDA approach falls short of achieving a holistic design synthesis and understanding, overlooking the intricate interplay of electrical, logical, and physical facets of circuit data. This perspective paper argues for a paradigm shift from AI4EDA towards AI-native EDA, integrating AI at the core of the design process. Pivotal to this vision is the development of a multimodal circuit representation learning technique, poised to provide a comprehensive understanding by harmonizing and extracting insights from varied data sources, such as functional specifications, RTL designs, circuit netlists, and physical layouts.\n",
      "  We champion the creation of large circuit models (LCMs) that are inherently multimodal, crafted to decode and express the rich semantics and structures of circuit data, thus fostering more resilient, efficient, and inventive design methodologies. Embracing this AI-native philosophy, we foresee a trajectory that transcends the current innovation plateau in EDA, igniting a profound shift-left in electronic design methodology. The envisioned advancements herald not just an evolution of existing EDA tools but a revolution, giving rise to novel instruments of design-tools that promise to radically enhance design productivity and inaugurate a new epoch where the optimization of circuit performance, power, and area (PPA) is achieved not incrementally, but through leaps that redefine the benchmarks of electronic systems' capabilities.\n",
      "\n",
      "Completed AI, EDA, AI4EDA, multi-modal, circuit, representation, learning, LCMs, design, revolution abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We establish a near-optimality guarantee for the full orthogonalization method (FOM), showing that the overall convergence of FOM is nearly as good as GMRES. In particular, we prove that at every iteration $k$, there exists an iteration $j\\leq k$ for which the FOM residual norm at iteration $j$ is no more than $\\sqrt{k+1}$ times larger than the GMRES residual norm at iteration $k$. This bound is sharp, and it has implications for algorithms for approximating the action of a matrix function on a vector.\n",
      "\n",
      "Completed FOM, GMRES, orthogonalization, convergence, optimality, residual, bound, matrix, function, vector abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Emotion recognition in conversation (ERC) is a task which predicts the emotion of an utterance in the context of a conversation. It tightly depends on dialogue context, speaker identity information, multiparty dialogue scenario and so on. However, the state-of-the-art method (instructERC) solely identifying speaker, and ignores commonsense knowledge(i.e., reaction of the listeners and intention of the speaker, etc.) behind speakers during a conversation, which can deeply mine speaker information. To this end, we propose a novel joint large language models with commonsense knowledge framework for emotion recognition in conversation, namely CKERC.We design prompts to generate interlocutors' commonsense based on historical utterances with large language model. And we use the interlocutor commonsense identification task for LLM pre-training to fine-tune speaker implicit clues information.By solving above challenge, our method achieve state-of-the-art.We extensive experiment on three widely-used datasets, i.e., IEMOCAP, MELD, EmoryNLP, demonstrate our method superiority. Also, we conduct in-depth analysis and further demonstrate the effectiveness of commonsense knowledge in ERC task in large language model.\n",
      "\n",
      "Completed Emotion, recognition, conversation, commonsense, knowledge, multiparty, speaker, identification, dialogue, utterance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Offline meta-reinforcement learning (OMRL) proficiently allows an agent to tackle novel tasks while solely relying on a static dataset. For precise and efficient task identification, existing OMRL research suggests learning separate task representations that be incorporated with policy input, thus forming a context-based meta-policy. A major approach to train task representations is to adopt contrastive learning using multi-task offline data. The dataset typically encompasses interactions from various policies (i.e., the behavior policies), thus providing a plethora of contextual information regarding different tasks. Nonetheless, amassing data from a substantial number of policies is not only impractical but also often unattainable in realistic settings. Instead, we resort to a more constrained yet practical scenario, where multi-task data collection occurs with a limited number of policies. We observed that learned task representations from previous OMRL methods tend to correlate spuriously with the behavior policy instead of reflecting the essential characteristics of the task, resulting in unfavorable out-of-distribution generalization. To alleviate this issue, we introduce a novel algorithm to disentangle the impact of behavior policy from task representation learning through a process called adversarial data augmentation. Specifically, the objective of adversarial data augmentation is not merely to generate data analogous to offline data distribution; instead, it aims to create adversarial examples designed to confound learned task representations and lead to incorrect task identification. Our experiments show that learning from such adversarial samples significantly enhances the robustness and effectiveness of the task identification process and realizes satisfactory out-of-distribution generalization.\n",
      "\n",
      "Completed offline, meta-reinforcement, learning, task, representation, contrastive, learning, adversarial, data, augmentation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Offline Reinforcement Learning (RL) endeavors to leverage offline datasets to craft effective agent policy without online interaction, which imposes proper conservative constraints with the support of behavior policies to tackle the Out-Of-Distribution (OOD) problem. However, existing works often suffer from the constraint conflict issue when offline datasets are collected from multiple behavior policies, i.e., different behavior policies may exhibit inconsistent actions with distinct returns across the state space. To remedy this issue, recent Advantage-Weighted (AW) methods prioritize samples with high advantage values for agent training while inevitably leading to overfitting on these samples. In this paper, we introduce a novel Advantage-Aware Policy Optimization (A2PO) method to explicitly construct advantage-aware policy constraints for offline learning under mixed-quality datasets. Specifically, A2PO employs a Conditional Variational Auto-Encoder (CVAE) to disentangle the action distributions of intertwined behavior policies by modeling the advantage values of all training data as conditional variables. Then the agent can follow such disentangled action distribution constraints to optimize the advantage-aware policy towards high advantage values. Extensive experiments conducted on both the single-quality and mixed-quality datasets of the D4RL benchmark demonstrate that A2PO yields results superior to state-of-the-art counterparts. Our code will be made publicly available.\n",
      "\n",
      "Completed Offline, Reinforcement, Learning, Advantage-Weighted, Overfitting, Policy, Optimization, Conditional, Variational, Auto-Encoder abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Quantifying a model's predictive uncertainty is essential for safety-critical applications such as autonomous driving. We consider quantifying such uncertainty for multi-object detection. In particular, we leverage conformal prediction to obtain uncertainty intervals with guaranteed coverage for object bounding boxes. One challenge in doing so is that bounding box predictions are conditioned on the object's class label. Thus, we develop a novel two-step conformal approach that propagates uncertainty in predicted class labels into the uncertainty intervals for the bounding boxes. This broadens the validity of our conformal coverage guarantees to include incorrectly classified objects, ensuring their usefulness when maximal safety assurances are required. Moreover, we investigate novel ensemble and quantile regression formulations to ensure the bounding box intervals are adaptive to object size, leading to a more balanced coverage across sizes. Validating our two-step approach on real-world datasets for 2D bounding box localization, we find that desired coverage levels are satisfied with actionably tight predictive uncertainty intervals.\n",
      "\n",
      "Completed conformal prediction, uncertainty, multi-object detection, bounding boxes, coverage, classification, ensemble, regression, size, adaptive abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Contrastive learning-based recommendation algorithms have significantly advanced the field of self-supervised recommendation, particularly with BPR as a representative ranking prediction task that dominates implicit collaborative filtering. However, the presence of false-positive and false-negative examples in recommendation systems hampers accurate preference learning. In this study, we propose a simple self-supervised contrastive learning framework that leverages positive feature augmentation and negative label augmentation to improve the self-supervisory signal. Theoretical analysis demonstrates that our learning method is equivalent to maximizing the likelihood estimation with latent variables representing user interest centers. Additionally, we establish an efficient negative label augmentation technique that samples unlabeled examples with a probability linearly dependent on their relative ranking positions, enabling efficient augmentation in constant time complexity. Through validation on multiple datasets, we illustrate the significant improvements our method achieves over the widely used BPR optimization objective while maintaining comparable runtime.\n",
      "\n",
      "Completed Contrastive, Self-supervised, Recommendation, BPR, Preference Learning, Label Augmentation, Feature Augmentation, Latent Variables, Ranking Positions, Datasets abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present model predictive selection (MPS), a new method for selecting the stable closed-loop (CL) equilibrium attitude-error quaternion (AEQ) of an uncrewed aerial vehicle (UAV) during the execution of high-speed yaw maneuvers. In this approach, we minimize the cost of yawing measured with a performance figure of merit (PFM) that takes into account both the aerodynamic-torque control input and attitude-error state of the UAV. Specifically, this method uses a control law with a term whose sign is dynamically switched in real time to select, between two options, the torque associated with the lesser cost of rotation as predicted by a dynamical model of the UAV derived from first principles. This problem is relevant because the selection of the stable CL equilibrium AEQ significantly impacts the performance of a UAV during high-speed rotational flight, from both the power and control-error perspectives. To test and demonstrate the functionality and performance of the proposed method, we present data collected during one hundred real-time high-speed yaw-tracking flight experiments. These results highlight the superior capabilities of the proposed MPS-based scheme when compared to a benchmark controller commonly used in aerial robotics, as the PFM used to quantify the cost of flight is reduced by 60.30 %, on average. To our best knowledge, these are the first flight-test results that thoroughly demonstrate, evaluate, and compare the performance of a real-time controller capable of selecting the stable CL equilibrium AEQ during operation.\n",
      "\n",
      "Completed Model, predictive, selection, equilibrium, attitude, quaternion, UAV, yaw, rotation, performance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Reconfigurable intelligent surface (RIS) is a novel meta-material which can form a smart radio environment by dynamically altering reflection directions of the impinging electromagnetic waves. In the prior literature, the inter-RIS links which also contribute to the performance of the whole system are usually neglected when multiple RISs are deployed. In this paper we investigate a general double-RIS assisted multiple-input multiple-output (MIMO) wireless communication system under spatially correlated non line-of-sight propagation channels, where the cooperation of the double RISs is also considered. The design objective is to maximize the achievable ergodic rate based on full statistical channel state information (CSI). Specifically, we firstly present a closed-form asymptotic expression for the achievable ergodic rate by utilizing replica method from statistical physics. Then a full statistical CSI-enabled optimal design is proposed which avoids high pilot training overhead compared to instantaneous CSI-enabled design. To further reduce the signal processing overhead and lower the complexity for practical realization, a common-phase scheme is proposed to design the double RISs. Simulation results show that the derived asymptotic ergodic rate is quite accurate even for small-sized antenna arrays. And the proposed optimization algorithm can achieve substantial gain at the expense of a low overhead and complexity. Furthermore, the cooperative double-RIS assisted MIMO framework is proven to achieve superior ergodic rate performance and high communication reliability under harsh propagation environment.\n",
      "\n",
      "Completed Reconfigurable, intelligent, surface, double, RIS, MIMO, cooperative, asymptotic, ergodic, rate abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "An important and unsolved problem in computer vision is to ensure that the algorithms are robust to changes in image domains. We address this problem in the scenario where we have access to images from the target domains but no annotations. Motivated by the challenges of the OOD-CV benchmark where we encounter real world Out-of-Domain (OOD) nuisances and occlusion, we introduce a novel Bayesian approach to OOD robustness for object classification. Our work extends Compositional Neural Networks (CompNets), which have been shown to be robust to occlusion but degrade badly when tested on OOD data. We exploit the fact that CompNets contain a generative head defined over feature vectors represented by von Mises-Fisher (vMF) kernels, which correspond roughly to object parts, and can be learned without supervision. We obverse that some vMF kernels are similar between different domains, while others are not. This enables us to learn a transitional dictionary of vMF kernels that are intermediate between the source and target domains and train the generative model on this dictionary using the annotations on the source domain, followed by iterative refinement. This approach, termed Unsupervised Generative Transition (UGT), performs very well in OOD scenarios even when occlusion is present. UGT is evaluated on different OOD benchmarks including the OOD-CV dataset, several popular datasets (e.g., ImageNet-C [9]), artificial image corruptions (including adding occluders), and synthetic-to-real domain transfer, and does well in all scenarios outperforming SOTA alternatives (e.g. up to 10% top-1 accuracy on Occluded OOD-CV dataset).\n",
      "\n",
      "Completed out-of-domain, object classification, compositional neural networks, von Mises-Fisher kernels, generative head, transitional dictionary, iterative refinement, unsupervised generative transition, OOD benchmarks, SOTA abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "With the long term accumulation of high quality educational data, artificial intelligence has shown excellent performance in knowledge tracing. However, due to the lack of interpretability and transparency of some algorithms, this approach will result in reduced stakeholder trust and a decreased acceptance of intelligent decisions. Therefore, algorithms need to achieve high accuracy, and users need to understand the internal operating mechanism and provide reliable explanations for decisions. This paper thoroughly analyzes the interpretability of KT algorithms. First, the concepts and common methods of explainable artificial intelligence and knowledge tracing are introduced. Next, explainable knowledge tracing models are classified into two categories: transparent models and black box models. Then, the interpretable methods used are reviewed from three stages: ante hoc interpretable methods, post hoc interpretable methods, and other dimensions. It is worth noting that current evaluation methods for explainable knowledge tracing are lacking. Hence, contrast and deletion experiments are conducted to explain the prediction results of the deep knowledge tracing model on the ASSISTment2009 by using three XAI methods. Moreover, this paper offers some insights into evaluation methods from the perspective of educational stakeholders. This paper provides a detailed and comprehensive review of the research on explainable knowledge tracing, aiming to offer some basis and inspiration for researchers interested in the interpretability of knowledge tracing.\n",
      "\n",
      "Completed Knowledge, tracing, artificial intelligence, interpretability, transparency, explainability, methods, evaluation, ASSISTment2009, XAI abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Transfer learning has recently shown significant performance across various tasks involving deep neural networks. In these transfer learning scenarios, the prior distribution for downstream data becomes crucial in Bayesian model averaging (BMA). While previous works proposed the prior over the neural network parameters centered around the pre-trained solution, such strategies have limitations when dealing with distribution shifts between upstream and downstream data. This paper introduces nonparametric transfer learning (NPTL), a flexible posterior sampling method to address the distribution shift issue within the context of nonparametric learning. The nonparametric learning (NPL) method is a recent approach that employs a nonparametric prior for posterior sampling, efficiently accounting for model misspecification scenarios, which is suitable for transfer learning scenarios that may involve the distribution shift between upstream and downstream tasks. Through extensive empirical validations, we demonstrate that our approach surpasses other baselines in BMA performance.\n",
      "\n",
      "Completed transfer, learning, Bayesian, model, averaging, distribution, shift, nonparametric, learning, sampling abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "As Large Language Models (LLMs) gain great success in real-world applications, an increasing number of users are seeking to develop and deploy their customized LLMs through cloud services. Nonetheless, in some specific domains, there are still concerns regarding cost and trade-offs between privacy issues and accuracy. In this study, we introduce a cost-effective and self-adaptive LLM shaking tuning and recovery mechanism, named CypherTalk. With carefully designed horizontal and vertical shaking operators, we can achieve comparable accuracy results with SOTA privacy-preserving LLM schemes using Cryptography-based or Differential Privacy-based methods. Experiments also show that with the CypherTalk framework, users can achieve reliable accuracy when using optimized shaking operator settings. To our best knowledge, this is the first work that considers cost, and trade-off between model utility and privacy in LLM scenarios.\n",
      "\n",
      "Completed LLMs, cloud, cost, privacy, accuracy, shaking, tuning, recovery, CypherTalk, differential abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Sparse 3D detectors have received significant attention since the query-based paradigm embraces low latency without explicit dense BEV feature construction. However, these detectors achieve worse performance than their dense counterparts. In this paper, we find the key to bridging the performance gap is to enhance the awareness of rich representations in two modalities. Here, we present a high-performance fully sparse detector for end-to-end multi-modality 3D object detection. The detector, termed SparseLIF, contains three key designs, which are (1) Perspective-Aware Query Generation (PAQG) to generate high-quality 3D queries with perspective priors, (2) RoI-Aware Sampling (RIAS) to further refine prior queries by sampling RoI features from each modality, (3) Uncertainty-Aware Fusion (UAF) to precisely quantify the uncertainty of each sensor modality and adaptively conduct final multi-modality fusion, thus achieving great robustness against sensor noises. By the time of submission (2024/03/08), SparseLIF achieves state-of-the-art performance on the nuScenes dataset, ranking 1st on both validation set and test benchmark, outperforming all state-of-the-art 3D object detectors by a notable margin. The source code will be released upon acceptance.\n",
      "\n",
      "Completed Sparse, Detectors, Multi-modality, Object, Detection, Perspective, RoI, Fusion, Uncertainty, Robustness abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Text detection is frequently used in vision-based mobile robots when they need to interpret texts in their surroundings to perform a given task. For instance, delivery robots in multilingual cities need to be capable of doing multilingual text detection so that the robots can read traffic signs and road markings. Moreover, the target languages change from region to region, implying the need of efficiently re-training the models to recognize the novel/new languages. However, collecting and labeling training data for novel languages are cumbersome, and the efforts to re-train an existing/trained text detector are considerable. Even worse, such a routine would repeat whenever a novel language appears. This motivates us to propose a new problem setting for tackling the aforementioned challenges in a more efficient way: \"We ask for a generalizable multilingual text detection framework to detect and identify both seen and unseen language regions inside scene images without the requirement of collecting supervised training data for unseen languages as well as model re-training\". To this end, we propose \"MENTOR\", the first work to realize a learning strategy between zero-shot learning and few-shot learning for multilingual scene text detection.\n",
      "\n",
      "Completed text, detection, mobile, robots, multilingual, training, efficiency, unseen, languages, mentor abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper introduces the concept of uniform classification, which employs a unified threshold to classify all samples rather than adaptive threshold classifying each individual sample. We also propose the uniform classification accuracy as a metric to measure the model's performance in uniform classification. Furthermore, begin with a naive loss, we mathematically derive a loss function suitable for the uniform classification, which is the BCE function integrated with a unified bias. We demonstrate the unified threshold could be learned via the bias. The extensive experiments on six classification datasets and three feature extraction models show that, compared to the SoftMax loss, the models trained with the BCE loss not only exhibit higher uniform classification accuracy but also higher sample-wise classification accuracy. In addition, the learned bias from BCE loss is very close to the unified threshold used in the uniform classification. The features extracted by the models trained with BCE loss not only possess uniformity but also demonstrate better intra-class compactness and inter-class distinctiveness, yielding superior performance on open-set tasks such as face recognition.\n",
      "\n",
      "Completed uniform classification, unified threshold, uniform classification accuracy, BCE loss, naive loss, SoftMax loss, sample-wise classification accuracy, intra-class compactness, inter-class distinctiveness, open-set tasks abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Color information is the most commonly used prior knowledge for depth map super-resolution (DSR), which can provide high-frequency boundary guidance for detail restoration. However, its role and functionality in DSR have not been fully developed. In this paper, we rethink the utilization of color information and propose a hierarchical color guidance network to achieve DSR. On the one hand, the low-level detail embedding module is designed to supplement high-frequency color information of depth features in a residual mask manner at the low-level stages. On the other hand, the high-level abstract guidance module is proposed to maintain semantic consistency in the reconstruction process by using a semantic mask that encodes the global guidance information. The color information of these two dimensions plays a role in the front and back ends of the attention-based feature projection (AFP) module in a more comprehensive form. Simultaneously, the AFP module integrates the multi-scale content enhancement block and adaptive attention projection block to make full use of multi-scale information and adaptively project critical restoration information in an attention manner for DSR. Compared with the state-of-the-art methods on four benchmark datasets, our method achieves more competitive performance both qualitatively and quantitatively.\n",
      "\n",
      "Completed Color, Depth, Super-resolution, Hierarchical, Guidance, Enhancement, Projection, Attention, Guidance, Information abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In real-world applications, image degeneration caused by adverse weather is always complex and changes with different weather conditions from days and seasons. Systems in real-world environments constantly encounter adverse weather conditions that are not previously observed. Therefore, it practically requires adverse weather removal models to continually learn from incrementally collected data reflecting various degeneration types. Existing adverse weather removal approaches, for either single or multiple adverse weathers, are mainly designed for a static learning paradigm, which assumes that the data of all types of degenerations to handle can be finely collected at one time before a single-phase learning process. They thus cannot directly handle the incremental learning requirements. To address this issue, we made the earliest effort to investigate the continual all-in-one adverse weather removal task, in a setting closer to real-world applications. Specifically, we develop a novel continual learning framework with effective knowledge replay (KR) on a unified network structure. Equipped with a principal component projection and an effective knowledge distillation mechanism, the proposed KR techniques are tailored for the all-in-one weather removal task. It considers the characteristics of the image restoration task with multiple degenerations in continual learning, and the knowledge for different degenerations can be shared and accumulated in the unified network structure. Extensive experimental results demonstrate the effectiveness of the proposed method to deal with this challenging task, which performs competitively to existing dedicated or joint training image restoration methods. Our code is available at https://github.com/xiaojihh/CL_all-in-one.\n",
      "\n",
      "Completed continual, adverse weather, removal, incremental learning, knowledge replay, unified network, real-world applications, image restoration, complex, diverse abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "With the increasing demands of training graph neural networks (GNNs) on large-scale graphs, graph data condensation has emerged as a critical technique to relieve the storage and time costs during the training phase. It aims to condense the original large-scale graph to a much smaller synthetic graph while preserving the essential information necessary for efficiently training a downstream GNN. However, existing methods concentrate either on optimizing node features exclusively or endeavor to independently learn node features and the graph structure generator. They could not explicitly leverage the information of the original graph structure and failed to construct an interpretable graph structure for the synthetic dataset. To address these issues, we introduce a novel framework named \\textbf{G}raph Data \\textbf{C}ondensation via \\textbf{S}elf-expressive Graph Structure \\textbf{R}econstruction (\\textbf{GCSR}). Our method stands out by (1) explicitly incorporating the original graph structure into the condensing process and (2) capturing the nuanced interdependencies between the condensed nodes by reconstructing an interpretable self-expressive graph structure. Extensive experiments and comprehensive analysis validate the efficacy of the proposed method across diverse GNN models and datasets. Our code is available at https://www.dropbox.com/scl/fi/2aonyp5ln5gisdqtjimu8/GCSR.zip?rlkey=11cuwfpsf54wxiiktu0klud0x&amp;dl=0\n",
      "\n",
      "Completed graph, neural, networks, condensation, synthetic, interpretable, structure, reconstruction, GCSR, GNN abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Multivariate time series forecasting has recently gained great success with the rapid growth of deep learning models. However, existing approaches usually train models from scratch using limited temporal data, preventing their generalization. Recently, with the surge of the Large Language Models (LLMs), several works have attempted to introduce LLMs into time series forecasting. Despite promising results, these methods directly take time series as the input to LLMs, ignoring the inherent modality gap between temporal and text data. In this work, we propose a novel Large Language Models and time series alignment framework, dubbed LLaTA, to fully unleash the potentials of LLMs in the time series forecasting challenge. Based on cross-modal knowledge distillation, the proposed method exploits both input-agnostic static knowledge and input-dependent dynamic knowledge in pre-trained LLMs. In this way, it empowers the forecasting model with favorable performance as well as strong generalization abilities. Extensive experiments demonstrate the proposed method establishes a new state of the art for both long- and short-term forecasting. Code is available at \\url{https://github.com/Hank0626/LLaTA}.\n",
      "\n",
      "Completed forecasting, time series, deep learning, Large Language Models, modality gap, cross-modal knowledge distillation, static knowledge, dynamic knowledge, generalization, state of the art abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Storytelling aims to generate reasonable and vivid narratives based on an ordered image stream. The fidelity to the image story theme and the divergence of story plots attract readers to keep reading. Previous works iteratively improved the alignment of multiple modalities but ultimately resulted in the generation of simplistic storylines for image streams. In this work, we propose a new pipeline, termed LLaMS, to generate multimodal human-level stories that are embodied in expressiveness and consistency. Specifically, by fully exploiting the commonsense knowledge within the LLM, we first employ a sequence data auto-enhancement strategy to enhance factual content expression and leverage a textual reasoning architecture for expressive story generation and prediction. Secondly, we propose SQ-Adatpter module for story illustration generation which can maintain sequence consistency. Numerical results are conducted through human evaluation to verify the superiority of proposed LLaMS. Evaluations show that LLaMS achieves state-of-the-art storytelling performance and 86% correlation and 100% consistency win rate as compared with previous SOTA methods. Furthermore, ablation experiments are conducted to verify the effectiveness of proposed sequence data enhancement and SQ-Adapter.\n",
      "\n",
      "Completed storytelling, image, narrative, expressiveness, consistency, LLM, auto-enhancement, textual reasoning, SQ-Adapter, SOTA abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Large Multimodal Model (LMM) is a hot research topic in the computer vision area and has also demonstrated remarkable potential across multiple disciplinary fields. A recent trend is to further extend and enhance the perception capabilities of LMMs. The current methods follow the paradigm of adapting the visual task outputs to the format of the language model, which is the main component of a LMM. This adaptation leads to convenient development of such LMMs with minimal modifications, however, it overlooks the intrinsic characteristics of diverse visual tasks and hinders the learning of perception capabilities. To address this issue, we propose a novel LMM architecture named Lumen, a Large multimodal model with versatile vision-centric capability enhancement. We decouple the LMM's learning of perception capabilities into task-agnostic and task-specific stages. Lumen first promotes fine-grained vision-language concept alignment, which is the fundamental capability for various visual tasks. Thus the output of the task-agnostic stage is a shared representation for all the tasks we address in this paper. Then the task-specific decoding is carried out by flexibly routing the shared representation to lightweight task decoders with negligible training efforts. Benefiting from such a decoupled design, our Lumen surpasses existing LMM-based approaches on the COCO detection benchmark with a clear margin and exhibits seamless scalability to additional visual tasks. Furthermore, we also conduct comprehensive ablation studies and generalization evaluations for deeper insights. The code will be released at https://github.com/SxJyJay/Lumen.\n",
      "\n",
      "Completed Large, Multimodal, Model, Perception, Decoupled, Learning, Task-agnostic, Task-specific, Alignment, Representation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Integrated communications and localization (ICAL) will play an important part in future sixth generation (6G) networks for the realization of Internet of Everything (IoE) to support both global communications and seamless localization. Massive multiple-input multiple-output (MIMO) low earth orbit (LEO) satellite systems have great potential in providing wide coverage with enhanced gains, and thus are strong candidates for realizing ubiquitous ICAL. In this paper, we develop a wideband massive MIMO LEO satellite system to simultaneously support wireless communications and localization operations in the downlink. In particular, we first characterize the signal propagation properties and derive a localization performance bound. Based on these analyses, we focus on the hybrid analog/digital precoding design to achieve high communication capability and localization precision. Numerical results demonstrate that the proposed ICAL scheme supports both the wireless communication and localization operations for typical system setups.\n",
      "\n",
      "Completed Integrated, communications, localization, 6G, Internet, Everything, MIMO, LEO, satellite, systems abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Barrier functions are a general framework for establishing a safety guarantee for a system. However, there is no general method for finding these functions. To address this shortcoming, recent approaches use self-supervised learning techniques to learn these functions using training data that are periodically generated by a verification procedure, leading to a verification-aided learning framework. Despite its immense potential in automating barrier function synthesis, the verification-aided learning framework does not have termination guarantees and may suffer from a low success rate of finding a valid barrier function in practice. In this paper, we propose a holistic approach to address these drawbacks. With a convex formulation of the barrier function synthesis, we propose to first learn an empirically well-behaved NN basis function and then apply a fine-tuning algorithm that exploits the convexity and counterexamples from the verification failure to find a valid barrier function with finite-step termination guarantees: if there exist valid barrier functions, the fine-tuning algorithm is guaranteed to find one in a finite number of iterations. We demonstrate that our fine-tuning method can significantly boost the performance of the verification-aided learning framework on examples of different scales and using various neural network verifiers.\n",
      "\n",
      "Completed Barrier functions, safety guarantee, self-supervised learning, verification-aided learning, termination guarantees, convex formulation, NN basis function, fine-tuning, counterexamples, neural network verifiers abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Sepsis, a life-threatening condition triggered by the body's exaggerated response to infection, demands urgent intervention to prevent severe complications. Existing machine learning methods for managing sepsis struggle in offline scenarios, exhibiting suboptimal performance with survival rates below 50%. This paper introduces the POSNEGDM -- ``Reinforcement Learning with Positive and Negative Demonstrations for Sequential Decision-Making\" framework utilizing an innovative transformer-based model and a feedback reinforcer to replicate expert actions while considering individual patient characteristics. A mortality classifier with 96.7\\% accuracy guides treatment decisions towards positive outcomes. The POSNEGDM framework significantly improves patient survival, saving 97.39% of patients, outperforming established machine learning algorithms (Decision Transformer and Behavioral Cloning) with survival rates of 33.4% and 43.5%, respectively. Additionally, ablation studies underscore the critical role of the transformer-based decision maker and the integration of a mortality classifier in enhancing overall survival rates. In summary, our proposed approach presents a promising avenue for enhancing sepsis treatment outcomes, contributing to improved patient care and reduced healthcare costs.\n",
      "\n",
      "Completed sepsis, machine learning, reinforcement learning, survival, treatment, transformer, mortality classifier, decision maker, ablation studies, healthcare abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The task of predicting multiple links within knowledge graphs (KGs) stands as a challenge in the field of knowledge graph analysis, a challenge increasingly resolvable due to advancements in natural language processing (NLP) and KG embedding techniques. This paper introduces a novel methodology, the Knowledge Graph Large Language Model Framework (KG-LLM), which leverages pivotal NLP paradigms, including chain-of-thought (CoT) prompting and in-context learning (ICL), to enhance multi-hop link prediction in KGs. By converting the KG to a CoT prompt, our framework is designed to discern and learn the latent representations of entities and their interrelations. To show the efficacy of the KG-LLM Framework, we fine-tune three leading Large Language Models (LLMs) within this framework, employing both non-ICL and ICL tasks for a comprehensive evaluation. Further, we explore the framework's potential to provide LLMs with zero-shot capabilities for handling previously unseen prompts. Our experimental findings discover that integrating ICL and CoT not only augments the performance of our approach but also significantly boosts the models' generalization capacity, thereby ensuring more precise predictions in unfamiliar scenarios.\n",
      "\n",
      "Completed Knowledge, Graphs, Link, Prediction, Language, Natural, Paradigm, Chain-of-Thought, Large, Model abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Modeling a generalized visuomotor policy has been a longstanding challenge for both computer vision and robotics communities. Existing approaches often fail to efficiently leverage cross-dataset resources or rely on heavy Vision-Language models, which require substantial computational resources, thereby limiting their multi-task performance and application potential. In this paper, we introduce a novel paradigm that effectively utilizes latent modeling of manipulation skills and an efficient visuomotor latent diffusion policy, which enhances the utilizing of existing cross-embodiment and cross-environment datasets, thereby improving multi-task capabilities. Our methodology consists of two decoupled phases: action modeling and policy modeling. Firstly, we introduce a task-agnostic, embodiment-aware trajectory latent autoencoder for unified action skills modeling. This step condenses action data and observation into a condensed latent space, effectively benefiting from large-scale cross-datasets. Secondly, we propose to use a visuomotor latent diffusion policy that recovers target skill latent from noises for effective task execution. We conducted extensive experiments on two widely used benchmarks, and the results demonstrate the effectiveness of our proposed paradigms on multi-tasking and pre-training. Code is available at https://github.com/AlbertTan404/RoLD.\n",
      "\n",
      "Completed visuomotor, policy, modeling, diffusion, latent, representation, embodiment, cross-dataset, multi-task, pre-training abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Customizable 3D avatar-based facial expression stimuli may improve user engagement in behavioral biomarker discovery and therapeutic intervention for autism, Alzheimer's disease, facial palsy, and more. However, there is a lack of customizable avatar-based stimuli with Facial Action Coding System (FACS) action unit (AU) labels. Therefore, this study focuses on (1) FACS-labeled, customizable avatar-based expression stimuli for maintaining subjects' engagement, (2) learning-based measurements that quantify subjects' facial responses to such stimuli, and (3) validation of constructs represented by stimulus-measurement pairs. We propose Customizable Avatars with Dynamic Facial Action Coded Expressions (CADyFACE) labeled with AUs by a certified FACS expert. To measure subjects' AUs in response to CADyFACE, we propose a novel Beta-guided Correlation and Multi-task Expression learning neural network (BeCoME-Net) for multi-label AU detection. The beta-guided correlation loss encourages feature correlation with AUs while discouraging correlation with subject identities for improved generalization. We train BeCoME-Net for unilateral and bilateral AU detection and compare with state-of-the-art approaches. To assess construct validity of CADyFACE and BeCoME-Net, twenty healthy adult volunteers complete expression recognition and mimicry tasks in an online feasibility study while webcam-based eye-tracking and video are collected. We test validity of multiple constructs, including face preference during recognition and AUs during mimicry.\n",
      "\n",
      "Completed CADyFACE, BeCoME-Net, Facial Action Coding System, action unit, avatar-based, customizable, expression, measurement, construct validity, biomarker abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The configuration of most robotic systems lies in continuous transformation groups. However, in mobile robot trajectory tracking, many recent works still naively utilize optimization methods for elements in vector space without considering the manifold constraint of the robot configuration. In this letter, we propose a geometric model predictive control (MPC) framework for wheeled mobile robot trajectory tracking. We first derive the error dynamics of the wheeled mobile robot trajectory tracking by considering its manifold constraint and kinematic constraint simultaneously. After that, we utilize the relationship between the Lie group and Lie algebra to convexify the tracking control problem, which enables us to solve the problem efficiently. Thanks to the Lie group formulation, our method tracks the trajectory more smoothly than existing nonlinear MPC. Simulations and physical experiments verify the effectiveness of our proposed methods. Our pure Python-based simulation platform is publicly available to benefit further research in the community.\n",
      "\n",
      "Completed geometric, Lie, model, control, MPC, trajectory, tracking, wheeled, mobile, robot abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "While diffusion-based image restoration (IR) methods have achieved remarkable success, they are still limited by the low inference speed attributed to the necessity of executing hundreds or even thousands of sampling steps. Existing acceleration sampling techniques, though seeking to expedite the process, inevitably sacrifice performance to some extent, resulting in over-blurry restored outcomes. To address this issue, this study proposes a novel and efficient diffusion model for IR that significantly reduces the required number of diffusion steps. Our method avoids the need for post-acceleration during inference, thereby avoiding the associated performance deterioration. Specifically, our proposed method establishes a Markov chain that facilitates the transitions between the high-quality and low-quality images by shifting their residuals, substantially improving the transition efficiency. A carefully formulated noise schedule is devised to flexibly control the shifting speed and the noise strength during the diffusion process. Extensive experimental evaluations demonstrate that the proposed method achieves superior or comparable performance to current state-of-the-art methods on three classical IR tasks, namely image super-resolution, image inpainting, and blind face restoration, \\textit{\\textbf{even only with four sampling steps}}. Our code and model are publicly available at \\url{https://github.com/zsyOAOA/ResShift}.\n",
      "\n",
      "Completed Diffusion, Image Restoration, Acceleration, Sampling, Efficiency, Markov Chain, Noise Schedule, Shifting, Super-Resolution, Inpainting abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Neural compression has brought tremendous progress in designing lossy compressors with good rate-distortion (RD) performance at low complexity. Thus far, neural compression design involves transforming the source to a latent vector, which is then rounded to integers and entropy coded. While this approach has been shown to be optimal in a one-shot sense on certain sources, we show that it is highly sub-optimal on i.i.d. sequences, and in fact always recovers scalar quantization of the original source sequence. We demonstrate that the sub-optimality is due to the choice of quantization scheme in the latent space, and not the transform design. By employing lattice quantization instead of scalar quantization in the latent space, we demonstrate that Lattice Transform Coding (LTC) is able to recover optimal vector quantization at various dimensions and approach the asymptotically-achievable rate-distortion function at reasonable complexity. On general vector sources, LTC improves upon standard neural compressors in one-shot coding performance. LTC also enables neural compressors that perform block coding on i.i.d. vector sources, which yields coding gain over optimal one-shot coding.\n",
      "\n",
      "Completed neural, compression, rate-distortion, latent, vector, quantization, lattice, transform, coding, sequence abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "As natural language models like ChatGPT become increasingly prevalent in applications and services, the need for robust and accurate methods to detect their output is of paramount importance. In this paper, we present GPT Reddit Dataset (GRiD), a novel Generative Pretrained Transformer (GPT)-generated text detection dataset designed to assess the performance of detection models in identifying generated responses from ChatGPT. The dataset consists of a diverse collection of context-prompt pairs based on Reddit, with human-generated and ChatGPT-generated responses. We provide an analysis of the dataset's characteristics, including linguistic diversity, context complexity, and response quality. To showcase the dataset's utility, we benchmark several detection methods on it, demonstrating their efficacy in distinguishing between human and ChatGPT-generated responses. This dataset serves as a resource for evaluating and advancing detection techniques in the context of ChatGPT and contributes to the ongoing efforts to ensure responsible and trustworthy AI-driven communication on the internet. Finally, we propose GpTen, a novel tensor-based GPT text detection method that is semi-supervised in nature since it only has access to human-generated text and performs on par with fully-supervised baselines.\n",
      "\n",
      "Completed ChatGPT, GPT, GRiD, Detection, Human, Generated, Dataset, Tensor, Semi-Supervised, AI abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Knowledge tracing (KT) plays a crucial role in predicting students' future performance by analyzing their historical learning processes. Deep neural networks (DNNs) have shown great potential in solving the KT problem. However, there still exist some important challenges when applying deep learning techniques to model the KT process. The first challenge lies in taking the individual information of the question into modeling. This is crucial because, despite questions sharing the same knowledge component (KC), students' knowledge acquisition on homogeneous questions can vary significantly. The second challenge lies in interpreting the prediction results from existing deep learning-based KT models. In real-world applications, while it may not be necessary to have complete transparency and interpretability of the model parameters, it is crucial to present the model's prediction results in a manner that teachers find interpretable. This makes teachers accept the rationale behind the prediction results and utilize them to design teaching activities and tailored learning strategies for students. However, the inherent black-box nature of deep learning techniques often poses a hurdle for teachers to fully embrace the model's prediction results. To address these challenges, we propose a Question-centric Multi-experts Contrastive Learning framework for KT called Q-MCKT.\n",
      "\n",
      "Completed Knowledge tracing, deep neural networks, question modeling, prediction interpretation, transparency, interpretability, teachers, prediction utilization, teaching activities, tailored learning strategies abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Fast and accurate depth sensing has long been a significant research challenge. Event camera, as a device that quickly responds to intensity changes, provides a new solution for structured light (SL) systems. In this paper, we introduce Gray code into event-based SL systems for the first time. Our setup includes an event camera and Digital Light Processing (DLP) projector, enabling depth estimation through high-speed projection and decoding of Gray code patterns. By employing spatio-temporal encoding for point matching, our method is immune to timestamp noise, realizing high-speed depth estimation without loss of accuracy. The binary nature of events and Gray code minimizes data redundancy, enabling us to fully utilize sensor bandwidth at 100%. Experimental results show that our approach achieves accuracy comparable to state-of-the-art scanning methods while surpassing them in data acquisition speed (up to 41 times improvement) without sacrificing accuracy. Our proposed approach offers a highly promising solution for ultra-fast, real-time, and high-precision dense depth estimation. Code and dataset will be publicly available.\n",
      "\n",
      "Completed event, camera, depth, sensing, Gray, code, projection, encoding, matching, accuracy abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In MaxSAT with Cardinality Constraint problem (CC-MaxSAT), we are given a CNF-formula $\\Phi$, and $k \\ge 0$, and the goal is to find an assignment $\\beta$ with at most $k$ variables set to true (also called a weight $k$-assignment) such that the number of clauses satisfied by $\\beta$ is maximized. MaxCov can be seen as a special case of CC-MaxSAT, where the formula $\\Phi$ is monotone, i.e., does not contain any negative literals. CC-MaxSAT and MaxCov are extremely well-studied problems in the approximation algorithms as well as parameterized complexity literature.\n",
      "  Our first contribution is that the two problems are equivalent to each other in the context of FPT-Approximation parameterized by $k$ (approximation is in terms of number of clauses satisfied/elements covered). We give a randomized reduction from CC-MaxSAT to MaxCov in time $O(1/\\epsilon)^{k} \\cdot (m+n)^{O(1)}$ that preserves the approximation guarantee up to a factor of $1-\\epsilon$. Furthermore, this reduction also works in the presence of fairness and matroid constraints.\n",
      "  Armed with this reduction, we focus on designing FPT-Approximation schemes (FPT-ASes) for MaxCov and its generalizations. Our algorithms are based on a novel combination of a variety of ideas, including a carefully designed probability distribution that exploits sparse coverage functions. These algorithms substantially generalize the results in Jain et al. [SODA 2023] for CC-MaxSAT and MaxCov for $K_{d,d}$-free set systems (i.e., no $d$ sets share $d$ elements), as well as a recent FPT-AS for Matroid-Constrained MaxCov by Sellier [ESA 2023] for frequency-$d$ set systems.\n",
      "\n",
      "Completed MaxSAT, Cardinality Constraint, CNF-formula, MaxCov, Monotone, Approximation, Parameterized, FPT-Approximation, Reduction, Fairness abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The objective of domain generalization (DG) is to enhance the transferability of the model learned from a source domain to unobserved domains. To prevent overfitting to a specific domain, Sharpness-Aware Minimization (SAM) reduces source domain's loss sharpness. Although SAM variants have delivered significant improvements in DG, we highlight that there's still potential for improvement in generalizing to unknown domains through the exploration on data space. This paper introduces an objective rooted in both parameter and data perturbed regions for domain generalization, coined Unknown Domain Inconsistency Minimization (UDIM). UDIM reduces the loss landscape inconsistency between source domain and unknown domains. As unknown domains are inaccessible, these domains are empirically crafted by perturbing instances from the source domain dataset. In particular, by aligning the loss landscape acquired in the source domain to the loss landscape of perturbed domains, we expect to achieve generalization grounded on these flat minima for the unknown domains. Theoretically, we validate that merging SAM optimization with the UDIM objective establishes an upper bound for the true objective of the DG task. In an empirical aspect, UDIM consistently outperforms SAM variants across multiple DG benchmark datasets. Notably, UDIM shows statistically significant improvements in scenarios with more restrictive domain information, underscoring UDIM's generalization capability in unseen domains. Our code is available at \\url{https://github.com/SJShin-AI/UDIM}.\n",
      "\n",
      "Completed generalization, domain, sharpness, minimization, data, unknown, inconsistency, perturbed, parameter, landscape abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "With the proliferation of spatio-textual data, Top-k KNN spatial keyword queries (TkQs), which return a list of objects based on a ranking function that evaluates both spatial and textual relevance, have found many real-life applications. Existing geo-textual indexes for TkQs use traditional retrieval models like BM25 to compute text relevance and usually exploit a simple linear function to compute spatial relevance, but its effectiveness is limited. To improve effectiveness, several deep learning models have recently been proposed, but they suffer severe efficiency issues. To the best of our knowledge, there are no efficient indexes specifically designed to accelerate the top-k search process for these deep learning models.\n",
      "  To tackle these issues, we propose a novel technique, which Learns to Index the Spatio-Textual data for answering embedding based spatial keyword queries (called LIST). LIST is featured with two novel components. Firstly, we propose a lightweight and effective relevance model that is capable of learning both textual and spatial relevance. Secondly, we introduce a novel machine learning based Approximate Nearest Neighbor Search (ANNS) index, which utilizes a new learning-to-cluster technique to group relevant queries and objects together while separating irrelevant queries and objects. Two key challenges in building an effective and efficient index are the absence of high-quality labels and unbalanced clustering results. We develop a novel pseudo-label generation technique to address the two challenges. Experimental results show that LIST significantly outperforms state-of-the-art methods on effectiveness, with improvements up to 19.21% and 12.79% in terms of NDCG@1 and Recall@10, and is three orders of magnitude faster than the most effective baseline.\n",
      "\n",
      "Completed spatial, textual, data, deep, learning, embedding, relevance, clustering, effectiveness, efficiency abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In clinical practice, medical image segmentation provides useful information on the contours and dimensions of target organs or tissues, facilitating improved diagnosis, analysis, and treatment. In the past few years, convolutional neural networks (CNNs) and Transformers have dominated this area, but they still suffer from either limited receptive fields or costly long-range modeling. Mamba, a State Space Sequence Model (SSM), recently emerged as a promising paradigm for long-range dependency modeling with linear complexity. In this paper, we introduce a Large Window-based Mamba U}-shape Network, or LMa-UNet, for 2D and 3D medical image segmentation. A distinguishing feature of our LMa-UNet is its utilization of large windows, excelling in locally spatial modeling compared to small kernel-based CNNs and small window-based Transformers, while maintaining superior efficiency in global modeling compared to self-attention with quadratic complexity. Additionally, we design a novel hierarchical and bidirectional Mamba block to further enhance the global and neighborhood spatial modeling capability of Mamba. Comprehensive experiments demonstrate the effectiveness and efficiency of our method and the feasibility of using large window size to achieve large receptive fields. Codes are available at https://github.com/wjh892521292/LMa-UNet.\n",
      "\n",
      "Completed Medical, image, segmentation, large window, Mamba, convolutional neural networks, Transformers, State Space Sequence Model, global modeling, hierarchical abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Furihata and Matsuo proposed in 2010 an energy-conserving scheme for the Zakharov equations, as an application of the discrete variational derivative method (DVDM).\n",
      "  This scheme is distinguished from conventional methods (in particular the one devised by Glassey in 1992) in that the invariants are consistent with respect to time, but it has not been sufficiently studied both theoretically and numerically.\n",
      "  In this study, we theoretically prove the solvability under the loosest possible assumptions.\n",
      "  We also prove the convergence of this DVDM scheme by improving the argument by Glassey.\n",
      "  Furthermore, we perform intensive numerical experiments for comparing the above two schemes.\n",
      "  It is found that the DVDM scheme is superior in terms of accuracy, but since it is fully-implicit, the linearly-implicit Glassey scheme is better for practical efficiency.\n",
      "  In addition, we proposed a way to choose a solution for the first step that would allow Glassey's scheme to work more efficiently.\n",
      "\n",
      "Completed Zakharov, DVDM, invariants, Glassey, solvability, convergence, accuracy, efficiency, first step, solution abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Semantic communications (SemCom) have emerged as a new paradigm for supporting sixth-generation applications, where semantic features of data are transmitted using artificial intelligence algorithms to attain high communication efficiencies. Most existing SemCom techniques utilize deep neural networks (DNNs) to implement analog source-channel mappings, which are incompatible with existing digital communication architectures. To address this issue, this paper proposes a novel framework of digital deep joint source-channel coding (D$^2$-JSCC) targeting image transmission in SemCom. The framework features digital source and channel codings that are jointly optimized to reduce the end-to-end (E2E) distortion. First, deep source coding with an adaptive density model is designed to encode semantic features according to their distributions. Second, digital channel coding is employed to protect encoded features against channel distortion. To facilitate their joint design, the E2E distortion is characterized as a function of the source and channel rates via the analysis of the Bayesian model and Lipschitz assumption on the DNNs. Then to minimize the E2E distortion, a two-step algorithm is proposed to control the source-channel rates for a given channel signal-to-noise ratio. Simulation results reveal that the proposed framework outperforms classic deep JSCC and mitigates the cliff and leveling-off effects, which commonly exist for separation-based approaches.\n",
      "\n",
      "Completed semantic, communication, deep, joint, source, channel, coding, image, transmission, distortion abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "GEneral Matrix Multiply (GEMM) is a central operation in deep learning and corresponds to the largest chunk of the compute footprint. Therefore, improving its efficiency is an active topic of ongoing research. A popular strategy is the use of low bit-width integers to approximate the original entries in a matrix. This allows efficiency gains, but often requires sophisticated techniques to control the rounding error incurred. In this work, we first verify/check that when the low bit-width restriction is removed, for a variety of Transformer-based models, whether integers are sufficient for all GEMMs need -- for {\\em both} training and inference stages, and can achieve parity with floating point counterparts. No sophisticated techniques are needed. We find that while a large majority of entries in matrices (encountered in such models) can be easily represented by {\\em low} bit-width integers, the existence of a few heavy hitter entries make it difficult to achieve efficiency gains via the exclusive use of low bit-width GEMMs alone. To address this issue, we develop a simple algorithm, Integer Matrix Unpacking (IM-Unpack), to {\\em unpack} a matrix with large integer entries into a larger matrix whose entries all lie within the representable range of arbitrarily low bit-width integers. This allows {\\em equivalence} with the original GEMM, i.e., the exact result can be obtained using purely low bit-width integer GEMMs. This comes at the cost of additional operations -- we show that for many popular models, this overhead is quite small.\n",
      "\n",
      "Completed matrix, multiplication, deep learning, low bit-width, integers, transformer, rounding, IM-Unpack, equivalence, overhead abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Aspect Sentiment Triplet Extraction (ASTE) is a burgeoning subtask of fine-grained sentiment analysis, aiming to extract structured sentiment triplets from unstructured textual data. Existing approaches to ASTE often complicate the task with additional structures or external data. In this research, we propose a novel tagging scheme and employ a contrastive learning approach to mitigate these challenges. The proposed approach demonstrates comparable or superior performance in comparison to state-of-the-art techniques, while featuring a more compact design and reduced computational overhead. Notably, even in the era of Large Language Models (LLMs), our method exhibits superior efficacy compared to GPT 3.5 and GPT 4 in a few-shot learning scenarios. This study also provides valuable insights for the advancement of ASTE techniques within the paradigm of large language models.\n",
      "\n",
      "Completed Aspect, Sentiment, Triplet, Extraction, Tagging, Contrastive, Learning, Compact, Efficient, Large, Language, Models abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Reliable hand mesh reconstruction (HMR) from commonly-used color and depth sensors is challenging especially under scenarios with varied illuminations and fast motions. Event camera is a highly promising alternative for its high dynamic range and dense temporal resolution properties, but it lacks key texture appearance for hand mesh reconstruction. In this paper, we propose EvRGBHand -- the first approach for 3D hand mesh reconstruction with an event camera and an RGB camera compensating for each other. By fusing two modalities of data across time, space, and information dimensions,EvRGBHand can tackle overexposure and motion blur issues in RGB-based HMR and foreground scarcity and background overflow issues in event-based HMR. We further propose EvRGBDegrader, which allows our model to generalize effectively in challenging scenes, even when trained solely on standard scenes, thus reducing data acquisition costs. Experiments on real-world data demonstrate that EvRGBHand can effectively solve the challenging issues when using either type of camera alone via retaining the merits of both, and shows the potential of generalization to outdoor scenes and another type of event camera.\n",
      "\n",
      "Completed Hand, mesh, reconstruction, event, camera, RGB, illumination, motion, fusion, generalization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Video Motion Magnification (VMM) aims to reveal subtle and imperceptible motion information of objects in the macroscopic world. Prior methods directly model the motion field from the Eulerian perspective by Representation Learning that separates shape and texture or Multi-domain Learning from phase fluctuations. Inspired by the frequency spectrum, we observe that the low-frequency components with stable energy always possess spatial structure and less noise, making them suitable for modeling the subtle motion field. To this end, we present FD4MM, a new paradigm of Frequency Decoupling for Motion Magnification with a Multi-level Isomorphic Architecture to capture multi-level high-frequency details and a stable low-frequency structure (motion field) in video space. Since high-frequency details and subtle motions are susceptible to information degradation due to their inherent subtlety and unavoidable external interference from noise, we carefully design Sparse High/Low-pass Filters to enhance the integrity of details and motion structures, and a Sparse Frequency Mixer to promote seamless recoupling. Besides, we innovatively design a contrastive regularization for this task to strengthen the model's ability to discriminate irrelevant features, reducing undesired motion magnification. Extensive experiments on both Real-world and Synthetic Datasets show that our FD4MM outperforms SOTA methods. Meanwhile, FD4MM reduces FLOPs by 1.63$\\times$ and boosts inference speed by 1.68$\\times$ than the latest method. Our code is available at https://github.com/Jiafei127/FD4MM.\n",
      "\n",
      "Completed Motion, Magnification, Frequency, Decoupling, Architecture, Details, Filters, Mixer, Contrastive, Regularization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Currently, little research has been done on knowledge editing for Large Vision-Language Models (LVLMs). Editing LVLMs faces the challenge of effectively integrating diverse modalities (image and text) while ensuring coherent and contextually relevant modifications. An existing benchmark has three metrics (Reliability, Locality and Generality) to measure knowledge editing for LVLMs. However, the benchmark falls short in the quality of generated images used in evaluation and cannot assess whether models effectively utilize edited knowledge in relation to the associated content. We adopt different data collection methods to construct a new benchmark, $\\textbf{KEBench}$, and extend new metric (Portability) for a comprehensive evaluation. Leveraging a multimodal knowledge graph, our image data exhibits clear directionality towards entities. This directional aspect can be further utilized to extract entity-related knowledge and form editing data. We conducted experiments of different editing methods on five LVLMs, and thoroughly analyze how these methods impact the models. The results reveal strengths and deficiencies of these methods and, hopefully, provide insights into potential avenues for future research.\n",
      "\n",
      "Completed Knowledge, Editing, Large, Vision-Language, Models, KEBench, Portability, Image, Entities, Directionality abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Graph Neural Networks (GNNs) have achieved remarkable success in various real-world applications. However, GNNs may be trained on undesirable graph data, which can degrade their performance and reliability. To enable trained GNNs to efficiently unlearn unwanted data, a desirable solution is retraining-based graph unlearning, which partitions the training graph into subgraphs and trains sub-models on them, allowing fast unlearning through partial retraining. However, the graph partition process causes information loss in the training graph, resulting in the low model utility of sub-GNN models. In this paper, we propose GraphRevoker, a novel graph unlearning framework that better maintains the model utility of unlearnable GNNs. Specifically, we preserve the graph property with graph property-aware sharding and effectively aggregate the sub-GNN models for prediction with graph contrastive sub-model aggregation. We conduct extensive experiments to demonstrate the superiority of our proposed approach.\n",
      "\n",
      "Completed Graph, Neural, Networks, Unlearning, Retraining, Partitioning, Information, Loss, Utility, Aggregation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Skeleton-based motion representations are robust for action localization and understanding for their invariance to perspective, lighting, and occlusion, compared with images. Yet, they are often ambiguous and incomplete when taken out of context, even for human annotators. As infants discern gestures before associating them with words, actions can be conceptualized before being grounded with labels. Therefore, we propose the first unsupervised pre-training framework, Boundary-Interior Decoding (BID), that partitions a skeleton-based motion sequence into discovered semantically meaningful pre-action segments. By fine-tuning our pre-training network with a small number of annotated data, we show results out-performing SOTA methods by a large margin.\n",
      "\n",
      "Completed skeleton, motion, action, localization, understanding, perspective, lighting, occlusion, segmentation, unsupervised abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Continual learning requires a model to adapt to ongoing changes in the data distribution, and often to the set of tasks to be performed. It is rare, however, that the data and task changes are completely unpredictable. Given a description of an overarching goal or data theme, which we call a realm, humans can often guess what concepts are associated with it. We show here that the combination of a large language model and an image generation model can similarly provide useful premonitions as to how a continual learning challenge might develop over time. We use the large language model to generate text descriptions of semantically related classes that might potentially appear in the data stream in future. These descriptions are then rendered using Stable Diffusion to generate new labelled image samples. The resulting synthetic dataset is employed for supervised pre-training, but is discarded prior to commencing continual learning, along with the pre-training classification head. We find that the backbone of our pre-trained networks can learn representations useful for the downstream continual learning problem, thus becoming a valuable input to any existing continual learning method. Although there are complexities arising from the domain gap between real and synthetic images, we show that pre-training models in this manner improves multiple Class Incremenal Learning (CIL) methods on fine-grained image classification benchmarks. Supporting code can be found at https://github.com/cl-premonition/premonition.\n",
      "\n",
      "Completed continual learning, data distribution, task changes, realm, large language model, image generation model, synthetic dataset, pre-training, Class Incremental Learning, fine-grained image classification abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we develop a novel fast iterative moment method for the steady-state simulation of near-continuum flows, which are modeled by the high-order moment system derived from the Boltzmann-BGK equation. The fast convergence of the present method is mainly achieved by alternately solving the moment system and the hydrodynamic equations with compatible constitutive relations and boundary conditions. To be specific, the compatible hydrodynamic equations are solved in each iteration to get improved predictions of macroscopic quantities, which are subsequently utilized to expedite the evolution of the moment system. Additionally, a semi-implicit scheme treating the collision term implicitly is introduced for the moment system. With cell-by-cell sweeping strategy, the resulting alternating iteration can be further accelerated for steady-state computation. It is also worth mentioning that such an alternating iteration works well with the nonlinear multigrid method. Numerical experiments for planar Couette flow, shock structure, and lid-driven cavity flow are carried out to investigate the performance of the proposed fast iterative moment method, and all results show wonderful efficiency and robustness.\n",
      "\n",
      "Completed fast, iterative, moment, method, simulation, near-continuum, flows, hydrodynamic, equations, Boltzmann-BGK abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "While previous studies have demonstrated successful 3D object shape completion with a sufficient number of points, they often fail in scenarios when a few points, e.g. tens of points, are observed. Surprisingly, via entropy analysis, we find that even a few points, e.g. 64 points, could retain substantial information to help recover the 3D shape of the object. To address the challenge of shape completion with very sparse point clouds, we then propose Few-point Shape Completion (FSC) model, which contains a novel dual-branch feature extractor for handling extremely sparse inputs, coupled with an extensive branch for maximal point utilization with a saliency branch for dynamic importance assignment. This model is further bolstered by a two-stage revision network that refines both the extracted features and the decoder output, enhancing the detail and authenticity of the completed point cloud. Our experiments demonstrate the feasibility of recovering 3D shapes from a few points. The proposed FSC (FSC) model outperforms previous methods on both few-point inputs and many-point inputs, and shows good generalizability to different object categories.\n",
      "\n",
      "Completed 3D, object, shape, completion, sparse, point, clouds, entropy, features, saliency abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Injecting greenhouse gas into deep underground reservoirs for permanent storage can inadvertently lead to fault reactivation, caprock fracturing and greenhouse gas leakage when the injection-induced stress exceeds the critical threshold. Extraction of pre-existing fluids at various stages of injection process, referred as pressure management, can mitigate associated risks and lessen environmental impact. However, identifying optimal pressure management strategies typically requires thousands of full-order simulations due to the need for function evaluations, making the process computationally prohibitive. This paper introduces a novel surrogate model-based reinforcement learning method for devising optimal pressure management strategies for geological CO2 sequestration efficiently. Our approach comprises two steps. Firstly, a surrogate model is developed through the embed to control method, which employs an encoder-transition-decoder structure to learn latent dynamics. Leveraging this proxy model, reinforcement learning is utilized to find an optimal strategy that maximizes economic benefits while satisfying various control constraints. The reinforcement learning agent receives the latent state space representation and immediate reward tailored for CO2 sequestration and choose real-time controls which are subject to predefined engineering constraints in order to maximize the long-term cumulative rewards. To demonstrate its effectiveness, this framework is applied to a compositional simulation model where CO2 is injected into saline aquifer. The results reveal that our surrogate model-based reinforcement learning approach significantly optimizes CO2 sequestration strategies, leading to notable economic gains compared to baseline scenarios.\n",
      "\n",
      "Completed reinforcement, learning, pressure, management, CO2, sequestration, surrogate, model, optimization, economic abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The trustworthy machine learning (ML) community is increasingly recognizing the crucial need for models capable of selectively 'unlearning' data points after training. This leads to the problem of machine unlearning (MU), aiming to eliminate the influence of chosen data points on model performance, while still maintaining the model's utility post-unlearning. Despite various MU methods for data influence erasure, evaluations have largely focused on random data forgetting, ignoring the vital inquiry into which subset should be chosen to truly gauge the authenticity of unlearning performance. To tackle this issue, we introduce a new evaluative angle for MU from an adversarial viewpoint. We propose identifying the data subset that presents the most significant challenge for influence erasure, i.e., pinpointing the worst-case forget set. Utilizing a bi-level optimization principle, we amplify unlearning challenges at the upper optimization level to emulate worst-case scenarios, while simultaneously engaging in standard training and unlearning at the lower level, achieving a balance between data influence erasure and model utility. Our proposal offers a worst-case evaluation of MU's resilience and effectiveness. Through extensive experiments across different datasets (including CIFAR-10, 100, CelebA, Tiny ImageNet, and ImageNet) and models (including both image classifiers and generative models), we expose critical pros and cons in existing (approximate) unlearning strategies. Our results illuminate the complex challenges of MU in practice, guiding the future development of more accurate and robust unlearning algorithms. The code is available at https://github.com/OPTML-Group/Unlearn-WorstCase.\n",
      "\n",
      "Completed machine, learning, unlearning, influence, erasure, subset, adversarial, worst-case, forget, evaluation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Classification is essential to the applications in the field of data mining, artificial intelligence, and fault detection. There exists a strong need in developing accurate, suitable, and efficient classification methods and algorithms with broad applicability. Random forest is a general algorithm that is often used for classification under complex conditions. Although it has been widely adopted, its combination with diverse fuzzy theory is still worth exploring. In this paper, we propose the intuitionistic fuzzy random forest (IFRF), a new random forest ensemble of intuitionistic fuzzy decision trees (IFDT). Such trees in forest use intuitionistic fuzzy information gain to select features and consider hesitation in information transmission. The proposed method enjoys the power of the randomness from bootstrapped sampling and feature selection, the flexibility of fuzzy logic and fuzzy sets, and the robustness of multiple classifier systems. Extensive experiments demonstrate that the IFRF has competitative and superior performance compared to other state-of-the-art fuzzy and ensemble algorithms. IFDT is more suitable for ensemble learning with outstanding classification accuracy. This study is the first to propose a random forest ensemble based on the intuitionistic fuzzy theory.\n",
      "\n",
      "Completed classification, data mining, artificial intelligence, fault detection, random forest, fuzzy theory, intuitionistic fuzzy random forest, intuitionistic fuzzy decision trees, bootstrapped sampling, ensemble learning abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Test-time adaptation (TTA) fine-tunes pre-trained deep neural networks for unseen test data. The primary challenge of TTA is limited access to the entire test dataset during online updates, causing error accumulation. To mitigate it, TTA methods have utilized the model output's entropy as a confidence metric that aims to determine which samples have a lower likelihood of causing error. Through experimental studies, however, we observed the unreliability of entropy as a confidence metric for TTA under biased scenarios and theoretically revealed that it stems from the neglect of the influence of latent disentangled factors of data on predictions. Building upon these findings, we introduce a novel TTA method named Destroy Your Object (DeYO), which leverages a newly proposed confidence metric named Pseudo-Label Probability Difference (PLPD). PLPD quantifies the influence of the shape of an object on prediction by measuring the difference between predictions before and after applying an object-destructive transformation. DeYO consists of sample selection and sample weighting, which employ entropy and PLPD concurrently. For robust adaptation, DeYO prioritizes samples that dominantly incorporate shape information when making predictions. Our extensive experiments demonstrate the consistent superiority of DeYO over baseline methods across various scenarios, including biased and wild. Project page is publicly available at https://whitesnowdrop.github.io/DeYO/.\n",
      "\n",
      "Completed Test-time, Adaptation, Entropy, Confidence, Bias, Disentangled, Factors, Pseudo-Label, Probability, Difference abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we study the problem of Generalized Category Discovery (GCD), which aims to cluster unlabeled data from both known and unknown categories using the knowledge of labeled data from known categories. Current GCD methods rely on only visual cues, which however neglect the multi-modality perceptive nature of human cognitive processes in discovering novel visual categories. To address this, we propose a two-phase TextGCD framework to accomplish multi-modality GCD by exploiting powerful Visual-Language Models. TextGCD mainly includes a retrieval-based text generation (RTG) phase and a cross-modality co-teaching (CCT) phase. First, RTG constructs a visual lexicon using category tags from diverse datasets and attributes from Large Language Models, generating descriptive texts for images in a retrieval manner. Second, CCT leverages disparities between textual and visual modalities to foster mutual learning, thereby enhancing visual GCD. In addition, we design an adaptive class aligning strategy to ensure the alignment of category perceptions between modalities as well as a soft-voting mechanism to integrate multi-modality cues. Experiments on eight datasets show the large superiority of our approach over state-of-the-art methods. Notably, our approach outperforms the best competitor, by 7.7% and 10.8% in All accuracy on ImageNet-1k and CUB, respectively.\n",
      "\n",
      "Completed Generalized, Category, Discovery, Multi-Modality, Visual, Language, Models, TextGCD, Cross-Modality, Co-Teaching abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This study discusses the critical issues of Virtual Try-On in contemporary e-commerce and the prospective metaverse, emphasizing the challenges of preserving intricate texture details and distinctive features of the target person and the clothes in various scenarios, such as clothing texture and identity characteristics like tattoos or accessories. In addition to the fidelity of the synthesized images, the efficiency of the synthesis process presents a significant hurdle. Various existing approaches are explored, highlighting the limitations and unresolved aspects, e.g., identity information omission, uncontrollable artifacts, and low synthesis speed. It then proposes a novel diffusion-based solution that addresses garment texture preservation and user identity retention during virtual try-on. The proposed network comprises two primary modules - a warping module aligning clothing with individual features and a try-on module refining the attire and generating missing parts integrated with a mask-aware post-processing technique ensuring the integrity of the individual's identity. It demonstrates impressive results, surpassing the state-of-the-art in speed by nearly 20 times during inference, with superior fidelity in qualitative assessments. Quantitative evaluations confirm comparable performance with the recent SOTA method on the VITON-HD and Dresscode datasets.\n",
      "\n",
      "Completed Virtual, Try-On, E-commerce, Metaverse, Texture, Identity, Diffusion, Warping, Post-processing, Fidelity abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recent 3D object detectors typically utilize multi-sensor data and unify multi-modal features in the shared bird's-eye view (BEV) representation space. However, our empirical findings indicate that previous methods have limitations in generating fusion BEV features free from cross-modal conflicts. These conflicts encompass extrinsic conflicts caused by BEV feature construction and inherent conflicts stemming from heterogeneous sensor signals. Therefore, we propose a novel Eliminating Conflicts Fusion (ECFusion) method to explicitly eliminate the extrinsic/inherent conflicts in BEV space and produce improved multi-modal BEV features. Specifically, we devise a Semantic-guided Flow-based Alignment (SFA) module to resolve extrinsic conflicts via unifying spatial distribution in BEV space before fusion. Moreover, we design a Dissolved Query Recovering (DQR) mechanism to remedy inherent conflicts by preserving objectness clues that are lost in the fusion BEV feature. In general, our method maximizes the effective information utilization of each modality and leverages inter-modal complementarity. Our method achieves state-of-the-art performance in the highly competitive nuScenes 3D object detection dataset. The code is released at https://github.com/fjhzhixi/ECFusion.\n",
      "\n",
      "Completed 3D, object, detection, multi-sensor, multi-modal, BEV, fusion, conflicts, SFA, DQR abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Vision-and-Language Navigation (VLN), as a crucial research problem of Embodied AI, requires an embodied agent to navigate through complex 3D environments following natural language instructions. Recent research has highlighted the promising capacity of large language models (LLMs) in VLN by improving navigational reasoning accuracy and interpretability. However, their predominant use in an offline manner usually suffers from substantial domain gap between the VLN task and the LLM training corpus. This paper introduces a novel strategy called Navigational Chain-of-Thought (NavCoT), where we fulfill parameter-efficient in-domain training to enable self-guided navigational decision, leading to a significant mitigation of the domain gap in a cost-effective manner. Specifically, at each timestep, the LLM is prompted to forecast the navigational chain-of-thought by: 1) acting as a world model to imagine the next observation according to the instruction, 2) selecting the candidate observation that best aligns with the imagination, and 3) determining the action based on the reasoning from the prior steps. Through constructing formalized labels for training, the LLM can learn to generate desired and reasonable chain-of-thought outputs for improving the action decision. Experimental results across various training settings and popular VLN benchmarks (e.g., Room-to-Room (R2R), Room-across-Room (RxR), Room-for-Room (R4R)) show the significant superiority of NavCoT over the direct action prediction variants. Through simple parameter-efficient finetuning, our NavCoT outperforms a recent GPT4-based approach with ~7% relative improvement on the R2R dataset. We believe that NavCoT will help unlock more task-adaptive and scalable LLM-based embodied agents, which are helpful for developing real-world robotics applications. Code is available at https://github.com/expectorlin/NavCoT.\n",
      "\n",
      "Completed Vision-and-Language Navigation, Embodied AI, Large Language Models, Navigational Chain-of-Thought, In-Domain Training, Self-Guided Navigation, Domain Gap Mitigation, Cost-Effective, Formalized Labels, Task-Adaptive Embodied Agents abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The advancements in Large Language Models (LLMs) have been hindered by their substantial sizes, which necessitate LLM compression methods for practical deployment. Singular Value Decomposition (SVD) offers a promising solution for LLM compression. However, state-of-the-art SVD-based LLM compression methods have two key limitations: truncating smaller singular values may lead to higher compression loss, and the lack of update on the remaining model parameters after SVD truncation. In this work, we propose SVD-LLM, a new SVD-based LLM compression method that addresses the limitations of existing methods. SVD-LLM incorporates a truncation-aware data whitening strategy to ensure a direct mapping between singular values and compression loss. Moreover, SVD-LLM adopts a layer-wise closed-form model parameter update strategy to compensate for accuracy degradation caused by SVD truncation. We evaluate SVD-LLM on a total of 11 datasets and seven models from three different LLM families at four different scales. Our results demonstrate the superiority of SVD-LLM over state-of-the-arts, especially at high model compression ratios. The source code is available at https://github.com/AIoT-MLSys-Lab/SVD-LLM.\n",
      "\n",
      "Completed SVD, LLM, compression, truncation-aware, data whitening, closed-form update, high ratios, state-of-the-art, family scale, source code abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We propose a fresh take on understanding the mechanisms of neural networks by analyzing the rich structure of parameters contained within their optimization trajectories. Towards this end, we introduce some natural notions of the complexity of optimization trajectories, both qualitative and quantitative, which reveal the inherent nuance and interplay involved between various optimization choices, such as momentum, weight decay, and batch size. We use them to provide key hallmarks about the nature of optimization in deep neural networks: when it goes right, and when it finds itself in a dead end. Further, thanks to our trajectory perspective, we uncover an intertwined behaviour of momentum and weight decay that promotes directional exploration, as well as a directional regularization behaviour of some others. We perform experiments over large-scale vision and language settings, including large language models (LLMs) with up to 12 billion parameters, to demonstrate the value of our approach.\n",
      "\n",
      "Completed Neural, Networks, Parameters, Optimization, Trajectories, Complexity, Momentum, Weight Decay, Batch Size, Language Models abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Image deraining have have gained a great deal of attention in order to address the challenges posed by the effects of harsh weather conditions on visual tasks. While convolutional neural networks (CNNs) are popular, their limitations in capturing global information may result in ineffective rain removal. Transformer-based methods with self-attention mechanisms have improved, but they tend to distort high-frequency details that are crucial for image fidelity. To solve this problem, we propose the Gabor-guided tranformer (Gabformer) for single image deraining. The focus on local texture features is enhanced by incorporating the information processed by the Gabor filter into the query vector, which also improves the robustness of the model to noise due to the properties of the filter. Extensive experiments on the benchmarks demonstrate that our method outperforms state-of-the-art approaches.\n",
      "\n",
      "Completed rain, deraining, transformer, attention, Gabor, texture, noise, robustness, images, benchmarks abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Despite the effectiveness of data selection for large language models (LLMs) during pretraining and instruction fine-tuning phases, improving data efficiency in supervised fine-tuning (SFT) for specialized domains poses significant challenges due to the complexity of fine-tuning data. To bridge this gap, we introduce an effective and scalable data selection method for SFT, SmallToLarge (S2L), which leverages training trajectories from small models to guide the data selection for larger models. We demonstrate through extensive experiments that S2L significantly improves data efficiency in SFT for mathematical problem-solving, reducing the training data to just 11% of the original MathInstruct dataset (Yue et al., 2023) to match full dataset performance while outperforming state-of-the-art data selection algorithms by an average of 4.7% across 6 in- and out-domain evaluation datasets. Remarkably, selecting only 50K data for SFT, S2L achieves a 32.7% accuracy on the most challenging MATH (Hendrycks et al., 2021) benchmark, improving Phi-2 (Li et al., 2023b) by 16.6%. In clinical text summarization on the MIMIC-III dataset (Johnson et al., 2016), S2L again outperforms training on the full dataset using only 50% of the data. Notably, S2L can perform data selection using a reference model 40x smaller than the target model, proportionally reducing the cost of data selection.\n",
      "\n",
      "Completed Data, Selection, Supervised, Fine-tuning, LLMs, S2L, Training, Scalable, Efficiency, Performance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In recent years, semantic communication is progressively emerging as an effective means of facilitating intelligent and context-aware communication. However, current researches seldom simultaneously consider the reliability and timeliness of semantic communication, where scheduling and resource allocation (SRA) plays a crucial role. In contrast, conventional age-based approaches cannot seamlessly extend to semantic communication due to their oversight of semantic importance. To bridge this gap, we introduce a novel metric: Age of Semantic Importance (AoSI), which adaptly captures both the freshness of information and its semantic importance. Utilizing AoSI, we formulate an average AoSI minimization problem by optimizing multi-source SRA. To address this problem, we proposed a AoSI-aware joint SRA algorithm based on Deep Q-Network (DQN). Simulation results validate the effectiveness of our proposed method, demonstrating its ability to facilitate timely and reliable semantic communication.\n",
      "\n",
      "Completed semantic, communication, scheduling, resource, allocation, AoSI, freshness, importance, DQN, optimization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Generative models enable the translation from a source image domain where readily trained models are available to a target domain unseen during training. While Cycle Generative Adversarial Networks (GANs) are well established, the associated cycle consistency constrain relies on that an invertible mapping exists between the two domains. This is, however, not the case for the translation between images stained with chromogenic monoplex and duplex immunohistochemistry (IHC) assays. Focusing on the translation from the latter to the first, we propose - through the introduction of a novel training design, an alternative constrain leveraging a set of immunofluorescence (IF) images as an auxiliary unpaired image domain. Quantitative and qualitative results on a downstream segmentation task show the benefit of the proposed method in comparison to baseline approaches.\n",
      "\n",
      "Completed CycleGAN, generative, translation, immunohistochemistry, unpaired, auxiliary, segmentation, monoplex, duplex, IF abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Although Vision Transformer (ViT) has achieved significant success in computer vision, it does not perform well in dense prediction tasks due to the lack of inner-patch information interaction and the limited diversity of feature scale. Most existing studies are devoted to designing vision-specific transformers to solve the above problems, which introduce additional pre-training costs. Therefore, we present a plain, pre-training-free, and feature-enhanced ViT backbone with Convolutional Multi-scale feature interaction, named ViT-CoMer, which facilitates bidirectional interaction between CNN and transformer. Compared to the state-of-the-art, ViT-CoMer has the following advantages: (1) We inject spatial pyramid multi-receptive field convolutional features into the ViT architecture, which effectively alleviates the problems of limited local information interaction and single-feature representation in ViT. (2) We propose a simple and efficient CNN-Transformer bidirectional fusion interaction module that performs multi-scale fusion across hierarchical features, which is beneficial for handling dense prediction tasks. (3) We evaluate the performance of ViT-CoMer across various dense prediction tasks, different frameworks, and multiple advanced pre-training. Notably, our ViT-CoMer-L achieves 64.3% AP on COCO val2017 without extra training data, and 62.1% mIoU on ADE20K val, both of which are comparable to state-of-the-art methods. We hope ViT-CoMer can serve as a new backbone for dense prediction tasks to facilitate future research. The code will be released at https://github.com/Traffic-X/ViT-CoMer.\n",
      "\n",
      "Completed Vision Transformer, Convolutional Multi-scale, CNN-Transformer, Dense Prediction, Feature Enhancement, Object Detection, Instance Segmentation, Spatial Pyramid, Multi-receptive Field, Multi-scale Fusion abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Event commonsense reasoning requires the ability to reason about the relationship between events, as well as infer implicit context underlying that relationship. However, data scarcity makes it challenging for language models to learn to generate commonsense inferences for contexts and questions involving interactions between complex events. To address this demand, we present COM2 (COMplex COMmonsense), a new dataset created by sampling multi-hop logical queries (e.g., the joint effect or cause of both event A and B, or the effect of the effect of event C) from an existing commonsense knowledge graph (CSKG), and verbalizing them using handcrafted rules and large language models into multiple-choice and text generation questions. Our experiments show that language models trained on COM2 exhibit significant improvements in complex reasoning ability, resulting in enhanced zero-shot performance in both in-domain and out-of-domain tasks for question answering and generative commonsense reasoning, without expensive human annotations.\n",
      "\n",
      "Completed commonsense, reasoning, events, knowledge, data, scarcity, language, models, COM2, multi-hop abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The precise recognition of food categories plays a pivotal role for intelligent health management, attracting significant research attention in recent years. Prominent benchmarks, such as Food-101 and VIREO Food-172, provide abundant food image resources that catalyze the prosperity of research in this field. Nevertheless, these datasets are well-curated from canteen scenarios and thus deviate from food appearances in daily life. This discrepancy poses great challenges in effectively transferring classifiers trained on these canteen datasets to broader daily-life scenarios encountered by humans. Toward this end, we present two new benchmarks, namely DailyFood-172 and DailyFood-16, specifically designed to curate food images from everyday meals. These two datasets are used to evaluate the transferability of approaches from the well-curated food image domain to the everyday-life food image domain. In addition, we also propose a simple yet effective baseline method named Multi-Cluster Reference Learning (MCRL) to tackle the aforementioned domain gap. MCRL is motivated by the observation that food images in daily-life scenarios exhibit greater intra-class appearance variance compared with those in well-curated benchmarks. Notably, MCRL can be seamlessly coupled with existing approaches, yielding non-trivial performance enhancements. We hope our new benchmarks can inspire the community to explore the transferability of food recognition models trained on well-curated datasets toward practical real-life applications.\n",
      "\n",
      "Completed Food, recognition, benchmarks, daily, life, transfer, domain, gap, MCRL, performance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Driven by the demand for energy-efficient employment of deep neural networks, early-exit methods have experienced a notable increase in research attention. These strategies allow for swift predictions by making decisions early in the network, thereby conserving computation time and resources. However, so far the early-exit networks have only been developed for stationary data distributions, which restricts their application in real-world scenarios with continuous non-stationary data. This study aims to explore the continual learning of the early-exit networks. We adapt existing continual learning methods to fit with early-exit architectures and investigate their behavior in the continual setting. We notice that early network layers exhibit reduced forgetting and can outperform standard networks even when using significantly fewer resources. Furthermore, we analyze the impact of task-recency bias on early-exit inference and propose Task-wise Logits Correction (TLC), a simple method that equalizes this bias and improves the network performance for every given compute budget in the class-incremental setting. We assess the accuracy and computational cost of various continual learning techniques enhanced with early-exits and TLC across standard class-incremental learning benchmarks such as 10 split CIFAR100 and ImageNetSubset and show that TLC can achieve the accuracy of the standard methods using less than 70\\% of their computations. Moreover, at full computational budget, our method outperforms the accuracy of the standard counterparts by up to 15 percentage points. Our research underscores the inherent synergy between early-exit networks and continual learning, emphasizing their practical utility in resource-constrained environments.\n",
      "\n",
      "Completed early-exit, networks, continual learning, non-stationary data, task-recency bias, Task-wise Logits Correction, resource efficiency, class-incremental learning, CIFAR100, ImageNetSubset abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Exemplar-free class-incremental learning (EFCIL) poses significant challenges, primarily due to catastrophic forgetting, necessitating a delicate balance between stability and plasticity to accurately recognize both new and previous classes. Traditional EFCIL approaches typically skew towards either model plasticity through successive fine-tuning or stability by employing a fixed feature extractor beyond the initial incremental state. Building upon the foundational FeTrIL framework, our research extends into novel experimental domains to examine the efficacy of various oversampling techniques and dynamic optimization strategies across multiple challenging datasets and incremental settings. We specifically explore how oversampling impacts accuracy relative to feature availability and how different optimization methodologies, including dynamic recalibration and feature pool diversification, influence incremental learning outcomes. The results from these comprehensive experiments, conducted on CIFAR100, Tiny-ImageNet, and an ImageNet-Subset, under-score the superior performance of FeTrIL in balancing accuracy for both new and past classes against ten contemporary methods. Notably, our extensions reveal the nuanced impacts of oversampling and optimization on EFCIL, contributing to a more refined understanding of feature-space manipulation for class incremental learning. FeTrIL and its extended analysis in this paper FeTrIL++ pave the way for more adaptable and efficient EFCIL methodologies, promising significant improvements in handling catastrophic forgetting without the need for exemplars.\n",
      "\n",
      "Completed Exemplar-free, Class-incremental, Learning, Stability, Plasticity, Oversampling, Optimization, Dynamic, Feature-space, Manipulation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Medical image classification requires labeled, task-specific datasets which are used to train deep learning networks de novo, or to fine-tune foundation models. However, this process is computationally and technically demanding. In language processing, in-context learning provides an alternative, where models learn from within prompts, bypassing the need for parameter updates. Yet, in-context learning remains underexplored in medical image analysis. Here, we systematically evaluate the model Generative Pretrained Transformer 4 with Vision capabilities (GPT-4V) on cancer image processing with in-context learning on three cancer histopathology tasks of high importance: Classification of tissue subtypes in colorectal cancer, colon polyp subtyping and breast tumor detection in lymph node sections. Our results show that in-context learning is sufficient to match or even outperform specialized neural networks trained for particular tasks, while only requiring a minimal number of samples. In summary, this study demonstrates that large vision language models trained on non-domain specific data can be applied out-of-the box to solve medical image-processing tasks in histopathology. This democratizes access of generalist AI models to medical experts without technical background especially for areas where annotated data is scarce.\n",
      "\n",
      "Completed Medical, image, classification, in-context, learning, GPT-4V, histopathology, colorectal, cancer, breast abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Masked autoencoder (MAE) shows that severe augmentation during training produces robust representations for high-level tasks. This paper brings the MAE-like framework to nighttime image enhancement, demonstrating that severe augmentation during training produces strong network priors that are resilient to real-world night haze degradations. We propose a novel nighttime image dehazing method with self-prior learning. Our main novelty lies in the design of severe augmentation, which allows our model to learn robust priors. Unlike MAE that uses masking, we leverage two key challenging factors of nighttime images as augmentation: light effects and noise. During training, we intentionally degrade clear images by blending them with light effects as well as by adding noise, and subsequently restore the clear images. This enables our model to learn clear background priors. By increasing the noise values to approach as high as the pixel intensity values of the glow and light effect blended images, our augmentation becomes severe, resulting in stronger priors. While our self-prior learning is considerably effective in suppressing glow and revealing details of background scenes, in some cases, there are still some undesired artifacts that remain, particularly in the forms of over-suppression. To address these artifacts, we propose a self-refinement module based on the semi-supervised teacher-student framework. Our NightHaze, especially our MAE-like self-prior learning, shows that models trained with severe augmentation effectively improve the visibility of input haze images, approaching the clarity of clear nighttime images. Extensive experiments demonstrate that our NightHaze achieves state-of-the-art performance, outperforming existing nighttime image dehazing methods by a substantial margin of 15.5% for MUSIQ and 23.5% for ClipIQA.\n",
      "\n",
      "Completed nighttime, image enhancement, severe augmentation, MAE, self-prior learning, light effects, noise, over-suppression, self-refinement module, performance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We establish a coding theorem and a matching converse theorem for separate encodings and joint decoding of individual sequences using finite-state machines. The achievable rate region is characterized in terms of the Lempel-Ziv (LZ) complexities, the conditional LZ complexities and the joint LZ complexity of the two source sequences. An important feature that is needed to this end, which may be interesting on its own right, is a certain asymptotic form of a chain rule for LZ complexities, which we establish in this work. The main emphasis in the achievability scheme is on the universal decoder and its properties. We then show that the achievable rate region is universally attainable by a modified version of Draper's universal incremental Slepian-Wolf (SW) coding scheme, provided that there exists a low-rate reliable feedback link.\n",
      "\n",
      "Completed codable, complexities, decoding, finite-state, incremental, Lempel-Ziv, machines, sequences, Slepian-Wolf, universal abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper addresses point-to-point packet routing in undirected networks, which is the most important communication primitive in most networks. The main result proves the existence of routing tables that guarantee a polylog-competitive completion-time $\\textbf{deterministically}$: in any undirected network, it is possible to give each node simple stateless deterministic local forwarding rules, such that, any adversarially chosen set of packets are delivered as fast as possible, up to polylog factors.\n",
      "  All previous routing strategies crucially required randomization for both route selection and packet scheduling.\n",
      "  The core technical contribution of this paper is a new local packet scheduling result of independent interest. This scheduling strategy integrates well with recent sparse semi-oblivious path selection strategies. Such strategies deterministically select not one but several candidate paths for each packet and require a global coordinator to select a single good path from those candidates for each packet. Another challenge is that, even if a single path is selected for each packet, no strategy for scheduling packets along low-congestion paths that is both local and deterministic is known. Our novel scheduling strategy utilizes the fact that every semi-oblivious routing strategy uses only a small (polynomial) subset of candidate routes. It overcomes the issue of global coordination by furthermore being provably robust to adversarial noise. This avoids the issue of having to choose a single path per packet because congestion caused by ineffective candidate paths can be treated as noise.\n",
      "  Our results imply the first deterministic universally-optimal algorithms in the distributed supported-CONGEST model for many important global distributed tasks, including computing minimum spanning trees, approximate shortest paths, and part-wise aggregates.\n",
      "\n",
      "Completed packet, routing, undirected, network, deterministic, completion-time, local, scheduling, path, selection abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recent advances in algorithmic design show how to utilize predictions obtained by machine learning models from past and present data. These approaches have demonstrated an enhancement in performance when the predictions are accurate, while also ensuring robustness by providing worst-case guarantees when predictions fail. In this paper we focus on online problems; prior research in this context was focused on a paradigm where the predictor is pre-trained on past data and then used as a black box (to get the predictions it was trained for). In contrast, in this work, we unpack the predictor and integrate the learning problem it gives rise for within the algorithmic challenge. In particular we allow the predictor to learn as it receives larger parts of the input, with the ultimate goal of designing online learning algorithms specifically tailored for the algorithmic task at hand. Adopting this perspective, we focus on a number of fundamental problems, including caching and scheduling, which have been well-studied in the black-box setting. For each of the problems we consider, we introduce new algorithms that take advantage of explicit learning algorithms which we carefully design towards optimizing the overall performance. We demonstrate the potential of our approach by deriving performance bounds which improve over those established in previous work.\n",
      "\n",
      "Completed algorithmic, black-box, caching, learning, machine learning, online, predictor, predictions, problems, scheduling abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We introduce DragAnything, which utilizes a entity representation to achieve motion control for any object in controllable video generation. Comparison to existing motion control methods, DragAnything offers several advantages. Firstly, trajectory-based is more userfriendly for interaction, when acquiring other guidance signals (e.g., masks, depth maps) is labor-intensive. Users only need to draw a line (trajectory) during interaction. Secondly, our entity representation serves as an open-domain embedding capable of representing any object, enabling the control of motion for diverse entities, including background. Lastly, our entity representation allows simultaneous and distinct motion control for multiple objects. Extensive experiments demonstrate that our DragAnything achieves state-of-the-art performance for FVD, FID, and User Study, particularly in terms of object motion control, where our method surpasses the previous methods (e.g., DragNUWA) by 26% in human voting.\n",
      "\n",
      "Completed DragAnything, entity representation, motion control, controllable video generation, trajectory-based, user-friendly, open-domain embedding, diverse entities, multiple objects, state-of-the-art abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "A beam-slider system is considered whose passive self-adaption relies on an intricate locomotion process involving both frictional and unilateral contact. The system also exploits geometric nonlinearity to achieve broadband efficacy. The dynamics of the system take place on three distinct time scales: On the fast time scale of the harmonic base excitation are the vibrations and the locomotion cycle. On the slow time scale, the slider changes its position along the beam, and the overall vibration level varies. Finally, on an intermediate time scale, strong modulations of the vibration amplitude may take place. In the present work, first, an analytical approximation of the beam's response on the slow time scale is derived as function of the slider position, which is a crucial prerequisite for identifying the main drivers of the slider's locomotion. Then, the most important forms of locomotion are described and approximations of their individual contribution to the overall slider transport are estimated. Finally, the theoretical results are compared against numerical results obtained from an experimentally validated model.\n",
      "\n",
      "Completed beam-slider, self-adaption, locomotion, friction, unilateral contact, geometric nonlinearity, broadband efficacy, time scales, vibration amplitude, slider transport abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Single RGB or LiDAR is the mainstream sensor for the challenging scene flow, which relies heavily on visual features to match motion features. Compared with single modality, existing methods adopt a fusion strategy to directly fuse the cross-modal complementary knowledge in motion space. However, these direct fusion methods may suffer the modality gap due to the visual intrinsic heterogeneous nature between RGB and LiDAR, thus deteriorating motion features. We discover that event has the homogeneous nature with RGB and LiDAR in both visual and motion spaces. In this work, we bring the event as a bridge between RGB and LiDAR, and propose a novel hierarchical visual-motion fusion framework for scene flow, which explores a homogeneous space to fuse the cross-modal complementary knowledge for physical interpretation. In visual fusion, we discover that event has a complementarity (relative v.s. absolute) in luminance space with RGB for high dynamic imaging, and has a complementarity (local boundary v.s. global shape) in scene structure space with LiDAR for structure integrity. In motion fusion, we figure out that RGB, event and LiDAR are complementary (spatial-dense, temporal-dense v.s. spatiotemporal-sparse) to each other in correlation space, which motivates us to fuse their motion correlations for motion continuity. The proposed hierarchical fusion can explicitly fuse the multimodal knowledge to progressively improve scene flow from visual space to motion space. Extensive experiments have been performed to verify the superiority of the proposed method.\n",
      "\n",
      "Completed event, RGB, LiDAR, scene flow, fusion, visual, motion, complementary knowledge, heterogeneous nature, homogeneous space abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Event-based moving object detection is a challenging task, where static background and moving object are mixed together. Typically, existing methods mainly align the background events to the same spatial coordinate system via motion compensation to distinguish the moving object. However, they neglect the potential spatial tailing effect of moving object events caused by excessive motion, which may affect the structure integrity of the extracted moving object. We discover that the moving object has a complete columnar structure in the point cloud composed of motion-compensated events along the timestamp. Motivated by this, we propose a novel joint spatio-temporal reasoning method for event-based moving object detection. Specifically, we first compensate the motion of background events using inertial measurement unit. In spatial reasoning stage, we project the compensated events into the same image coordinate, discretize the timestamp of events to obtain a time image that can reflect the motion confidence, and further segment the moving object through adaptive threshold on the time image. In temporal reasoning stage, we construct the events into a point cloud along timestamp, and use RANSAC algorithm to extract the columnar shape in the cloud for peeling off the background. Finally, we fuse the results from the two reasoning stages to extract the final moving object region. This joint spatio-temporal reasoning framework can effectively detect the moving object from motion confidence and geometric structure. Moreover, we conduct extensive experiments on various datasets to verify that the proposed method can improve the moving object detection accuracy by 13\\%.\n",
      "\n",
      "Completed event-based, moving object detection, motion compensation, spatial tailing, columnar structure, spatio-temporal reasoning, motion confidence, geometric structure, RANSAC, background segmentation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The goal of object pose estimation is to visually determine the pose of a specific object in the RGB-D input. Unfortunately, when faced with new categories, both instance-based and category-based methods are unable to deal with unseen objects of unseen categories, which is a challenge for pose estimation. To address this issue, this paper proposes a method to introduce geometric features for pose estimation of point clouds without requiring category information. The method is based only on the patch feature of the point cloud, a geometric feature with rotation invariance. After training without category information, our method achieves as good results as other category-based methods. Our method successfully achieved pose annotation of no category information instances on the CAMERA25 dataset and ModelNet40 dataset.\n",
      "\n",
      "Completed object, pose, estimation, unseen, categories, geometric, features, point, clouds, rotation, invariance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Fine-tuning techniques based on Large Pretrained Language Models (LPLMs) have been proven to significantly enhance model performance on a variety of downstream tasks and effectively control the output behaviors of LPLMs. Recent studies have proposed numerous methods for fine-tuning a small number of parameters based on open-source LPLMs, reducing the demand for computational and storage resources. Among these, reparameterization fine-tuning methods represented by LoRA (Low-Rank Adaptation) have gained popularity. We find that although these methods perform well in many aspects, there is still considerable room for improvement in terms of complex task adaptability, performance, stability, and algorithm complexity. In response to this, inspired by the idea that the functions of the brain are shaped by its geometric structure, this paper integrates this idea into LoRA technology and proposes a new matrix transformation-based reparameterization method for efficient fine-tuning, named Matrix-Transformation based Low-Rank Adaptation (MTLoRA). MTLoRA aims to dynamically alter its spatial geometric structure by applying a transformation-matrix T to perform linear transformations, such as rotation, scaling, and translation, on the task-specific parameter matrix, generating new matrix feature patterns (eigenvectors) to mimic the fundamental influence of complex geometric structure feature patterns in the brain on functions, thereby enhancing the model's performance in downstream tasks. In Natural Language Understanding (NLU) tasks, it is evaluated using the GLUE benchmark test, and the results reveal that MTLoRA achieves an overall performance increase of about 1.0% across eight tasks; in Natural Language Generation (NLG) tasks, MTLoRA improves performance by an average of 0.95% and 0.31% in the DART and WebNLG tasks, respectively.\n",
      "\n",
      "Completed Fine-tuning, LPLMs, LoRA, Reparamaterization, Matrix-Transformation, Geometry, Brain, MTLoRA, NLU, NLG abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We study the problem of domain adaptation under distribution shift, where the shift is due to a change in the distribution of an unobserved, latent variable that confounds both the covariates and the labels. In this setting, neither the covariate shift nor the label shift assumptions apply. Our approach to adaptation employs proximal causal learning, a technique for estimating causal effects in settings where proxies of unobserved confounders are available. We demonstrate that proxy variables allow for adaptation to distribution shift without explicitly recovering or modeling latent variables. We consider two settings, (i) Concept Bottleneck: an additional ''concept'' variable is observed that mediates the relationship between the covariates and labels; (ii) Multi-domain: training data from multiple source domains is available, where each source domain exhibits a different distribution over the latent confounder. We develop a two-stage kernel estimation approach to adapt to complex distribution shifts in both settings. In our experiments, we show that our approach outperforms other methods, notably those which explicitly recover the latent confounder.\n",
      "\n",
      "Completed domain, adaptation, distribution, shift, latent, variable, confounder, proxy, causal, kernel abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The development of Intelligent Transportation System (ITS) has brought about comprehensive urban traffic information that not only provides convenience to urban residents in their daily lives but also enhances the efficiency of urban road usage, leading to a more harmonious and sustainable urban life. Typical scenarios in ITS mainly include traffic flow prediction, traffic target recognition, and vehicular edge computing. However, most current ITS applications rely on a centralized training approach where users upload source data to a cloud server with high computing power for management and centralized training. This approach has limitations such as poor real-time performance, data silos, and difficulty in guaranteeing data privacy. To address these limitations, federated learning (FL) has been proposed as a promising solution. In this paper, we present a comprehensive review of the application of FL in ITS, with a particular focus on three key scenarios: traffic flow prediction, traffic target recognition, and vehicular edge computing. For each scenario, we provide an in-depth analysis of its key characteristics, current challenges, and specific manners in which FL is leveraged. Moreover, we discuss the benefits that FL can offer as a potential solution to the limitations of the centralized training approach currently used in ITS applications.\n",
      "\n",
      "Completed ITS, Traffic, Flow, Prediction, Recognition, Vehicular, Edge, Computing, Federated, Learning abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In multiple federated learning schemes, a random subset of clients sends in each round their model updates to the server for aggregation. Although this client selection strategy aims to reduce communication overhead, it remains energy and computationally inefficient, especially when considering resource-constrained devices as clients. This is because conventional random client selection overlooks the content of exchanged information and falls short of providing a mechanism to reduce the transmission of semantically redundant data. To overcome this challenge, we propose clustering the clients with the aid of similarity metrics, where a single client from each of the formed clusters is selected in each round to participate in the federated training. To evaluate our approach, we perform an extensive feasibility study considering the use of nine statistical metrics in the clustering process. Simulation results reveal that, when considering a scenario with high data heterogeneity of clients, similarity-based clustering can reduce the number of required rounds compared to the baseline random client selection. In addition, energy consumption can be notably reduced from 23.93% to 41.61%, for those similarity metrics with an equivalent number of clients per round as the baseline random scheme.\n",
      "\n",
      "Completed Federated, learning, clustering, similarity, clients, communication, overhead, energy, computation, efficiency abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Given the widespread attention to individual thermal comfort, coupled with significant energy-saving potential inherent in energy management systems for optimizing indoor environments, this paper aims to introduce advanced \"Humans-in-the-building\" control techniques to redefine the paradigm of indoor temperature design. Firstly, we innovatively redefine the role of individuals in the control loop, establishing a model for users' thermal comfort and constructing discomfort signals based on individual preferences. Unlike traditional temperature-centric approaches, \"thermal comfort control\" prioritizes personalized comfort. Then, considering the diversity among users, we propose a novel method to determine the optimal indoor temperature range, thus minimizing discomfort for various users and reducing building energy consumption. Finally, the efficacy of the \"thermal comfort control\" approach is substantiated through simulations conducted using Matlab.\n",
      "\n",
      "Completed Humans, Buildings, Control, Thermal, Comfort, Energy, Management, Optimization, Indoor, Simulation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "There has been a growing interest in recent years in modelling multiple modalities (or views) of data to for example, understand the relationship between modalities or to generate missing data. Multi-view autoencoders have gained significant traction for their adaptability and versatility in modelling multi-modal data, demonstrating an ability to tailor their approach to suit the characteristics of the data at hand. However, most multi-view autoencoders have inconsistent notation and are often implemented using different coding frameworks. To address this, we present a unified mathematical framework for multi-view autoencoders, consolidating their formulations. Moreover, we offer insights into the motivation and theoretical advantages of each model. To facilitate accessibility and practical use, we extend the documentation and functionality of the previously introduced \\texttt{multi-view-AE} library. This library offers Python implementations of numerous multi-view autoencoder models, presented within a user-friendly framework. Through benchmarking experiments, we evaluate our implementations against previous ones, demonstrating comparable or superior performance. This work aims to establish a cohesive foundation for multi-modal modelling, serving as a valuable educational resource in the field.\n",
      "\n",
      "Completed multi-view, autoencoders, formulations, framework, accessible, library, documentation, functionality, Python, performance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Smart Contracts are programs running logic in the Blockchain network by executing operations through immutable transactions. The Blockchain network validates such transactions, storing them into sequential blocks of which integrity is ensured. Smart Contracts deal with value stakes, if a damaging transaction is validated, it may never be reverted, leading to unrecoverable losses. To prevent this, security aspects have been explored in several fields, with research providing catalogs of security defects, secure code recommendations, and possible solutions to fix vulnerabilities. In our study, we refer to vulnerability fixing in the ways found in the literature as guidelines. However, it is not clear to what extent developers adhere to these guidelines, nor whether there are other viable common solutions and what they are. The goal of our research is to fill knowledge gaps related to developers' observance of existing guidelines and to propose new and viable solutions to security vulnerabilities. To reach our goal, we will obtain from Solidity GitHub repositories the commits that fix vulnerabilities included in the DASP TOP 10 and we will conduct a manual analysis of fixing approaches employed by developers. Our analysis aims to determine the extent to which literature-based fixing strategies are followed. Additionally, we will identify and discuss emerging fixing techniques not currently documented in the literature. Through qualitative analysis, we will evaluate the suitability of these new fixing solutions and discriminate between valid approaches and potential mistakes.\n",
      "\n",
      "Completed Smart, Contracts, Blockchain, Transactions, Security, Vulnerabilities, DASP, TOP, Qualitative, Analysis abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Time-to-event analysis is a branch of statistics that has increased in popularity during the last decades due to its many application fields, such as predictive maintenance, customer churn prediction and population lifetime estimation. In this paper, we review and compare the performance of several prediction models for time-to-event analysis. These consist of semi-parametric and parametric statistical models, in addition to machine learning approaches. Our study is carried out on three datasets and evaluated in two different scores (the integrated Brier score and concordance index). Moreover, we show how ensemble methods, which surprisingly have not yet been much studied in time-to-event analysis, can improve the prediction accuracy and enhance the robustness of the prediction performance. We conclude the analysis with a simulation experiment in which we evaluate the factors influencing the performance ranking of the methods using both scores.\n",
      "\n",
      "Completed Time-to-event, analysis, prediction, models, semi-parametric, parametric, machine learning, ensemble methods, accuracy, robustness abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The modeling of cracks is an important topic - both in engineering as well as in mathematics. Since crack propagation is characterized by a free boundary value problem (the geometry of the crack is not known beforehand, but part of the solution), approximations of the underlying sharp-interface problem based on phase-field models are often considered. Focusing on a rate-independent setting, these models are defined by a unidirectional gradient-flow of an energy functional. Since this energy functional is non-convex, the evolution of the variables such as the displacement field and the phase-field variable might be discontinuous in time leading to so-called brutal crack growth. For this reason, solution concepts have to be carefully chosen in order to predict discontinuities that are physically reasonable. One such concept is that of Balanced Viscosity solutions (BV solutions). This concept predicts physically sound energy trajectories that do not jump across energy barriers. The paper deals with a time-adaptive finite element phase-field model for rate-independent fracture which converges to BV solutions. The model is motivated by constraining the pseudo-velocity of the crack tip. The resulting constrained minimization problem is solved by the augmented Lagrangian method. Numerical examples highlight the predictive capabilities of the model and furthermore show the efficiency and the robustness of the final algorithm.\n",
      "\n",
      "Completed crack, propagation, phase-field, gradient-flow, non-convex, discontinuities, brutal, Balanced, Viscosity, pseudo-velocity abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Backdoor attacks become a significant security concern for deep neural networks in recent years. An image classification model can be compromised if malicious backdoors are injected into it. This corruption will cause the model to function normally on clean images but predict a specific target label when triggers are present. Previous research can be categorized into two genres: poisoning a portion of the dataset with triggered images for users to train the model from scratch, or training a backdoored model alongside a triggered image generator. Both approaches require significant amount of attackable parameters for optimization to establish a connection between the trigger and the target label, which may raise suspicions as more people become aware of the existence of backdoor attacks. In this paper, we propose a backdoor attack paradigm that only requires minimal alterations (specifically, the output layer) to a clean model in order to inject the backdoor under the guise of fine-tuning. To achieve this, we leverage mode mixture samples, which are located between different modes in latent space, and introduce a novel method for conducting backdoor attacks. We evaluate the effectiveness of our method on four popular benchmark datasets: MNIST, CIFAR-10, GTSRB, and TinyImageNet.\n",
      "\n",
      "Completed backdoor, attacks, deep, neural, networks, triggers, model, fine-tuning, mode mixture, latent space abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Control-Flow Attestation (CFA) is a security service that allows an entity (verifier) to verify the integrity of code execution on a remote computer system (prover). Existing CFA schemes suffer from impractical assumptions, such as requiring access to the prover's internal state (e.g., memory or code), the complete Control-Flow Graph (CFG) of the prover's software, large sets of measurements, or tailor-made hardware. Moreover, current CFA schemes are inadequate for attesting embedded systems due to their high computational overhead and resource usage.\n",
      "  In this paper, we overcome the limitations of existing CFA schemes for embedded devices by introducing RAGE, a novel, lightweight CFA approach with minimal requirements. RAGE can detect Code Reuse Attacks (CRA), including control- and non-control-data attacks. It efficiently extracts features from one execution trace and leverages Unsupervised Graph Neural Networks (GNNs) to identify deviations from benign executions. The core intuition behind RAGE is to exploit the correspondence between execution trace, execution graph, and execution embeddings to eliminate the unrealistic requirement of having access to a complete CFG.\n",
      "  We evaluate RAGE on embedded benchmarks and demonstrate that (i) it detects 40 real-world attacks on embedded software; (ii) Further, we stress our scheme with synthetic return-oriented programming (ROP) and data-oriented programming (DOP) attacks on the real-world embedded software benchmark Embench, achieving 98.03% (ROP) and 91.01% (DOP) F1-Score while maintaining a low False Positive Rate of 3.19%; (iii) Additionally, we evaluate RAGE on OpenSSL, used by millions of devices and achieve 97.49% and 84.42% F1-Score for ROP and DOP attack detection, with an FPR of 5.47%.\n",
      "\n",
      "Completed Control-Flow, Attestation, Embedded, Systems, RAGE, Graph, Neural, Networks, Execution, Embeddings abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Three-Dimensional (3D) dense captioning is an emerging vision-language bridging task that aims to generate multiple detailed and accurate descriptions for 3D scenes. It presents significant potential and challenges due to its closer representation of the real world compared to 2D visual captioning, as well as complexities in data collection and processing of 3D point cloud sources. Despite the popularity and success of existing methods, there is a lack of comprehensive surveys summarizing the advancements in this field, which hinders its progress. In this paper, we provide a comprehensive review of 3D dense captioning, covering task definition, architecture classification, dataset analysis, evaluation metrics, and in-depth prosperity discussions. Based on a synthesis of previous literature, we refine a standard pipeline that serves as a common paradigm for existing methods. We also introduce a clear taxonomy of existing models, summarize technologies involved in different modules, and conduct detailed experiment analysis. Instead of a chronological order introduction, we categorize the methods into different classes to facilitate exploration and analysis of the differences and connections among existing techniques. We also provide a reading guideline to assist readers with different backgrounds and purposes in reading efficiently. Furthermore, we propose a series of promising future directions for 3D dense captioning by identifying challenges and aligning them with the development of related tasks, offering valuable insights and inspiring future research in this field. Our aim is to provide a comprehensive understanding of 3D dense captioning, foster further investigations, and contribute to the development of novel applications in multimedia and related domains.\n",
      "\n",
      "Completed 3D, Dense, Captioning, Review, Architecture, Dataset, Evaluation, Pipeline, Taxonomy, Future abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Motion planners are essential for the safe operation of automated vehicles across various scenarios. However, no motion planning algorithm has achieved perfection in the literature, and improving its performance is often time-consuming and labor-intensive. To tackle the aforementioned issues, we present DrPlanner, the first framework designed to automatically diagnose and repair motion planners using large language models. Initially, we generate a structured description of the planner and its planned trajectories from both natural and programming languages. Leveraging the profound capabilities of large language models in addressing reasoning challenges, our framework returns repaired planners with detailed diagnostic descriptions. Furthermore, the framework advances iteratively with continuous feedback from the evaluation of the repaired outcomes. Our approach is validated using search-based motion planners; experimental results highlight the need of demonstrations in the prompt and the ability of our framework in identifying and rectifying elusive issues effectively.\n",
      "\n",
      "Completed DrPlanner, motion planning, automated vehicles, diagnosis, repair, large language models, structured description, reasoning challenges, iterative feedback, evaluations abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In the face of significant biodiversity decline, species distribution models (SDMs) are essential for understanding the impact of climate change on species habitats by connecting environmental conditions to species occurrences. Traditionally limited by a scarcity of species observations, these models have significantly improved in performance through the integration of larger datasets provided by citizen science initiatives. However, they still suffer from the strong class imbalance between species within these datasets, often resulting in the penalization of rare species--those most critical for conservation efforts. To tackle this issue, this study assesses the effectiveness of training deep learning models using a balanced presence-only loss function on large citizen science-based datasets. We demonstrate that this imbalance-aware loss function outperforms traditional loss functions across various datasets and tasks, particularly in accurately modeling rare species with limited observations.\n",
      "\n",
      "Completed citizen, science, deep, learning, models, loss, function, imbalance, rare, species, conservation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In the realm of personalization, integrating diverse information sources such as consumption signals and content-based representations is becoming increasingly critical to build state-of-the-art solutions. In this regard, two of the biggest trends in research around this subject are Graph Neural Networks (GNNs) and Foundation Models (FMs). While GNNs emerged as a popular solution in industry for powering personalization at scale, FMs have only recently caught attention for their promising performance in personalization tasks like ranking and retrieval. In this paper, we present a graph-based foundation modeling approach tailored to personalization. Central to this approach is a Heterogeneous GNN (HGNN) designed to capture multi-hop content and consumption relationships across a range of recommendable item types. To ensure the generality required from a Foundation Model, we employ a Large Language Model (LLM) text-based featurization of nodes that accommodates all item types, and construct the graph using co-interaction signals, which inherently transcend content specificity. To facilitate practical generalization, we further couple the HGNN with an adaptation mechanism based on a two-tower (2T) architecture, which also operates agnostically to content type. This multi-stage approach ensures high scalability; while the HGNN produces general purpose embeddings, the 2T component models in a continuous space the sheer size of user-item interaction data. Our comprehensive approach has been rigorously tested and proven effective in delivering recommendations across a diverse array of products within a real-world, industrial audio streaming platform.\n",
      "\n",
      "Completed personalization, GNN, FM, HGNN, LLM, featurization, co-interaction, adaptation, 2T, audio streaming abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This seminal paper proposes a new query language for graph matching and rewriting overcoming {the declarative} limitation of Cypher while outperforming {Neo4j} on graph matching and rewriting by at least one order of magnitude. We exploited columnar databases (KnoBAB) to represent graphs using the Generalised Semistructured Model.\n",
      "\n",
      "Completed query, language, graph, matching, rewriting, Cypher, Neo4j, columnar, databases, KnoBAB abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Diabetes, resulting from inadequate insulin production or utilization, causes extensive harm to the body. Existing diagnostic methods are often invasive and come with drawbacks, such as cost constraints. Although there are machine learning models like Classwise k Nearest Neighbor (CkNN) and General Regression Neural Network (GRNN), they struggle with imbalanced data and result in under-performance. Leveraging advancements in sensor technology and machine learning, we propose a non-invasive diabetes diagnosis using a Back Propagation Neural Network (BPNN) with batch normalization, incorporating data re-sampling and normalization for class balancing. Our method addresses existing challenges such as limited performance associated with traditional machine learning. Experimental results on three datasets show significant improvements in overall accuracy, sensitivity, and specificity compared to traditional methods. Notably, we achieve accuracies of 89.81% in Pima diabetes dataset, 75.49% in CDC BRFSS2015 dataset, and 95.28% in Mesra Diabetes dataset. This underscores the potential of deep learning models for robust diabetes diagnosis. See project website https://steve-zeyu-zhang.github.io/DiabetesDiagnosis/\n",
      "\n",
      "Completed Diabetes, Diagnosis, Machine Learning, BPNN, Data Resampling, Class Balancing, Traditional Methods, Pima Dataset, CDC Dataset, Mesra Dataset abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In recent years, Explainable AI (XAI) methods have facilitated profound validation and knowledge extraction from ML models. While extensively studied for classification, few XAI solutions have addressed the challenges specific to regression models. In regression, explanations need to be precisely formulated to address specific user queries (e.g.\\ distinguishing between `Why is the output above 0?' and `Why is the output above 50?'). They should furthermore reflect the model's behavior on the relevant data sub-manifold. In this paper, we introduce XpertAI, a framework that disentangles the prediction strategy into multiple range-specific sub-strategies and allows the formulation of precise queries about the model (the `explanandum') as a linear combination of those sub-strategies. XpertAI is formulated generally to work alongside popular XAI attribution techniques, based on occlusion, gradient integration, or reverse propagation. Qualitative and quantitative results, demonstrate the benefits of our approach.\n",
      "\n",
      "Completed Explainable, AI, XAI, regression, models, queries, sub-strategies, sub-manifold, XpertAI, attribution abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Human motion generation stands as a significant pursuit in generative computer vision, while achieving long-sequence and efficient motion generation remains challenging. Recent advancements in state space models (SSMs), notably Mamba, have showcased considerable promise in long sequence modeling with an efficient hardware-aware design, which appears to be a promising direction to build motion generation model upon it. Nevertheless, adapting SSMs to motion generation faces hurdles since the lack of a specialized design architecture to model motion sequence. To address these challenges, we propose Motion Mamba, a simple and efficient approach that presents the pioneering motion generation model utilized SSMs. Specifically, we design a Hierarchical Temporal Mamba (HTM) block to process temporal data by ensemble varying numbers of isolated SSM modules across a symmetric U-Net architecture aimed at preserving motion consistency between frames. We also design a Bidirectional Spatial Mamba (BSM) block to bidirectionally process latent poses, to enhance accurate motion generation within a temporal frame. Our proposed method achieves up to 50% FID improvement and up to 4 times faster on the HumanML3D and KIT-ML datasets compared to the previous best diffusion-based method, which demonstrates strong capabilities of high-quality long sequence motion modeling and real-time human motion generation. See project website https://steve-zeyu-zhang.github.io/MotionMamba/\n",
      "\n",
      "Completed Motion, Generation, State, Space, Models, Efficient, Hierarchical, Temporal, Bidirectional, Spatial abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Quantum computers promise polynomial or exponential speed-up in solving certain problems compared to classical computers. However, in practical use, there are currently a number of fundamental technical challenges. One of them concerns the loading of data into quantum computers, since they cannot access common databases. In this vision paper, we develop a hybrid data management architecture in which databases can serve as data sources for quantum algorithms. To test the architecture, we perform experiments in which we assign data points stored in a database to clusters. For cluster assignment, a quantum algorithm processes this data by determining the distances between data points and cluster centroids.\n",
      "\n",
      "Completed quantum, computers, data, databases, loading, algorithms, clusters, centroids, distances, experiments abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We propose $\\frac{|x-y|}{1+|y|}$, termed the ``P1 error\" or ``plus-1 error\", as a metric of errors. It equals half the harmonic mean of absolute error and relative error, effectively combining their advantages while mitigating their limitations. The P1 error approaches absolute error when $|y|$ is small, and approaches relative error when $|y|$ is large. An $\\epsilon$ P1 error indicates that $x$ is close to $y$ at a tolerance level of $\\epsilon$, in compliance with the ``isclose\" definition used in popular numerical libraries.\n",
      "\n",
      "Completed metric, P1, error, absolute, relative, harmonic, mean, isclose, tolerance level, large abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We propose SemGauss-SLAM, the first semantic SLAM system utilizing 3D Gaussian representation, that enables accurate 3D semantic mapping, robust camera tracking, and high-quality rendering in real-time. In this system, we incorporate semantic feature embedding into 3D Gaussian representation, which effectively encodes semantic information within the spatial layout of the environment for precise semantic scene representation. Furthermore, we propose feature-level loss for updating 3D Gaussian representation, enabling higher-level guidance for 3D Gaussian optimization. In addition, to reduce cumulative drift and improve reconstruction accuracy, we introduce semantic-informed bundle adjustment leveraging semantic associations for joint optimization of 3D Gaussian representation and camera poses, leading to more robust tracking and consistent mapping. Our SemGauss-SLAM method demonstrates superior performance over existing dense semantic SLAM methods in terms of mapping and tracking accuracy on Replica and ScanNet datasets, while also showing excellent capabilities in novel-view semantic synthesis and 3D semantic mapping.\n",
      "\n",
      "Completed Semantic, SLAM, 3D, Gaussian, Representation, Feature, Embedding, Optimization, Tracking, Rendering, Synthesis abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The objective of personalization and stylization in text-to-image is to instruct a pre-trained diffusion model to analyze new concepts introduced by users and incorporate them into expected styles. Recently, parameter-efficient fine-tuning (PEFT) approaches have been widely adopted to address this task and have greatly propelled the development of this field. Despite their popularity, existing efficient fine-tuning methods still struggle to achieve effective personalization and stylization in T2I generation. To address this issue, we propose block-wise Low-Rank Adaptation (LoRA) to perform fine-grained fine-tuning for different blocks of SD, which can generate images faithful to input prompts and target identity and also with desired style. Extensive experiments demonstrate the effectiveness of the proposed method.\n",
      "\n",
      "Completed stylization, personalization, text-to-image, diffusion, parameter-efficient, fine-tuning, LoRA, fine-grained, SD, prompts abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "To detect security vulnerabilities, static analysis tools need to be configured with security-relevant methods. Current approaches can automatically identify such methods using binary relevance machine learning approaches. However, they ignore dependencies among security-relevant methods, over-generalize and perform poorly in practice. Additionally, users have to nevertheless manually configure static analysis tools using the detected methods. Based on feedback from users and our observations, the excessive manual steps can often be tedious, error-prone and counter-intuitive.\n",
      "  In this paper, we present Dev-Assist, an IntelliJ IDEA plugin that detects security-relevant methods using a multi-label machine learning approach that considers dependencies among labels. The plugin can automatically generate configurations for static analysis tools, run the static analysis, and show the results in IntelliJ IDEA. Our experiments reveal that Dev-Assist's machine learning approach has a higher F1-Measure than related approaches. Moreover, the plugin reduces and simplifies the manual effort required when configuring and using static analysis tools.\n",
      "\n",
      "Completed Dev-Assist, IntelliJ, plugin, security-relevant, methods, dependencies, machine learning, configurations, static analysis, manual effort abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Hybrid electric vehicles (HEVs) are becoming increasingly popular because they can better combine the working characteristics of internal combustion engines and electric motors. However, the minimum fuel consumption of an HEV for a battery electrical balance case under a specific assembly condition and a specific speed curve still needs to be clarified in academia and industry. Regarding this problem, this work provides the mathematical expression of constrained optimal fuel consumption (COFC) from the perspective of constrained reinforcement learning (CRL) for the first time globally. Also, two mainstream approaches of CRL, constrained variational policy optimization (CVPO) and Lagrangian-based approaches, are utilized for the first time to obtain the vehicle's minimum fuel consumption under the battery electrical balance condition. We conduct case studies on the well-known Prius TOYOTA hybrid system (THS) under the NEDC condition; we give vital steps to implement CRL approaches and compare the performance between the CVPO and Lagrangian-based approaches. Our case study found that CVPO and Lagrangian-based approaches can obtain the lowest fuel consumption while maintaining the SOC balance constraint. The CVPO approach converges stable, but the Lagrangian-based approach can obtain the lowest fuel consumption at 3.95 L/100km, though with more significant oscillations. This result verifies the effectiveness of our proposed CRL approaches to the COFC problem.\n",
      "\n",
      "Completed fuel, consumption, hybrid, electric, vehicles, constrained, reinforcement, learning, CVPO, Lagrangian abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Large language models for code (LLM4Code), which demonstrate strong performance (e.g., high accuracy) in processing source code, have significantly transformed software engineering. Many studies separately investigate the non-functional properties of LM4Code, but there is no systematic review of how these properties are evaluated and enhanced. This paper fills this gap by thoroughly examining 146 relevant studies, thereby presenting the first systematic literature review to identify seven important properties beyond accuracy, including robustness, security, privacy, explainability, efficiency, and usability. We discuss the current state-of-the-art methods and trends, identify gaps in existing research, and present promising directions for future study.\n",
      "\n",
      "Completed Code, Language, Models, Evaluation, Properties, Accuracy, Robustness, Security, Privacy, Explainability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The rise of large language models (LLMs) and instruction tuning has led to the current trend of instruction-tuned large language and vision models (LLVMs). This trend involves either meticulously curating numerous instruction tuning datasets tailored to specific objectives or enlarging LLVMs to manage vast amounts of vision language (VL) data. However, current LLVMs have disregarded the detailed and comprehensive real-world scene understanding available from specialized computer vision (CV) models in visual perception tasks such as segmentation, detection, scene graph generation (SGG), and optical character recognition (OCR). Instead, the existing LLVMs rely mainly on the large capacity and emergent capabilities of their LLM backbones. Therefore, we present a new LLVM, Mixture of All Intelligence (MoAI), which leverages auxiliary visual information obtained from the outputs of external segmentation, detection, SGG, and OCR models. MoAI operates through two newly introduced modules: MoAI-Compressor and MoAI-Mixer. After verbalizing the outputs of the external CV models, the MoAI-Compressor aligns and condenses them to efficiently use relevant auxiliary visual information for VL tasks. MoAI-Mixer then blends three types of intelligence (1) visual features, (2) auxiliary features from the external CV models, and (3) language features by utilizing the concept of Mixture of Experts. Through this integration, MoAI significantly outperforms both open-source and closed-source LLVMs in numerous zero-shot VL tasks, particularly those related to real-world scene understanding such as object existence, positions, relations, and OCR without enlarging the model size or curating extra visual instruction tuning datasets.\n",
      "\n",
      "Completed Large, Language, Models, Vision, Perception, CV, OCR, MoAI, Mixture, Multimedia abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Landmarks are facts or actions that appear in all valid solutions of a planning problem. They have been used successfully to calculate heuristics that guide the search for a plan. We investigate an extension to this concept by defining a novel \"relevance score\" that helps identify facts or actions that appear in most but not all plans to achieve any given goal. We describe an approach to compute this relevance score and use it as a heuristic in the search for a plan. We experimentally compare the performance of our approach with that of a state of the art landmark-based heuristic planning approach using benchmark planning problems. While the original landmark-based heuristic leads to better performance on problems with well-defined landmarks, our approach substantially improves performance on problems that lack non-trivial landmarks.\n",
      "\n",
      "Completed relevance, score, plans, landmarks, heuristic, guide, search, compare, performance, approach abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Analyzing temporal developments is crucial for the accurate prognosis of many medical conditions. Temporal changes that occur over short time scales are key to assessing the health of physiological functions, such as the cardiac cycle. Moreover, tracking longer term developments that occur over months or years in evolving processes, such as age-related macular degeneration (AMD), is essential for accurate prognosis. Despite the importance of both short and long term analysis to clinical decision making, they remain understudied in medical deep learning. State of the art methods for spatiotemporal representation learning, developed for short natural videos, prioritize the detection of temporal constants rather than temporal developments. Moreover, they do not account for varying time intervals between acquisitions, which are essential for contextualizing observed changes. To address these issues, we propose two approaches. First, we combine clip-level contrastive learning with a novel temporal embedding to adapt to irregular time series. Second, we propose masking and predicting latent frame representations of the temporal sequence. Our two approaches outperform all prior methods on temporally-dependent tasks including cardiac output estimation and three prognostic AMD tasks. Overall, this enables the automated analysis of temporal patterns which are typically overlooked in applications of deep learning to medicine.\n",
      "\n",
      "Completed temporal, developments, prognosis, cardiac, cycle, macular, degeneration, spatiotemporal, embedding, masking abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In the context of single domain generalisation, the objective is for models that have been exclusively trained on data from a single domain to demonstrate strong performance when confronted with various unfamiliar domains. In this paper, we introduce a novel model referred to as Contrastive Uncertainty Domain Generalisation Network (CUDGNet). The key idea is to augment the source capacity in both input and label spaces through the fictitious domain generator and jointly learn the domain invariant representation of each class through contrastive learning. Extensive experiments on two Single Source Domain Generalisation (SSDG) datasets demonstrate the effectiveness of our approach, which surpasses the state-of-the-art single-DG methods by up to $7.08\\%$. Our method also provides efficient uncertainty estimation at inference time from a single forward pass through the generator subnetwork.\n",
      "\n",
      "Completed single-domain, generalisation, CUDGNet, contrastive, uncertainty, domain, generator, representation, efficient, estimation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Ground-truth RGBD data are fundamental for a wide range of computer vision applications; however, those labeled samples are difficult to collect and time-consuming to produce. A common solution to overcome this lack of data is to employ graphic engines to produce synthetic proxies; however, those data do not often reflect real-world images, resulting in poor performance of the trained models at the inference step. In this paper we propose a novel training pipeline that incorporates Diffusion4D (D4D), a customized 4-channels diffusion model able to generate realistic RGBD samples. We show the effectiveness of the developed solution in improving the performances of deep learning models on the monocular depth estimation task, where the correspondence between RGB and depth map is crucial to achieving accurate measurements. Our supervised training pipeline, enriched by the generated samples, outperforms synthetic and original data performances achieving an RMSE reduction of (8.2%, 11.9%) and (8.1%, 6.1%) respectively on the indoor NYU Depth v2 and the outdoor KITTI dataset.\n",
      "\n",
      "Completed ground-truth, RGBD, synthetic, diffusion, monocular, depth, estimation, supervised, NYU, KITTI abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We explore how to improve the energy performance of battery-less Internet of Things (IoT) devices at the cost of a reduction in the quality of the output. Battery-less IoT devices are extremely resource-constrained energy-harvesting devices. Due to erratic energy patterns from the ambient, their executions become intermittent; periods of active computation are interleaved by periods of recharging small energy buffers. To cross periods of energy unavailability, a device persists application and system state onto Non-Volatile Memory (NVM) in anticipation of energy failures. We purposely control the energy invested in these operations, representing a major energy overhead, when using Spin-Transfer Torque Magnetic Random-Access Memory (STT-MRAM) as NVM. As a result, we abate the corresponding overhead, yet introduce write errors. Based on 1.9+ trillion experimental data points, we illustrate whether this is a gamble worth taking, when, and where. We measure the energy consumption and quality of output obtained from the execution of nine diverse benchmarks on top of seven different platforms. Our results allow us to draw three key observations: i) the trade-off between energy saving and reduction of output quality is program-specific; ii) the same trade-off is a function of a platform's specific compute efficiency and power figures; and iii) data encoding and input size impact a program's resilience to errors. As a paradigmatic example, we reveal cases where we achieve up to 50% reduction in energy consumption with negligible effects on output quality, as opposed to settings where a minimal energy gain causes drastic drops in output quality.\n",
      "\n",
      "Completed IoT, energy, quality, NVM, STT-MRAM, write errors, energy consumption, benchmarks, program, platform abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Scene text recognition is an important and challenging task in computer vision. However, most prior works focus on recognizing pre-defined words, while there are various out-of-vocabulary (OOV) words in real-world applications.\n",
      "  In this paper, we propose a novel open-vocabulary text recognition framework, Pseudo-OCR, to recognize OOV words. The key challenge in this task is the lack of OOV training data. To solve this problem, we first propose a pseudo label generation module that leverages character detection and image inpainting to produce substantial pseudo OOV training data from real-world images. Unlike previous synthetic data, our pseudo OOV data contains real characters and backgrounds to simulate real-world applications. Secondly, to reduce noises in pseudo data, we present a semantic checking mechanism to filter semantically meaningful data. Thirdly, we introduce a quality-aware margin loss to boost the training with pseudo data. Our loss includes a margin-based part to enhance the classification ability, and a quality-aware part to penalize low-quality samples in both real and pseudo data.\n",
      "  Extensive experiments demonstrate that our approach outperforms the state-of-the-art on eight datasets and achieves the first rank in the ICDAR2022 challenge.\n",
      "\n",
      "Completed Pseudo-OCR, OOV, Text Recognition, Computer Vision, Pseudo Label, Image Inpainting, Semantic Checking, Quality-Aware Margin Loss, ICDAR2022, State-of-the-Art abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Technology-facilitated gender-based violence has become a global threat to women's political representation and democracy. Understanding how online hate affects its targets is thus paramount. We analyse 10 million tweets directed at female candidates in the Brazilian election in 2022 and examine their reactions to online misogyny. Using a self-trained machine learning classifier to detect Portuguese misogynistic tweets and a quantitative analysis of the candidates' tweeting behaviour, we investigate how the number of misogynistic attacks received alters the online activity of the female candidates. We find that young and left-wing candidates and candidates with higher visibility online received significantly more attacks. Furthermore, we find that an increase in misogynistic attacks in the previous week is associated with a decrease in female candidates' tweets in the following week. This potentially threatens their equal participation in public opinion building and silences women's voices in political discourse.\n",
      "\n",
      "Completed Technology-facilitated, gender-based, violence, female, representation, online, hate, Brazil, misogyny, machine abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "For the vertex selection problem $(\\sigma,\\rho)$-DomSet one is given two fixed sets $\\sigma$ and $\\rho$ of integers and the task is to decide whether we can select vertices of the input graph, such that, for every selected vertex, the number of selected neighbors is in $\\sigma$ and, for every unselected vertex, the number of selected neighbors is in $\\rho$. This framework covers Independent Set and Dominating Set for example.\n",
      "  We investigate the case when $\\sigma$ and $\\rho$ are periodic sets with the same period $m\\ge 2$, that is, the sets are two (potentially different) residue classes modulo $m$. We study the problem parameterized by treewidth and present an algorithm that solves in time $m^{tw} \\cdot n^{O(1)}$ the decision, minimization and maximization version of the problem. This significantly improves upon the known algorithms where for the case $m \\ge 3$ not even an explicit running time is known. We complement our algorithm by providing matching lower bounds which state that there is no $(m-\\epsilon)^{pw} \\cdot n^{O(1)}$ unless SETH fails. For $m = 2$, we extend these bound to the minimization version as the decision version is efficiently solvable.\n",
      "\n",
      "Completed vertex, selection, DomSet, periodic, residue, classes, treewidth, bounds, SETH, Independent abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Koo is a microblogging platform based in India launched in 2020 with the explicit aim of catering to non-Western communities in their vernacular languages. With a near-complete dataset totalling over 71M posts and 399M user interactions, we show how Koo has attracted users from several countries including India, Nigeria and Brazil, but with variable levels of sustained user engagement. We highlight how Koo's interaction network has been shaped by multiple country-specific migrations and displays strong divides between linguistic and cultural communities, for instance, with English-speaking communities from India and Nigeria largely isolated from one another. Finally, we analyse the content shared by each linguistic community and identify cultural patterns that promote similar discourses across language groups. Our study raises the prospect that a multilingual and politically diverse platform like Koo may be able to cultivate vernacular communities that have, historically, not been prioritised by US-based social media platforms.\n",
      "\n",
      "Completed Koo, microblogging, India, vernacular, languages, engagement, migrations, diversity, communities, discourse abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Interpreting camera data is key for autonomously acting systems, such as autonomous vehicles. Vision systems that operate in real-world environments must be able to understand their surroundings and need the ability to deal with novel situations. This paper tackles open-world semantic segmentation, i.e., the variant of interpreting image data in which objects occur that have not been seen during training. We propose a novel approach that performs accurate closed-world semantic segmentation and, at the same time, can identify new categories without requiring any additional training data. Our approach additionally provides a similarity measure for every newly discovered class in an image to a known category, which can be useful information in downstream tasks such as planning or mapping. Through extensive experiments, we show that our model achieves state-of-the-art results on classes known from training data as well as for anomaly segmentation and can distinguish between different unknown classes.\n",
      "\n",
      "Completed open-world, semantic segmentation, novel situations, closed-world, unknown category, similarity measure, downstream tasks, state-of-the-art, anomaly segmentation, unknown classes abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Multi-view depth estimation has achieved impressive performance over various benchmarks. However, almost all current multi-view systems rely on given ideal camera poses, which are unavailable in many real-world scenarios, such as autonomous driving. In this work, we propose a new robustness benchmark to evaluate the depth estimation system under various noisy pose settings. Surprisingly, we find current multi-view depth estimation methods or single-view and multi-view fusion methods will fail when given noisy pose settings. To address this challenge, we propose a single-view and multi-view fused depth estimation system, which adaptively integrates high-confident multi-view and single-view results for both robust and accurate depth estimations. The adaptive fusion module performs fusion by dynamically selecting high-confidence regions between two branches based on a wrapping confidence map. Thus, the system tends to choose the more reliable branch when facing textureless scenes, inaccurate calibration, dynamic objects, and other degradation or challenging conditions. Our method outperforms state-of-the-art multi-view and fusion methods under robustness testing. Furthermore, we achieve state-of-the-art performance on challenging benchmarks (KITTI and DDAD) when given accurate pose estimations. Project website: https://github.com/Junda24/AFNet/.\n",
      "\n",
      "Completed multi-view, depth, estimation, noisy, pose, fusion, adaptive, robustness, challenging, KITTI abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Many anatomical structures can be described by surface or volume meshes. Machine learning is a promising tool to extract information from these 3D models. However, high-fidelity meshes often contain hundreds of thousands of vertices, which creates unique challenges in building deep neural network architectures. Furthermore, patient-specific meshes may not be canonically aligned which limits the generalisation of machine learning algorithms. We propose LaB-GATr, a transfomer neural network with geometric tokenisation that can effectively learn with large-scale (bio-)medical surface and volume meshes through sequence compression and interpolation. Our method extends the recently proposed geometric algebra transformer (GATr) and thus respects all Euclidean symmetries, i.e. rotation, translation and reflection, effectively mitigating the problem of canonical alignment between patients. LaB-GATr achieves state-of-the-art results on three tasks in cardiovascular hemodynamics modelling and neurodevelopmental phenotype prediction, featuring meshes of up to 200,000 vertices. Our results demonstrate that LaB-GATr is a powerful architecture for learning with high-fidelity meshes which has the potential to enable interesting downstream applications. Our implementation is publicly available.\n",
      "\n",
      "Completed machine, learning, transformer, geometric, tokenisation, symmetry, interpolation, cardiovascular, neurodevelopmental, meshes abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Ransomware, a fearsome and rapidly evolving cybersecurity threat, continues to inflict severe consequences on individuals and organizations worldwide. Traditional detection methods, reliant on static signatures and application behavioral patterns, are challenged by the dynamic nature of these threats. This paper introduces three primary contributions to address this challenge. First, we introduce a ransomware emulator. This tool is designed to safely mimic ransomware attacks without causing actual harm or spreading malware, making it a unique solution for studying ransomware behavior. Second, we demonstrate how we use this emulator to create storage I/O traces. These traces are then utilized to train machine-learning models. Our results show that these models are effective in detecting ransomware, highlighting the practical application of our emulator in developing responsible cybersecurity tools. Third, we show how our emulator can be used to mimic the I/O behavior of existing ransomware thereby enabling safe trace collection. Both the emulator and its application represent significant steps forward in ransomware detection in the era of machine-learning-driven cybersecurity.\n",
      "\n",
      "Completed Ransomware, CyberSecurity, Detection, Emulator, I/O, Machine-Learning, Trace, Behavioral, Signature, Dynamic abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In the realm of Business Process Management (BPM), process modeling plays a crucial role in translating complex process dynamics into comprehensible visual representations, facilitating the understanding, analysis, improvement, and automation of organizational processes. Traditional process modeling methods often require extensive expertise and can be time-consuming. This paper explores the integration of Large Language Models (LLMs) into process modeling to enhance flexibility, efficiency, and accessibility of process modeling for both expert and non-expert users. We propose a framework that leverages LLMs for the automated generation and iterative refinement of process models starting from textual descriptions. Our framework involves innovative prompting strategies for effective LLM utilization, along with a secure model generation protocol and an error-handling mechanism. Moreover, we instantiate a concrete system extending our framework. This system provides robust quality guarantees on the models generated and supports exporting them in standard modeling notations, such as the Business Process Modeling Notation (BPMN) and Petri nets. Preliminary results demonstrate the framework's ability to streamline process modeling tasks, underscoring the transformative potential of generative AI in the BPM field.\n",
      "\n",
      "Completed Business, Process, Management, Modeling, Language, Large, Models, Framework, Generation, Refinement, Notation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This survey explores the adaptation of visual transformer models in Autonomous Driving, a transition inspired by their success in Natural Language Processing. Surpassing traditional Recurrent Neural Networks in tasks like sequential image processing and outperforming Convolutional Neural Networks in global context capture, as evidenced in complex scene recognition, Transformers are gaining traction in computer vision. These capabilities are crucial in Autonomous Driving for real-time, dynamic visual scene processing. Our survey provides a comprehensive overview of Vision Transformer applications in Autonomous Driving, focusing on foundational concepts such as self-attention, multi-head attention, and encoder-decoder architecture. We cover applications in object detection, segmentation, pedestrian detection, lane detection, and more, comparing their architectural merits and limitations. The survey concludes with future research directions, highlighting the growing role of Vision Transformers in Autonomous Driving.\n",
      "\n",
      "Completed Vision, Transformers, Autonomous, Driving, Self-Attention, Object, Detection, Segmentation, Pedestrian, Lane abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "NLP in the age of monolithic large language models is approaching its limits in terms of size and information that can be handled. The trend goes to modularization, a necessary step into the direction of designing smaller sub-networks and components with specialized functionality. In this paper, we present the MAMMOTH toolkit: a framework designed for training massively multilingual modular machine translation systems at scale, initially derived from OpenNMT-py and then adapted to ensure efficient training across computation clusters. We showcase its efficiency across clusters of A100 and V100 NVIDIA GPUs, and discuss our design philosophy and plans for future information. The toolkit is publicly available online.\n",
      "\n",
      "Completed NLP, modularization, sub-networks, components, MAMMOTH, multilingual, machine translation, OpenNMT-py, NVIDIA GPUs, online abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Neural radiance fields (NeRF) has attracted considerable attention for their exceptional ability in synthesizing novel views with high fidelity. However, the presence of motion blur, resulting from slight camera movements during extended shutter exposures, poses a significant challenge, potentially compromising the quality of the reconstructed 3D scenes. While recent studies have addressed this issue, they do not consider the continuous dynamics of camera movements during image acquisition, leading to inaccurate scene reconstruction. Additionally, these methods are plagued by slow training and rendering speed. To effectively handle these issues, we propose sequential motion understanding radiance fields (SMURF), a novel approach that employs neural ordinary differential equation (Neural-ODE) to model continuous camera motion and leverages the explicit volumetric representation method for faster training and robustness to motion-blurred input images. The core idea of the SMURF is continuous motion blurring kernel (CMBK), a unique module designed to model a continuous camera movements for processing blurry inputs. Our model, rigorously evaluated against benchmark datasets, demonstrates state-of-the-art performance both quantitatively and qualitatively.\n",
      "\n",
      "Completed neural, radiance, fields, motion, blur, camera, movements, neural-ode, volumetric, rendering abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In learning an embodied agent executing daily tasks via language directives, the literature largely assumes that the agent learns all training data at the beginning. We argue that such a learning scenario is less realistic since a robotic agent is supposed to learn the world continuously as it explores and perceives it. To take a step towards a more realistic embodied agent learning scenario, we propose two continual learning setups for embodied agents; learning new behaviors (Behavior Incremental Learning, Behavior-IL) and new environments (Environment Incremental Learning, Environment-IL) For the tasks, previous 'data prior' based continual learning methods maintain logits for the past tasks. However, the stored information is often insufficiently learned information and requires task boundary information, which might not always be available. Here, we propose to update them based on confidence scores without task boundary information during training (i.e., task-free) in a moving average fashion, named Confidence-Aware Moving Average (CAMA). In the proposed Behavior-IL and Environment-IL setups, our simple CAMA outperforms prior state of the art in our empirical validations by noticeable margins. The project page including codes is https://github.com/snumprlab/cl-alfred.\n",
      "\n",
      "Completed continuous, learning, embodied, agent, continual, Behavior-IL, Environment-IL, confidence, CAMA, task-free abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Industrial projects rely heavily on lengthy, complex specification documents, making tedious manual extraction of structured information a major bottleneck. This paper introduces an innovative approach to automate this process, leveraging the capabilities of two cutting-edge AI models: Donut, a model that extracts information directly from scanned documents without OCR, and OpenAI GPT-3.5 Turbo, a robust large language model. The proposed methodology is initiated by acquiring the table of contents (ToCs) from construction specification documents and subsequently structuring the ToCs text into JSON data. Remarkable accuracy is achieved, with Donut reaching 85% and GPT-3.5 Turbo reaching 89% in effectively organizing the ToCs. This landmark achievement represents a significant leap forward in document indexing, demonstrating the immense potential of AI to automate information extraction tasks across diverse document types, boosting efficiency and liberating critical resources in various industries.\n",
      "\n",
      "Completed Industrial, projects, specification, documents, extraction, Donut, GPT-3.5, Turbo, automation, accuracy abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Although large language models (LLMs) have demonstrated impressive text generation capabilities, they are easily misled by the untruthful context provided by users or knowledge argumentation tools, thereby producing hallucinations. To alleviate the LLMs from being misled by untruthful information and take advantage of knowledge argumentation, we propose Truth-Aware Context Selection (TACS), a lightweight method to shield untruthful context from the inputs. TACS begins by performing truth detection on the input context, leveraging the parameterized knowledge within the LLM. Subsequently, it constructs a corresponding attention mask based on the truthfulness of each position, selecting the truthful context and discarding the untruthful context. Additionally, we introduce a new evaluation metric, Disturbance Adaption Rate, to further study the LLMs' ability to accept truthful information and resist untruthful information. Experimental results show that TACS can effectively filter information in context and significantly improve the overall quality of LLMs' responses when presented with misleading information.\n",
      "\n",
      "Completed Truth-Aware, Context Selection, Hallucinations, Large Language Models, Knowledge Argumentation, Information, Untruthful, Parameterized, Disturbance Adaption Rate, Evaluation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Ensuring factual consistency between the summary and the original document is paramount in summarization tasks. Consequently, considerable effort has been dedicated to detecting inconsistencies. With the advent of Large Language Models (LLMs), recent studies have begun to leverage their advanced language understanding capabilities for inconsistency detection. However, early attempts have shown that LLMs underperform traditional models due to their limited ability to follow instructions and the absence of an effective detection methodology. In this study, we reassess summary inconsistency detection with LLMs, comparing the performances of GPT-3.5 and GPT-4. To advance research in LLM-based inconsistency detection, we propose SIFiD (Summary Inconsistency Detection with Filtered Document) that identify key sentences within documents by either employing natural language inference or measuring semantic similarity between summaries and documents.\n",
      "\n",
      "Completed summary, inconsistency, detection, LLMs, GPT-3.5, GPT-4, SIFiD, natural language inference, semantic similarity, filtered document abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In liquid democracy, agents can either vote directly or delegate their vote to a different agent of their choice. This results in a power structure in which certain agents possess more voting weight than others. As a result, it opens up certain possibilities of vote manipulation, including control and bribery, that do not exist in standard voting scenarios of direct democracy. Here we formalize a certain kind of election control -- in which an external agent may change certain delegation arcs -- and study the computational complexity of the corresponding combinatorial problem.\n",
      "\n",
      "Completed liquid, democracy, agents, delegation, power, structure, manipulation, control, bribery, complexity abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Multi-Agent Reinforcement Learning (MARL) based Multi-Agent Path Finding (MAPF) has recently gained attention due to its efficiency and scalability. Several MARL-MAPF methods choose to use communication to enrich the information one agent can perceive. However, existing works still struggle in structured environments with high obstacle density and a high number of agents. To further improve the performance of the communication-based MARL-MAPF solvers, we propose a new method, Ensembling Prioritized Hybrid Policies (EPH). We first propose a selective communication block to gather richer information for better agent coordination within multi-agent environments and train the model with a Q-learning-based algorithm. We further introduce three advanced inference strategies aimed at bolstering performance during the execution phase. First, we hybridize the neural policy with single-agent expert guidance for navigating conflict-free zones. Secondly, we propose Q value-based methods for prioritized resolution of conflicts as well as deadlock situations. Finally, we introduce a robust ensemble method that can efficiently collect the best out of multiple possible solutions. We empirically evaluate EPH in complex multi-agent environments and demonstrate competitive performance against state-of-the-art neural methods for MAPF.\n",
      "\n",
      "Completed MAPF, MARL, communication, obstacles, agents, EPH, selective communication, inference strategies, expert guidance, ensemble abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Semantic scene completion (SSC) aims to predict complete 3D voxel occupancy and semantics from a single-view RGB-D image, and recent SSC methods commonly adopt multi-modal inputs. However, our investigation reveals two limitations: ineffective feature learning from single modalities and overfitting to limited datasets. To address these issues, this paper proposes a novel SSC framework - Adversarial Modality Modulation Network (AMMNet) - with a fresh perspective of optimizing gradient updates. The proposed AMMNet introduces two core modules: a cross-modal modulation enabling the interdependence of gradient flows between modalities, and a customized adversarial training scheme leveraging dynamic gradient competition. Specifically, the cross-modal modulation adaptively re-calibrates the features to better excite representation potentials from each single modality. The adversarial training employs a minimax game of evolving gradients, with customized guidance to strengthen the generator's perception of visual fidelity from both geometric completeness and semantic correctness. Extensive experimental results demonstrate that AMMNet outperforms state-of-the-art SSC methods by a large margin, providing a promising direction for improving the effectiveness and generalization of SSC methods.\n",
      "\n",
      "Completed Semantic, Scene, Completion, Multi-modal, Gradient, Modulation, Adversarial, Training, Generator, Perception abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The concept of $k$-defective clique, a relaxation of clique by allowing up-to $k$ missing edges, has been receiving increasing interests recently. Although the problem of finding the maximum $k$-defective clique is NP-hard, several practical algorithms have been recently proposed in the literature, with kDC being the state of the art. kDC not only runs the fastest in practice, but also achieves the best time complexity. Specifically, it runs in $O^*(\\gamma_k^n)$ time when ignoring polynomial factors; here, $\\gamma_k$ is a constant that is smaller than two and only depends on $k$, and $n$ is the number of vertices in the input graph $G$. In this paper, we propose the kDC-Two algorithm to improve the time complexity as well as practical performance. kDC-Two runs in $O^*( (\\alpha\\Delta)^{k+2} \\gamma_{k-1}^\\alpha)$ time when the maximum $k$-defective clique size $\\omega_k(G)$ is at least $k+2$, and in $O^*(\\gamma_{k-1}^n)$ time otherwise, where $\\alpha$ and $\\Delta$ are the degeneracy and maximum degree of $G$, respectively. In addition, with slight modification, kDC-Two also runs in $O^*( (\\alpha\\Delta)^{k+2} (k+1)^{\\alpha+k+1-\\omega_k(G)})$ time by using the degeneracy gap $\\alpha+k+1-\\omega_k(G)$ parameterization; this is better than $O^*( (\\alpha\\Delta)^{k+2}\\gamma_{k-1}^\\alpha)$ when $\\omega_k(G)$ is close to the degeneracy-based upper bound $\\alpha+k+1$. Finally, to further improve the practical performance, we propose a new degree-sequence-based reduction rule that can be efficiently applied, and theoretically demonstrate its effectiveness compared with those proposed in the literature. Extensive empirical studies on three benchmark graph collections show that our algorithm outperforms the existing fastest algorithm by several orders of magnitude.\n",
      "\n",
      "Completed k-defective, clique, maximum, algorithm, kDC, time, complexity, kDC-Two, degeneracy, reduction abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Jupyter Notebook is an interactive development environment commonly used for rapid experimentation of machine learning (ML) solutions. Describing the ML activities performed along code cells improves the readability and understanding of Notebooks. Manual annotation of code cells is time-consuming and error-prone. Therefore, tools have been developed that classify the cells of a notebook concerning the ML activity performed in them. However, the current tools are not flexible, as they work based on look-up tables that have been created, which map function calls of commonly used ML libraries to ML activities. These tables must be manually adjusted to account for new or changed libraries.\n",
      "  This paper presents a more flexible approach to cell classification based on a hybrid classification approach that combines a rule-based and a decision tree classifier. We discuss the design rationales and describe the developed classifiers in detail. We implemented the new flexible cell classification approach in a tool called JupyLabel. Its evaluation and the obtained metric scores regarding precision, recall, and F1-score are discussed. Additionally, we compared JupyLabel with HeaderGen, an existing cell classification tool. We were able to show that the presented flexible cell classification approach outperforms this tool significantly.\n",
      "\n",
      "Completed Jupyter Notebook, Machine Learning, Cell Annotation, Flexible Classification, Rule-based Classifier, Decision Tree Classifier, JupyLabel, HeaderGen, Precision, Recall abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "An open problem in mobile manipulation is how to represent objects and scenes in a unified manner, so that robots can use it both for navigating in the environment and manipulating objects. The latter requires capturing intricate geometry while understanding fine-grained semantics, whereas the former involves capturing the complexity inherit to an expansive physical scale. In this work, we present GeFF (Generalizable Feature Fields), a scene-level generalizable neural feature field that acts as a unified representation for both navigation and manipulation that performs in real-time. To do so, we treat generative novel view synthesis as a pre-training task, and then align the resulting rich scene priors with natural language via CLIP feature distillation. We demonstrate the effectiveness of this approach by deploying GeFF on a quadrupedal robot equipped with a manipulator. We evaluate GeFF's ability to generalize to open-set objects as well as running time, when performing open-vocabulary mobile manipulation in dynamic scenes.\n",
      "\n",
      "Completed GeFF, mobile manipulation, navigation, object representation, scene representation, generative novel view synthesis, CLIP feature distillation, generalization, open-vocabulary, real-time abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The intelligent interpretation of buildings plays a significant role in urban planning and management, macroeconomic analysis, population dynamics, etc. Remote sensing image building interpretation primarily encompasses building extraction and change detection. However, current methodologies often treat these two tasks as separate entities, thereby failing to leverage shared knowledge. Moreover, the complexity and diversity of remote sensing image scenes pose additional challenges, as most algorithms are designed to model individual small datasets, thus lacking cross-scene generalization. In this paper, we propose a comprehensive remote sensing image building understanding model, termed RSBuilding, developed from the perspective of the foundation model. RSBuilding is designed to enhance cross-scene generalization and task universality. Specifically, we extract image features based on the prior knowledge of the foundation model and devise a multi-level feature sampler to augment scale information. To unify task representation and integrate image spatiotemporal clues, we introduce a cross-attention decoder with task prompts. Addressing the current shortage of datasets that incorporate annotations for both tasks, we have developed a federated training strategy to facilitate smooth model convergence even when supervision for some tasks is missing, thereby bolstering the complementarity of different tasks. Our model was trained on a dataset comprising up to 245,000 images and validated on multiple building extraction and change detection datasets. The experimental results substantiate that RSBuilding can concurrently handle two structurally distinct tasks and exhibits robust zero-shot generalization capabilities.\n",
      "\n",
      "Completed Building, Interpretation, Remote sensing, Image understanding, Cross-scene generalization, Multi-level feature sampler, Cross-attention decoder, Task prompts, Federated training, Zero-shot generalization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Blood Glucose (BG) control involves keeping an individual's BG within a healthy range through extracorporeal insulin injections is an important task for people with type 1 diabetes. However,traditional patient self-management is cumbersome and risky. Recent research has been devoted to exploring individualized and automated BG control approaches, among which Deep Reinforcement Learning (DRL) shows potential as an emerging approach. In this paper, we use an exponential decay model of drug concentration to convert the formalization of the BG control problem, which takes into account the delay and prolongedness of drug effects, from a PAE-POMDP (Prolonged Action Effect-Partially Observable Markov Decision Process) to a MDP, and we propose a novel multi-step DRL-based algorithm to solve the problem. The Prioritized Experience Replay (PER) sampling method is also used in it. Compared to single-step bootstrapped updates, multi-step learning is more efficient and reduces the influence from biasing targets. Our proposed method converges faster and achieves higher cumulative rewards compared to the benchmark in the same training environment, and improves the time-in-range (TIR), the percentage of time the patient's BG is within the target range, in the evaluation phase. Our work validates the effectiveness of multi-step reinforcement learning in BG control, which may help to explore the optimal glycemic control measure and improve the survival of diabetic patients.\n",
      "\n",
      "Completed Blood, Glucose, Control, Reinforcement, Learning, Deep, Exponential, Decay, Prioritized, Experience abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Most data-to-text datasets are for English, so the difficulties of modelling data-to-text for low-resource languages are largely unexplored. In this paper we tackle data-to-text for isiXhosa, which is low-resource and agglutinative. We introduce Triples-to-isiXhosa (T2X), a new dataset based on a subset of WebNLG, which presents a new linguistic context that shifts modelling demands to subword-driven techniques. We also develop an evaluation framework for T2X that measures how accurately generated text describes the data. This enables future users of T2X to go beyond surface-level metrics in evaluation. On the modelling side we explore two classes of methods - dedicated data-to-text models trained from scratch and pretrained language models (PLMs). We propose a new dedicated architecture aimed at agglutinative data-to-text, the Subword Segmental Pointer Generator (SSPG). It jointly learns to segment words and copy entities, and outperforms existing dedicated models for 2 agglutinative languages (isiXhosa and Finnish). We investigate pretrained solutions for T2X, which reveals that standard PLMs come up short. Fine-tuning machine translation models emerges as the best method overall. These findings underscore the distinct challenge presented by T2X: neither well-established data-to-text architectures nor customary pretrained methodologies prove optimal. We conclude with a qualitative analysis of generation errors and an ablation study.\n",
      "\n",
      "Completed data-to-text, isiXhosa, agglutinative, T2X, evaluation, SSPG, segmentation, pointer, PLMs, machine translation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Due to the influence of imaging equipment and complex imaging environments, most images in daily life have features of intensity inhomogeneity and noise. Therefore, many scholars have designed many image segmentation algorithms to address these issues. Among them, the active contour model is one of the most effective image segmentation algorithms.This paper proposes an active contour model driven by the hybrid signed pressure function that combines global and local information construction. Firstly, a new global region-based signed pressure function is introduced by combining the average intensity of the inner and outer regions of the curve with the median intensity of the inner region of the evolution curve. Then, the paper uses the energy differences between the inner and outer regions of the curve in the local region to design the signed pressure function of the local term. Combine the two SPF function to obtain a new signed pressure function and get the evolution equation of the new model. Finally, experiments and numerical analysis show that the model has excellent segmentation performance for both intensity inhomogeneous images and noisy images.\n",
      "\n",
      "Completed image, segmentation, intensity inhomogeneous, noise, active contour model, hybrid signed pressure function, global information, local information, excellent segmentation performance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recommender systems mainly tailor personalized recommendations according to user interests learned from user feedback. However, such recommender systems passively cater to user interests and even reinforce existing interests in the feedback loop, leading to problems like filter bubbles and opinion polarization. To counteract this, proactive recommendation actively steers users towards developing new interests in a target item or topic by strategically modulating recommendation sequences. Existing work for proactive recommendation faces significant hurdles: 1) overlooking the user feedback in the guidance process; 2) lacking explicit modeling of the guiding objective; and 3) insufficient flexibility for integration into existing industrial recommender systems. To address these issues, we introduce an Iterative Preference Guidance (IPG) framework. IPG performs proactive recommendation in a flexible post-processing manner by ranking items according to their IPG scores that consider both interaction probability and guiding value. These scores are explicitly estimated with iteratively updated user representation that considers the most recent user interactions. Extensive experiments validate that IPG can effectively guide user interests toward target interests with a reasonable trade-off in recommender accuracy. The code is available at https://github.com/GabyUSTC/IPG-Rec.\n",
      "\n",
      "Completed proactive, recommendation, user feedback, IPG, post-processing, ranking, iteratively updated user representation, target interests, recommender accuracy, GitHub abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In the context of advancing 6G, a substantial paradigm shift is anticipated, highlighting comprehensive everything-to-everything interactions characterized by numerous connections and stringent adherence to Quality of Service/Experience (QoS/E) prerequisites. The imminent challenge stems from resource scarcity, prompting a deliberate transition to Computing-Network Convergence (CNC) as an auspicious approach for joint resource orchestration. While CNC-based mechanisms have garnered attention, their effectiveness in realizing future services, particularly in use cases like the Metaverse, may encounter limitations due to the continually changing nature of users, services, and resources. Hence, this paper presents the concept of Adaptable CNC (ACNC) as an autonomous Machine Learning (ML)-aided mechanism crafted for the joint orchestration of computing and network resources, catering to dynamic and voluminous user requests with stringent requirements. ACNC encompasses two primary functionalities: state recognition and context detection. Given the intricate nature of the user-service-computing-network space, the paper employs dimension reduction to generate live, holistic, abstract system states in a hierarchical structure. To address the challenges posed by dynamic changes, Continual Learning (CL) is employed, classifying the system state into contexts controlled by dedicated ML agents, enabling them to operate efficiently. These two functionalities are intricately linked within a closed loop overseen by the End-to-End (E2E) orchestrator to allocate resources. The paper introduces the components of ACNC, proposes a Metaverse scenario to exemplify ACNC's role in resource provisioning with Segment Routing v6 (SRv6), outlines ACNC's workflow, details a numerical analysis for efficiency assessment, and concludes with discussions on relevant challenges and potential avenues for future research.\n",
      "\n",
      "Completed Adaptable CNC, Computing-Network Convergence, Continuous Learning, Dynamic Resource Orchestration, End-to-End Orchestration, Metaverse, Quality of Experience, Quality of Service, Segment Routing v6, State Recognition abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Parameter-efficient fine-tuning (PEFT) is proposed as a cost-effective way to transfer pre-trained models to downstream tasks, avoiding the high cost of updating entire large-scale pre-trained models (LPMs). In this work, we present Fine-grained Prompt Tuning (FPT), a novel PEFT method for medical image classification. FPT significantly reduces memory consumption compared to other PEFT methods, especially in high-resolution contexts. To achieve this, we first freeze the weights of the LPM and construct a learnable lightweight side network. The frozen LPM takes high-resolution images as input to extract fine-grained features, while the side network is fed low-resolution images to reduce memory usage. To allow the side network to access pre-trained knowledge, we introduce fine-grained prompts that summarize information from the LPM through a fusion module. Important tokens selection and preloading techniques are employed to further reduce training cost and memory requirements. We evaluate FPT on four medical datasets with varying sizes, modalities, and complexities. Experimental results demonstrate that FPT achieves comparable performance to fine-tuning the entire LPM while using only 1.8% of the learnable parameters and 13% of the memory costs of an encoder ViT-B model with a 512 x 512 input resolution.\n",
      "\n",
      "Completed Parameter-efficient fine-tuning, Fine-grained Prompt Tuning, Medical image classification, High-resolution contexts, Learnable lightweight side network, Pre-trained knowledge, Fine-grained prompts, Fusion module, Important tokens selection, Preloading abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The Aesthetics Assessment of Children's Paintings (AACP) is an important branch of the image aesthetics assessment (IAA), playing a significant role in children's education. This task presents unique challenges, such as limited available data and the requirement for evaluation metrics from multiple perspectives. However, previous approaches have relied on training large datasets and subsequently providing an aesthetics score to the image, which is not applicable to AACP. To solve this problem, we construct an aesthetics assessment dataset of children's paintings and a model based on self-supervised learning. 1) We build a novel dataset composed of two parts: the first part contains more than 20k unlabeled images of children's paintings; the second part contains 1.2k images of children's paintings, and each image contains eight attributes labeled by multiple design experts. 2) We design a pipeline that includes a feature extraction module, perception modules and a disentangled evaluation module. 3) We conduct both qualitative and quantitative experiments to compare our model's performance with five other methods using the AACP dataset. Our experiments reveal that our method can accurately capture aesthetic features and achieve state-of-the-art performance.\n",
      "\n",
      "Completed Aesthetics, Assessment, Children's, Paintings, Evaluation, Metrics, Self-Supervised, Learning, Dataset, Features abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Personality detection aims to detect one's personality traits underlying in social media posts. One challenge of this task is the scarcity of ground-truth personality traits which are collected from self-report questionnaires. Most existing methods learn post features directly by fine-tuning the pre-trained language models under the supervision of limited personality labels. This leads to inferior quality of post features and consequently affects the performance. In addition, they treat personality traits as one-hot classification labels, overlooking the semantic information within them. In this paper, we propose a large language model (LLM) based text augmentation enhanced personality detection model, which distills the LLM's knowledge to enhance the small model for personality detection, even when the LLM fails in this task. Specifically, we enable LLM to generate post analyses (augmentations) from the aspects of semantic, sentiment, and linguistic, which are critical for personality detection. By using contrastive learning to pull them together in the embedding space, the post encoder can better capture the psycho-linguistic information within the post representations, thus improving personality detection. Furthermore, we utilize the LLM to enrich the information of personality labels for enhancing the detection performance. Experimental results on the benchmark datasets demonstrate that our model outperforms the state-of-the-art methods on personality detection.\n",
      "\n",
      "Completed personality, detection, social media, language models, self-report, semantic, augmentation, contrastive learning, embedding, enrichment abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The past few years have witnessed the flourishing of large-scale deep neural network models with ever-growing parameter numbers. Training such large-scale models typically requires massive memory and computing resources that exceed those of a single GPU, necessitating distributed training. As GPU performance has rapidly evolved in recent years, computation time has shrunk, thereby increasing the proportion of communication in the overall training time. Therefore, optimizing communication for distributed training has become an urgent issue. In this article, we briefly introduce the general architecture of distributed deep neural network training and analyze relationships among Parallelization Strategy, Collective Communication Library, and Network from the perspective of communication optimization, which forms a three-layer paradigm. We then review current representative research advances with this three-layer paradigm. We find that layers in the current three-layer paradigm are relatively independent, but there is a rich design space for cross-layer collaborative optimization in distributed training scenarios. Therefore, we further advocate a communication-efficient five-layer paradigm underlining opportunities for collaboration designs and look forward to the perspectives of \"Vertical\", \"Horizontal\", \"Intra-Inter\" and \"Host-Net\" collaboration designs. We hope this article can shed some light on future research on communication optimization for distributed training.\n",
      "\n",
      "Completed Distributed, Training, Communication, Models, Deep Neural Networks, GPUs, Optimization, Paradigm, Collaboration, Architectures abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "As social robots become increasingly integrated into daily life, ensuring their behaviours align with social norms is crucial. For their widespread open-world application, it is important to explore Federated Learning (FL) settings where individual robots can learn about their unique environments while also learning from each others' experiences. In this paper, we present a novel FL benchmark that evaluates different strategies, using multi-label regression objectives, where each client individually learns to predict the social appropriateness of different robot actions while also sharing their learning with others. Furthermore, splitting the training data by different contexts such that each client incrementally learns across contexts, we present a novel Federated Continual Learning (FCL) benchmark that adapts FL-based methods to use state-of-the-art Continual Learning (CL) methods to continually learn socially appropriate agent behaviours under different contextual settings. Federated Averaging (FedAvg) of weights emerges as a robust FL strategy while rehearsal-based FCL enables incrementally learning the social appropriateness of robot actions, across contextual splits.\n",
      "\n",
      "Completed Social Robots, Federated Learning, Open-world, Multi-label, Regression, Context, Federated Continual Learning, Continual Learning, Federated Averaging, Rehearsal abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In today's digital landscape, the Web has become increasingly centralized, raising concerns about user privacy violations. Decentralized Web architectures, such as Solid, offer a promising solution by empowering users with better control over their data in their personal `Pods'. However, a significant challenge remains: users must navigate numerous applications to decide which application can be trusted with access to their data Pods. This often involves reading lengthy and complex Terms of Use agreements, a process that users often find daunting or simply ignore. This compromises user autonomy and impedes detection of data misuse. We propose a novel formal description of Data Terms of Use (DToU), along with a DToU reasoner. Users and applications specify their own parts of the DToU policy with local knowledge, covering permissions, requirements, prohibitions and obligations. Automated reasoning verifies compliance, and also derives policies for output data. This constitutes a ``perennial'' DToU language, where the policy authoring only occurs once, and we can conduct ongoing automated checks across users, applications and activity cycles. Our solution is built on Turtle, Notation 3 and RDF Surfaces, for the language and the reasoning engine. It ensures seamless integration with other semantic tools for enhanced interoperability. We have successfully integrated this language into the Solid framework, and conducted performance benchmark. We believe this work demonstrates a practicality of a perennial DToU language and the potential of a paradigm shift to how users interact with data and applications in a decentralized Web, offering both improved privacy and usability.\n",
      "\n",
      "Completed Decentralized, Web, Privacy, DToU, Data, Terms, Use, Policy, Reasoner, Integration abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Image reconstruction attacks on machine learning models pose a significant risk to privacy by potentially leaking sensitive information. Although defending against such attacks using differential privacy (DP) has proven effective, determining appropriate DP parameters remains challenging. Current formal guarantees on data reconstruction success suffer from overly theoretical assumptions regarding adversary knowledge about the target data, particularly in the image domain. In this work, we empirically investigate this discrepancy and find that the practicality of these assumptions strongly depends on the domain shift between the data prior and the reconstruction target. We propose a reconstruction attack based on diffusion models (DMs) that assumes adversary access to real-world image priors and assess its implications on privacy leakage under DP-SGD. We show that (1) real-world data priors significantly influence reconstruction success, (2) current reconstruction bounds do not model the risk posed by data priors well, and (3) DMs can serve as effective auditing tools for visualizing privacy leakage.\n",
      "\n",
      "Completed differential privacy, image reconstruction, machine learning, data leakage, diffusion models, privacy auditing, data priors, domain shift, attack effectiveness, formal guarantees abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recently, some large kernel convnets strike back with appealing performance and efficiency. However, given the square complexity of convolution, scaling up kernels can bring about an enormous amount of parameters and the proliferated parameters can induce severe optimization problem. Due to these issues, current CNNs compromise to scale up to 51x51 in the form of stripe convolution (i.e., 51x5 + 5x51) and start to saturate as the kernel size continues growing. In this paper, we delve into addressing these vital issues and explore whether we can continue scaling up kernels for more performance gains. Inspired by human vision, we propose a human-like peripheral convolution that efficiently reduces over 90% parameter count of dense grid convolution through parameter sharing, and manage to scale up kernel size to extremely large. Our peripheral convolution behaves highly similar to human, reducing the complexity of convolution from O(K^2) to O(logK) without backfiring performance. Built on this, we propose Parameter-efficient Large Kernel Network (PeLK). Our PeLK outperforms modern vision Transformers and ConvNet architectures like Swin, ConvNeXt, RepLKNet and SLaK on various vision tasks including ImageNet classification, semantic segmentation on ADE20K and object detection on MS COCO. For the first time, we successfully scale up the kernel size of CNNs to an unprecedented 101x101 and demonstrate consistent improvements.\n",
      "\n",
      "Completed kernel, convnets, optimization, scaling, convolution, human, parameter, peripheral, transformer, performance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Neural architecture search (NAS) has become a key component of AutoML and a standard tool to automate the design of deep neural networks. Recently, training-free NAS as an emerging paradigm has successfully reduced the search costs of standard training-based NAS by estimating the true architecture performance with only training-free metrics. Nevertheless, the estimation ability of these metrics typically varies across different tasks, making it challenging to achieve robust and consistently good search performance on diverse tasks with only a single training-free metric. Meanwhile, the estimation gap between training-free metrics and the true architecture performances limits training-free NAS to achieve superior performance. To address these challenges, we propose the robustifying and boosting training-free NAS (RoBoT) algorithm which (a) employs the optimized combination of existing training-free metrics explored from Bayesian optimization to develop a robust and consistently better-performing metric on diverse tasks, and (b) applies greedy search, i.e., the exploitation, on the newly developed metric to bridge the aforementioned gap and consequently to boost the search performance of standard training-free NAS further. Remarkably, the expected performance of our RoBoT can be theoretically guaranteed, which improves over the existing training-free NAS under mild conditions with additional interesting insights. Our extensive experiments on various NAS benchmark tasks yield substantial empirical evidence to support our theoretical results.\n",
      "\n",
      "Completed Neural, architecture, search, training-free, Bayesian, optimization, robust, boosting, performance, benchmark abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recent advancements in Spatial Transcriptomics (ST) technology have facilitated detailed gene expression analysis within tissue contexts. However, the high costs and methodological limitations of ST necessitate a more robust predictive model. In response, this paper introduces TRIPLEX, a novel deep learning framework designed to predict spatial gene expression from Whole Slide Images (WSIs). TRIPLEX uniquely harnesses multi-resolution features, capturing cellular morphology at individual spots, the local context around these spots, and the global tissue organization. By integrating these features through an effective fusion strategy, TRIPLEX achieves accurate gene expression prediction. Our comprehensive benchmark study, conducted on three public ST datasets and supplemented with Visium data from 10X Genomics, demonstrates that TRIPLEX outperforms current state-of-the-art models in Mean Squared Error (MSE), Mean Absolute Error (MAE), and Pearson Correlation Coefficient (PCC). The model's predictions align closely with ground truth gene expression profiles and tumor annotations, underscoring TRIPLEX's potential in advancing cancer diagnosis and treatment.\n",
      "\n",
      "Completed Spatial, Transcriptomics, Gene, Expression, Prediction, Deep, Learning, Whole, Slide, Images abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper presents MinkUNeXt, an effective and efficient architecture for place-recognition from point clouds entirely based on the new 3D MinkNeXt Block, a residual block composed of 3D sparse convolutions that follows the philosophy established by recent Transformers but purely using simple 3D convolutions. Feature extraction is performed at different scales by a U-Net encoder-decoder network and the feature aggregation of those features into a single descriptor is carried out by a Generalized Mean Pooling (GeM). The proposed architecture demonstrates that it is possible to surpass the current state-of-the-art by only relying on conventional 3D sparse convolutions without making use of more complex and sophisticated proposals such as Transformers, Attention-Layers or Deformable Convolutions. A thorough assessment of the proposal has been carried out using the Oxford RobotCar and the In-house datasets. As a result, MinkUNeXt proves to outperform other methods in the state-of-the-art.\n",
      "\n",
      "Completed MinkUNeXt, place-recognition, point-clouds, 3D, MinkNeXt Block, Transformers, U-Net, GeM, Oxford RobotCar, In-house abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we present Mondrian, an edge system that enables high-performance object detection on high-resolution video streams. Many lightweight models and system optimization techniques have been proposed for resource-constrained devices, but they do not fully utilize the potential of the accelerators over dynamic, high-resolution videos. To enable such capability, we devise a novel Compressive Packed Inference to minimize per-pixel processing costs by selectively determining the necessary pixels to process and combining them to maximize processing parallelism. In particular, our system quickly extracts ROIs and dynamically shrinks them, reflecting the effect of the fast-changing characteristics of objects and scenes. It then intelligently combines such scaled ROIs into large canvases to maximize the utilization of inference accelerators such as GPU. Evaluation across various datasets, models, and devices shows Mondrian outperforms state-of-the-art baselines (e.g., input rescaling, ROI extractions, ROI extractions+batching) by 15.0-19.7% higher accuracy, leading to $\\times$6.65 higher throughput than frame-wise inference for processing various 1080p video streams. We will release the code after the paper review.\n",
      "\n",
      "Completed Mondrian, edge, object, detection, video, lightweight, optimization, compressive, inference, ROIs, dynamic abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In the pursuit of transferring a source model to a target domain without access to the source training data, Source-Free Domain Adaptation (SFDA) has been extensively explored across various scenarios, including closed-set, open-set, partial-set, and generalized settings. Existing methods, focusing on specific scenarios, not only address only a subset of challenges but also necessitate prior knowledge of the target domain, significantly limiting their practical utility and deployability. In light of these considerations, we introduce a more practical yet challenging problem, termed unified SFDA, which comprehensively incorporates all specific scenarios in a unified manner. To tackle this unified SFDA problem, we propose a novel approach called Latent Causal Factors Discovery (LCFD). In contrast to previous alternatives that emphasize learning the statistical description of reality, we formulate LCFD from a causality perspective. The objective is to uncover the causal relationships between latent variables and model decisions, enhancing the reliability and robustness of the learned model against domain shifts. To integrate extensive world knowledge, we leverage a pre-trained vision-language model such as CLIP. This aids in the formation and discovery of latent causal factors in the absence of supervision in the variation of distribution and semantics, coupled with a newly designed information bottleneck with theoretical guarantees. Extensive experiments demonstrate that LCFD can achieve new state-of-the-art results in distinct SFDA settings, as well as source-free out-of-distribution generalization.Our code and data are available at https://github.com/tntek/source-free-domain-adaptation.\n",
      "\n",
      "Completed Source-Free, Domain, Adaptation, Causality, Latent, Variables, Semantics, Information, Bottleneck, Generalization, Out-of-distribution abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Partial Multi-label Learning (PML) is a type of weakly supervised learning where each training instance corresponds to a set of candidate labels, among which only some are true. In this paper, we introduce \\our{}, a novel probabilistic approach to this problem that extends the binary cross entropy to the PML setup. In contrast to existing methods, it does not require suboptimal disambiguation and, as such, can be applied to any deep architecture. Furthermore, experiments conducted on artificial and real-world datasets indicate that \\our{} outperforms existing approaches, especially for high noise in a candidate set.\n",
      "\n",
      "Completed Partial, Multi-label, Learning, Probabilistic, Cross, Entropy, Architecture, Disambiguation, Performance, Candidate abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In text-to-image generation, using negative prompts, which describe undesirable image characteristics, can significantly boost image quality. However, producing good negative prompts is manual and tedious. To address this, we propose NegOpt, a novel method for optimizing negative prompt generation toward enhanced image generation, using supervised fine-tuning and reinforcement learning. Our combined approach results in a substantial increase of 25% in Inception Score compared to other approaches and surpasses ground-truth negative prompts from the test set. Furthermore, with NegOpt we can preferentially optimize the metrics most important to us. Finally, we construct Negative Prompts DB, a dataset of negative prompts.\n",
      "\n",
      "Completed text-to-image, negative prompts, image quality, NegOpt, supervised fine-tuning, reinforcement learning, Inception Score, ground-truth, Negative Prompts DB abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Graph grammars form an interesting area of research because of their versatility in modelling diverse situations with graphs as the structures which are to be manipulated. A new class of graph grammars, nc-eNCE Graph Grammars has been introduced recently with an aim of restricting the order of application of graph production rules, thereby generating different graph classes using the same set of rules. On the other hand 2D game design using an algorithmic approach known as procedural content generation has been of interest recently. In this paper we modify the structure of nc-eNCE graph grammars with the aim of generating directed graphs. We show that employing these graph grammars simplifies the design of 2D games. We have also developed an algorithm which makes use of these graph grammars for generating random game level layouts ensuring that the players will get a different gaming experience each time they play.\n",
      "\n",
      "Completed Graph, Grammars, nc-eNCE, Directed, Procedural, Content, Generation, Random, Level, Layout abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Machine Learning (ML) has become ubiquitous, fueling data-driven applications across various organizations. Contrary to the traditional perception of ML in research, ML workflows can be complex, resource-intensive, and time-consuming. Expanding an ML workflow to encompass a wider range of data infrastructure and data types may lead to larger workloads and increased deployment costs. Currently, numerous workflow engines are available (with over ten being widely recognized). This variety poses a challenge for end-users in terms of mastering different engine APIs. While efforts have primarily focused on optimizing ML Operations (MLOps) for a specific workflow engine, current methods largely overlook workflow optimization across different engines.\n",
      "  In this work, we design and implement Couler, a system designed for unified ML workflow optimization in the cloud. Our main insight lies in the ability to generate an ML workflow using natural language (NL) descriptions. We integrate Large Language Models (LLMs) into workflow generation, and provide a unified programming interface for various workflow engines. This approach alleviates the need to understand various workflow engines' APIs. Moreover, Couler enhances workflow computation efficiency by introducing automated caching at multiple stages, enabling large workflow auto-parallelization and automatic hyperparameters tuning. These enhancements minimize redundant computational costs and improve fault tolerance during deep learning workflow training. Couler is extensively deployed in real-world production scenarios at Ant Group, handling approximately 22k workflows daily, and has successfully improved the CPU/Memory utilization by more than 15% and the workflow completion rate by around 17%.\n",
      "\n",
      "Completed workflow, computing, MLOps, Couler, ML, optimization, natural language, workflow engine, large language model, caching abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Machine unlearning has garnered significant attention due to its ability to selectively erase knowledge obtained from specific training data samples in an already trained machine learning model. This capability enables data holders to adhere strictly to data protection regulations. However, existing unlearning techniques face practical constraints, often causing performance degradation, demanding brief fine-tuning post unlearning, and requiring significant storage. In response, this paper introduces a novel class of machine unlearning algorithms. First method is partial amnesiac unlearning, integration of layer-wise pruning with amnesiac unlearning. In this method, updates made to the model during training are pruned and stored, subsequently used to forget specific data from trained model. The second method assimilates layer-wise partial-updates into label-flipping and optimization-based unlearning to mitigate the adverse effects of data deletion on model efficacy. Through a detailed experimental evaluation, we showcase the effectiveness of proposed unlearning methods. Experimental results highlight that the partial amnesiac unlearning not only preserves model efficacy but also eliminates the necessity for brief post fine-tuning, unlike conventional amnesiac unlearning. Moreover, employing layer-wise partial updates in label-flipping and optimization-based unlearning techniques demonstrates superiority in preserving model efficacy compared to their naive counterparts.\n",
      "\n",
      "Completed machine, unlearning, data, protection, regulations, partial, amnesiac, optimization, efficacy, post, fine-tuning abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Though images are ubiquitous across Wikipedia, it is not obvious that the image choices optimally support learning. When well selected, images can enhance learning by dual coding, complementing, or supporting articles. When chosen poorly, images can mislead, distract, and confuse. We developed a large dataset containing 470 questions & answers to 94 Wikipedia articles with images on a wide range of topics. Through an online experiment (n=704), we determined whether the images displayed alongside the text of the article are effective in helping readers understand and learn. For certain tasks, such as learning to identify targets visually (e.g., \"which of these pictures is a gujia?\"), article images significantly improve accuracy. Images did not significantly improve general knowledge questions (e.g., \"where are gujia from?\"). Most interestingly, only some images helped with visual knowledge questions (e.g., \"what shape is a gujia?\"). Using our findings, we reflect on the implications for editors and tools to support image selection.\n",
      "\n",
      "Completed learning, images, Wikipedia, dataset, questions, experiment, accuracy, knowledge, visual, implications abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Smart indoor tourist attractions, such as smart museums and aquariums, usually require a significant investment in indoor localization devices. The smartphone Global Positional Systems use is unsuitable for scenarios where dense materials such as concrete and metal block weaken the GPS signals, which is the most common scenario in an indoor tourist attraction. Deep learning makes it possible to perform region-wise indoor localization using smartphone images. This approach does not require any investment in infrastructure, reducing the cost and time to turn museums and aquariums into smart museums or smart aquariums. This paper proposes using deep learning algorithms to classify locations using smartphone camera images for indoor tourism attractions. We evaluate our proposal in a real-world scenario in Brazil. We extensively collect images from ten different smartphones to classify biome-themed fish tanks inside the Pantanal Biopark, creating a new dataset of 3654 images. We tested seven state-of-the-art neural networks, three being transformer-based, achieving precision around 90% on average and recall and f-score around 89% on average. The results indicate good feasibility of the proposal in a most indoor tourist attractions.\n",
      "\n",
      "Completed Indoor, localization, deep learning, smartphone, GPS, images, classification, aquariums, museums, Brazil abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Dark image enhancement aims at converting dark images to normal-light images. Existing dark image enhancement methods take uncompressed dark images as inputs and achieve great performance. However, in practice, dark images are often compressed before storage or transmission over the Internet. Current methods get poor performance when processing compressed dark images. Artifacts hidden in the dark regions are amplified by current methods, which results in uncomfortable visual effects for observers. Based on this observation, this study aims at enhancing compressed dark images while avoiding compression artifacts amplification. Since texture details intertwine with compression artifacts in compressed dark images, detail enhancement and blocking artifacts suppression contradict each other in image space. Therefore, we handle the task in latent space. To this end, we propose a novel latent mapping network based on variational auto-encoder (VAE). Firstly, different from previous VAE-based methods with single-resolution features only, we exploit multiple latent spaces with multi-resolution features, to reduce the detail blur and improve image fidelity. Specifically, we train two multi-level VAEs to project compressed dark images and normal-light images into their latent spaces respectively. Secondly, we leverage a latent mapping network to transform features from compressed dark space to normal-light space. Specifically, since the degradation models of darkness and compression are different from each other, the latent mapping process is divided mapping into enlightening branch and deblocking branch. Comprehensive experiments demonstrate that the proposed method achieves state-of-the-art performance in compressed dark image enhancement.\n",
      "\n",
      "Completed Dark, Enhancement, Compressed, Artifacts, Amplification, Latent, Mapping, Network, Multi-resolution, Features abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Sequential recommender systems (SRS) could capture dynamic user preferences by modeling historical behaviors ordered in time. Despite effectiveness, focusing only on the \\textit{collaborative signals} from behaviors does not fully grasp user interests. It is also significant to model the \\textit{semantic relatedness} reflected in content features, e.g., images and text. Towards that end, in this paper, we aim to enhance the SRS tasks by effectively unifying collaborative signals and semantic relatedness together. Notably, we empirically point out that it is nontrivial to achieve such a goal due to semantic gap issues. Thus, we propose an end-to-end two-stream architecture for sequential recommendation, named TSSR, to learn user preferences from ID-based and content-based sequence. Specifically, we first present novel hierarchical contrasting module, including coarse user-grained and fine item-grained terms, to align the representations of inter-modality. Furthermore, we also design a two-stream architecture to learn the dependence of intra-modality sequence and the complex interactions of inter-modality sequence, which can yield more expressive capacity in understanding user interests. We conduct extensive experiments on five public datasets. The experimental results show that the TSSR could yield superior performance than competitive baselines. We also make our experimental codes publicly available at https://anonymous.4open.science/r/TSSR-2A27/.\n",
      "\n",
      "Completed Sequential, Recommender, Collaborative, Semantic, Relatedness, Enhancement, Gap, Architecture, User, Content abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Large language models (LLMs) are widely deployed in various downstream tasks, e.g., auto-completion, aided writing, or chat-based text generation. However, the considered output candidates of the underlying search algorithm are under-explored and under-explained. We tackle this shortcoming by proposing a tree-in-the-loop approach, where a visual representation of the beam search tree is the central component for analyzing, explaining, and adapting the generated outputs. To support these tasks, we present generAItor, a visual analytics technique, augmenting the central beam search tree with various task-specific widgets, providing targeted visualizations and interaction possibilities. Our approach allows interactions on multiple levels and offers an iterative pipeline that encompasses generating, exploring, and comparing output candidates, as well as fine-tuning the model based on adapted data. Our case study shows that our tool generates new insights in gender bias analysis beyond state-of-the-art template-based methods. Additionally, we demonstrate the applicability of our approach in a qualitative user study. Finally, we quantitatively evaluate the adaptability of the model to few samples, as occurring in text-generation use cases.\n",
      "\n",
      "Completed beam, search, tree, visual, analytics, generation, tree-in-the-loop, generAItor, model, adaptability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recent weakly supervised semantic segmentation (WSSS) methods strive to incorporate contextual knowledge to improve the completeness of class activation maps (CAM). In this work, we argue that the knowledge bias between instances and contexts affects the capability of the prototype to sufficiently understand instance semantics. Inspired by prototype learning theory, we propose leveraging prototype awareness to capture diverse and fine-grained feature attributes of instances. The hypothesis is that contextual prototypes might erroneously activate similar and frequently co-occurring object categories due to this knowledge bias. Therefore, we propose to enhance the prototype representation ability by mitigating the bias to better capture spatial coverage in semantic object regions. With this goal, we present a Context Prototype-Aware Learning (CPAL) strategy, which leverages semantic context to enrich instance comprehension. The core of this method is to accurately capture intra-class variations in object features through context-aware prototypes, facilitating the adaptation to the semantic attributes of various instances. We design feature distribution alignment to optimize prototype awareness, aligning instance feature distributions with dense features. In addition, a unified training framework is proposed to combine label-guided classification supervision and prototypes-guided self-supervision. Experimental results on PASCAL VOC 2012 and MS COCO 2014 show that CPAL significantly improves off-the-shelf methods and achieves state-of-the-art performance. The project is available at https://github.com/Barrett-python/CPAL.\n",
      "\n",
      "Completed weakly, supervised, semantic, segmentation, prototype, learning, context, bias, instance, features abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Navigation in complex 3D scenarios requires appropriate environment representation for efficient scene understanding and trajectory generation. We propose a highly efficient and extensible global navigation framework based on a tomographic understanding of the environment to navigate ground robots in multi-layer structures. Our approach generates tomogram slices using the point cloud map to encode the geometric structure as ground and ceiling elevations. Then it evaluates the scene traversability considering the robot's motion capabilities. Both the tomogram construction and the scene evaluation are accelerated through parallel computation. Our approach further alleviates the trajectory generation complexity compared with planning in 3D spaces directly. It generates 3D trajectories by searching through multiple tomogram slices and separately adjusts the robot height to avoid overhangs. We evaluate our framework in various simulation scenarios and further test it in the real world on a quadrupedal robot. Our approach reduces the scene evaluation time by 3 orders of magnitude and improves the path planning speed by 3 times compared with existing approaches, demonstrating highly efficient global navigation in various complex 3D environments. The code is available at: https://github.com/byangw/PCT_planner.\n",
      "\n",
      "Completed navigation,3D,tomotography,ground,robot,traversability,parallel,complexity,overhangs,quadrupedal abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Drug-induced cardiotoxicity is a major health concern which can lead to serious adverse effects including life-threatening cardiac arrhythmias via the blockade of the voltage-gated hERG potassium ion channel. It is therefore of tremendous interest to develop advanced methods to identify hERG-active compounds in early stages of drug development, as well as to optimize commercially available drugs for reduced hERG activity. In this work, we present CardioGenAI, a machine learning-based framework for re-engineering both developmental and marketed drugs for reduced hERG activity while preserving their pharmacological activity. The framework incorporates novel state-of-the-art discriminative models for predicting hERG channel activity, as well as activity against the voltage-gated NaV1.5 and CaV1.2 channels due to their potential implications in modulating the arrhythmogenic potential induced by hERG channel blockade. These models can also serve independently as effective components of a virtual screening pipeline. We applied the complete framework to pimozide, an FDA-approved antipsychotic agent that demonstrates high affinity to the hERG channel, and generated 100 refined candidates. Remarkably, among the candidates is fluspirilene, a compound which is of the same class of drugs (diphenylmethanes) as pimozide and therefore has similar pharmacological activity, yet exhibits over 700-fold weaker binding to hERG. We have made all of our software open-source to facilitate integration of the CardioGenAI framework for molecular hypothesis generation into drug discovery workflows.\n",
      "\n",
      "Completed hERG, Cardiotoxicity, Machine learning, Drug development, Antipsychotic, Discriminative models, Voltage-gated, NaV1.5, CaV1.2, Fluspirilene abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Drones are also known as UAVs are originally designed for military purposes. With the technological advances, they can be seen in most of the aspects of life from filming to logistics. The increased use of drones made it sometimes essential to form a collaboration between them to perform the task efficiently in a defined process. This paper investigates the use of a combined centralised and decentralised architecture for the collaborative operation of drones in a parts delivery scenario to enable and expedite the operation of the factories of the future. The centralised and decentralised approaches were extensively researched, with experimentation being undertaken to determine the appropriateness of each approach for this use-case. Decentralised control was utilised to remove the need for excessive communication during the operation of the drones, resulting in smoother operations. Initial results suggested that the decentralised approach is more appropriate for this use-case. The individual functionalities necessary for the implementation of a decentralised architecture were proven and assessed, determining that a combination of multiple individual functionalities, namely VSLAM, dynamic collision avoidance and object tracking, would give an appropriate solution for use in an industrial setting. A final architecture for the parts delivery system was proposed for future work, using a combined centralised and decentralised approach to combat the limitations inherent in each architecture.\n",
      "\n",
      "Completed drones, UAVs, collaboration, parts delivery, factories, centralised, decentralised, VSLAM, collision, object tracking abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Medical vision language pre-training (VLP) has emerged as a frontier of research, enabling zero-shot pathological recognition by comparing the query image with the textual descriptions for each disease. Due to the complex semantics of biomedical texts, current methods struggle to align medical images with key pathological findings in unstructured reports. This leads to the misalignment with the target disease's textual representation. In this paper, we introduce a novel VLP framework designed to dissect disease descriptions into their fundamental aspects, leveraging prior knowledge about the visual manifestations of pathologies. This is achieved by consulting a large language model and medical experts. Integrating a Transformer module, our approach aligns an input image with the diverse elements of a disease, generating aspect-centric image representations. By consolidating the matches from each aspect, we improve the compatibility between an image and its associated disease. Additionally, capitalizing on the aspect-oriented representations, we present a dual-head Transformer tailored to process known and unknown diseases, optimizing the comprehensive detection efficacy. Conducting experiments on seven downstream datasets, ours outperforms recent methods by up to 8.07% and 11.23% in AUC scores for seen and novel categories, respectively. Our code is released at \\href{https://github.com/HieuPhan33/MAVL}{https://github.com/HieuPhan33/MAVL}.\n",
      "\n",
      "Completed Medical, vision, language, pre-training, pathological, recognition, alignment, disease, description, aspect abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Robotic manipulation relies on analytical or learned models to simulate the system dynamics. These models are often inaccurate and based on offline information, so that the robot planner is unable to cope with mismatches between the expected and the actual behavior of the system (e.g., the presence of an unexpected obstacle). In these situations, the robot should use information gathered online to correct its planning strategy and adapt to the actual system response. We propose a sampling-based motion planning approach that uses an estimate of the model error and online observations to correct the planning strategy at each new replanning. Our approach adapts the cost function and the sampling bias of a kinodynamic motion planner when the outcome of the executed transitions is different from the expected one (e.g., when the robot unexpectedly collides with an obstacle) so that future trajectories will avoid unreliable motions. To infer the properties of a new transition, we introduce the notion of context-awareness, i.e., we store local environment information for each executed transition and avoid new transitions with context similar to previous unreliable ones. This is helpful for leveraging online information even if the simulated transitions are far (in the state-and-action space) from the executed ones. Simulation and experimental results show that the proposed approach increases the success rate in execution and reduces the number of replannings needed to reach the goal.\n",
      "\n",
      "Completed motion, planning, sampling, model error, online, adaptation, cost function, context-awareness, simulation, experimental abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Purpose: Over the last few decades, the development of the hardware and software has enabled the application of advanced systems. In the robotics field, the UI design is an intriguing area to be explored due to the creation of devices with a wide range of functionalities in a reduced size. Moreover, the idea of using the same UI to control several systems arouses a great interest considering that this involves less learning effort and time for the users. Therefore, this paper will present a mobile application to control two industrial robots with four modes of operation. Design/methodology/approach: The smartphone was selected to be the interface due to its wide range of capabilities and the MIT Inventor App was used to create the application, whose environment is supported by Android smartphones. For the validation, ROS was used since it is a fundamental framework utilised in industrial robotics and the Arduino Uno was used to establish the data transmission between the smartphone and the board NVIDIA Jetson TX2. In MIT Inventor App, the graphical interface was created to visualize the options available in the app whereas two scripts in python were programmed to perform the simulations in ROS and carry out the tests. Findings: The results indicated that the use of the sliders to control the robots is more favourable than the Orientation Sensor due to the sensibility of the sensor and human limitations to hold the smartphone perfectly still. Another important finding was the limitations of the autonomous mode, in which the robot grabs an object. In this case, the configuration of the Kinect camera and the controllers has a significant impact on the success of the simulation. Finally, it was observed that the delay was appropriate despite the use of the Arduino UNO to transfer the data between the Smartphone and the Nvidia Jetson TX2.\n",
      "\n",
      "Completed robotics, UI design, mobile application, industrial robots, ROS, Arduino Uno, MIT Inventor App, graphical interface, python, sliders abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We study a multi-agent resilient consensus problem, where some agents are of the Byzantine type and try to prevent the normal ones from reaching consensus. In our setting, normal agents communicate with each other asynchronously over multi-hop relay channels with delays. To solve this asynchronous Byzantine consensus problem, we develop the multi-hop weighted mean subsequence reduced (MW-MSR) algorithm. The main contribution is that we characterize a tight graph condition for our algorithm to achieve Byzantine consensus, which is expressed in the novel notion of strictly robust graphs. We show that the multi-hop communication is effective for enhancing the network's resilience against Byzantine agents. As a result, we also obtain novel conditions for resilient consensus under the malicious attack model, which are tighter than those known in the literature. Furthermore, the proposed algorithm can be viewed as a generalization of the conventional flooding-based algorithms, with less computational complexity. Lastly, we provide numerical examples to show the effectiveness of the proposed algorithm.\n",
      "\n",
      "Completed resilient, consensus, Byzantine, asynchronous, delays, weighted, mean, subsequence, reduced, graphs abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Information leakage can have dramatic consequences on the security of real-time systems. Timing leaks occur when an attacker is able to infer private behavior depending on timing information. In this work, we propose a definition of expiring timed opacity w.r.t. execution time, where a system is opaque whenever the attacker is unable to deduce the reachability of some private state solely based on the execution time; in addition, the secrecy is violated only when the private state was entered \"recently\", i.e., within a given time bound (or expiration date) prior to system completion. This has an interesting parallel with concrete applications, notably cache deducibility: it may be useless for the attacker to know the cache content too late after its observance. We study here expiring timed opacity problems in timed automata. We consider the set of time bounds (or expiration dates) for which a system is opaque and show when they can be effectively computed for timed automata. We then study the decidability of several parameterized problems, when not only the bounds, but also some internal timing constants become timing parameters of unknown constant values.\n",
      "\n",
      "Completed information, leakage, timed, opacity, execution, time, secret, violation, expiration, timed automata abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Large Language Models (LLMs) have presented impressive performance across several transformative tasks. However, it is non-trivial to efficiently utilize large-scale cluster resources to develop LLMs, often riddled with numerous challenges such as frequent hardware failures, intricate parallelization strategies, and imbalanced resource utilization. In this paper, we present an in-depth characterization study of a six-month LLM development workload trace collected from our GPU datacenter Acme. Specifically, we investigate discrepancies between LLMs and prior task-specific Deep Learning (DL) workloads, explore resource utilization patterns, and identify the impact of various job failures. Our analysis summarizes hurdles we encountered and uncovers potential opportunities to optimize systems tailored for LLMs. Furthermore, we introduce our system efforts: (1) fault-tolerant pretraining, which enhances fault tolerance through LLM-involved failure diagnosis and automatic recovery. (2) decoupled scheduling for evaluation, which achieves timely performance feedback via trial decomposition and scheduling optimization.\n",
      "\n",
      "Completed Large, Language, Models, Workload, Characterization, Resource Utilization, Job Failures, Fault Tolerant, Decoupled Scheduling, Optimization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we introduce a novel dynamic expert selection framework for Mixture of Experts (MoE) models, aiming to enhance computational efficiency and model performance by adjusting the number of activated experts based on input difficulty. Unlike traditional MoE approaches that rely on fixed Top-K routing, which activates a predetermined number of experts regardless of the input's complexity, our method dynamically selects experts based on the confidence level in expert selection for each input. This allows for a more efficient utilization of computational resources, activating more experts for complex tasks requiring advanced reasoning and fewer for simpler tasks. Through extensive evaluations, our dynamic routing method demonstrates substantial improvements over conventional Top-2 routing across various benchmarks, achieving an average improvement of 0.7% with less than 90% activated parameters. Further analysis shows our model dispatches more experts to tasks requiring complex reasoning skills, like BBH, confirming its ability to dynamically allocate computational resources in alignment with the input's complexity. Our findings also highlight a variation in the number of experts needed across different layers of the transformer model, offering insights into the potential for designing heterogeneous MoE frameworks. The code and models are available at https://github.com/ZhenweiAn/Dynamic_MoE.\n",
      "\n",
      "Completed Dynamic, MoE, Expert, Selection, Computational, Efficiency, Top-K, Routing, Heterogeneous, Transformer abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "How can we discover join relationships among columns of tabular data in a data repository? Can this be done effectively when metadata is missing? Traditional column matching works mainly rely on similarity measures based on exact value overlaps, hence missing important semantics or failing to handle noise in the data. At the same time, recent dataset discovery methods focusing on deep table representation learning techniques, do not take into consideration the rich set of column similarity signals found in prior matching and discovery methods. Finally, existing methods heavily depend on user-provided similarity thresholds, hindering their deployability in real-world settings. In this paper, we propose OmniMatch, a novel join discovery technique that detects equi-joins and fuzzy-joins betwen columns by combining column-pair similarity measures with Graph Neural Networks (GNNs). OmniMatch's GNN can capture column relatedness leveraging graph transitivity, significantly improving the recall of join discovery tasks. At the same time, OmniMatch also increases the precision by augmenting its training data with negative column join examples through an automated negative example generation process. Most importantly, compared to the state-of-the-art matching and discovery methods, OmniMatch exhibits up to 14% higher effectiveness in F1 score and AUC without relying on metadata or user-provided thresholds for each similarity metric.\n",
      "\n",
      "Completed OmniMatch, join discovery, column similarity, GNN, graph transitivity, negative examples, metadata independence, user-independent, high effectiveness, F1 score, AUC abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Modern sequence-to-sequence relevance models like monoT5 can effectively capture complex textual interactions between queries and documents through cross-encoding. However, the use of natural language tokens in prompts, such as Query, Document, and Relevant for monoT5, opens an attack vector for malicious documents to manipulate their relevance score through prompt injection, e.g., by adding target words such as true. Since such possibilities have not yet been considered in retrieval evaluation, we analyze the impact of query-independent prompt injection via manually constructed templates and LLM-based rewriting of documents on several existing relevance models. Our experiments on the TREC Deep Learning track show that adversarial documents can easily manipulate different sequence-to-sequence relevance models, while BM25 (as a typical lexical model) is not affected. Remarkably, the attacks also affect encoder-only relevance models (which do not rely on natural language prompt tokens), albeit to a lesser extent.\n",
      "\n",
      "Completed sequence-to-sequence, relevance, monoT5, prompt injection, adversarial, documents, TREC, lexical, encoder-only abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Spatiotemporal datasets, which consist of spatially-referenced time series, are ubiquitous in many scientific and business-intelligence applications, such as air pollution monitoring, disease tracking, and cloud-demand forecasting. As modern datasets continue to increase in size and complexity, there is a growing need for new statistical methods that are flexible enough to capture complex spatiotemporal dynamics and scalable enough to handle large prediction problems. This work presents the Bayesian Neural Field (BayesNF), a domain-general statistical model for inferring rich probability distributions over a spatiotemporal domain, which can be used for data-analysis tasks including forecasting, interpolation, and variography. BayesNF integrates a novel deep neural network architecture for high-capacity function estimation with hierarchical Bayesian inference for robust uncertainty quantification. By defining the prior through a sequence of smooth differentiable transforms, posterior inference is conducted on large-scale data using variationally learned surrogates trained via stochastic gradient descent. We evaluate BayesNF against prominent statistical and machine-learning baselines, showing considerable improvements on diverse prediction problems from climate and public health datasets that contain tens to hundreds of thousands of measurements. The paper is accompanied with an open-source software package (https://github.com/google/bayesnf) that is easy-to-use and compatible with modern GPU and TPU accelerators on the JAX machine learning platform.\n",
      "\n",
      "Completed spatiotemporal, Bayesian, Neural, Field, forecasting, interpolation, variography, uncertainty, quantification, prediction abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Machine learning has become a common approach to predicting the outcomes of soccer matches, and the body of literature in this domain has grown substantially in the past decade and a half. This chapter discusses available datasets, the types of models and features, and ways of evaluating model performance in this application domain. The aim of this chapter is to give a broad overview of the current state and potential future developments in machine learning for soccer match results prediction, as a resource for those interested in conducting future studies in the area. Our main findings are that while gradient-boosted tree models such as CatBoost, applied to soccer-specific ratings such as pi-ratings, are currently the best-performing models on datasets containing only goals as the match features, there needs to be a more thorough comparison of the performance of deep learning models and Random Forest on a range of datasets with different types of features. Furthermore, new rating systems using both player- and team-level information and incorporating additional information from, e.g., spatiotemporal tracking and event data, could be investigated further. Finally, the interpretability of match result prediction models needs to be enhanced for them to be more useful for team management.\n",
      "\n",
      "Completed Machine, learning, soccer, prediction, datasets, models, features, evaluation, future, interpretability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Model extraction attacks (MEAs) enable an attacker to replicate the functionality of a victim deep neural network (DNN) model by only querying its API service remotely, posing a severe threat to the security and integrity of pay-per-query DNN-based services. Although the majority of current research on MEAs has primarily concentrated on neural classifiers, there is a growing prevalence of image-to-image translation (I2IT) tasks in our everyday activities. However, techniques developed for MEA of DNN classifiers cannot be directly transferred to the case of I2IT, rendering the vulnerability of I2IT models to MEA attacks often underestimated. This paper unveils the threat of MEA in I2IT tasks from a new perspective. Diverging from the traditional approach of bridging the distribution gap between attacker queries and victim training samples, we opt to mitigate the effect caused by the different distributions, known as the domain shift. This is achieved by introducing a new regularization term that penalizes high-frequency noise, and seeking a flatter minimum to avoid overfitting to the shifted distribution. Extensive experiments on different image translation tasks, including image super-resolution and style transfer, are performed on different backbone victim models, and the new design consistently outperforms the baseline by a large margin across all metrics. A few real-life I2IT APIs are also verified to be extremely vulnerable to our attack, emphasizing the need for enhanced defenses and potentially revised API publishing policies.\n",
      "\n",
      "Completed Model extraction attacks, Image-to-image translation, Deep neural networks, Domain shift, Regularization, Flatter minimum, Image super-resolution, Style transfer, I2IT APIs, Security abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this work, we extend our previously proposed offline SpatialNet for long-term streaming multichannel speech enhancement in both static and moving speaker scenarios. SpatialNet exploits spatial information, such as the spatial/steering direction of speech, for discriminating between target speech and interferences, and achieved outstanding performance. The core of SpatialNet is a narrow-band self-attention module used for learning the temporal dynamic of spatial vectors. Towards long-term streaming speech enhancement, we propose to replace the offline self-attention network with online networks that have linear inference complexity w.r.t signal length and meanwhile maintain the capability of learning long-term information. Three variants are developed based on (i) masked self-attention, (ii) Retention, a self-attention variant with linear inference complexity, and (iii) Mamba, a structured-state-space-based RNN-like network. Moreover, we investigate the length extrapolation ability of different networks, namely test on signals that are much longer than training signals, and propose a short-signal training plus long-signal fine-tuning strategy, which largely improves the length extrapolation ability of the networks within limited training time. Overall, the proposed online SpatialNet achieves outstanding speech enhancement performance for long audio streams, and for both static and moving speakers. The proposed method will be open-sourced in https://github.com/Audio-WestlakeU/NBSS.\n",
      "\n",
      "Completed streaming, multichannel, speech, enhancement, SpatialNet, self-attention, online, RNN, Mamba, NBSS abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Morality plays a fundamental role in how we perceive information while greatly influencing our decisions and judgements. Controversial topics, including vaccination, abortion, racism, and sexuality, often elicit opinions and attitudes that are not solely based on evidence but rather reflect moral worldviews. Recent advances in natural language processing have demonstrated that moral values can be gauged in human-generated textual content. Here, we design a range of language representation models fine-tuned to capture exactly the moral nuances in text, called MoralBERT. We leverage annotated moral data from three distinct sources: Twitter, Reddit, and Facebook user-generated content covering various socially relevant topics. This approach broadens linguistic diversity and potentially enhances the models' ability to comprehend morality in various contexts. We also explore a domain adaptation technique and compare it to the standard fine-tuned BERT model, using two different frameworks for moral prediction: single-label and multi-label. We compare in-domain approaches with conventional models relying on lexicon-based techniques, as well as a Machine Learning classifier with Word2Vec representation. Our results showed that in-domain prediction models significantly outperformed traditional models. While the single-label setting reaches a higher accuracy than previously achieved for the task when using BERT pretrained models. Experiments in an out-of-domain setting, instead, suggest that further work is needed for existing domain adaptation techniques to generalise between different social media platforms, especially for the multi-label task. The investigations and outcomes from this study pave the way for further exploration, enabling a more profound comprehension of moral narratives about controversial social issues.\n",
      "\n",
      "Completed morality, language processing, moral values, MoralBERT, Twitter, Reddit, Facebook, domain adaptation, single-label, multi-label abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This article proposes O-LoRaWAN, an adaptation of the LoRaWAN architecture into a modular network architecture based on the Open RAN (O-RAN) principles. In our vision, standardization of the network components and interfaces will enable the reuse of network functions, and thus, foster an accelerated tailoring of the network functions to the changing application demands. LoRaWAN shares similarities to cellular networks and becomes an interesting candidate for a transformation to the O-RAN standard. In the article we draw several transition strategies, these include the reorganization of the LoRa gateway functions into Radio and Distributed Units; enhancing network performance with RAN Intelligent Controllers exploiting the network data; and the standardization of the management and orchestration of network components. Key for that adaptation are the O-RAN interfaces. Along the article, we analyze them and suggest protocol extensions or adjustments for compatibility and interoperability between network components, advocating for the design of extensible protocols\n",
      "\n",
      "Completed LoRaWAN, O-LoRaWAN, O-RAN, Open RAN, network architecture, modularity, standardization, network functions, interoperability, extensible protocols abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Real-world vision tasks frequently suffer from the appearance of unexpected adverse weather conditions, including rain, haze, snow, and raindrops. In the last decade, convolutional neural networks and vision transformers have yielded outstanding results in single-weather video removal. However, due to the absence of appropriate adaptation, most of them fail to generalize to other weather conditions. Although ViWS-Net is proposed to remove adverse weather conditions in videos with a single set of pre-trained weights, it is seriously blinded by seen weather at train-time and degenerates when coming to unseen weather during test-time. In this work, we introduce test-time adaptation into adverse weather removal in videos, and propose the first framework that integrates test-time adaptation into the iterative diffusion reverse process. Specifically, we devise a diffusion-based network with a novel temporal noise model to efficiently explore frame-correlated information in degraded video clips at training stage. During inference stage, we introduce a proxy task named Diffusion Tubelet Self-Calibration to learn the primer distribution of test video stream and optimize the model by approximating the temporal noise model for online adaptation. Experimental results, on benchmark datasets, demonstrate that our Test-Time Adaptation method with Diffusion-based network(Diff-TTA) outperforms state-of-the-art methods in terms of restoring videos degraded by seen weather conditions. Its generalizable capability is also validated with unseen weather conditions in both synthesized and real-world videos.\n",
      "\n",
      "Completed iterative, diffusion, reverse, adaptation, video, weather, degradation, test-time, online, temporal abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Current foundation models have shown impressive performance across various tasks. However, several studies have revealed that these models are not effective for everyone due to the imbalanced geographical and economic representation of the data used in the training process. Most of this data comes from Western countries, leading to poor results for underrepresented countries. To address this issue, more data needs to be collected from these countries, but the cost of annotation can be a significant bottleneck. In this paper, we propose methods to identify the data to be annotated to balance model performance and annotation costs. Our approach first involves finding the countries with images of topics (objects and actions) most visually distinct from those already in the training datasets used by current large vision-language foundation models. Next, we identify countries with higher visual similarity for these topics and show that using data from these countries to supplement the training data improves model performance and reduces annotation costs. The resulting lists of countries and corresponding topics are made available at https://github.com/MichiganNLP/visual_diversity_budget.\n",
      "\n",
      "Completed Foundation, models, diversity, datasets, language, vision, annotation, performance, costs, bottleneck abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "When training deep neural networks, the phenomenon of $\\textit{dying neurons}$ $\\unicode{x2013}$units that become inactive or saturated, output zero during training$\\unicode{x2013}$ has traditionally been viewed as undesirable, linked with optimization challenges, and contributing to plasticity loss in continual learning scenarios. In this paper, we reassess this phenomenon, focusing on sparsity and pruning. By systematically exploring the impact of various hyperparameter configurations on dying neurons, we unveil their potential to facilitate simple yet effective structured pruning algorithms. We introduce $\\textit{Demon Pruning}$ (DemP), a method that controls the proliferation of dead neurons, dynamically leading to network sparsity. Achieved through a combination of noise injection on active units and a one-cycled schedule regularization strategy, DemP stands out for its simplicity and broad applicability. Experiments on CIFAR10 and ImageNet datasets demonstrate that DemP surpasses existing structured pruning techniques, showcasing superior accuracy-sparsity tradeoffs and training speedups. These findings suggest a novel perspective on dying neurons as a valuable resource for efficient model compression and optimization.\n",
      "\n",
      "Completed dying neurons, pruning, sparsity, structured pruning, Demon Pruning, noise injection, one-cycled schedule regularization, CIFAR10, ImageNet, optimization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Self-admitted technical debt (SATD) refers to a form of technical debt in which developers explicitly acknowledge and document the existence of technical shortcuts, workarounds, or temporary solutions within the codebase. Over recent years, researchers have manually labeled datasets derived from various software development artifacts: source code comments, messages from the issue tracker and pull request sections, and commit messages. These datasets are designed for training, evaluation, performance validation, and improvement of machine learning and deep learning models to accurately identify SATD instances. However, class imbalance poses a serious challenge across all the existing datasets, particularly when researchers are interested in categorizing the specific types of SATD. In order to address the scarcity of labeled data for SATD \\textit{identification} (i.e., whether an instance is SATD or not) and \\textit{categorization} (i.e., which type of SATD is being classified) in existing datasets, we share the \\textit{SATDAUG} dataset, an augmented version of existing SATD datasets, including source code comments, issue tracker, pull requests, and commit messages. These augmented datasets have been balanced in relation to the available artifacts and provide a much richer source of labeled data for training machine learning or deep learning models.\n",
      "\n",
      "Completed Self-admitted, technical debt, SATD, software development artifacts, datasets, machine learning, deep learning, class imbalance, identification, categorization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "While recent preference alignment algorithms for language models have demonstrated promising results, supervised fine-tuning (SFT) remains imperative for achieving successful convergence. In this paper, we study the crucial role of SFT within the context of preference alignment, emphasizing that a minor penalty for the disfavored generation style is sufficient for preference-aligned SFT. Building on this foundation, we introduce a straightforward and innovative reference model-free monolithic odds ratio preference optimization algorithm, ORPO, eliminating the necessity for an additional preference alignment phase. We demonstrate, both empirically and theoretically, that the odds ratio is a sensible choice for contrasting favored and disfavored styles during SFT across the diverse sizes from 125M to 7B. Specifically, fine-tuning Phi-2 (2.7B), Llama-2 (7B), and Mistral (7B) with ORPO on the UltraFeedback alone surpasses the performance of state-of-the-art language models with more than 7B and 13B parameters: achieving up to 12.20% on $\\text{AlpacaEval}_{2.0}$ and 7.32 in MT-Bench, as shown in Figures 1 and 12. We release code and model checkpoints for Mistral-ORPO-$\\alpha$ (7B) and Mistral-ORPO-$\\beta$ (7B).\n",
      "\n",
      "Completed preference, alignment, SFT, ORPO, reference-free, monolithic, odds ratio, empirical, theoretical, state-of-the-art abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Inspired by the success of general-purpose models in NLP, recent studies attempt to unify different vision tasks in the same sequence format and employ autoregressive Transformers for sequence prediction. They apply uni-directional attention to capture sequential dependencies and generate task sequences recursively. However, such autoregressive Transformers may not fit vision tasks well, as vision task sequences usually lack the sequential dependencies typically observed in natural languages. In this work, we design Masked AutoDecoder~(MAD), an effective multi-task vision generalist. MAD consists of two core designs. First, we develop a parallel decoding framework that introduces bi-directional attention to capture contextual dependencies comprehensively and decode vision task sequences in parallel. Second, we design a masked sequence modeling approach that learns rich task contexts by masking and reconstructing task sequences. In this way, MAD handles all the tasks by a single network branch and a simple cross-entropy loss with minimal task-specific designs. Extensive experiments demonstrate the great potential of MAD as a new paradigm for unifying various vision tasks. MAD achieves superior performance and inference efficiency compared to autoregressive counterparts while obtaining competitive accuracy with task-specific models. Code will be released.\n",
      "\n",
      "Completed unifying, vision, tasks, sequence, Transformers, autoregressive, attention, dependencies, Masked, AutoDecoder abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "As more than 70$\\%$ of reviews in the existing opinion summary data set are positive, current opinion summarization approaches are reluctant to generate negative summaries given the input of negative texts. To address such sentiment bias, a direct approach without the over-reliance on a specific framework is to generate additional data based on large language models to balance the emotional distribution of the dataset. However, data augmentation based on large language models faces two disadvantages: 1) the potential issues or toxicity in the augmented data; 2) the expensive costs. Therefore, in this paper, we propose a novel data augmentation framework based on both large and small language models for debiasing opinion summarization. In specific, a small size of synthesized negative reviews is obtained by rewriting the positive text via a large language model. Then, a disentangle reconstruction model is trained based on the generated data. After training, a large amount of synthetic data can be obtained by decoding the new representation obtained from the combination of different sample representations and filtering based on confusion degree and sentiment classification. Experiments have proved that our framework can effectively alleviate emotional bias same as using only large models, but more economically.\n",
      "\n",
      "Completed bias, opinion, summarization, data augmentation, large language models, small language models, rewriting, disentanglement, reconstruction, synthetic data abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we introduce VoteCut, an innovative method for unsupervised object discovery that leverages feature representations from multiple self-supervised models. VoteCut employs normalized-cut based graph partitioning, clustering and a pixel voting approach. Additionally, We present CuVLER (Cut-Vote-and-LEaRn), a zero-shot model, trained using pseudo-labels, generated by VoteCut, and a novel soft target loss to refine segmentation accuracy. Through rigorous evaluations across multiple datasets and several unsupervised setups, our methods demonstrate significant improvements in comparison to previous state-of-the-art models. Our ablation studies further highlight the contributions of each component, revealing the robustness and efficacy of our approach. Collectively, VoteCut and CuVLER pave the way for future advancements in image segmentation.\n",
      "\n",
      "Completed VoteCut, unsupervised, object discovery, normalized-cut, graph partitioning, clustering, pixel voting, CuVLER, zero-shot, pseudo-labels abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In deep reinforcement learning, estimating the value function to evaluate the quality of states and actions is essential. The value function is often trained using the least squares method, which implicitly assumes a Gaussian error distribution. However, a recent study suggested that the error distribution for training the value function is often skewed because of the properties of the Bellman operator, and violates the implicit assumption of normal error distribution in the least squares method. To address this, we proposed a method called Symmetric Q-learning, in which the synthetic noise generated from a zero-mean distribution is added to the target values to generate a Gaussian error distribution. We evaluated the proposed method on continuous control benchmark tasks in MuJoCo. It improved the sample efficiency of a state-of-the-art reinforcement learning method by reducing the skewness of the error distribution.\n",
      "\n",
      "Completed Deep, Reinforcement, Learning, Value, Function, Bellman, Operator, Normal, Distribution, Symmetric abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "With advancements in domain generalized stereo matching networks, models pre-trained on synthetic data demonstrate strong robustness to unseen domains. However, few studies have investigated the robustness after fine-tuning them in real-world scenarios, during which the domain generalization ability can be seriously degraded. In this paper, we explore fine-tuning stereo matching networks without compromising their robustness to unseen domains. Our motivation stems from comparing Ground Truth (GT) versus Pseudo Label (PL) for fine-tuning: GT degrades, but PL preserves the domain generalization ability. Empirically, we find the difference between GT and PL implies valuable information that can regularize networks during fine-tuning. We also propose a framework to utilize this difference for fine-tuning, consisting of a frozen Teacher, an exponential moving average (EMA) Teacher, and a Student network. The core idea is to utilize the EMA Teacher to measure what the Student has learned and dynamically improve GT and PL for fine-tuning. We integrate our framework with state-of-the-art networks and evaluate its effectiveness on several real-world datasets. Extensive experiments show that our method effectively preserves the domain generalization ability during fine-tuning.\n",
      "\n",
      "Completed stereo, matching, networks, domain, generalization, robustness, fine-tuning, pseudo, label, regularization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We propose a fast and simple explainable AI (XAI) method for point cloud data. It computes pointwise importance with respect to a trained network downstream task. This allows better understanding of the network properties, which is imperative for safety-critical applications. In addition to debugging and visualization, our low computational complexity facilitates online feedback to the network at inference. This can be used to reduce uncertainty and to increase robustness. In this work, we introduce \\emph{Feature Based Interpretability} (FBI), where we compute the features' norm, per point, before the bottleneck. We analyze the use of gradients and post- and pre-bottleneck strategies, showing pre-bottleneck is preferred, in terms of smoothness and ranking. We obtain at least three orders of magnitude speedup, compared to current XAI methods, thus, scalable for big point clouds or large-scale architectures. Our approach achieves SOTA results, in terms of classification explainability. We demonstrate how the proposed measure is helpful in analyzing and characterizing various aspects of 3D learning, such as rotation invariance, robustness to out-of-distribution (OOD) outliers or domain shift and dataset bias.\n",
      "\n",
      "Completed XAI, explainability, point cloud, safety-critical, debugging, visualization, online feedback, uncertainty reduction, robustness, explainability measure abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Reinforcement learning from human feedback (RLHF) is the mainstream paradigm used to align large language models (LLMs) with human preferences. Yet existing RLHF heavily relies on accurate and informative reward models, which are vulnerable and sensitive to noise from various sources, e.g. human labeling errors, making the pipeline fragile. In this work, we improve the effectiveness of the reward model by introducing a penalty term on the reward, named as \\textit{contrastive rewards}. %Contrastive rewards Our approach involves two steps: (1) an offline sampling step to obtain responses to prompts that serve as baseline calculation and (2) a contrastive reward calculated using the baseline responses and used in the Proximal Policy Optimization (PPO) step. We show that contrastive rewards enable the LLM to penalize reward uncertainty, improve robustness, encourage improvement over baselines, calibrate according to task difficulty, and reduce variance in PPO. We show empirically contrastive rewards can improve RLHF substantially, evaluated by both GPTs and humans, and our method consistently outperforms strong baselines.\n",
      "\n",
      "Completed Reinforcement, learning, human, feedback, reward, model, contrastive, reward, uncertainty, robustness abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper we present a first non-iterative imaging method for nonlinear materials, based on Monotonicity Principle. Specifically, we deal with the inverse obstacle problem, where the aim is to retrieve a nonlinear anomaly embedded in linear known background.\n",
      "  The Monotonicity Principle (MP) is a general property for various class of PDEs, that has recently generalized to nonlinear elliptic PDEs. Basically, it states a monotone relation between the point-wise value of the unknown material property and the boundary measurements. It is at the foundation of a class of non-iterative imaging methods, characterized by a very low execution time that makes them ideal candidates for real-time applications.\n",
      "  In this work, we develop an inversion method that overcomes some of the peculiar difficulties in practical application of MP to imaging of nonlinear materials, preserving the feasibility for real-time applications. For the sake of clarity, we focus on a specific application, i.e. the Magnetostatic Permeability Tomography where the goal is retrieving the unknown (nonlinear) permeability by boundary measurements in DC operations. This choice is motivated by applications in the inspection of boxes and containers for security.\n",
      "  Reconstructions from simulated data prove the effectiveness of the presented method.\n",
      "\n",
      "Completed nonlinear, materials, Monotonicity, Principle, inverse, obstacle, problem, elliptic, PDEs, permeability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Given the remarkable achievements in image generation through diffusion models, the research community has shown increasing interest in extending these models to video generation. Recent diffusion models for video generation have predominantly utilized attention layers to extract temporal features. However, attention layers are limited by their memory consumption, which increases quadratically with the length of the sequence. This limitation presents significant challenges when attempting to generate longer video sequences using diffusion models. To overcome this challenge, we propose leveraging state-space models (SSMs). SSMs have recently gained attention as viable alternatives due to their linear memory consumption relative to sequence length. In the experiments, we first evaluate our SSM-based model with UCF101, a standard benchmark of video generation. In addition, to investigate the potential of SSMs for longer video generation, we perform an experiment using the MineRL Navigate dataset, varying the number of frames to 64 and 150. In these settings, our SSM-based model can considerably save memory consumption for longer sequences, while maintaining competitive FVD scores to the attention-based models. Our codes are available at https://github.com/shim0114/SSM-Meets-Video-Diffusion-Models.\n",
      "\n",
      "Completed diffusion, video generation, attention layers, state-space models, linear memory consumption, UCF101 benchmark, MineRL Navigate dataset, memory consumption, FVD scores, codes abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Large Language Models (LLMs) have witnessed remarkable advancements in recent years, prompting the exploration of tool learning, which integrates LLMs with external tools to address diverse real-world challenges. Assessing the capability of LLMs to utilise tools necessitates large-scale and stable benchmarks. However, previous works relied on either hand-crafted online tools with limited scale, or large-scale real online APIs suffering from instability of API status. To address this problem, we introduce StableToolBench, a benchmark evolving from ToolBench, proposing a virtual API server and stable evaluation system. The virtual API server contains a caching system and API simulators which are complementary to alleviate the change in API status. Meanwhile, the stable evaluation system designs solvable pass and win rates using GPT-4 as the automatic evaluator to eliminate the randomness during evaluation. Experimental results demonstrate the stability of StableToolBench, and further discuss the effectiveness of API simulators, the caching system, and the evaluator system.\n",
      "\n",
      "Completed Large, Language, Models, Tool, Learning, Benchmark, Stable, Virtual, API, Evaluator abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We study the use of large language model-based agents for interacting with software via web browsers. Unlike prior work, we focus on measuring the agents' ability to perform tasks that span the typical daily work of knowledge workers utilizing enterprise software systems. To this end, we propose WorkArena, a remote-hosted benchmark of 29 tasks based on the widely-used ServiceNow platform. We also introduce BrowserGym, an environment for the design and evaluation of such agents, offering a rich set of actions as well as multimodal observations. Our empirical evaluation reveals that while current agents show promise on WorkArena, there remains a considerable gap towards achieving full task automation. Notably, our analysis uncovers a significant performance disparity between open and closed-source LLMs, highlighting a critical area for future exploration and development in the field.\n",
      "\n",
      "Completed Large, Language, Model, WorkArena, Benchmark, BrowserGym, Automation, Open, Source, LLMs abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Histopathological whole slide images (WSIs) classification has become a foundation task in medical microscopic imaging processing. Prevailing approaches involve learning WSIs as instance-bag representations, emphasizing significant instances but struggling to capture the interactions between instances. Additionally, conventional graph representation methods utilize explicit spatial positions to construct topological structures but restrict the flexible interaction capabilities between instances at arbitrary locations, particularly when spatially distant. In response, we propose a novel dynamic graph representation algorithm that conceptualizes WSIs as a form of the knowledge graph structure. Specifically, we dynamically construct neighbors and directed edge embeddings based on the head and tail relationships between instances. Then, we devise a knowledge-aware attention mechanism that can update the head node features by learning the joint attention score of each neighbor and edge. Finally, we obtain a graph-level embedding through the global pooling process of the updated head, serving as an implicit representation for the WSI classification. Our end-to-end graph representation learning approach has outperformed the state-of-the-art WSI analysis methods on three TCGA benchmark datasets and in-house test sets. Our code is available at https://github.com/WonderLandxD/WiKG.\n",
      "\n",
      "Completed histopathology, whole slide images, graph representation, knowledge graph, dynamic graphs, attention mechanism, TCGA, benchmark datasets, WSI analysis, WiKG abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Large Language Models (LLMs), benefiting from the auto-regressive modelling approach performed on massive unannotated texts corpora, demonstrates powerful perceptual and reasoning capabilities. However, as for extending auto-regressive modelling to multi-modal scenarios to build Large Multi-modal Models (LMMs), there lies a great difficulty that the image information is processed in the LMM as continuous visual embeddings, which cannot obtain discrete supervised labels for classification. In this paper, we successfully perform multi-modal auto-regressive modeling with a unified objective for the first time. Specifically, we propose the concept of visual words, which maps the visual features to probability distributions over LLM's vocabulary, providing supervision information for visual modelling. We further explore the distribution of visual features in the semantic space within LMM and the possibility of using text embeddings to represent visual information. Experimental results and ablation studies on 5 VQA tasks and 4 benchmark toolkits validate the powerful performance of our proposed approach.\n",
      "\n",
      "Completed Large, Language, Models, Multi-modal, Models, Visual, Words, Vocabulary, Semantic, Representation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "How to decode human vision through neural signals has attracted a long-standing interest in neuroscience and machine learning. Modern contrastive learning and generative models improved the performance of fMRI-based visual decoding and reconstruction. However, the high cost and low temporal resolution of fMRI limit their applications in brain-computer interfaces (BCIs), prompting a high need for EEG-based visual reconstruction. In this study, we present an EEG-based visual reconstruction framework. It consists of a plug-and-play EEG encoder called the Adaptive Thinking Mapper (ATM), which is aligned with image embeddings, and a two-stage EEG guidance image generator that first transforms EEG features into image priors and then reconstructs the visual stimuli with a pre-trained image generator. Our approach allows EEG embeddings to achieve superior performance in image classification and retrieval tasks. Our two-stage image generation strategy vividly reconstructs images seen by humans. Furthermore, we analyzed the impact of signals from different time windows and brain regions on decoding and reconstruction. The versatility of our framework is demonstrated in the magnetoencephalogram (MEG) data modality. We report that EEG-based visual decoding achieves SOTA performance, highlighting the portability, low cost, and high temporal resolution of EEG, enabling a wide range of BCI applications. The code of ATM is available at https://anonymous.4open.science/status/EEG_Image_decode-DEEF.\n",
      "\n",
      "Completed EEG, fMRI, neural signals, visual reconstruction, contrastive learning, generative models, brain-computer interfaces, image recognition, image generation, magnetoencephalogram abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Shuffling gradient methods, which are also known as stochastic gradient descent (SGD) without replacement, are widely implemented in practice, particularly including three popular algorithms: Random Reshuffle (RR), Shuffle Once (SO), and Incremental Gradient (IG). Compared to the empirical success, the theoretical guarantee of shuffling gradient methods was not well-understanding for a long time. Until recently, the convergence rates had just been established for the average iterate for convex functions and the last iterate for strongly convex problems (using squared distance as the metric). However, when using the function value gap as the convergence criterion, existing theories cannot interpret the good performance of the last iterate in different settings (e.g., constrained optimization). To bridge this gap between practice and theory, we prove last-iterate convergence rates for shuffling gradient methods with respect to the objective value even without strong convexity. Our new results either (nearly) match the existing last-iterate lower bounds or are as fast as the previous best upper bounds for the average iterate.\n",
      "\n",
      "Completed shuffling, gradient, methods, SGD, RR, SO, IG, convergence, function value gap, last iterate abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Applications that deal with sensitive information may have restrictions placed on the data available to a machine learning (ML) classifier. For example, in some applications, a classifier may not have direct access to sensitive attributes, affecting its ability to produce accurate and fair decisions. This paper proposes a framework that models the trade-off between accuracy and fairness under four practical scenarios that dictate the type of data available for analysis. Prior works examine this trade-off by analyzing the outputs of a scoring function that has been trained to implicitly learn the underlying distribution of the feature vector, class label, and sensitive attribute of a dataset. In contrast, our framework directly analyzes the behavior of the optimal Bayesian classifier on this underlying distribution by constructing a discrete approximation it from the dataset itself. This approach enables us to formulate multiple convex optimization problems, which allow us to answer the question: How is the accuracy of a Bayesian classifier affected in different data restricting scenarios when constrained to be fair? Analysis is performed on a set of fairness definitions that include group and individual fairness. Experiments on three datasets demonstrate the utility of the proposed framework as a tool for quantifying the trade-offs among different fairness notions and their distributional dependencies.\n",
      "\n",
      "Completed machine, learning, fairness, accuracy, classifier, Bayesian, distribution, scenarios, datasets, convex abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper presents the results of the SHROOM, a shared task focused on detecting hallucinations: outputs from natural language generation (NLG) systems that are fluent, yet inaccurate. Such cases of overgeneration put in jeopardy many NLG applications, where correctness is often mission-critical. The shared task was conducted with a newly constructed dataset of 4000 model outputs labeled by 5 annotators each, spanning 3 NLP tasks: machine translation, paraphrase generation and definition modeling.\n",
      "  The shared task was tackled by a total of 58 different users grouped in 42 teams, out of which 27 elected to write a system description paper; collectively, they submitted over 300 prediction sets on both tracks of the shared task. We observe a number of key trends in how this approach was tackled -- many participants rely on a handful of model, and often rely either on synthetic data for fine-tuning or zero-shot prompting strategies. While a majority of the teams did outperform our proposed baseline system, the performances of top-scoring systems are still consistent with a random handling of the more challenging items.\n",
      "\n",
      "Completed hallucinations, NLG, overgeneration, correctness, dataset, annotators, machine translation, paraphrase generation, definition modeling, synthetic data abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The devices designed for the Internet-of-Things encompass a large variety of distinct processor architectures, forming a highly heterogeneous zoo. In order to tackle this, we employ a simulator to estimate the performance of the matrix-matrix multiplication (GEMM) kernel on processors designed to operate at the edge. Our simulator adheres to the modern implementations of GEMM, advocated by GotoBLAS2, BLIS, OpenBLAS, etc., to carefully account for the amount of data transfers across the memory hierarchy of different algorithmic variants of the kernel. %Armed with this tool, A small collection of experiments provide the necessary data to calibrate the simulator and deliver highly accurate estimations of the execution time for a given processor architecture.\n",
      "\n",
      "Completed Internet-of-Things, heterogeneous, simulator, GEMM, edge, GotoBLAS2, BLIS, OpenBLAS, calibration, execution abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The DESERE Workshop, our First Workshop on Decentralised Search and Recommendation, offers a platform for researchers to explore and share innovative ideas on decentralised web services, mainly focusing on three major topics: (i) societal impact of decentralised systems: their effect on privacy, policy, and regulation; (ii) decentralising applications: algorithmic and performance challenges that arise from decentralisation; and (iii) infrastructure to support decentralised systems and services: peer-to-peer networks, routing, and performance evaluation tools\n",
      "\n",
      "Completed decentralized, search, recommendation, privacy, policy, regulation, algorithms, performance, infrastructure, networks, routing abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Explainable Artificial Intelligence is critical in unraveling decision-making processes in complex machine learning models. LIME (Local Interpretable Model-agnostic Explanations) is a well-known XAI framework for image analysis. It utilizes image segmentation to create features to identify relevant areas for classification. Consequently, poor segmentation can compromise the consistency of the explanation and undermine the importance of the segments, affecting the overall interpretability. Addressing these challenges, we introduce DSEG-LIME (Data-Driven Segmentation LIME), featuring: i) a data-driven segmentation for human-recognized feature generation, and ii) a hierarchical segmentation procedure through composition. We benchmark DSEG-LIME on pre-trained models with images from the ImageNet dataset - scenarios without domain-specific knowledge. The analysis includes a quantitative evaluation using established XAI metrics, complemented by a qualitative assessment through a user study. Our findings demonstrate that DSEG outperforms in most of the XAI metrics and enhances the alignment of explanations with human-recognized concepts, significantly improving interpretability. The code is available under: https://github. com/patrick-knab/DSEG-LIME\n",
      "\n",
      "Completed Explainable, Artificial Intelligence, LIME, Image analysis, Data-driven, Segmentation, Human-recognized, Interpretability, ImageNet, User study abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The estimation of 6D object poses is a fundamental task in many computer vision applications. Particularly, in high risk scenarios such as human-robot interaction, industrial inspection, and automation, reliable pose estimates are crucial. In the last years, increasingly accurate and robust deep-learning-based approaches for 6D object pose estimation have been proposed. Many top-performing methods are not end-to-end trainable but consist of multiple stages. In the context of deep uncertainty quantification, deep ensembles are considered as state of the art since they have been proven to produce well-calibrated and robust uncertainty estimates. However, deep ensembles can only be applied to methods that can be trained end-to-end. In this work, we propose a method to quantify the uncertainty of multi-stage 6D object pose estimation approaches with deep ensembles. For the implementation, we choose SurfEmb as representative, since it is one of the top-performing 6D object pose estimation approaches in the BOP Challenge 2022. We apply established metrics and concepts for deep uncertainty quantification to evaluate the results. Furthermore, we propose a novel uncertainty calibration score for regression tasks to quantify the quality of the estimated uncertainty.\n",
      "\n",
      "Completed 6D, object, pose, estimation, deep, learning, uncertainty, quantification, ensembles, SurfEmb, BOP abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Low-cost, vision-centric 3D perception systems for autonomous driving have made significant progress in recent years, narrowing the gap to expensive LiDAR-based methods. The primary challenge in becoming a fully reliable alternative lies in robust depth prediction capabilities, as camera-based systems struggle with long detection ranges and adverse lighting and weather conditions. In this work, we introduce HyDRa, a novel camera-radar fusion architecture for diverse 3D perception tasks. Building upon the principles of dense BEV (Bird's Eye View)-based architectures, HyDRa introduces a hybrid fusion approach to combine the strengths of complementary camera and radar features in two distinct representation spaces. Our Height Association Transformer module leverages radar features already in the perspective view to produce more robust and accurate depth predictions. In the BEV, we refine the initial sparse representation by a Radar-weighted Depth Consistency. HyDRa achieves a new state-of-the-art for camera-radar fusion of 64.2 NDS (+1.8) and 58.4 AMOTA (+1.5) on the public nuScenes dataset. Moreover, our new semantically rich and spatially accurate BEV features can be directly converted into a powerful occupancy representation, beating all previous camera-based methods on the Occ3D benchmark by an impressive 3.7 mIoU.\n",
      "\n",
      "Completed camera-radar, 3D perception, autonomous driving, LiDAR, depth prediction, HyDRa, BEV, Height Association Transformer, Radar-weighted Depth Consistency, Occ3D abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "To thoroughly assess the mathematical reasoning abilities of Large Language Models (LLMs), we need to carefully curate evaluation datasets covering diverse mathematical concepts and mathematical problems at different difficulty levels. In pursuit of this objective, we propose FineMath in this paper, a fine-grained mathematical evaluation benchmark dataset for assessing Chinese LLMs. FineMath is created to cover the major key mathematical concepts taught in elementary school math, which are further divided into 17 categories of math word problems, enabling in-depth analysis of mathematical reasoning abilities of LLMs. All the 17 categories of math word problems are manually annotated with their difficulty levels according to the number of reasoning steps required to solve these problems. We conduct extensive experiments on a wide range of LLMs on FineMath and find that there is still considerable room for improvements in terms of mathematical reasoning capability of Chinese LLMs. We also carry out an in-depth analysis on the evaluation process and methods that have been overlooked previously. These two factors significantly influence the model results and our understanding of their mathematical reasoning capabilities. The dataset will be publicly available soon.\n",
      "\n",
      "Completed FineMath, mathematical, reasoning, Chinese, benchmark, dataset, elementary, school, word, difficulty abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We investigate two fundamental problems in mobile computing: exploration and rendezvous, with two distinct mobile agents in an unknown graph. The agents can read and write information on whiteboards that are located at all nodes. They both move along one adjacent edge at every time-step. In the exploration problem, both agents start from the same node of the graph and must traverse all of its edges. We show that a simple variant of depth-first search achieves collective exploration in $m$ synchronous time-steps, where $m$ is the number of edges of the graph. This improves the competitive ratio of collective graph exploration. In the rendezvous problem, the agents start from different nodes of the graph and must meet as fast as possible. We introduce an algorithm guaranteeing rendezvous in at most $\\frac{3}{2}m$ time-steps. This improves over the so-called `wait for Mommy' algorithm which requires $2m$ time-steps. All our guarantees are derived from a more general asynchronous setting in which the speeds of the agents are controlled by an adversary at all times. Our guarantees also generalize to weighted graphs, if the number of edges $m$ is replaced by the sum of all edge lengths.\n",
      "\n",
      "Completed mobile, computing, exploration, rendezvous, agents, graph, whiteboards, time-steps, synchronous, asynchronous abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We consider the problem of estimation of a function by two agents (and a fusion center) given local data. Data comprises of samples of an independent variable and the corresponding value of a dependent variable. The agents are given a set of features using which they construct suitable function spaces to formulate and solve the estimation problem. The estimated functions are to be uploaded to a fusion space where they are fused to obtain the system estimate of the mapping and then downloaded by the agents to gather knowledge about the other agents estimate of the function. To this end, we present the following: a systematic construction of fusion space given the features of the agents; the derivation of an uploading operator for the agents to upload their estimated functions to a fusion space; an optimization problem in the fusion space to fuse the functions uploaded; the derivation of a downloading operator for the fused function to be downloaded. Through an example on least squares regression, we demonstrate the distributed estimation architecture that has been developed.\n",
      "\n",
      "Completed fusion, space, function, estimation, agents, features, upload, download, least, squares abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The creation of high-quality human-labeled image-caption datasets presents a significant bottleneck in the development of Visual-Language Models (VLMs). We propose a novel approach that leverages the strengths of Large Language Models (LLMs) and image generation models to create synthetic image-text pairs for efficient and effective VLM training. Our method employs pretraining a text-to-image model to synthesize image embeddings starting from captions generated by an LLM. These synthetic pairs are then used to train a VLM. Extensive experiments demonstrate that the VLM trained with synthetic data exhibits comparable performance on image captioning, while requiring a fraction of the data used by models trained solely on human-annotated data. In particular, we outperform the baseline by 17% through augmentation with a synthetic dataset. Furthermore, we show that synthesizing in the image embedding space is 25% faster than in the pixel space. This research introduces a promising technique for generating large-scale, customizable image datasets, leading to enhanced VLM performance and wider applicability across various domains, all with improved data efficiency and resource utilization.\n",
      "\n",
      "Completed visual-language models, captioning, synthetic data, large language models, embedding space, image generation, image embeddings, data efficiency, resource utilization, applicability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Due to the needs of road traffic flow monitoring and public safety management, video surveillance cameras are widely distributed in urban roads. However, the information captured directly by each camera is siloed, making it difficult to use it effectively. Vehicle re-identification refers to finding a vehicle that appears under one camera in another camera, which can correlate the information captured by multiple cameras. While license plate recognition plays an important role in some applications, there are some scenarios where re-identification method based on vehicle appearance are more suitable. The main challenge is that the data of vehicle appearance has the characteristics of high inter-class similarity and large intra-class differences. Therefore, it is difficult to accurately distinguish between different vehicles by relying only on vehicle appearance information. At this time, it is often necessary to introduce some extra information, such as spatio-temporal information. Nevertheless, the relative position of the vehicles rarely changes when passing through two adjacent cameras in the bridge scenario. In this paper, we present a vehicle re-identification method based on flock similarity, which improves the accuracy of vehicle re-identification by utilizing vehicle information adjacent to the target vehicle. When the relative position of the vehicles remains unchanged and flock size is appropriate, we obtain an average relative improvement of 204% on VeRi dataset in our experiments. Then, the effect of the magnitude of the relative position change of the vehicles as they pass through two cameras is discussed. We present two metrics that can be used to quantify the difference and establish a connection between them. Although this assumption is based on the bridge scenario, it is often true in other scenarios due to driving safety and camera location.\n",
      "\n",
      "Completed vehicle, re-identification, surveillance, appearance, spatio-temporal, flock, similarity, VeRi, bridge, dataset abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The sequence reconstruction problem, introduced by Levenshtein in 2001, considers a scenario where the sender transmits a codeword from some codebook, and the receiver obtains $N$ noisy outputs of the codeword. We study the problem of efficient reconstruction using $N$ outputs that are each corrupted by at most $t$ substitutions. Specifically, for the ubiquitous Reed-Solomon codes, we adapt the Koetter-Vardy soft-decoding algorithm, presenting a reconstruction algorithm capable of correcting beyond Johnson radius. Furthermore, the algorithm uses $\\mathcal{O}(nN)$ field operations, where $n$ is the codeword length.\n",
      "\n",
      "Completed sequence, reconstruction, Levenshtein, codebook, outputs, substitutions, Reed-Solomon, Koetter-Vardy, soft-decoding, Johnson abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Given an increasing sequence of integers $x_1,\\ldots,x_n$ from a universe $\\{0,\\ldots,u-1\\}$, the monotone minimal perfect hash function (MMPHF) for this sequence is a data structure that answers the following rank queries: $rank(x) = i$ if $x = x_i$, for $i\\in \\{1,\\ldots,n\\}$, and $rank(x)$ is arbitrary otherwise. Assadi, Farach-Colton, and Kuszmaul recently presented at SODA'23 a proof of the lower bound $\\Omega(n \\min\\{\\log\\log\\log u, \\log n\\})$ for the bits of space required by MMPHF, provided $u \\ge n 2^{2^{\\sqrt{\\log\\log n}}}$, which is tight since there is a data structure for MMPHF that attains this space bound (and answers the queries in $O(\\log u)$ time). In this paper, we close the remaining gap by proving that, for $u \\ge (1+\\epsilon)n$, where $\\epsilon > 0$ is any constant, the tight lower bound is $\\Omega(n \\min\\{\\log\\log\\log \\frac{u}{n}, \\log n\\})$, which is also attainable; we observe that, for all reasonable cases when $n < u < (1+\\epsilon)n$, known facts imply tight bounds, which virtually settles the problem. Along the way we substantially simplify the proof of Assadi et al. replacing a part of their heavy combinatorial machinery by trivial observations. However, an important part of the proof still remains complicated. This part of our paper repeats arguments of Assadi et al. and is not novel. Nevertheless, we include it, for completeness, offering a somewhat different perspective on these arguments.\n",
      "\n",
      "Completed MMPHF, rank queries, monotone, space bound, tight lower bound, combinatorial machinery, Assadi, Farach-Colton, Kuszmaul, SODA'23 abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Without well-labeled ground truth data, machine learning-based systems would not be as ubiquitous as they are today, but these systems rely on substantial amounts of correctly labeled data. Unfortunately, crowdsourced labeling is time consuming and expensive. To address the concerns of effort and tedium, we designed CAL, a novel interface to aid in data labeling. We made several key design decisions for CAL, which include preventing inapt labels from being selected, guiding users in selecting an appropriate label when they need assistance, incorporating labeling documentation into the interface, and providing an efficient means to view previous labels. We implemented a production-quality implementation of CAL and report a user-study evaluation that compares CAL to a standard spreadsheet. Key findings of our study include users using CAL reported lower cognitive load, did not increase task time, users rated CAL to be easier to use, and users preferred CAL over the spreadsheet.\n",
      "\n",
      "Completed machine, learning, data, labeling, crowdsourced, time, effort, tedium, interface, spreadsheet abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Terrestrial networks form the fundamental infrastructure of modern communication systems, serving more than 4 billion users globally. However, terrestrial networks are facing a wide range of challenges, from coverage and reliability to interference and congestion. As the demands of the 6G era are expected to be much higher, it is crucial to address these challenges to ensure a robust and efficient communication infrastructure for the future. To address these problems, Non-terrestrial Network (NTN) has emerged to be a promising solution. NTNs are communication networks that leverage airborne (e.g., unmanned aerial vehicles) and spaceborne vehicles (e.g., satellites) to facilitate ultra-reliable communications and connectivity with high data rates and low latency over expansive regions. This article aims to provide a comprehensive survey on the utilization of network slicing, Artificial Intelligence/Machine Learning (AI/ML), and Open Radio Access Network (ORAN) to address diverse challenges of NTNs from the perspectives of both academia and industry. Particularly, we first provide an in-depth tutorial on NTN and the key enabling technologies including network slicing, AI/ML, and ORAN. Then, we provide a comprehensive survey on how network slicing and AI/ML have been leveraged to overcome the challenges that NTNs are facing. Moreover, we present how ORAN can be utilized for NTNs. Finally, we highlight important challenges, open issues, and future research directions of NTN in the 6G era.\n",
      "\n",
      "Completed non-terrestrial networks, network slicing, artificial intelligence, machine learning, open radio access networks, unmanned aerial vehicles, satellites, ultra-reliable communications, 6G, communication infrastructure abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Current makeup transfer methods are limited to simple makeup styles, making them difficult to apply in real-world scenarios. In this paper, we introduce Stable-Makeup, a novel diffusion-based makeup transfer method capable of robustly transferring a wide range of real-world makeup, onto user-provided faces. Stable-Makeup is based on a pre-trained diffusion model and utilizes a Detail-Preserving (D-P) makeup encoder to encode makeup details. It also employs content and structural control modules to preserve the content and structural information of the source image. With the aid of our newly added makeup cross-attention layers in U-Net, we can accurately transfer the detailed makeup to the corresponding position in the source image. After content-structure decoupling training, Stable-Makeup can maintain content and the facial structure of the source image. Moreover, our method has demonstrated strong robustness and generalizability, making it applicable to varioustasks such as cross-domain makeup transfer, makeup-guided text-to-image generation and so on. Extensive experiments have demonstrated that our approach delivers state-of-the-art (SOTA) results among existing makeup transfer methods and exhibits a highly promising with broad potential applications in various related fields.\n",
      "\n",
      "Completed makeup, transfer, diffusion, Stable-Makeup, encoder, U-Net, cross-attention, decoupling, robustness, SOTA abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This article explores the dynamic influence of computational entities based on multi-agent systems theory (SMA) combined with large language models (LLM), which are characterized by their ability to simulate complex human interactions, as a possibility to revolutionize human user interaction from the use of specialized artificial agents to support everything from operational organizational processes to strategic decision making based on applied knowledge and human orchestration. Previous investigations reveal that there are limitations, particularly in the autonomous approach of artificial agents, especially when dealing with new challenges and pragmatic tasks such as inducing logical reasoning and problem solving. It is also considered that traditional techniques, such as the stimulation of chains of thoughts, require explicit human guidance. In our approach we employ agents developed from large language models (LLM), each with distinct prototyping that considers behavioral elements, driven by strategies that stimulate the generation of knowledge based on the use case proposed in the scenario (role-play) business, using a discussion approach between agents (guided conversation). We demonstrate the potential of developing agents useful for organizational strategies, based on multi-agent system theories (SMA) and innovative uses based on large language models (LLM based), offering a differentiated and adaptable experiment to different applications, complexities, domains, and capabilities from LLM.\n",
      "\n",
      "Completed large, language, models, multi-agent, systems, agents, simulation, human, interaction, orchestration, strategies abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Acting is an important decisional function for autonomous robots. Acting relies on skills to implement and to model the activities it oversees: refinement, local recovery, temporal dispatching, external asynchronous events, and commands execution, all done online. While sitting between planning and the robotic platform, acting often relies on programming primitives and an interpreter which executes these skills. Following our experience in providing a formal framework to program the functional components of our robots, we propose a new language, to program the acting skills. This language maps unequivocally into a formal model which can then be used to check properties offline or execute the skills, or more precisely their formal equivalent, and perform runtime verification. We illustrate with a real example how we can program a survey mission for a drone in this new language, prove some formal properties on the program and directly execute the formal model on the drone to perform the mission.\n",
      "\n",
      "Completed acting, skills, robots, programming, language, formal model, runtime verification, drone, survey mission, execution abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present \"SemCity,\" a 3D diffusion model for semantic scene generation in real-world outdoor environments. Most 3D diffusion models focus on generating a single object, synthetic indoor scenes, or synthetic outdoor scenes, while the generation of real-world outdoor scenes is rarely addressed. In this paper, we concentrate on generating a real-outdoor scene through learning a diffusion model on a real-world outdoor dataset. In contrast to synthetic data, real-outdoor datasets often contain more empty spaces due to sensor limitations, causing challenges in learning real-outdoor distributions. To address this issue, we exploit a triplane representation as a proxy form of scene distributions to be learned by our diffusion model. Furthermore, we propose a triplane manipulation that integrates seamlessly with our triplane diffusion model. The manipulation improves our diffusion model's applicability in a variety of downstream tasks related to outdoor scene generation such as scene inpainting, scene outpainting, and semantic scene completion refinements. In experimental results, we demonstrate that our triplane diffusion model shows meaningful generation results compared with existing work in a real-outdoor dataset, SemanticKITTI. We also show our triplane manipulation facilitates seamlessly adding, removing, or modifying objects within a scene. Further, it also enables the expansion of scenes toward a city-level scale. Finally, we evaluate our method on semantic scene completion refinements where our diffusion model enhances predictions of semantic scene completion networks by learning scene distribution. Our code is available at https://github.com/zoomin-lee/SemCity.\n",
      "\n",
      "Completed diffusion, model, semantic, scene, generation, outdoor, triplane, manipulation, inpainting, completion abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Algorithms for initializing particle distribution in SPH simulations of complex geometries have been proven essential for improving the accuracy of SPH simulations. However, no such algorithms exist for boundary integral SPH models, which can model complex geometries without needing virtual particle layers. This study introduces a Boundary Integral based Particle Initialization (BIPI) algorithm. It consists of a particle-shifting technique carefully designed to redistribute particles to fit the boundary by using the boundary integral formulation for particles adjacent to the boundary. The proposed BIPI algorithm gives special consideration to particles adjacent to the boundary to prevent artificial volume compression. It can automatically produce a \"uniform\" particle distribution with reduced and stabilized concentration gradient for domains with complex geometrical shapes. Finally, a number of examples are presented to demonstrate the effectiveness of the proposed algorithm.\n",
      "\n",
      "Completed particle, SPH, geometry, boundary integral, BIPI, particle-shifting, boundary, volume compression, uniform distribution, concentration gradient abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The transparent boundary condition for the free Schr\\\"{o}dinger equation on a rectangular computational domain requires implementation of an operator of the form $\\sqrt{\\partial_t-i\\triangle_{\\Gamma}}$ where $\\triangle_{\\Gamma}$ is the Laplace-Beltrami operator. It is known that this operator is nonlocal in time as well as space which poses a significant challenge in developing an efficient numerical method of solution. The computational complexity of the existing methods scale with the number of time-steps which can be attributed to the nonlocal nature of the boundary operator. In this work, we report an effectively local approximation for the boundary operator such that the resulting complexity remains independent of number of time-steps. At the heart of this algorithm is a Pad\\'e approximant based rational approximation of certain fractional operators that handles corners of the domain adequately. For the spatial discretization, we use a Legendre-Galerkin spectral method with a new boundary adapted basis which ensures that the resulting linear system is banded. A compatible boundary-lifting procedure is also presented which accommodates the segments as well as the corners on the boundary. The proposed novel scheme can be implemented within the framework of any one-step time marching schemes. In particular, we demonstrate these ideas for two one-step methods, namely, the backward-differentiation formula of order 1 (BDF1) and the trapezoidal rule (TR). For the sake of comparison, we also present a convolution quadrature based scheme conforming to the one-step methods which is computationally expensive but serves as a golden standard. Finally, several numerical tests are presented to demonstrate the effectiveness of our novel method as well as to verify the order of convergence empirically.\n",
      "\n",
      "Completed Schrödinger equation, Laplace-Beltrami operator, nonlocal boundary operator, effective local approximation, Padé approximant, Legendre-Galerkin spectral method, boundary adapted basis, compatible boundary-lifting procedure, backward-differentiation formula, trapezoidal rule abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Imitation learning from human hand motion data presents a promising avenue for imbuing robots with human-like dexterity in real-world manipulation tasks. Despite this potential, substantial challenges persist, particularly with the portability of existing hand motion capture (mocap) systems and the difficulty of translating mocap data into effective control policies. To tackle these issues, we introduce DexCap, a portable hand motion capture system, alongside DexIL, a novel imitation algorithm for training dexterous robot skills directly from human hand mocap data. DexCap offers precise, occlusion-resistant tracking of wrist and finger motions based on SLAM and electromagnetic field together with 3D observations of the environment. Utilizing this rich dataset, DexIL employs inverse kinematics and point cloud-based imitation learning to replicate human actions with robot hands. Beyond learning from human motion, DexCap also offers an optional human-in-the-loop correction mechanism to refine and further improve robot performance. Through extensive evaluation across six dexterous manipulation tasks, our approach not only demonstrates superior performance but also showcases the system's capability to effectively learn from in-the-wild mocap data, paving the way for future data collection methods for dexterous manipulation. More details can be found at https://dex-cap.github.io\n",
      "\n",
      "Completed DexCap, DexIL, imitation learning, robot, hand motion, motion capture, SLAM, electromagnetic field, inverse kinematics, point cloud abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper introduces RobotCycle, a novel ongoing project that leverages Autonomous Vehicle (AV) research to investigate how cycling infrastructure influences cyclist behaviour and safety during real-world journeys. The project's requirements were defined in collaboration with key stakeholders (i.e. city planners, cyclists, and policymakers), informing the design of risk and safety metrics and the data collection criteria. We propose a data-driven approach relying on a novel, rich dataset of diverse traffic scenes captured through a custom-designed wearable sensing unit. We extract road-user trajectories and analyse deviations suggesting risk or potentially hazardous interactions in correlation with infrastructural elements in the environment. Driving profiles and trajectory patterns are associated with local road segments, driving conditions, and road-user interactions to predict traffic behaviour and identify critical scenarios. Moreover, leveraging advancements in AV research, the project extracts detailed 3D maps, traffic flow patterns, and trajectory models to provide an in-depth assessment and analysis of the behaviour of all traffic agents. This data can then inform the design of cyclist-friendly road infrastructure, improving road safety and cyclability, as it provides valuable insights for enhancing cyclist protection and promoting sustainable urban mobility.\n",
      "\n",
      "Completed RobotCycle, Cycling, Infrastructure, Behaviour, Safety, Risk, Metrics, Data, Analysis, Mobility abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Large language models (LLMs) struggle to follow a sequence of instructions in a single query as they may ignore or misinterpret part of it. This impairs their performance in complex problems whose solution requires multiple intermediate steps, such as multilingual (translate then answer) and multimodal (caption then answer) tasks. We empirically verify this with open-source LLMs as large as LLaMA-2 70B and Mixtral-8x7B. Targeting the scarcity of sequential instructions in present-day data, we propose sequential instruction tuning, a simple yet effective strategy to automatically augment instruction tuning data and equip LLMs with the ability to execute multiple sequential instructions. After exploring interleaving instructions in existing datasets, such as Alpaca, with a wide range of intermediate tasks, we find that sequential instruction-tuned models consistently outperform the conventional instruction-tuned baselines in downstream tasks involving reasoning, multilingual, and multimodal abilities. To shed further light on our technique, we analyse how adversarial intermediate texts, unseen tasks, prompt verbalization, number of tasks, and prompt length affect SIT. We hope that this method will open new research avenues on instruction tuning for complex tasks.\n",
      "\n",
      "Completed sequence, instructions, language models, multilingual, multimodal, sequential instruction tuning, instruction tuning, reasoning, adversarial, verbalization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Mechanisms for generating differentially private synthetic data based on marginals and graphical models have been successful in a wide range of settings. However, one limitation of these methods is their inability to incorporate public data. Initializing a data generating model by pre-training on public data has shown to improve the quality of synthetic data, but this technique is not applicable when model structure is not determined a priori. We develop the mechanism jam-pgm, which expands the adaptive measurements framework to jointly select between measuring public data and private data. This technique allows for public data to be included in a graphical-model-based mechanism. We show that jam-pgm is able to outperform both publicly assisted and non publicly assisted synthetic data generation mechanisms even when the public data distribution is biased.\n",
      "\n",
      "Completed differential, private, synthetic, data, marginals, graphical, models, public, data, jam-pgm abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "By using unsupervised domain adaptation (UDA), knowledge can be transferred from a label-rich source domain to a target domain that contains relevant information but lacks labels. Many existing UDA algorithms suffer from directly using raw images as input, resulting in models that overly focus on redundant information and exhibit poor generalization capability. To address this issue, we attempt to improve the performance of unsupervised domain adaptation by employing the Fourier method (FTF).Specifically, FTF is inspired by the amplitude of Fourier spectra, which primarily preserves low-level statistical information. In FTF, we effectively incorporate low-level information from the target domain into the source domain by fusing the amplitudes of both domains in the Fourier domain. Additionally, we observe that extracting features from batches of images can eliminate redundant information while retaining class-specific features relevant to the task. Building upon this observation, we apply the Fourier Transform at the data stream level for the first time. To further align multiple sources of data, we introduce the concept of correlation alignment. To evaluate the effectiveness of our FTF method, we conducted evaluations on four benchmark datasets for domain adaptation, including Office-31, Office-Home, ImageCLEF-DA, and Office-Caltech. Our results demonstrate superior performance.\n",
      "\n",
      "Completed unsupervised, domain adaptation, Fourier, amplitude, features, fusion, correlation, alignment, evaluation, benchmark abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Keyword spotting systems for always-on TinyML-constrained applications require on-site tuning to boost the accuracy of offline trained classifiers when deployed in unseen inference conditions. Adapting to the speech peculiarities of target users requires many in-domain samples, often unavailable in real-world scenarios. Furthermore, current on-device learning techniques rely on computationally intensive and memory-hungry backbone update schemes, unfit for always-on, battery-powered devices. In this work, we propose a novel on-device learning architecture, composed of a pretrained backbone and a user-aware embedding learning the user's speech characteristics. The so-generated features are fused and used to classify the input utterance. For domain shifts generated by unseen speakers, we measure error rate reductions of up to 19% from 30.1% to 24.3% based on the 35-class problem of the Google Speech Commands dataset, through the inexpensive update of the user projections. We moreover demonstrate the few-shot learning capabilities of our proposed architecture in sample- and class-scarce learning conditions. With 23.7 kparameters and 1 MFLOP per epoch required for on-device training, our system is feasible for TinyML applications aimed at battery-powered microcontrollers.\n",
      "\n",
      "Completed TinyML, keyword, spotting, on-device, learning, speech, domain, adaptation, few-shot, resource-constrained abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recent developments in Language Models (LMs) have shown their effectiveness in NLP tasks, particularly in knowledge-intensive tasks. However, the mechanisms underlying knowledge storage and memory access within their parameters remain elusive. In this paper, we investigate whether a generative LM (e.g., GPT-2) is able to access its memory sequentially or randomly. Through carefully-designed synthetic tasks, covering the scenarios of full recitation, selective recitation and grounded question answering, we reveal that LMs manage to sequentially access their memory while encountering challenges in randomly accessing memorized content. We find that techniques including recitation and permutation improve the random memory access capability of LMs. Furthermore, by applying this intervention to realistic scenarios of open-domain question answering, we validate that enhancing random access by recitation leads to notable improvements in question answering. The code to reproduce our experiments can be found at https://github. com/sail-sg/lm-random-memory-access.\n",
      "\n",
      "Completed Language, Models, Knowledge, Storage, Memory, Access, Sequential, Random, Recitation, Permutation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We introduce StyleGaussian, a novel 3D style transfer technique that allows instant transfer of any image's style to a 3D scene at 10 frames per second (fps). Leveraging 3D Gaussian Splatting (3DGS), StyleGaussian achieves style transfer without compromising its real-time rendering ability and multi-view consistency. It achieves instant style transfer with three steps: embedding, transfer, and decoding. Initially, 2D VGG scene features are embedded into reconstructed 3D Gaussians. Next, the embedded features are transformed according to a reference style image. Finally, the transformed features are decoded into the stylized RGB. StyleGaussian has two novel designs. The first is an efficient feature rendering strategy that first renders low-dimensional features and then maps them into high-dimensional features while embedding VGG features. It cuts the memory consumption significantly and enables 3DGS to render the high-dimensional memory-intensive features. The second is a K-nearest-neighbor-based 3D CNN. Working as the decoder for the stylized features, it eliminates the 2D CNN operations that compromise strict multi-view consistency. Extensive experiments show that StyleGaussian achieves instant 3D stylization with superior stylization quality while preserving real-time rendering and strict multi-view consistency. Project page: https://kunhao-liu.github.io/StyleGaussian/\n",
      "\n",
      "Completed StyleGaussian, 3D, Style, Transfer, 3DGS, Embedding, Transfer, Decoding, Multi-view, Consistency abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Context: Static analyses are well-established to aid in understanding bugs or vulnerabilities during the development process or in large-scale studies. A low false-positive rate is essential for the adaption in practice and for precise results of empirical studies. Unfortunately, static analyses tend to report where a vulnerability manifests rather than the fix location. This can cause presumed false positives or imprecise results. Method: To address this problem, we designed an adaption of an existing static analysis algorithm that can distinguish between a manifestation and fix location, and reports error chains. An error chain represents at least two interconnected errors that occur successively, thus building the connection between the fix and manifestation location. We used our tool CogniCryptSUBS for a case study on 471 GitHub repositories, a performance benchmark to compare different analysis configurations, and conducted an expert interview. Result: We found that 50 % of the projects with a report had at least one error chain. Our runtime benchmark demonstrated that our improvement caused only a minimal runtime overhead of less than 4 %. The results of our expert interview indicate that with our adapted version participants require fewer executions of the analysis. Conclusion: Our results indicate that error chains occur frequently in real-world projects, and ignoring them can lead to imprecise evaluation results. The runtime benchmark indicates that our tool is a feasible and efficient solution for detecting error chains in real-world projects. Further, our results gave a hint that the usability of static analyses may benefit from supporting error chains.\n",
      "\n",
      "Completed static, analysis, vulnerability, manifestation, fix, error, chain, CogniCryptSUBS, performance, usability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Interventions on model-internal states are fundamental operations in many areas of AI, including model editing, steering, robustness, and interpretability. To facilitate such research, we introduce $\\textbf{pyvene}$, an open-source Python library that supports customizable interventions on a range of different PyTorch modules. $\\textbf{pyvene}$ supports complex intervention schemes with an intuitive configuration format, and its interventions can be static or include trainable parameters. We show how $\\textbf{pyvene}$ provides a unified and extensible framework for performing interventions on neural models and sharing the intervened upon models with others. We illustrate the power of the library via interpretability analyses using causal abstraction and knowledge localization. We publish our library through Python Package Index (PyPI) and provide code, documentation, and tutorials at https://github.com/stanfordnlp/pyvene.\n",
      "\n",
      "Completed pyvene, interventions, model editing, steering, robustness, interpretability, PyTorch, causal abstraction, knowledge localization, open source abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We introduce Chronos, a simple yet effective framework for pretrained probabilistic time series models. Chronos tokenizes time series values using scaling and quantization into a fixed vocabulary and trains existing transformer-based language model architectures on these tokenized time series via the cross-entropy loss. We pretrained Chronos models based on the T5 family (ranging from 20M to 710M parameters) on a large collection of publicly available datasets, complemented by a synthetic dataset that we generated via Gaussian processes to improve generalization. In a comprehensive benchmark consisting of 42 datasets, and comprising both classical local models and deep learning methods, we show that Chronos models: (a) significantly outperform other methods on datasets that were part of the training corpus; and (b) have comparable and occasionally superior zero-shot performance on new datasets, relative to methods that were trained specifically on them. Our results demonstrate that Chronos models can leverage time series data from diverse domains to improve zero-shot accuracy on unseen forecasting tasks, positioning pretrained models as a viable tool to greatly simplify forecasting pipelines.\n",
      "\n",
      "Completed Pretrained, Probabilistic, Time, Series, Transformer, Language, Models, Generalization, Zero-shot, Forecasting abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We investigate efficient methods for training Large Language Models (LLMs) to possess capabilities in multiple specialized domains, such as coding, math reasoning and world knowledge. Our method, named Branch-Train-MiX (BTX), starts from a seed model, which is branched to train experts in embarrassingly parallel fashion with high throughput and reduced communication cost. After individual experts are asynchronously trained, BTX brings together their feedforward parameters as experts in Mixture-of-Expert (MoE) layers and averages the remaining parameters, followed by an MoE-finetuning stage to learn token-level routing. BTX generalizes two special cases, the Branch-Train-Merge method, which does not have the MoE finetuning stage to learn routing, and sparse upcycling, which omits the stage of training experts asynchronously. Compared to alternative approaches, BTX achieves the best accuracy-efficiency tradeoff.\n",
      "\n",
      "Completed Branch-Train-MiX, Large Language Models, Specialized Domains, Mixture-of-Expert, Asynchronous Training, Embarrassingly Parallel, High Throughput, Reduced Communication Cost, MoE Fine-tuning, Accuracy-Efficiency Tradeoff abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Introducing Small Cell Networks (SCN) has significantly improved wireless link quality, spectrum efficiency and network capacity, which has been viewed as one of the key technologies in the fifth-generation (5G) mobile network. However, this technology increases the frequency of handover (HO) procedures caused by the dense deployment of cells in the network with reduced cell coverage, bringing new security and privacy issues. The current 5G-AKA and HO protocols are vulnerable to security weaknesses, such as the lack of forward secrecy and identity confusion attacks. The high HO frequency of HOs might magnify these security and privacy concerns in the 5G mobile network. This work addresses these issues by proposing a secure privacy-preserving universal HO scheme ($\\UniHand$) for SCNs in 5G mobile communication. $\\UniHand$ can achieve mutual authentication, strong anonymity, perfect forward secrecy, key-escrow-free and key compromise impersonation (KCI) resilience. To the best of our knowledge, this is the \\textit{first} scheme to achieve secure, privacy-preserving universal HO with \\textit{KCI} resilience for roaming users in 5G environment. We demonstrate that our proposed scheme is resilient against all the essential security threats by performing a comprehensive formal security analysis and conducting relevant experiments to show the cost-effectiveness of the proposed scheme.\n",
      "\n",
      "Completed 5G, handover, security, privacy, mutual authentication, anonymity, forward secrecy, key-escrow-free, KCI resilience, roaming abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Echocardiography (echo) is the first imaging modality used when assessing cardiac function. The measurement of functional biomarkers from echo relies upon the segmentation of cardiac structures and deep learning models have been proposed to automate the segmentation process. However, in order to translate these tools to widespread clinical use it is important that the segmentation models are robust to a wide variety of images (e.g. acquired from different scanners, by operators with different levels of expertise etc.). To achieve this level of robustness it is necessary that the models are trained with multiple diverse datasets. A significant challenge faced when training with multiple diverse datasets is the variation in label presence, i.e. the combined data are often partially-labelled. Adaptations of the cross entropy loss function have been proposed to deal with partially labelled data. In this paper we show that training naively with such a loss function and multiple diverse datasets can lead to a form of shortcut learning, where the model associates label presence with domain characteristics, leading to a drop in performance. To address this problem, we propose a novel label dropout scheme to break the link between domain characteristics and the presence or absence of labels. We demonstrate that label dropout improves echo segmentation Dice score by 62% and 25% on two cardiac structures when training using multiple diverse partially labelled datasets.\n",
      "\n",
      "Completed echocardiography, cardiac function, biomarkers, deep learning, segmentation, cross entropy loss function, partial labelling, shortcut learning, label dropout, segmentation performance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this work, we introduce a strong Designated Verifier Signature (DVS) scheme that incorporates a message recovery mechanism inspired by the concept of the Universal Designated Verifier Signature (UDVS) scheme. It is worth noting that Saeednia's strong designated verifier signature scheme fails to guarantee the privacy of the signature, making it unsuitable for certain applications such as medical record certificates or voting systems. To overcome this limitation, we extend Lee's strong designated verifier signature with a message recovery scheme to develop a universal designated verifier signature scheme. This universal designated verifier scheme is crafted to safeguard the privacy of signature holders, ensuring that only designated verifiers can authenticate the true signer and recover the messages.\n",
      "\n",
      "Completed Designated, Verifier, Signature, Scheme, Message, Recovery, Universal, Privacy, Signature, Holder abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Software model checking is a challenging problem, and generating relevant invariants is a key factor in proving the safety properties of a program. Program invariants can be obtained by various approaches, including lightweight procedures based on data-flow analysis and intensive techniques using Craig interpolation. Although data-flow analysis runs efficiently, it often produces invariants that are too weak to prove the properties. By contrast, interpolation-based approaches build strong invariants from interpolants, but they might not scale well due to expensive interpolation procedures. Invariants can also be injected into model-checking algorithms to assist the analysis. Invariant injection has been studied for many well-known approaches, including k-induction, predicate abstraction, and symbolic execution. We propose an augmented interpolation-based verification algorithm that injects external invariants into interpolation-based model checking (McMillan, 2003), a hardware model-checking algorithm recently adopted for software verification. The auxiliary invariants help prune unreachable states in Craig interpolants and confine the analysis to the reachable parts of a program. We implemented the proposed technique in the verification framework CPAchecker and evaluated it against mature SMT-based methods in CPAchecker as well as other state-of-the-art software verifiers. We found that injecting invariants reduces the number of interpolation queries needed to prove safety properties and improves the run-time efficiency. Consequently, the proposed invariant-injection approach verified difficult tasks that none of its plain version (i.e., without invariants), the invariant generator, or any compared tools could solve.\n",
      "\n",
      "Completed Software, model checking, invariants, generation, data-flow analysis, interpolation, invariant injection, k-induction, predicate abstraction, symbolic execution abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper discusses a multi-term time-fractional delay differential equation in a real Hilbert space. An iterative scheme for a multi-term time-fractional differential equation is established using Rothe's method. The method of semi-discretization is extended to this kind of time fractional problem with delay in the case that the time delay parameter $\\nu >0$ satisfies $\\nu\\leq T$, where $T$ denotes the final time. We apply the accretivity of the operator $A$ in an iterative scheme to establish the existence and regularity of strong solutions to the considered problem. Finally, an example is provided to demonstrate the abstract result.\n",
      "\n",
      "Completed multi-term, time-fractional, delay, differential, equation, real, Hilbert, space, iterative, scheme abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "A preconditioning strategy is proposed for the iterative solve of large numbers of linear systems with variable matrix and right-hand side which arise during the computation of solution statistics of stochastic elliptic partial differential equations with random variable coefficients sampled by Monte Carlo. Building on the assumption that a truncated Karhunen-Lo\\`{e}ve expansion of a known transform of the random variable coefficient is known, we introduce a compact representation of the random coefficient in the form of a Voronoi quantizer. The number of Voronoi cells, each of which is represented by a centroidal variable coefficient, is set to the prescribed number $P$ of preconditioners. Upon sampling the random variable coefficient, the linear system assembled with a given realization of the coefficient is solved with the preconditioner whose centroidal variable coefficient is the closest to the realization. We consider different ways to define and obtain the centroidal variable coefficients, and we investigate the properties of the induced preconditioning strategies in terms of average number of solver iterations for sequential simulations, and of load balancing for parallel simulations. Another approach, which is based on deterministic grids on the system of stochastic coordinates of the truncated representation of the random variable coefficient, is proposed with a stochastic dimension which increases with the number $P$ of preconditioners. This approach allows to bypass the need for preliminary computations in order to determine the optimal stochastic dimension of the truncated approximation of the random variable coefficient for a given number of preconditioners.\n",
      "\n",
      "Completed Monte, Carlo, stochastic, elliptic, partial, differential, equations, random, variable, coefficients, preconditioning abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Large Language Models have revolutionized numerous tasks with their remarkable efficacy.However, the editing of these models, crucial for rectifying outdated or erroneous information, often leads to a complex issue known as the ripple effect in the hidden space. This effect, while difficult to detect, can significantly impede the efficacy of model editing tasks and deteriorate model performance.This paper addresses this scientific challenge by proposing a novel evaluation methodology, Graphical Outlier Relation based Assessment(GORA), which quantitatively evaluates the adaptations of the model and the subsequent impact of editing. Furthermore, we introduce the Selective Outlier Re-Editing Approach(SORA), a model editing method designed to mitigate this ripple effect. Our comprehensive evaluations reveal that the ripple effect in the hidden space is a significant issue in all current model editing methods. However, our proposed methods, GORA and SORA, effectively identify and alleviate this issue, respectively, contributing to the advancement of LLM editing techniques.\n",
      "\n",
      "Completed ripple effect, hidden space, Large Language Models, editing, GORA, SORA, evaluation, model performance, re-editing, outliers abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Over the last 30 years, the World Wide Web has changed significantly. In this paper, we argue that common practices to prepare web pages for delivery conflict with many efforts to present content with minimal latency, one fundamental goal that pushed changes in the WWW. To bolster our arguments, we revisit reasons that led to changes of HTTP and compare them systematically with techniques to prepare web pages. We found that the structure of many web pages leverages features of HTTP/1.1 but hinders the use of recent HTTP features to present content quickly. To improve the situation in the future, we propose fine-grained content segmentation. This would allow to exploit streaming capabilities of recent HTTP versions and to render content as quickly as possible without changing underlying protocols or web browsers.\n",
      "\n",
      "Completed World Wide Web, latency, HTTP, content delivery, web pages, streaming, segmentation, protocols, browsers, efficiency abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The ubiquity and energy needs of industrial refrigeration has prompted several research studies investigating various control opportunities for reducing energy demand. This work focuses on one such opportunity, termed compressor sequencing, which entails intelligently selecting the operational state of the compressors to service the required refrigeration load with the least possible work. We first study the static compressor sequencing problem and observe that deriving the optimal compressor operational state is computationally challenging and can vary dramatically based on the refrigeration load. Thus we introduce load shifting in conjunction with compressor sequencing, which entails strategically precooling the facility to allow for more efficient compressor operation. Interestingly, we show that load shifting not only provides benefits in computing the optimal compressor operational state, but also can lead to significant energy savings. Our results are based on and compared to real-world sensor data from an operating industrial refrigeration site of Butterball LLC located in Huntsville, AR, which demonstrated that without load shifting, even optimal compressor operation results in compressors often running at intermediate capacity levels, which can lead to inefficiencies. Through collected data, we demonstrate that a load shifting approach for compressor sequencing has the potential to reduce energy use of the compressors up to 20% compared to optimal sequencing without load shifting.\n",
      "\n",
      "Completed Refrigeration, Compressor, Sequencing, Load, Energy, Demand, Optimization, Butterball, Huntsville, Savings abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Large language models (LLMs) can provide rich physical descriptions of most worldly objects, allowing robots to achieve more informed and capable grasping. We leverage LLMs' common sense physical reasoning and code-writing abilities to infer an object's physical characteristics--mass $m$, friction coefficient $\\mu$, and spring constant $k$--from a semantic description, and then translate those characteristics into an executable adaptive grasp policy. Using a current-controllable, two-finger gripper with a built-in depth camera, we demonstrate that LLM-generated, physically-grounded grasp policies outperform traditional grasp policies on a custom benchmark of 12 delicate and deformable items including food, produce, toys, and other everyday items, spanning two orders of magnitude in mass and required pick-up force. We also demonstrate how compliance feedback from DeliGrasp policies can aid in downstream tasks such as measuring produce ripeness. Our code and videos are available at: https://deligrasp.github.io\n",
      "\n",
      "Completed large, language, models, grasp, physical, reasoning, code-writing, deformable, compliance, feedback abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Time-varying phasor-based analysis of subsynchronous oscillations (SSOs) involving grid-following converters (GFLCs) and its benchmarking with electromagnetic transient (EMT) models have so far been restricted to highly simplified grid models with constant voltage sources behind series R-L circuits. In this paper, modeling adequacy of bulk power systems with synchronous generators (SGs), transmission systems, loads, and GFLCs are considered. To this end, we revisit the notions of time-varying phasor calculus, highlighting the distinction between space-phasor-calculus (SPC) and two often interchangeably used frameworks namely baseband-abc and generalized averaging. We present the models of grids in SPC framework that include transmission line dynamics, load dynamics, and SG stator transients. Next, we propose a generic approach to study modeling adequacy in small-signal sense by (a) identifying critical modes through eigenvalue and singular value analysis followed by (b) using weighted maximum singular value error magnitudes as metrics, and (c) further cross-validation. Using a modified 4-machine IEEE benchmark model with up to 3 GFLCs we show that SPC framework can be used for analysis of SSOs. Further, we consider the quasistationary phasor calculus (QPC) framework that neglects transmission line, load, and SG stator dynamics to show its adequacy in SSO modeling and analysis. Time-domain and frequency-domain results with EMT models are also presented.\n",
      "\n",
      "Completed phasor, subsynchronous oscillations, grid-following converters, time-varying, time-varying phasor calculus, space-phasor-calculus, generalized averaging, transmission line dynamics, load dynamics, synchronous generators abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Privacy-preserving computing is crucial for multi-center machine learning in many applications such as healthcare and finance. In this paper a Multi-center Privacy Computing framework with Predictions Aggregation (MPCPA) based on denoising diffusion probabilistic model (DDPM) is proposed, in which conditional diffusion model training, DDPM data generation, a classifier, and strategy of prediction aggregation are included. Compared to federated learning, this framework necessitates fewer communications and leverages high-quality generated data to support robust privacy computing. Experimental validation across multiple datasets demonstrates that the proposed framework outperforms classic federated learning and approaches the performance of centralized learning with original data. Moreover, our approach demonstrates robust security, effectively addressing challenges such as image memorization and membership inference attacks. Our experiments underscore the efficacy of the proposed framework in the realm of privacy computing, with the code set to be released soon.\n",
      "\n",
      "Completed Privacy, Computing, Multi-center, Machine Learning, DDPM, Aggregation, Federated Learning, Security, Image Memorization, Membership Inference abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Vision-language pre-trained models have achieved impressive performance on various downstream tasks. However, their large model sizes hinder their utilization on platforms with limited computational resources. We find that directly using smaller pre-trained models and applying magnitude-based pruning on CLIP models leads to inflexibility and inferior performance. Recent efforts for VLP compression either adopt uni-modal compression metrics resulting in limited performance or involve costly mask-search processes with learnable masks. In this paper, we first propose the Module-wise Pruning Error (MoPE) metric, accurately assessing CLIP module importance by performance decline on cross-modal tasks. Using the MoPE metric, we introduce a unified pruning framework applicable to both pre-training and task-specific fine-tuning compression stages. For pre-training, MoPE-CLIP effectively leverages knowledge from the teacher model, significantly reducing pre-training costs while maintaining strong zero-shot capabilities. For fine-tuning, consecutive pruning from width to depth yields highly competitive task-specific models. Extensive experiments in two stages demonstrate the effectiveness of the MoPE metric, and MoPE-CLIP outperforms previous state-of-the-art VLP compression methods.\n",
      "\n",
      "Completed Module-wise, Pruning, Error, CLIP, Metric, Compression, Pre-training, Fine-tuning, Zero-shot, Competitive abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Synthetic data from generative models emerges as the privacy-preserving data-sharing solution. Such a synthetic data set shall resemble the original data without revealing identifiable private information. The backbone technology of tabular synthesizers is rooted in image generative models, ranging from Generative Adversarial Networks (GANs) to recent diffusion models. Recent prior work sheds light on the utility-privacy tradeoff on tabular data, revealing and quantifying privacy risks on synthetic data. We first conduct an exhaustive empirical analysis, highlighting the utility-privacy tradeoff of five state-of-the-art tabular synthesizers, against eight privacy attacks, with a special focus on membership inference attacks. Motivated by the observation of high data quality but also high privacy risk in tabular diffusion, we propose DP-TLDM, Differentially Private Tabular Latent Diffusion Model, which is composed of an autoencoder network to encode the tabular data and a latent diffusion model to synthesize the latent tables. Following the emerging f-DP framework, we apply DP-SGD to train the auto-encoder in combination with batch clipping and use the separation value as the privacy metric to better capture the privacy gain from DP algorithms. Our empirical evaluation demonstrates that DP-TLDM is capable of achieving a meaningful theoretical privacy guarantee while also significantly enhancing the utility of synthetic data. Specifically, compared to other DP-protected tabular generative models, DP-TLDM improves the synthetic quality by an average of 35% in data resemblance, 15% in the utility for downstream tasks, and 50% in data discriminability, all while preserving a comparable level of privacy risk.\n",
      "\n",
      "Completed Generative, Privacy, Synthetic, Data, Tabular, Diffusion, DP-TLDM, Differential, Privacy, Utility abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In the context of developing nations like India, traditional business to business (B2B) commerce heavily relies on the establishment of robust relationships, trust, and credit arrangements between buyers and sellers. Consequently, ecommerce enterprises frequently. Established in 2016 with a vision to revolutionize trade in India through technology, Udaan is the countrys largest business to business ecommerce platform. Udaan operates across diverse product categories, including lifestyle, electronics, home and employ telecallers to cultivate buyer relationships, streamline order placement procedures, and promote special promotions. The accurate anticipation of buyer order placement behavior emerges as a pivotal factor for attaining sustainable growth, heightening competitiveness, and optimizing the efficiency of these telecallers. To address this challenge, we have employed an ensemble approach comprising XGBoost and a modified version of Poisson Gamma model to predict customer order patterns with precision. This paper provides an in-depth exploration of the strategic fusion of machine learning and an empirical Bayesian approach, bolstered by the judicious selection of pertinent features. This innovative approach has yielded a remarkable 3 times increase in customer order rates, show casing its potential for transformative impact in the ecommerce industry.\n",
      "\n",
      "Completed India, B2B, E-commerce, Udaan, Customer order, XGBoost, Poisson Gamma model, Empirical Bayesian, Machine learning, Feature selection abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We formulate an XAI-based model improvement approach for Graph Neural Networks (GNNs) for node classification, called Explanation Enhanced Graph Learning (EEGL). The goal is to improve predictive performance of GNN using explanations. EEGL is an iterative self-improving algorithm, which starts with a learned \"vanilla\" GNN, and repeatedly uses frequent subgraph mining to find relevant patterns in explanation subgraphs. These patterns are then filtered further to obtain application-dependent features corresponding to the presence of certain subgraphs in the node neighborhoods. Giving an application-dependent algorithm for such a subgraph-based extension of the Weisfeiler-Leman (1-WL) algorithm has previously been posed as an open problem. We present experimental evidence, with synthetic and real-world data, which show that EEGL outperforms related approaches in predictive performance and that it has a node-distinguishing power beyond that of vanilla GNNs. We also analyze EEGL's training dynamics.\n",
      "\n",
      "Completed Explanation, Enhanced, Graph, Learning, Node, Classification, Patterns, Subgraphs, Weisfeiler-Leman, Iterative abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Few-Shot Class-Incremental Learning (FSCIL) enables machine learning systems to expand their inference capabilities to new classes using only a few labeled examples, without forgetting the previously learned classes. Classical backpropagation-based learning and its variants are often unsuitable for battery-powered, memory-constrained systems at the extreme edge. In this work, we introduce Online Few-Shot Class-Incremental Learning (O-FSCIL), based on a lightweight model consisting of a pretrained and metalearned feature extractor and an expandable explicit memory storing the class prototypes. The architecture is pretrained with a novel feature orthogonality regularization and metalearned with a multi-margin loss. For learning a new class, our approach extends the explicit memory with novel class prototypes, while the remaining architecture is kept frozen. This allows learning previously unseen classes based on only a few examples with one single pass (hence online). O-FSCIL obtains an average accuracy of 68.62% on the FSCIL CIFAR100 benchmark, achieving state-of-the-art results. Tailored for ultra-low-power platforms, we implement O-FSCIL on the 60 mW GAP9 microcontroller, demonstrating online learning capabilities within just 12 mJ per new class.\n",
      "\n",
      "Completed Few-Shot, Class-Incremental, Learning, Online, Memory, Prototype, Regularization, Orthogonality, Metalearning, Microcontroller abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In PV-rich power distribution systems, over-voltage issues are often addressed by curtailing excess generation from PV plants (in addition to reactive power control), raising fairness concerns. Existing fairness-aware control schemes tackle this problem by incorporating fairness objectives into the cost function. However, such schemes result in increased overall curtailments. This paper proposes a solution through daily topology reconfiguration, ensuring that different PV plants face varying grid conditions each day, leading to different curtailment levels and enhancing fairness. We illustrate that implementing this approach enhances overall fairness without significantly increasing overall curtailments. The optimization problem involves two stages. The day-ahead stage optimizes the network topology using day-ahead forecasts of PV generation and demand, minimizing net curtailment and accounting for fairness based on curtailments from prior days. The real-time stage implements the optimized topology and computes active and reactive power setpoints for the PV plants. Day-ahead grid constraints are modeled using LinDistFlow, and real-time control employs a linearized model with a first-order Taylor approximation. The proposed scheme is numerically validated on several benchmark test cases. Results are compared using the Jain Fairness Index, considering fairness and reconfiguration scenarios.\n",
      "\n",
      "Completed PV, fairness, curtailment, reconfiguration, topology, LinDistFlow, day-ahead, real-time, optimization, Jain Fairness Index abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "With the increasing size of datasets used for training neural networks, data pruning becomes an attractive field of research. However, most current data pruning algorithms are limited in their ability to preserve accuracy compared to models trained on the full data, especially in high pruning regimes. In this paper we explore the application of data pruning while incorporating knowledge distillation (KD) when training on a pruned subset. That is, rather than relying solely on ground-truth labels, we also use the soft predictions from a teacher network pre-trained on the complete data. By integrating KD into training, we demonstrate significant improvement across datasets, pruning methods, and on all pruning fractions. We first establish a theoretical motivation for employing self-distillation to improve training on pruned data. Then, we empirically make a compelling and highly practical observation: using KD, simple random pruning is comparable or superior to sophisticated pruning methods across all pruning regimes. On ImageNet for example, we achieve superior accuracy despite training on a random subset of only 50% of the data. Additionally, we demonstrate a crucial connection between the pruning factor and the optimal knowledge distillation weight. This helps mitigate the impact of samples with noisy labels and low-quality images retained by typical pruning algorithms. Finally, we make an intriguing observation: when using lower pruning fractions, larger teachers lead to accuracy degradation, while surprisingly, employing teachers with a smaller capacity than the student's may improve results. Our code will be made available.\n",
      "\n",
      "Completed Data, pruning, knowledge, distillation, accuracy, self-distillation, random, optimal, noisy, labels abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This study addresses the urgent need for improved prostate cancer detection methods by harnessing the power of advanced technological solutions. We introduce the application of Quantum Support Vector Machine (QSVM) to this critical healthcare challenge, showcasing an enhancement in diagnostic performance over the classical Support Vector Machine (SVM) approach. Our study not only outlines the remarkable improvements in diagnostic performance made by QSVM over the classic SVM technique, but it delves into the advancements brought about by the quantum feature map architecture, which has been carefully identified and evaluated, ensuring it aligns seamlessly with the unique characteristics of our prostate cancer dataset. This architecture succeded in creating a distinct feature space, enabling the detection of complex, non-linear patterns in the data. The findings reveal not only a comparable accuracy with classical SVM ($92\\%$) but also a $7.14\\%$ increase in sensitivity and a notably high F1-Score ($93.33\\%$). This study's important combination of quantum computing in medical diagnostics marks a pivotal step forward in cancer detection, offering promising implications for the future of healthcare technology.\n",
      "\n",
      "Completed Prostate cancer, quantum support vector machine, classical support vector machine, quantum feature map, diagnostic performance, sensitivity, F1-score, quantum computing, medical diagnostics, healthcare technology abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Model-induced distribution shifts (MIDS) occur as previous model outputs pollute new model training sets over generations of models. This is known as model collapse in the case of generative models, and performative prediction or unfairness feedback loops for supervised models. When a model induces a distribution shift, it also encodes its mistakes, biases, and unfairnesses into the ground truth of its data ecosystem. We introduce a framework that allows us to track multiple MIDS over many generations, finding that they can lead to loss in performance, fairness, and minoritized group representation, even in initially unbiased datasets. Despite these negative consequences, we identify how models might be used for positive, intentional, interventions in their data ecosystems, providing redress for historical discrimination through a framework called algorithmic reparation (AR). We simulate AR interventions by curating representative training batches for stochastic gradient descent to demonstrate how AR can improve upon the unfairnesses of models and data ecosystems subject to other MIDS. Our work takes an important step towards identifying, mitigating, and taking accountability for the unfair feedback loops enabled by the idea that ML systems are inherently neutral and objective.\n",
      "\n",
      "Completed model-induced, distribution, shifts, model, collapse, performative, prediction, unfairness, feedback, loops abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Counting (p,q)-bicliques in bipartite graphs poses a foundational challenge with broad applications, from densest subgraph discovery in algorithmic research to personalized content recommendation in practical scenarios. Despite its significance, current leading (p,q)-biclique counting algorithms fall short, particularly when faced with larger graph sizes and clique scales. Fortunately, the problem's inherent structure, allowing for the independent counting of each biclique starting from every vertex, combined with a substantial set intersections, makes it highly amenable to parallelization. Recent successes in GPU-accelerated algorithms across various domains motivate our exploration into harnessing the parallelism power of GPUs to efficiently address the (p,q)-biclique counting challenge. We introduce GBC (GPU-based Biclique Counting), a novel approach designed to enable efficient and scalable (p,q)-biclique counting on GPUs. To address major bottleneck arising from redundant comparisons in set intersections (occupying an average of 90% of the runtime), we introduce a novel data structure that hashes adjacency lists into truncated bitmaps to enable efficient set intersection on GPUs via bit-wise AND operations. Our innovative hybrid DFS-BFS exploration strategy further enhances thread utilization and effectively manages memory constraints. A composite load balancing strategy, integrating pre-runtime and runtime workload allocation, ensures equitable distribution among threads. Additionally, we employ vertex reordering and graph partitioning strategies for improved compactness and scalability. Experimental evaluations on eight real-life and two synthetic datasets demonstrate that GBC outperforms state-of-the-art algorithms by a substantial margin. In particular, GBC achieves an average speedup of 497.8x, with the largest instance achieving a remarkable 1217.7x speedup when p = q = 8.\n",
      "\n",
      "Completed biclique, counting, graphs, parallelism, algorithms, optimization, performance, efficiency, scalability, data structures abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Text-to-image generation has made significant advancements with the introduction of text-to-image diffusion models. These models typically consist of a language model that interprets user prompts and a vision model that generates corresponding images. As language and vision models continue to progress in their respective domains, there is a great potential in exploring the replacement of components in text-to-image diffusion models with more advanced counterparts. A broader research objective would therefore be to investigate the integration of any two unrelated language and generative vision models for text-to-image generation. In this paper, we explore this objective and propose LaVi-Bridge, a pipeline that enables the integration of diverse pre-trained language models and generative vision models for text-to-image generation. By leveraging LoRA and adapters, LaVi-Bridge offers a flexible and plug-and-play approach without requiring modifications to the original weights of the language and vision models. Our pipeline is compatible with various language models and generative vision models, accommodating different structures. Within this framework, we demonstrate that incorporating superior modules, such as more advanced language models or generative vision models, results in notable improvements in capabilities like text alignment or image quality. Extensive evaluations have been conducted to verify the effectiveness of LaVi-Bridge. Code is available at https://github.com/ShihaoZhaoZSH/LaVi-Bridge.\n",
      "\n",
      "Completed Text-to-Image, Diffusion-Models, Language-Models, Vision-Models, LaVi-Bridge, LoRA, Adapters, Plug-and-Play, Text-Alignment, Image-Quality abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The rapid advancement of Large Language Models (LLMs) has brought about remarkable capabilities in natural language processing but also raised concerns about their potential misuse. While strategies like supervised fine-tuning and reinforcement learning from human feedback have enhanced their safety, these methods primarily focus on natural languages, which may not generalize to other domains. This paper introduces CodeAttack, a framework that transforms natural language inputs into code inputs, presenting a novel environment for testing the safety generalization of LLMs. Our comprehensive studies on state-of-the-art LLMs including GPT-4, Claude-2, and Llama-2 series reveal a common safety vulnerability of these models against code input: CodeAttack consistently bypasses the safety guardrails of all models more than 80\\% of the time. Furthermore, we find that a larger distribution gap between CodeAttack and natural language leads to weaker safety generalization, such as encoding natural language input with data structures or using less popular programming languages. These findings highlight new safety risks in the code domain and the need for more robust safety alignment algorithms to match the code capabilities of LLMs.\n",
      "\n",
      "Completed CodeAttack, LLMs, Natural Language Processing, Safety Generalization, Code Input, GPT-4, Claude-2, Llama-2, Data Structures, Programming Languages abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this work, we introduce LazyBoE, a multi-query method for kinodynamic motion planning with forward propagation. This algorithm allows for the simultaneous exploration of a robot's state and control spaces, thereby enabling a wider suite of dynamic tasks in real-world applications. Our contributions are three-fold: i) a method for discretizing the state and control spaces to amortize planning times across multiple queries; ii) lazy approaches to collision checking and propagation of control sequences that decrease the cost of physics-based simulation; and iii) LazyBoE, a robust kinodynamic planner that leverages these two contributions to produce dynamically-feasible trajectories. The proposed framework not only reduces planning time but also increases success rate in comparison to previous approaches.\n",
      "\n",
      "Completed LazyBoE, kinodynamic, motion planning, forward propagation, state space, control space, collision checking, control propagation, physics-based simulation, dynamically-feasible abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "For users requesting popular contents from content providers, edge caching can alleviate backhaul pressure and enhance the quality of experience of users. Recently there is also a growing concern about content freshness that is quantified by age of information (AoI). Therefore, AoI-aware online caching algorithms are required, which is challenging because the content popularity is usually unknown in advance and may vary over time. In this paper, we propose an online digital twin (DT) empowered content resale mechanism in AoI-aware edge caching networks. We aim to design an optimal two-timescale caching strategy to maximize the utility of an edge network service provider (ENSP). The formulated optimization problem is non-convex and NP-hard. To tackle this intractable problem, we propose a DT-assisted Online Caching Algorithm (DT-OCA). In specific, we first decompose our formulated problem into a series of subproblems, each handling a cache period. For each cache period, we use a DT-based prediction method to effectively capture future content popularity, and develop online caching strategy. Competitive ratio analysis and extensive experimental results demonstrate that our algorithm has promising performance, and outperforms other benchmark algorithms. Insightful observations are also found and discussed.\n",
      "\n",
      "Completed edge, caching, AoI, online, digital twin, content resale, two-timescale, optimization, non-convex, intractable abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "A critical bottleneck limiting imitation learning in robotics is the lack of data. This problem is more severe in mobile manipulation, where collecting demonstrations is harder than in stationary manipulation due to the lack of available and easy-to-use teleoperation interfaces. In this work, we demonstrate TeleMoMa, a general and modular interface for whole-body teleoperation of mobile manipulators. TeleMoMa unifies multiple human interfaces including RGB and depth cameras, virtual reality controllers, keyboard, joysticks, etc., and any combination thereof. In its more accessible version, TeleMoMa works using simply vision (e.g., an RGB-D camera), lowering the entry bar for humans to provide mobile manipulation demonstrations. We demonstrate the versatility of TeleMoMa by teleoperating several existing mobile manipulators - PAL Tiago++, Toyota HSR, and Fetch - in simulation and the real world. We demonstrate the quality of the demonstrations collected with TeleMoMa by training imitation learning policies for mobile manipulation tasks involving synchronized whole-body motion. Finally, we also show that TeleMoMa's teleoperation channel enables teleoperation on site, looking at the robot, or remote, sending commands and observations through a computer network, and perform user studies to evaluate how easy it is for novice users to learn to collect demonstrations with different combinations of human interfaces enabled by our system. We hope TeleMoMa becomes a helpful tool for the community enabling researchers to collect whole-body mobile manipulation demonstrations. For more information and video results, https://robin-lab.cs.utexas.edu/telemoma-web.\n",
      "\n",
      "Completed TeleMoMa, mobile manipulation, teleoperation, whole-body, RGB-D, virtual reality, accessibility, imitation learning, human-robot interaction, user studies abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Open-sourced, user-friendly tools form the bedrock of scientific advancement across disciplines. The widespread adoption of data-driven learning has led to remarkable progress in multi-fingered dexterity, bimanual manipulation, and applications ranging from logistics to home robotics. However, existing data collection platforms are often proprietary, costly, or tailored to specific robotic morphologies. We present OPEN TEACH, a new teleoperation system leveraging VR headsets to immerse users in mixed reality for intuitive robot control. Built on the affordable Meta Quest 3, which costs $500, OPEN TEACH enables real-time control of various robots, including multi-fingered hands and bimanual arms, through an easy-to-use app. Using natural hand gestures and movements, users can manipulate robots at up to 90Hz with smooth visual feedback and interface widgets offering closeup environment views. We demonstrate the versatility of OPEN TEACH across 38 tasks on different robots. A comprehensive user study indicates significant improvement in teleoperation capability over the AnyTeleop framework. Further experiments exhibit that the collected data is compatible with policy learning on 10 dexterous and contact-rich manipulation tasks. Currently supporting Franka, xArm, Jaco, and Allegro platforms, OPEN TEACH is fully open-sourced to promote broader adoption. Videos are available at https://open-teach.github.io/.\n",
      "\n",
      "Completed Teleoperation, Virtual-reality, Open-source, User-friendly, Multi-fingered, Dexterity, Manipulation, OPEN-TEACH, Meta-Quest-3, Policy-learning abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Despite their sophisticated capabilities, large language models (LLMs) encounter a major hurdle in effective assessment. This paper first revisits the prevalent evaluation method-multiple choice question answering (MCQA), which allows for straightforward accuracy measurement. Through a comprehensive evaluation of 24 models across 11 benchmarks, we highlight several potential drawbacks of MCQA, for instance, the inconsistency between the MCQA evaluation and the generation of open-ended responses in practical scenarios. In response, we introduce an RWQ-Elo rating system, engaging 24 LLMs such as GPT-4, GPT-3.5, Google-Gemini-Pro and LLaMA-1/-2, in a two-player competitive format, with GPT-4 serving as the judge. Each LLM receives an Elo rating thereafter. This system is designed to mirror real-world usage, and for this purpose, we have compiled a new benchmark called ``Real-world questions'' (RWQ), comprising 20,772 authentic user inquiries. Additionally, we thoroughly analyze the characteristics of our system and compare it with prior leaderboards like AlpacaEval and MT-Bench. Our analysis reveals the stability of our RWQ-Elo system, the feasibility of registering new models, and its potential to reshape LLM leaderboards.\n",
      "\n",
      "Completed Large, language, models, MCQA, RWQ, Elo, GPT-4, LLaMA, AlpacaEval, MT-Bench abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this work, we investigate the potential of a large language model (LLM) to directly comprehend visual signals without the necessity of fine-tuning on multi-modal datasets. The foundational concept of our method views an image as a linguistic entity, and translates it to a set of discrete words derived from the LLM's vocabulary. To achieve this, we present the Vision-to-Language Tokenizer, abbreviated as V2T Tokenizer, which transforms an image into a ``foreign language'' with the combined aid of an encoder-decoder, the LLM vocabulary, and a CLIP model. With this innovative image encoding, the LLM gains the ability not only for visual comprehension but also for image denoising and restoration in an auto-regressive fashion-crucially, without any fine-tuning. We undertake rigorous experiments to validate our method, encompassing understanding tasks like image recognition, image captioning, and visual question answering, as well as image denoising tasks like inpainting, outpainting, deblurring, and shift restoration. Code and models are available at https://github.com/zh460045050/V2L-Tokenizer.\n",
      "\n",
      "Completed vision comprehension, large language model, cross-modal, image encoding, visual understanding, image restoration, auto-regressive, denoising, image recognition, natural language processing abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recent studies have demonstrated Large Language Models (LLMs) can extend their zero-shot generalization capabilities to multimodal learning through instruction tuning. As more modalities and downstream tasks are introduced, negative conflicts and interference may have a worse impact on performance. While this phenomenon has been overlooked in previous work, we propose a novel and extensible framework, called \\mname, for comprehensive studies and experimentation on multimodal learning with Multimodal Large Language Models (MLLMs). Specifically, we combine the well-known Mixture-of-Experts (MoE) and one of the representative PEFT techniques, \\emph{i.e.,} LoRA, designing a novel LLM-based decoder, called LoRA-MoE, for multimodal learning. The experimental results (about 20\\% improvement) have shown the effectiveness and versatility of our design in various 2D and 3D downstream tasks. Code and corresponding dataset will be available soon.\n",
      "\n",
      "Completed Multimodal, LLM, Instruction, Tuning, Interference, MoE, LoRA, LoRA-MoE, Downstream, Versatility abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We show the fault-tolerance of the not-so-well known [[8,1,4]] non-CSS code and study the logical error rates of the code.\n",
      "  To do so, we adopt the procedure of the bare ancilla method presented by Brown \\emph{et al.}\n",
      "  We choose the encoding procedure for stabilizer codes given by Gottesman and modify it to suit the setting of a class of non-CSS codes.\n",
      "  We consider two types of noise models for this study, namely the depolarizing noise and anisotropic noise to depict the logical error rates obtained in decoding.\n",
      "\n",
      "Completed non-CSS, code, logical, error, rates, bare, ancilla, method, stabilizer, noise abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present a phase autoencoder that encodes the asymptotic phase of a limit-cycle oscillator, a fundamental quantity characterizing its synchronization dynamics. This autoencoder is trained in such a way that its latent variables directly represent the asymptotic phase of the oscillator. The trained autoencoder can perform two functions without relying on the mathematical model of the oscillator: first, it can evaluate the asymptotic phase and phase sensitivity function of the oscillator; second, it can reconstruct the oscillator state on the limit cycle in the original space from the phase value as an input. Using several examples of limit-cycle oscillators, we demonstrate that the asymptotic phase and phase sensitivity function can be estimated only from time-series data by the trained autoencoder. We also present a simple method for globally synchronizing two oscillators as an application of the trained autoencoder.\n",
      "\n",
      "Completed Phase, autoencoder, asymptotic, phase, oscillator, synchronization, dynamics, representation, oscillation, reconstruction abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Fall detection based on embedded sensor is a practical and popular research direction in recent years. In terms of a specific application: fall detection methods based upon physics sensors such as [gyroscope and accelerator] have been exploited using traditional hand crafted features and feed them in machine learning models like Markov chain or just threshold based classification methods. In this paper, we build a complete system named TSFallDetect including data receiving device based on embedded sensor, mobile deep-learning model deploying platform, and a simple server, which will be used to gather models and data for future expansion. On the other hand, we exploit the sequential deep-learning methods to address this falling motion prediction problem based on data collected by inertial and film pressure sensors. We make a empirical study based on existing datasets and our datasets collected from our system separately, which shows that the deep-learning model has more potential advantage than other traditional methods, and we proposed a new deep-learning model based on the time series data to predict the fall, and it may be superior to other sequential models in this particular field.\n",
      "\n",
      "Completed fall, detection, embedded, sensor, deep-learning, time-series, Markov, chain, threshold, inertial, pressure abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Gesture recognition on wearable devices is extensively applied in human-computer interaction. Electromyography (EMG) has been used in many gesture recognition systems for its rapid perception of muscle signals. However, analyzing EMG signals on devices, like smart wristbands, usually needs inference models to have high performances, such as low inference latency, low power consumption, and low memory occupation. Therefore, this paper proposes an improved spiking neural network (SNN) to achieve these goals. We propose an adaptive multi-delta coding as a spiking coding method to improve recognition accuracy. We propose two additive solvers for SNN, which can reduce inference energy consumption and amount of parameters significantly, and improve the robustness of temporal differences. In addition, we propose a linear action detection method TAD-LIF, which is suitable for SNNs. TAD-LIF is an improved LIF neuron that can detect transient-state gestures quickly and accurately. We collected two datasets from 20 subjects including 6 micro gestures. The collection devices are two designed lightweight consumer-level EMG wristbands (3 and 8 electrode channels respectively). Compared to CNN, FCN, and normal SNN-based methods, the proposed SNN has higher recognition accuracy. The accuracy of the proposed SNN is 83.85% and 93.52% on the two datasets respectively. In addition, the inference latency of the proposed SNN is about 1% of CNN, the power consumption is about 0.1% of CNN, and the memory occupation is about 20% of CNN. The proposed methods can be used for precise, high-speed, and low-power micro-gesture recognition tasks, and are suitable for consumer-level intelligent wearable devices, which is a general way to achieve ubiquitous computing.\n",
      "\n",
      "Completed gesture, recognition, wearable, EMG, SNN, adaptive, multi-delta, coding, TAD-LIF, micro-gestures abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Tandem mass spectrometry has played a pivotal role in advancing proteomics, enabling the analysis of protein composition in biological samples. Despite the development of various deep learning methods for identifying amino acid sequences (peptides) responsible for observed spectra, challenges persist in \\emph{de novo} peptide sequencing. Firstly, prior methods struggle to identify amino acids with post-translational modifications (PTMs) due to their lower frequency in training data compared to canonical amino acids, further resulting in decreased peptide-level identification precision. Secondly, diverse types of noise and missing peaks in mass spectra reduce the reliability of training data (peptide-spectrum matches, PSMs). To address these challenges, we propose AdaNovo, a novel framework that calculates conditional mutual information (CMI) between the spectrum and each amino acid/peptide, using CMI for adaptive model training. Extensive experiments demonstrate AdaNovo's state-of-the-art performance on a 9-species benchmark, where the peptides in the training set are almost completely disjoint from the peptides of the test sets. Moreover, AdaNovo excels in identifying amino acids with PTMs and exhibits robustness against data noise. The supplementary materials contain the official code.\n",
      "\n",
      "Completed Tandem, mass, spectrometry, proteomics, deep, learning, de, novo, peptide, sequencing, PTMs abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Evolutionary Game Theory (EGT) and Artificial Intelligence (AI) are two fields that, at first glance, might seem distinct, but they have notable connections and intersections. The former focuses on the evolution of behaviors (or strategies) in a population, where individuals interact with others and update their strategies based on imitation (or social learning). The more successful a strategy is, the more prevalent it becomes over time. The latter, meanwhile, is centered on machine learning algorithms and (deep) neural networks. It is often from a single-agent perspective but increasingly involves multi-agent environments, in which intelligent agents adjust their strategies based on feedback and experience, somewhat akin to the evolutionary process yet distinct in their self-learning capacities. In light of the key components necessary to address real-world problems, including (i) learning and adaptation, (ii) cooperation and competition, (iii) robustness and stability, and altogether (iv) population dynamics of individual agents whose strategies evolve, the cross-fertilization of ideas between both fields will contribute to the advancement of mathematics of multi-agent learning systems, in particular, to the nascent domain of ``collective cooperative intelligence'' bridging evolutionary dynamics and multi-agent reinforcement learning.\n",
      "\n",
      "Completed Artificial, Intelligence, Evolutionary, Game, Theory, Learning, Adaptation, Cooperation, Competition, Reinforcement abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In the emergent realm of quantum computing, the Variational Quantum Eigensolver (VQE) stands out as a promising algorithm for solving complex quantum problems, especially in the noisy intermediate-scale quantum (NISQ) era. However, the ubiquitous presence of noise in quantum devices often limits the accuracy and reliability of VQE outcomes. This research introduces a novel approach to ameliorate this challenge by utilizing neural networks for zero noise extrapolation (ZNE) in VQE computations. By employing the Qiskit framework, we crafted parameterized quantum circuits using the RY-RZ ansatz and examined their behavior under varying levels of depolarizing noise. Our investigations spanned from determining the expectation values of a Hamiltonian, defined as a tensor product of Z operators, under different noise intensities to extracting the ground state energy. To bridge the observed outcomes under noise with the ideal noise-free scenario, we trained a Feed Forward Neural Network on the error probabilities and their associated expectation values. Remarkably, our model proficiently predicted the VQE outcome under hypothetical noise-free conditions. By juxtaposing the simulation results with real quantum device executions, we unveiled the discrepancies induced by noise and showcased the efficacy of our neural network-based ZNE technique in rectifying them. This integrative approach not only paves the way for enhanced accuracy in VQE computations on NISQ devices but also underlines the immense potential of hybrid quantum-classical paradigms in circumventing the challenges posed by quantum noise. Through this research, we envision a future where quantum algorithms can be reliably executed on noisy devices, bringing us one step closer to realizing the full potential of quantum computing.\n",
      "\n",
      "Completed Variational, Quantum, Eigensolver, Noise, Extrapolation, Neural, Networks, Qiskit, Depolarizing, ZNE abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We consider an unsupervised bilevel optimization strategy for learning regularization parameters in the context of imaging inverse problems in the presence of additive white Gaussian noise. Compared to supervised and semi-supervised metrics relying either on the prior knowledge of reference data and/or on some (partial) knowledge on the noise statistics, the proposed approach optimizes the whiteness of the residual between the observed data and the observation model with no need of ground-truth data.We validate the approach on standard Total Variation-regularized image deconvolution problems which show that the proposed quality metric provides estimates close to the mean-square error oracle and to discrepancy-based principles.\n",
      "\n",
      "Completed unsupervised, bilevel, optimization, regularization, imaging, inverse, problems, additive, white, Gaussian abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Benchmarking models via classical simulations is one of the main ways to judge ideas in quantum machine learning before noise-free hardware is available. However, the huge impact of the experimental design on the results, the small scales within reach today, as well as narratives influenced by the commercialisation of quantum technologies make it difficult to gain robust insights. To facilitate better decision-making we develop an open-source package based on the PennyLane software framework and use it to conduct a large-scale study that systematically tests 12 popular quantum machine learning models on 6 binary classification tasks used to create 160 individual datasets. We find that overall, out-of-the-box classical machine learning models outperform the quantum classifiers. Moreover, removing entanglement from a quantum model often results in as good or better performance, suggesting that \"quantumness\" may not be the crucial ingredient for the small learning tasks considered here. Our benchmarks also unlock investigations beyond simplistic leaderboard comparisons, and we identify five important questions for quantum model design that follow from our results.\n",
      "\n",
      "Completed quantum, machine learning, benchmarking, classical simulations, PennyLane, large-scale study, binary classification, entanglement, out-of-the-box, leaderboard abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Self-Supervised Learning (SSL) is at the core of training modern large machine learning models, providing a scheme for learning powerful representations that can be used in a variety of downstream tasks. However, SSL strategies must be adapted to the type of training data and downstream tasks required. We propose RS3L, a novel simulation-based SSL strategy that employs a method of re-simulation to drive data augmentation for contrastive learning. By intervening in the middle of the simulation process and re-running simulation components downstream of the intervention, we generate multiple realizations of an event, thus producing a set of augmentations covering all physics-driven variations available in the simulator. Using experiments from high-energy physics, we explore how this strategy may enable the development of a foundation model; we show how R3SL pre-training enables powerful performance in downstream tasks such as discrimination of a variety of objects and uncertainty mitigation. In addition to our results, we make the RS3L dataset publicly available for further studies on how to improve SSL strategies.\n",
      "\n",
      "Completed Self-Supervised, Learning, RS3L, Simulation, Re-simulation, Contrastive, Learning, High-energy, Physics, Foundation, Model abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Accurate detection and segmentation of diffuse large B-cell lymphoma (DLBCL) from PET images has important implications for estimation of total metabolic tumor volume, radiomics analysis, surgical intervention and radiotherapy. Manual segmentation of tumors in whole-body PET images is time-consuming, labor-intensive and operator-dependent. In this work, we develop and validate a fast and efficient three-step cascaded deep learning model for automated detection and segmentation of DLBCL tumors from PET images. As compared to a single end-to-end network for segmentation of tumors in whole-body PET images, our three-step model is more effective (improves 3D Dice score from 58.9% to 78.1%) since each of its specialized modules, namely the slice classifier, the tumor detector and the tumor segmentor, can be trained independently to a high degree of skill to carry out a specific task, rather than a single network with suboptimal performance on overall segmentation.\n",
      "\n",
      "Completed DLBCL, PET, tumor, segmentation, deep learning, cascaded, detection, slice classifier, tumor detector, tumor segmentor abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Automated slice classification is clinically relevant since it can be incorporated into medical image segmentation workflows as a preprocessing step that would flag slices with a higher probability of containing tumors, thereby directing physicians attention to the important slices. In this work, we train a ResNet-18 network to classify axial slices of lymphoma PET/CT images (collected from two institutions) depending on whether the slice intercepted a tumor (positive slice) in the 3D image or if the slice did not (negative slice). Various instances of the network were trained on 2D axial datasets created in different ways: (i) slice-level split and (ii) patient-level split; inputs of different types were used: (i) only PET slices and (ii) concatenated PET and CT slices; and different training strategies were employed: (i) center-aware (CAW) and (ii) center-agnostic (CAG). Model performances were compared using the area under the receiver operating characteristic curve (AUROC) and the area under the precision-recall curve (AUPRC), and various binary classification metrics. We observe and describe a performance overestimation in the case of slice-level split as compared to the patient-level split training. The model trained using patient-level split data with the network input containing only PET slices in the CAG training regime was the best performing/generalizing model on a majority of metrics. Our models were additionally more closely compared using the sensitivity metric on the positive slices from their respective test sets.\n",
      "\n",
      "Completed slice, classification, lymphoma, PET-CT, ResNet-18, AUROC, AUPRC, CAG, CAW, performance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Segmentation of blood vessels in murine cerebral 3D OCTA images is foundational for in vivo quantitative analysis of the effects of neurovascular disorders, such as stroke or Alzheimer's, on the vascular network. However, to accurately segment blood vessels with state-of-the-art deep learning methods, a vast amount of voxel-level annotations is required. Since cerebral 3D OCTA images are typically plagued by artifacts and generally have a low signal-to-noise ratio, acquiring manual annotations poses an especially cumbersome and time-consuming task. To alleviate the need for manual annotations, we propose utilizing synthetic data to supervise segmentation algorithms. To this end, we extract patches from vessel graphs and transform them into synthetic cerebral 3D OCTA images paired with their matching ground truth labels by simulating the most dominant 3D OCTA artifacts. In extensive experiments, we demonstrate that our approach achieves competitive results, enabling annotation-free blood vessel segmentation in cerebral 3D OCTA images.\n",
      "\n",
      "Completed cerebral, 3D, OCTA, images, segmentation, blood vessels, synthetic data, deep learning, annotations, artifacts abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In Coevolving Latent Space Networks with Attractors (CLSNA) models, nodes in a latent space represent social actors, and edges indicate their dynamic interactions. Attractors are added at the latent level to capture the notion of attractive and repulsive forces between nodes, borrowing from dynamical systems theory. However, CLSNA reliance on MCMC estimation makes scaling difficult, and the requirement for nodes to be present throughout the study period limit practical applications. We address these issues by (i) introducing a Stochastic gradient descent (SGD) parameter estimation method, (ii) developing a novel approach for uncertainty quantification using SGD, and (iii) extending the model to allow nodes to join and leave over time. Simulation results show that our extensions result in little loss of accuracy compared to MCMC, but can scale to much larger networks. We apply our approach to the longitudinal social networks of members of US Congress on the social media platform X. Accounting for node dynamics overcomes selection bias in the network and uncovers uniquely and increasingly repulsive forces within the Republican Party.\n",
      "\n",
      "Completed Stochastic, gradient, descent, attractors, latent, space, node, dynamics, social, media abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Diagnostic imaging has gained prominence as potential biomarkers for early detection and diagnosis in a diverse array of disorders including cancer. However, existing methods routinely face challenges arising from various factors such as image heterogeneity. We develop a novel imaging-based distributional data analysis (DDA) approach that incorporates the probability (quantile) distribution of the pixel-level features as covariates. The proposed approach uses a smoothed quantile distribution (via a suitable basis representation) as functional predictors in a scalar-on-functional quantile regression model. Some distinctive features of the proposed approach include the ability to: (i) account for heterogeneity within the image; (ii) incorporate granular information spanning the entire distribution; and (iii) tackle variability in image sizes for unregistered images in cancer applications. Our primary goal is risk prediction in Hepatocellular carcinoma that is achieved via predicting the change in tumor grades at post-diagnostic visits using pre-diagnostic enhancement pattern mapping (EPM) images of the liver. Along the way, the proposed DDA approach is also used for case versus control diagnosis and risk stratification objectives. Our analysis reveals that when coupled with global structural radiomics features derived from the corresponding T1-MRI scans, the proposed smoothed quantile distributions derived from EPM images showed considerable improvements in sensitivity and comparable specificity in contrast to classification based on routinely used summary measures that do not account for image heterogeneity. Given that there are limited predictive modeling approaches based on heterogeneous images in cancer, the proposed method is expected to provide considerable advantages in image-based early detection and risk prediction.\n",
      "\n",
      "Completed imaging, biomarkers, distributional, data, analysis, quantile, regression, heterogeneity, risk, prediction abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Brachycephaly, a conformation trait in some dog breeds, causes BOAS, a respiratory disorder that affects the health and welfare of the dogs with various symptoms. In this paper, a new annotated dataset composed of 190 images of bulldogs' nostrils is presented. Three degrees of stenosis are approximately equally represented in the dataset: mild, moderate and severe stenosis. The dataset also comprises a small quantity of non stenotic nostril images. To the best of our knowledge, this is the first image dataset addressing this problem. Furthermore, deep learning is investigated as an alternative to automatically infer stenosis degree using nostril images. In this work, several neural networks were tested: ResNet50, MobileNetV3, DenseNet201, SwinV2 and MaxViT. For this evaluation, the problem was modeled in two different ways: first, as a three-class classification problem (mild or open, moderate, and severe); second, as a binary classification problem, with severe stenosis as target. For the multiclass classification, a maximum median f-score of 53.77\\% was achieved by the MobileNetV3. For binary classification, a maximum median f-score of 72.08\\% has been reached by ResNet50, indicating that the problem is challenging but possibly tractable.\n",
      "\n",
      "Completed Brachycephaly, BOAS, Nostril Images, Bulldog, Stenosis, Deep Learning, Neural Networks, ResNet50, MobileNetV3, Binary Classification abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Assessing the biotype of cattle through human visual inspection is a very common and important practice in precision cattle breeding. This paper presents the results of a correlation analysis between scores produced by humans for Nelore cattle and a variety of measurements that can be derived from images or other instruments. It also presents a study using the k-means algorithm to generate new ways of clustering a batch of cattle using the measurements that most correlate with the animal's body weight and visual scores.\n",
      "\n",
      "Completed Cattle, Biotype, Precision, Human, Visual, Nelore, Measurements, Images, Clustering, K-means abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The Stochastic Extragradient (SEG) method is one of the most popular algorithms for solving finite-sum min-max optimization and variational inequality problems (VIPs) appearing in various machine learning tasks. However, existing convergence analyses of SEG focus on its with-replacement variants, while practical implementations of the method randomly reshuffle components and sequentially use them. Unlike the well-studied with-replacement variants, SEG with Random Reshuffling (SEG-RR) lacks established theoretical guarantees. In this work, we provide a convergence analysis of SEG-RR for three classes of VIPs: (i) strongly monotone, (ii) affine, and (iii) monotone. We derive conditions under which SEG-RR achieves a faster convergence rate than the uniform with-replacement sampling SEG. In the monotone setting, our analysis of SEG-RR guarantees convergence to an arbitrary accuracy without large batch sizes, a strong requirement needed in the classical with-replacement SEG. As a byproduct of our results, we provide convergence guarantees for Shuffle Once SEG (shuffles the data only at the beginning of the algorithm) and the Incremental Extragradient (does not shuffle the data). We supplement our analysis with experiments validating empirically the superior performance of SEG-RR over the classical with-replacement sampling SEG.\n",
      "\n",
      "Completed Stochastic, Extragradient, Convergence, Reshuffling, Variational, Inequality, Monotone, Strong, Arbitrary, Empirical abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In modal analysis and control of a nonlinear dynamical system, participation factors of state variables with respect to a mode of interest serve as pivotal tools for stability studies. Linear participation factors are uniquely determined by the mode's shape and composition, which are defined by the right and left eigenvectors of the linearized model. For nonlinear participation factors as well as five other variants of participation factors, this paper finds the sufficient conditions for them to be unique against scaling factors on the shape and composition of a mode. Besides, the similarity between the scaling factor and perturbation amplitude is also discussed.\n",
      "\n",
      "Completed Participation, factors, modal, analysis, nonlinear, scale, amplitude, eigenvector, stability, uniqueness abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Using $\\Gamma$-convergence, we study the Cahn-Hilliard problem with interface width parameter $\\varepsilon > 0$ for phase transitions on manifolds with conical singularities. We prove that minimizers of the corresponding energy functional exist and converge, as $\\varepsilon \\to 0$, to a function that takes only two values with an interface along a hypersurface that has minimal area among those satisfying a volume constraint. In a numerical example, we use continuation and bifurcation methods to study families of critical points at small $\\varepsilon > 0$ on 2D elliptical cones, parameterized by height and ellipticity of the base. Some of these critical points are minimizers with interfaces crossing the cone tip. On the other hand, we prove that interfaces which are minimizers of the perimeter functional, corresponding to $\\varepsilon = 0$, never pass through the cone tip for general cones with angle less than $2\\pi$. Thus tip minimizers for finite $\\varepsilon > 0$ must become saddles as $\\varepsilon \\to 0$, and we numerically identify the associated bifurcation, finding a delicate interplay of $\\varepsilon > 0$ and the cone parameters in our example.\n",
      "\n",
      "Completed Cahn-Hilliard, problem, manifolds, conical singularities, minimizers, interface, perimeter, bifurcation, interplay, tip abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Quantum circuit compilation comprises many computationally hard reasoning tasks that nonetheless lie inside #$\\mathbf{P}$ and its decision counterpart in $\\mathbf{PP}$. The classical simulation of general quantum circuits is a core example. We show for the first time that a strong simulation of universal quantum circuits can be efficiently tackled through weighted model counting by providing a linear encoding of Clifford+T circuits. To achieve this, we exploit the stabilizer formalism by Knill, Gottesmann, and Aaronson and the fact that stabilizer states form a basis for density operators. With an open-source simulator implementation, we demonstrate empirically that model counting often outperforms state-of-the-art simulation techniques based on the ZX calculus and decision diagrams. Our work paves the way to apply the existing array of powerful classical reasoning tools to realize efficient quantum circuit compilation; one of the obstacles on the road towards quantum supremacy.\n",
      "\n",
      "Completed quantum, circuit, compilation, model, counting, stabilizer, simulation, weighted, zx, decision abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Dynamic density estimation is ubiquitous in many applications, including computer vision and signal processing. One popular method to tackle this problem is the \"sliding window\" kernel density estimator. There exist various implementations of this method that use heuristically defined weight sequences for the observed data. The weight sequence, however, is a key aspect of the estimator affecting the tracking performance significantly. In this work, we study the exact mean integrated squared error (MISE) of \"sliding window\" Gaussian Kernel Density Estimators for evolving Gaussian densities. We provide a principled guide for choosing the optimal weight sequence by theoretically characterizing the exact MISE, which can be formulated as constrained quadratic programming. We present empirical evidence with synthetic datasets to show that our weighting scheme indeed improves the tracking performance compared to heuristic approaches.\n",
      "\n",
      "Completed kernel, density, estimation, sliding, window, mean, integrated, squared, error, Gaussian abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The annotation burden and extensive labor for gathering a large medical dataset with images and corresponding labels are rarely cost-effective and highly intimidating. This results in a lack of abundant training data that undermines downstream tasks and partially contributes to the challenge image analysis faces in the medical field. As a workaround, given the recent success of generative neural models, it is now possible to synthesize image datasets at a high fidelity guided by external constraints. This paper explores this possibility and presents \\textbf{GuideGen}: a pipeline that jointly generates CT images and tissue masks for abdominal organs and colorectal cancer conditioned on a text prompt. Firstly, we introduce Volumetric Mask Sampler to fit the discrete distribution of mask labels and generate low-resolution 3D tissue masks. Secondly, our Conditional Image Generator autoregressively generates CT slices conditioned on a corresponding mask slice to incorporate both style information and anatomical guidance. This pipeline guarantees high fidelity and variability as well as exact alignment between generated CT volumes and tissue masks. Both qualitative and quantitative experiments on 3D abdominal CTs demonstrate a high performance of our proposed pipeline, thereby proving our method can serve as a dataset generator and provide potential benefits to downstream tasks. It is hoped that our work will offer a promising solution on the multimodality generation of CT and its anatomical mask. Our source code is publicly available at https://github.com/OvO1111/JointImageGeneration.\n",
      "\n",
      "Completed GuideGen, Generative, Neural, Models, CT, Images, Tissue, Masks, Abdomen, Colorectal abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we present a novel approach for joint activity detection (AD), channel estimation (CE), and data detection (DD) in uplink grant-free non-orthogonal multiple access (NOMA) systems. Our approach employs an iterative and parallel interference removal strategy inspired by parallel interference cancellation (PIC), enhanced with deep learning to jointly tackle the AD, CE, and DD problems. Based on this approach, we develop three PIC frameworks, each of which is designed for either coherent or non-coherence schemes. The first framework performs joint AD and CE using received pilot signals in the coherent scheme. Building upon this framework, the second framework utilizes both the received pilot and data signals for CE, further enhancing the performances of AD, CE, and DD in the coherent scheme. The third framework is designed to accommodate the non-coherent scheme involving a small number of data bits, which simultaneously performs AD and DD. Through joint loss functions and interference cancellation modules, our approach supports end-to-end training, contributing to enhanced performances of AD, CE, and DD for both coherent and non-coherent schemes. Simulation results demonstrate the superiority of our approach over traditional techniques, exhibiting enhanced performances of AD, CE, and DD while maintaining lower computational complexity.\n",
      "\n",
      "Completed activity detection, channel estimation, data detection, grant-free NOMA, parallel interference cancellation, deep learning, coherent scheme, non-coherent scheme, end-to-end training abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We study the generalization capability of nearly-interpolating linear regressors: $\\boldsymbol{\\beta}$'s whose training error $\\tau$ is positive but small, i.e., below the noise floor. Under a random matrix theoretic assumption on the data distribution and an eigendecay assumption on the data covariance matrix $\\boldsymbol{\\Sigma}$, we demonstrate that any near-interpolator exhibits rapid norm growth: for $\\tau$ fixed, $\\boldsymbol{\\beta}$ has squared $\\ell_2$-norm $\\mathbb{E}[\\|{\\boldsymbol{\\beta}}\\|_{2}^{2}] = \\Omega(n^{\\alpha})$ where $n$ is the number of samples and $\\alpha >1$ is the exponent of the eigendecay, i.e., $\\lambda_i(\\boldsymbol{\\Sigma}) \\sim i^{-\\alpha}$. This implies that existing data-independent norm-based bounds are necessarily loose. On the other hand, in the same regime we precisely characterize the asymptotic trade-off between interpolation and generalization. Our characterization reveals that larger norm scaling exponents $\\alpha$ correspond to worse trade-offs between interpolation and generalization. We verify empirically that a similar phenomenon holds for nearly-interpolating shallow neural networks.\n",
      "\n",
      "Completed interpolation, generalization, norm growth, eigendecay, covariance matrix, asymptotic trade-off, data-independent bounds, norm scaling exponents, shallow neural networks, rapid norm growth abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Simulating long-term hydrothermal bid-based markets considering strategic agents is a challenging task. The representation of strategic agents considering inter-temporal constraints within a stochastic framework brings additional complexity to the already difficult single-period bilevel, thus, non-convex, optimal bidding problem. Thus, we propose a simulation methodology that effectively addresses these challenges for large-scale hydrothermal power systems. We demonstrate the effectiveness of the framework through a case study with real data from the large-scale Brazilian power system. In the case studies, we show the effects of market concentration in power systems and how contracts can be used to mitigate them. In particular, we show how market power might affect the current setting in Brazil. The developed method can strongly benefit policy makers, market monitors, and market designers as simulations can be used to understand existing power systems and experiment with alternative designs.\n",
      "\n",
      "Completed Simulation, Hydrothermal, Bid-Based, Strategic, Agents, Stochastic, Bilevel, Market Concentration, Contracts, Policy Makers abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Iteratively reweighted L1 (IRL1) algorithm is a common algorithm for solving sparse optimization problems with nonconvex and nonsmooth regularization. The development of its acceleration algorithm, often employing Nesterov acceleration, has sparked significant interest. Nevertheless, the convergence and complexity analysis of these acceleration algorithms consistently poses substantial challenges. Recently, Anderson acceleration has gained prominence owing to its exceptional performance for speeding up fixed-point iteration, with numerous recent studies applying it to gradient-based algorithms. Motivated by the powerful impact of Anderson acceleration, we propose an Anderson-accelerated IRL1 algorithm and establish its local linear convergence rate. We extend this convergence result, typically observed in smooth settings, to a nonsmooth scenario. Importantly, our theoretical results do not depend on the Kurdyka-Lojasiewicz condition, a necessary condition in existing Nesterov acceleration-based algorithms. Furthermore, to ensure global convergence, we introduce a globally convergent Anderson accelerated IRL1 algorithm by incorporating a classical nonmonotone line search condition. Experimental results indicate that our algorithm outperforms existing Nesterov acceleration-based algorithms.\n",
      "\n",
      "Completed IRL1, Anderson, acceleration, nonsmooth, Kurdyka-Lojasiewicz, Nesterov, nonconvex, line search, gradient-based, nonmonotone abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, without requiring any constraint qualifications, we establish tight error bounds for the log-determinant cone, which is the closure of the hypograph of the perspective function of the log-determinant function. This error bound is obtained using the recently developed framework based on one-step facial residual functions.\n",
      "\n",
      "Completed error, bounds, log-determinant, cone, constraint, qualifications, hypograph, perspective, function, facial, residual abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper presents a novel approach to noninvasive hyperglycemia monitoring utilizing electrocardiograms (ECG) from an extensive database comprising 1119 subjects. Previous research on hyperglycemia or glucose detection using ECG has been constrained by challenges related to generalization and scalability, primarily due to using all subjects' ECG in training without considering unseen subjects as a critical factor for developing methods with effective generalization. We designed a deep neural network model capable of identifying significant features across various spatial locations and examining the interdependencies among different features within each convolutional layer. To expedite processing speed, we segment the ECG of each user to isolate one heartbeat or one cycle of the ECG. Our model was trained using data from 727 subjects, while 168 were used for validation. The testing phase involved 224 unseen subjects, with a dataset consisting of 9,000 segments. The result indicates that the proposed algorithm effectively detects hyperglycemia with a 91.60% area under the curve (AUC), 81.05% sensitivity, and 85.54% specificity.\n",
      "\n",
      "Completed hyperglycemia, monitoring, electrocardiogram, database, generalization, scalability, neural networks, features, segmentation, AUC abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "U-Net has been widely used for segmenting abdominal organs, achieving promising performance. However, when it is used for multi-organ segmentation, first, it may be limited in exploiting global long-range contextual information due to the implementation of standard convolutions. Second, the use of spatial-wise downsampling (e.g., max pooling or strided convolutions) in the encoding path may lead to the loss of deformable or discriminative details. Third, features upsampled from the higher level are concatenated with those that persevered via skip connections. However, repeated downsampling and upsampling operations lead to misalignments between them and their concatenation degrades segmentation performance. To address these limitations, we propose Dynamically Calibrated Convolution (DCC), Dynamically Calibrated Downsampling (DCD), and Dynamically Calibrated Upsampling (DCU) modules, respectively. The DCC module can utilize global inter-dependencies between spatial and channel features to calibrate these features adaptively. The DCD module enables networks to adaptively preserve deformable or discriminative features during downsampling. The DCU module can dynamically align and calibrate upsampled features to eliminate misalignments before concatenations. We integrated the proposed modules into a standard U-Net, resulting in a new architecture, termed Dynamic U-Net. This architectural design enables U-Net to dynamically adjust features for different organs. We evaluated Dynamic U-Net in two abdominal multi-organ segmentation benchmarks. Dynamic U-Net achieved statistically improved segmentation accuracy compared with standard U-Net. Our code is available at https://github.com/sotiraslab/DynamicUNet.\n",
      "\n",
      "Completed Dynamic, U-Net, Abdominal, Organs, Segmentation, Convolution, Downsampling, Upsampling, Calibration, Alignment abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Group imbalance has been a known problem in empirical risk minimization (ERM), where the achieved high average accuracy is accompanied by low accuracy in a minority group. Despite algorithmic efforts to improve the minority group accuracy, a theoretical generalization analysis of ERM on individual groups remains elusive. By formulating the group imbalance problem with the Gaussian Mixture Model, this paper quantifies the impact of individual groups on the sample complexity, the convergence rate, and the average and group-level testing performance. Although our theoretical framework is centered on binary classification using a one-hidden-layer neural network, to the best of our knowledge, we provide the first theoretical analysis of the group-level generalization of ERM in addition to the commonly studied average generalization performance. Sample insights of our theoretical results include that when all group-level co-variance is in the medium regime and all mean are close to zero, the learning performance is most desirable in the sense of a small sample complexity, a fast training rate, and a high average and group-level testing accuracy. Moreover, we show that increasing the fraction of the minority group in the training data does not necessarily improve the generalization performance of the minority group. Our theoretical results are validated on both synthetic and empirical datasets, such as CelebA and CIFAR-10 in image classification.\n",
      "\n",
      "Completed group, imbalance, ERM, sample, complexity, convergence, testing, performance, GMM, mean abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Owning to the reflection gain and double path loss featured by intelligent reflecting surface (IRS) channels, handover (HO) locations become irregular and the signal strength fluctuates sharply with variations in IRS connections during HO, the risk of HO failures (HOFs) is exacerbated and thus HO parameters require reconfiguration. However, existing HO models only assume monotonic negative exponential path loss and cannot obtain sound HO parameters. This paper proposes a discrete-time model to explicitly track the HO process with variations in IRS connections, where IRS connections and HO process are discretized as finite states by measurement intervals, and transitions between states are modeled as stochastic processes. Specifically, to capture signal fluctuations during HO, IRS connection state-dependent distributions of the user-IRS distance are modified by the correlation between measurement intervals. In addition, states of the HO process are formed with Time-to-Trigger and HO margin whose transition probabilities are integrated concerning all IRS connection states. Trigger location distributions and probabilities of HO, HOF, and ping-pong (PP) are obtained by tracing user HO states. Results show IRSs mitigate PPs by 48% but exacerbate HOFs by 90% under regular parameters. Optimal parameters are mined ensuring probabilities of HOF and PP are both less than 0.1%.\n",
      "\n",
      "Completed handover, intelligent reflecting surface, path loss, fluctuation, reconfiguration, discrete-time model, connection state, time-to-trigger, ping-pong, transition probability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This is a continuation of the authors' previous work (A. Kirsch, Math. Meth. Appl. Sci., 45 (2022): 5737-5773.) on well-posedness of time-harmonic scattering by locally perturbed periodic curves of Dirichlet kind. The scattering interface is supposed to be given by a non-self-intersecting Lipschitz curve. We study properties of the Green's function and prove new well-posedness results for scattering of plane waves at a propagative wave number. In such a case there exist guided waves to the unperturbed problem, which are also known as Bounded States in the Continuity (BICs) in physics. In this paper uniqueness of the forward scattering follows from an orthogonal constraint condition enforcing on the total field to the unperturbed scattering problem. This constraint condition, which is also valid under the Neumann boundary condition, is derived from the singular perturbation arguments and also from the approach of approximating a plane wave by point source waves. For the inverse problem of determining the defect, we prove several uniqueness results using a finite or infinite number of point source and plane waves, depending on whether a priori information on the size and height of the defect is available.\n",
      "\n",
      "Completed Well-posedness, time-harmonic, scattering, periodic, perturbed, Green's, function, plane, waves, uniqueness, forward abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper presents a finite-rate deep-learning (DL)-based channel state information (CSI) feedback method for massive multiple-input multiple-output (MIMO) systems. The presented method provides a finite-bit representation of the latent vector based on a vector-quantized variational autoencoder (VQ-VAE) framework while reducing its computational complexity based on shape-gain vector quantization. In this method, the magnitude of the latent vector is quantized using a non-uniform scalar codebook with a proper transformation function, while the direction of the latent vector is quantized using a trainable Grassmannian codebook. A multi-rate codebook design strategy is also developed by introducing a codeword selection rule for a nested codebook along with the design of a loss function. Simulation results demonstrate that the proposed method reduces the computational complexity associated with VQ-VAE while improving CSI reconstruction performance under a given feedback overhead.\n",
      "\n",
      "Completed DL, CSI, MIMO, VQ-VAE, scalar codebook, Grassmannian codebook, nested codebook, loss function, computational complexity, reconstruction performance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Previous approaches for blind image super-resolution (SR) have relied on degradation estimation to restore high-resolution (HR) images from their low-resolution (LR) counterparts. However, accurate degradation estimation poses significant challenges. The SR model's incompatibility with degradation estimation methods, particularly the Correction Filter, may significantly impair performance as a result of correction errors. In this paper, we introduce a novel blind SR approach that focuses on Learning Correction Errors (LCE). Our method employs a lightweight Corrector to obtain a corrected low-resolution (CLR) image. Subsequently, within an SR network, we jointly optimize SR performance by utilizing both the original LR image and the frequency learning of the CLR image. Additionally, we propose a new Frequency-Self Attention block (FSAB) that enhances the global information utilization ability of Transformer. This block integrates both self-attention and frequency spatial attention mechanisms. Extensive ablation and comparison experiments conducted across various settings demonstrate the superiority of our method in terms of visual quality and accuracy. Our approach effectively addresses the challenges associated with degradation estimation and correction errors, paving the way for more accurate blind image SR.\n",
      "\n",
      "Completed Blind, Image, Super-Resolution, Degradation, Estimation, Correction, Learning, Attention, Quality, Accuracy abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We consider end-to-end learning approaches for inverse problems of gravimetry. Due to ill-posedness of the inverse gravimetry, the reliability of learning approaches is questionable. To deal with this problem, we propose the strategy of learning on the correct class. The well-posedness theorems are employed when designing the neural-network architecture and constructing the training set. Given the density-contrast function as a priori information, the domain of mass can be uniquely determined under certain constrains, and the domain inverse problem is a correct class of the inverse gravimetry. Under this correct class, we design the neural network for learning by mimicking the level-set formulation for the inverse gravimetry. Numerical examples illustrate that the method is able to recover mass models with non-constant density contrast.\n",
      "\n",
      "Completed inverse problems, gravimetry, ill-posedness, correct class, neural-network, level-set, density-contrast, domain inverse problem, mass models, non-constant density contrast abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Gaussian processes (GPs) are commonly used for geospatial analysis, but they suffer from high computational complexity when dealing with massive data. For instance, the log-likelihood function required in estimating the statistical model parameters for geospatial data is a computationally intensive procedure that involves computing the inverse of a covariance matrix with size n X n, where n represents the number of geographical locations. As a result, in the literature, studies have shifted towards approximation methods to handle larger values of n effectively while maintaining high accuracy. These methods encompass a range of techniques, including low-rank and sparse approximations. Vecchia approximation is one of the most promising methods to speed up evaluating the log-likelihood function. This study presents a parallel implementation of the Vecchia approximation, utilizing batched matrix computations on contemporary GPUs. The proposed implementation relies on batched linear algebra routines to efficiently execute individual conditional distributions in the Vecchia algorithm. We rely on the KBLAS linear algebra library to perform batched linear algebra operations, reducing the time to solution compared to the state-of-the-art parallel implementation of the likelihood estimation operation in the ExaGeoStat software by up to 700X, 833X, 1380X on 32GB GV100, 80GB A100, and 80GB H100 GPUs, respectively. We also successfully manage larger problem sizes on a single NVIDIA GPU, accommodating up to 1M locations with 80GB A100 and H100 GPUs while maintaining the necessary application accuracy. We further assess the accuracy performance of the implemented algorithm, identifying the optimal settings for the Vecchia approximation algorithm to preserve accuracy on two real geospatial datasets: soil moisture data in the Mississippi Basin area and wind speed data in the Middle East.\n",
      "\n",
      "Completed Gaussian, processes, geospatial, analysis, Vecchia, approximation, parallel, implementation, accuracy, GPUs abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In machine learning larger databases are usually associated with higher classification accuracy due to better generalization. This generalization may lead to non-optimal classifiers in some medical applications with highly variable expressions of pathologies. This paper presents a method for learning from a large training base by adaptively selecting optimal training samples for given input data. In this way heterogeneous databases are supported two-fold. First, by being able to deal with sparsely annotated data allows a quick inclusion of new data set and second, by training an input-dependent classifier. The proposed approach is evaluated using the SISS challenge. The proposed algorithm leads to a significant improvement of the classification accuracy.\n",
      "\n",
      "Completed machine, learning, classification, accuracy, generalization, pathologies, training, samples, heterogeneous, SISS abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Transfer learning has aroused great interest in the statistical community. In this article, we focus on knowledge transfer for unsupervised learning tasks in contrast to the supervised learning tasks in the literature. Given the transferable source populations, we propose a two-step transfer learning algorithm to extract useful information from multiple source principal component analysis (PCA) studies, thereby enhancing estimation accuracy for the target PCA task. In the first step, we integrate the shared subspace information across multiple studies by a proposed method named as Grassmannian barycenter, instead of directly performing PCA on the pooled dataset. The proposed Grassmannian barycenter method enjoys robustness and computational advantages in more general cases. Then the resulting estimator for the shared subspace from the first step is further utilized to estimate the target private subspace in the second step. Our theoretical analysis credits the gain of knowledge transfer between PCA studies to the enlarged eigenvalue gap, which is different from the existing supervised transfer learning tasks where sparsity plays the central role. In addition, we prove that the bilinear forms of the empirical spectral projectors have asymptotic normality under weaker eigenvalue gap conditions after knowledge transfer. When the set of informativesources is unknown, we endow our algorithm with the capability of useful dataset selection by solving a rectified optimization problem on the Grassmann manifold, which in turn leads to a computationally friendly rectified Grassmannian K-means procedure. In the end, extensive numerical simulation results and a real data case concerning activity recognition are reported to support our theoretical claims and to illustrate the empirical usefulness of the proposed transfer learning methods.\n",
      "\n",
      "Completed Transfer, Learning, Unsupervised, PCA, Grassmannian, Barycenter, Sparsity, Eigenvalue, Eigenvector, Grassmannian Manifold abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We propose a new method that employs transfer learning techniques to effectively correct sampling selection errors introduced by sparse annotations during supervised learning for automated tumor segmentation. The practicality of current learning-based automated tissue classification approaches is severely impeded by their dependency on manually segmented training databases that need to be recreated for each scenario of application, site, or acquisition setup. The comprehensive annotation of reference datasets can be highly labor-intensive, complex, and error-prone. The proposed method derives high-quality classifiers for the different tissue classes from sparse and unambiguous annotations and employs domain adaptation techniques for effectively correcting sampling selection errors introduced by the sparse sampling. The new approach is validated on labeled, multi-modal MR images of 19 patients with malignant gliomas and by comparative analysis on the BraTS 2013 challenge data sets. Compared to training on fully labeled data, we reduced the time for labeling and training by a factor greater than 70 and 180 respectively without sacrificing accuracy. This dramatically eases the establishment and constant extension of large annotated databases in various scenarios and imaging setups and thus represents an important step towards practical applicability of learning-based approaches in tissue classification.\n",
      "\n",
      "Completed sampling, selection, errors, transfer, learning, tissue, classification, annotations, domain, adaptation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Describing the dynamics of many-electron quantum systems is crucial for applications such as predicting electronic structures in quantum chemistry, the properties of condensed matter systems, and the behaviors of complex materials. However, the real-time evolution of non-equilibrium quantum electronic systems poses a significant challenge for theoretical and computational approaches, due to the system's exploration of a vast configuration space. This work introduces a variational approach for fermionic time-dependent wave functions, surpassing mean-field approximations by capturing many-body correlations. The proposed methodology involves parameterizing the time-evolving quantum state, enabling the approximation of the state's evolution. To account for electron correlations, we employ time-dependent Jastrow factors and backflow transformations. We also show that we can incorporate neural networks to parameterize these functions. The time-dependent variational Monte Carlo technique is employed to efficiently compute the optimal time-dependent parameters. The approach is demonstrated in three distinct systems: the solvable harmonic interaction model, the dynamics of a diatomic molecule in intense laser fields, and a quenched quantum dot. In all cases, we show clear signatures of many-body correlations in the dynamics not captured by mean-field methods. The results showcase the ability of our variational approach to accurately capture the time evolution of quantum states, providing insight into the quantum dynamics of interacting electronic systems, beyond the capabilities of mean-field.\n",
      "\n",
      "Completed fermionic, time-dependent, wave functions, many-body correlations, variational approach, time-dependent Jastrow factors, backflow transformations, neural networks, Monte Carlo, mean-field methods abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Bayesian inference for complex models with an intractable likelihood can be tackled using algorithms performing many calls to computer simulators. These approaches are collectively known as \"simulation-based inference\" (SBI). Recent SBI methods have made use of neural networks (NN) to provide approximate, yet expressive constructs for the unavailable likelihood function and the posterior distribution. However, they do not generally achieve an optimal trade-off between accuracy and computational demand. In this work, we propose an alternative that provides both approximations to the likelihood and the posterior distribution, using structured mixtures of probability distributions. Our approach produces accurate posterior inference when compared to state-of-the-art NN-based SBI methods, while exhibiting a much smaller computational footprint. We illustrate our results on several benchmark models from the SBI literature.\n",
      "\n",
      "Completed Bayesian, inference, intractable, likelihood, simulation-based, inference, neural, networks, structured, mixtures, accurate abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The push-forward operation enables one to redistribute a probability measure through a deterministic map. It plays a key role in statistics and optimization: many learning problems (notably from optimal transport, generative modeling, and algorithmic fairness) include constraints or penalties framed as push-forward conditions on the model. However, the literature lacks general theoretical insights on the (non)convexity of such constraints and its consequences on the associated learning problems. This paper aims at filling this gap. In a first part, we provide a range of sufficient and necessary conditions for the (non)convexity of two sets of functions: the maps transporting one probability measure to another; the maps inducing equal output distributions across distinct probability measures. This highlights that for most probability measures, these push-forward constraints are not convex. In a second time, we show how this result implies critical limitations on the design of convex optimization problems for learning generative models or group-fair predictors. This work will hopefully help researchers and practitioners have a better understanding of the critical impact of push-forward conditions onto convexity.\n",
      "\n",
      "Completed push-forward, convexity, learning, optimization, constraints, probability measure, generative models, group-fair predictors, necessary conditions, sufficient conditions abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We introduce a surrogate-based black-box optimization method, termed Polynomial-model-based optimization (PMBO). The algorithm alternates polynomial approximation with Bayesian optimization steps, using Gaussian processes to model the error between the objective and its polynomial fit. We describe the algorithmic design of PMBO and compare the results of the performance of PMBO with several optimization methods for a set of analytic test functions.\n",
      "  The results show that PMBO outperforms the classic Bayesian optimization and is robust with respect to the choice of its correlation function family and its hyper-parameter setting, which, on the contrary, need to be carefully tuned in classic Bayesian optimization. Remarkably, PMBO performs comparably with state-of-the-art evolutionary algorithms such as the Covariance Matrix Adaptation -- Evolution Strategy (CMA-ES). This finding suggests that PMBO emerges as the pivotal choice among surrogate-based optimization methods when addressing low-dimensional optimization problems. Hereby, the simple nature of polynomials opens the opportunity for interpretation and analysis of the inferred surrogate model, providing a macroscopic perspective on the landscape of the objective function.\n",
      "\n",
      "Completed Surrogate, Black-box, Optimization, Polynomial, Gaussian, Processes, Bayesian, Evolutionary, Algorithms, CMA-ES abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Signed graphs are an emergent way of representing data in a variety of contexts were conflicting interactions exist. These include data from biological, ecological, and social systems. Here we propose the concept of communicability geometry for signed graphs, proving that metrics in this space, such as the communicability distance and angles, are Euclidean and spherical. We then apply these metrics to solve several problems in data analysis of signed graphs in a unified way. They include the partitioning of signed graphs, dimensionality reduction, finding hierarchies of alliances in signed networks as well as the quantification of the degree of polarization between the existing factions in systems represented by this type of graphs.\n",
      "\n",
      "Completed signed, graphs, communicability, geometry, distance, angles, Euclidean, spherical, data analysis, polarization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Magnetic sounding using data collected from the Juno mission can be used to provide constraints on Jupiter's interior. However, inwards continuation of reconstructions assuming zero electrical conductivity and a representation in spherical harmonics are limited by the enhancement of noise at small scales. In this paper we describe new reconstructions of Jupiter's internal magnetic field based on physics-informed neural networks and either the first 33 (PINN33) or the first 50 (PINN50) of Juno's orbits. The method can resolve local structures, and allows for weak ambient electrical currents. Compared with other methods, our reconstructions of Jupiter's magnetic field both on and above the surface are similar, and we achieve a similar fit to the Juno data. However, our models are not hampered by noise at depth, and so offer a much clearer picture of the interior structure. We estimate that the dynamo boundary is at a fractional radius of 0.8. At this depth, the magnetic field is arranged into longitudinal bands, and the great blue spot appears to be rooted in neighbouring structures of oppositely signed flux.\n",
      "\n",
      "Completed Jupiter, Magnetic, Sounding, Juno, Interior, Neural, Networks, Dynamo, Bands, Blue, Spot abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The strength of materials, like many problems in the natural sciences, spans multiple length and time scales, and the solution has to balance accuracy and performance. Peierls stress is one of the central concepts in crystal plasticity that measures the strength through the resistance of a dislocation to plastic flow. The determination of Peierls stress involves a multiscale nature depending on both elastic lattice responses and the energy landscape of crystal slips. Material screening by strength via the Peierls stress from first-principles calculations is computationally intractable for the nonlocal characteristics of dislocations, and not included in the state-of-the-art computational material databases. In this work, we propose a physics-transfer framework to learn the physics of crystal plasticity from empirical atomistic simulations and then predict the Peierls stress from chemically accurate density functional theory-based calculations of material parameters. Notably, the strengths of single-crystalline metals can be predicted from a few single-point calculations for the deformed lattice and on the {\\gamma} surface, allowing efficient, high-throughput screening for material discovery. Uncertainty quantification is carried out to assess the accuracy of models and sources of errors, showing reduced physical and system uncertainties in the predictions by elevating the fidelity of training models. This physics-transfer framework can be generalized to other problems facing the accuracy-performance dilemma, by harnessing the hierarchy of physics in the multiscale models of materials science.\n",
      "\n",
      "Completed peierls, stress, multiscale, dislocation, plasticity, physics-transfer, density, functional, theory, uncertainty abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We prove that a first-order cooperative system of interacting agents converges to consensus if the so-called Persistence Excitation condition holds. This condition requires that the interaction function between any pair of agents satisfies an integral lower bound. The interpretation is that the interaction needs to ensure a minimal amount of service.\n",
      "\n",
      "Completed convergence, consensus, cooperative system, interacting agents, Persistence Excitation, integral lower bound, interaction function, service, minimal amount abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Contemporary deep learning models have demonstrated promising results across various applications within seismology and earthquake engineering. These models rely primarily on utilizing ground motion records for tasks such as earthquake event classification, localization, earthquake early warning systems, and structural health monitoring. However, the extent to which these models effectively learn from these complex time-series signals has not been thoroughly analyzed. In this study, our objective is to evaluate the degree to which auxiliary information, such as seismic phase arrival times or seismic station distribution within a network, dominates the process of deep learning from ground motion records, potentially hindering its effectiveness. We perform a hyperparameter search on two deep learning models to assess their effectiveness in deep learning from ground motion records while also examining the impact of auxiliary information on model performance. Experimental results reveal a strong reliance on the highly correlated P and S phase arrival information. Our observations highlight a potential gap in the field, indicating an absence of robust methodologies for deep learning of single-station ground motion recordings independent of any auxiliary information.\n",
      "\n",
      "Completed deep, learning, seismology, earthquake, engineering, time-series, signals, auxiliary, information, arrival, times abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Do cities have just one or several centers? Studies performing radial or monocentric analyses of cities are usually criticised by researchers stating that cities are actually polycentric, and this has been well known for a long time. Reversely, when cities are studied independently of any center, other researchers will wonder how the variables of interest evolve with the distance to the center, because this distance is known to be a major determinant at the intra-urban scale. Both monocentric and polycentric formalisms have been introduced centuries (respectively, decades) ago for the study of urban areas, and used both on the empirical and the theoretical side in different disciplines (economics, geography, complex systems, physics...). The present work performs a synthesis of both viewpoints on cities, regarding their use in the literature, and explores with data on European urban areas how some cities considered to be the most polycentric in Europe compare to more standard cities when studied through a combination of radial analysis and scaling laws.\n",
      "\n",
      "Completed cities, centers, monocentric, polycentric, radial, urban, scaling, laws, literature, comparison abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recently, and under the umbrella of Responsible AI, efforts have been made to develop gender-ambiguous synthetic speech to represent with a single voice all individuals in the gender spectrum. However, research efforts have completely overlooked the speaking style despite differences found among binary and non-binary populations. In this work, we synthesise gender-ambiguous speech by combining the timbre of a male speaker with the manner of speech of a female speaker using voice morphing and pitch shifting towards the male-female boundary. Subjective evaluations indicate that the ambiguity of the morphed samples that convey the female speech style is higher than those that undergo pure pitch transformations suggesting that the speaking style can be a contributing factor in creating gender-ambiguous speech. To our knowledge, this is the first study that explicitly uses the transfer of the speaking style to create gender-ambiguous voices.\n",
      "\n",
      "Completed gender-ambiguous, synthetic speech, responsible AI, speaking style, voice morphing, pitch shifting, male-female boundary, subjective evaluations, transfer of speaking style, first study abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We introduce a novel photonic neural network using photonic crystal fibers, leveraging femtosecond pulse supercontinuum generation for optical computing. Investigating its efficacy across machine learning tasks, we uncover the crucial impact of nonlinear pulse propagation dynamics on network performance. Our findings show that octave-spanning supercontinuum generation results in loss of dataset variety due to many-to-one mapping, and optimal performance requires balancing optical nonlinearity. This study offers guidance for designing energy-efficient and high-performance photonic neural network architectures by explaining the interplay between nonlinear dynamics and optical computing.\n",
      "\n",
      "Completed photonic, neural, network, photonic crystal fibers, femtosecond, supercontinuum, optical computing, machine learning, nonlinear, interplay abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Polynomials are widely used to represent the trajectories of states and/or inputs. It has been shown that a polynomial can be bounded by its coefficients, when expressed in the Bernstein basis. However, in general, the bounds provided by the Bernstein coefficients are not tight. We propose a method for obtaining numerical solutions to dynamic optimization problems, where a flexible discretization is used to achieve tight polynomial bounds. The proposed method is used to solve a constrained cart-pole swing-up optimal control problem. The flexible discretization eliminates the conservatism of the Bernstein bounds and enables a lower cost, in comparison with non-flexible discretizations. A theoretical result on obtaining tight polynomial bounds with a finite discretization is presented. In some applications with linear dynamics, the non-convexity introduced by the flexible discretization may be a drawback.\n",
      "\n",
      "Completed polynomials, Bernstein, coefficients, dynamic, optimization, discretization, bounds, control, conservatism, convexity abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we consider a new nonlocal approximation to the linear Stokes system with periodic boundary conditions in two and three dimensional spaces . A relaxation term is added to the equation of nonlocal divergence free equation, which is reminiscent to the relaxation of local Stokes equation with small artificial compressibility. Our analysis shows that the well-posedness of the nonlocal system can be established under some mild assumptions on the kernel of nonlocal interactions. Furthermore, the new nonlocal system converges to the conventional, local Stokes system in second order as the horizon parameter of the nonlocal interaction goes to zero. The study provides more theoretical understanding to some numerical methods, such as smoothed particle hydrodynamics, for simulating incompressible viscous flows.\n",
      "\n",
      "Completed nonlocal, Stokes, system, periodic, relaxation, divergence, free, smoothed, particle, hydrodynamics abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Self-supervised learning (SSL) is one strategy for addressing the paucity of labelled data in medical imaging by learning representations from unlabelled images. Contrastive and non-contrastive SSL methods produce learned representations that are similar for pairs of related images. Such pairs are commonly constructed by randomly distorting the same image twice. The videographic nature of ultrasound offers flexibility for defining the similarity relationship between pairs of images. In this study, we investigated the effect of utilizing proximal, distinct images from the same B-mode ultrasound video as pairs for SSL. Additionally, we introduced a sample weighting scheme that increases the weight of closer image pairs and demonstrated how it can be integrated into SSL objectives. Named Intra-Video Positive Pairs (IVPP), the method surpassed previous ultrasound-specific contrastive learning methods' average test accuracy on COVID-19 classification with the POCUS dataset by $\\ge 1.3\\%$. Detailed investigations of IVPP's hyperparameters revealed that some combinations of IVPP hyperparameters can lead to improved or worsened performance, depending on the downstream task. Guidelines for practitioners were synthesized based on the results, such as the merit of IVPP with task-specific hyperparameters, and the improved performance of contrastive methods for ultrasound compared to non-contrastive counterparts.\n",
      "\n",
      "Completed self-supervised, learning, medical, imaging, ultrasound, video, B-mode, IVPP, POCUS, hyperparameters abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We study the problem of post-selection predictive inference in an online fashion. To avoid devoting resources to unimportant units, a preliminary selection of the current individual before reporting its prediction interval is common and meaningful in online predictive tasks. Since the online selection causes a temporal multiplicity in the selected prediction intervals, it is important to control the real-time false coverage-statement rate (FCR) to measure the averaged miscoverage error. We develop a general framework named CAS (Calibration after Adaptive Selection) that can wrap around any prediction model and online selection rule to output post-selection prediction intervals. If the current individual is selected, we first perform an adaptive selection on historical data to construct a calibration set, then output a conformal prediction interval for the unobserved label. We provide tractable constructions for the calibration set for popular online selection rules. We proved that CAS can achieve an exact selection-conditional coverage guarantee in the finite-sample and distribution-free regimes. For the decision-driven selection rule, including most online multiple-testing procedures, CAS can exactly control the real-time FCR below the target level without any distributional assumptions. For the online selection with symmetric thresholds, we establish the error bound for the control gap of FCR under mild distributional assumptions. To account for the distribution shift in online data, we also embed CAS into some recent dynamic conformal prediction methods and examine the long-run FCR control. Numerical results on both synthetic and real data corroborate that CAS can effectively control FCR around the target level and yield more narrowed prediction intervals over existing baselines across various settings.\n",
      "\n",
      "Completed online, inference, prediction, interval, selection, calibration, coverage, guarantee, dynamic, distribution abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Kernel techniques are among the most influential approaches in data science and statistics. Under mild conditions, the reproducing kernel Hilbert space associated to a kernel is capable of encoding the independence of $M\\ge 2$ random variables. Probably the most widespread independence measure relying on kernels is the so-called Hilbert-Schmidt independence criterion (HSIC; also referred to as distance covariance in the statistics literature). Despite various existing HSIC estimators designed since its introduction close to two decades ago, the fundamental question of the rate at which HSIC can be estimated is still open. In this work, we prove that the minimax optimal rate of HSIC estimation on $\\mathbb R^d$ for Borel measures containing the Gaussians with continuous bounded translation-invariant characteristic kernels is $\\mathcal O\\!\\left(n^{-1/2}\\right)$. Specifically, our result implies the optimality in the minimax sense of many of the most-frequently used estimators (including the U-statistic, the V-statistic, and the Nystr\\\"om-based one) on $\\mathbb R^d$.\n",
      "\n",
      "Completed kernel, reproducing kernel, Hilbert space, independence, HSIC, distance covariance, independence measure, minimax rate, estimation, Gaussian abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Histopathology is a gold standard for cancer diagnosis under a microscopic examination. However, histological tissue processing procedures result in artifacts, which are ultimately transferred to the digitized version of glass slides, known as whole slide images (WSIs). Artifacts are diagnostically irrelevant areas and may result in wrong deep learning (DL) algorithms predictions. Therefore, detecting and excluding artifacts in the computational pathology (CPATH) system is essential for reliable automated diagnosis. In this paper, we propose a mixture of experts (MoE) scheme for detecting five notable artifacts, including damaged tissue, blur, folded tissue, air bubbles, and histologically irrelevant blood from WSIs. First, we train independent binary DL models as experts to capture particular artifact morphology. Then, we ensemble their predictions using a fusion mechanism. We apply probabilistic thresholding over the final probability distribution to improve the sensitivity of the MoE. We developed DL pipelines using two MoEs and two multiclass models of state-of-the-art deep convolutional neural networks (DCNNs) and vision transformers (ViTs). DCNNs-based MoE and ViTs-based MoE schemes outperformed simpler multiclass models and were tested on datasets from different hospitals and cancer types, where MoE using DCNNs yielded the best results. The proposed MoE yields 86.15% F1 and 97.93% sensitivity scores on unseen data, retaining less computational cost for inference than MoE using ViTs. This best performance of MoEs comes with relatively higher computational trade-offs than multiclass models. The proposed artifact detection pipeline will not only ensure reliable CPATH predictions but may also provide quality control.\n",
      "\n",
      "Completed Histopathology, artifacts, deep learning, computational pathology, mixture of experts, damaged tissue, blur, folded tissue, air bubbles, histologically irrelevant blood abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Let $X$ and $Z$ be random vectors, and $Y=g(X,Z)$. In this paper, on the one hand, for the case that $X$ and $Z$ are continuous, by using the ideas from the total variation and the flux of $g$, we develop a point of view in causal inference capable of dealing with a broad domain of causal problems. Indeed, we focus on a function, called Probabilistic Easy Variational Causal Effect (PEACE), which can measure the direct causal effect of $X$ on $Y$ with respect to continuously and interventionally changing the values of $X$ while keeping the value of $Z$ constant. PEACE is a function of $d\\ge 0$, which is a degree managing the strengths of probability density values $f(x|z)$. On the other hand, we generalize the above idea for the discrete case and show its compatibility with the continuous case. Further, we investigate some properties of PEACE using measure theoretical concepts. Furthermore, we provide some identifiability criteria and several examples showing the generic capability of PEACE. We note that PEACE can deal with the causal problems for which micro-level or just macro-level changes in the value of the input variables are important. Finally, PEACE is stable under small changes in $\\partial g_{in}/\\partial x$ and the joint distribution of $X$ and $Z$, where $g_{in}$ is obtained from $g$ by removing all functional relationships defining $X$ and $Z$.\n",
      "\n",
      "Completed PEACE, causal, inference, probability, variation, flux, continuous, discrete, identifiability, stability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Paralinguistic traits like cognitive load and emotion are increasingly recognized as pivotal areas in speech recognition research, often examined through specialized datasets like CLSE and IEMOCAP. However, the integrity of these datasets is seldom scrutinized for text-dependency. This paper critically evaluates the prevalent assumption that machine learning models trained on such datasets genuinely learn to identify paralinguistic traits, rather than merely capturing lexical features. By examining the lexical overlap in these datasets and testing the performance of machine learning models, we expose significant text-dependency in trait-labeling. Our results suggest that some machine learning models, especially large pre-trained models like HuBERT, might inadvertently focus on lexical characteristics rather than the intended paralinguistic features. The study serves as a call to action for the research community to reevaluate the reliability of existing datasets and methodologies, ensuring that machine learning models genuinely learn what they are designed to recognize.\n",
      "\n",
      "Completed paralinguistic, cognitive, emotion, datasets, CLSE, IEMOCAP, text-dependency, lexical, HuBERT, methodologies abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The increasing usage of machine learning models in consequential decision-making processes has spurred research into the fairness of these systems. While significant work has been done to study group fairness in the in-processing and post-processing setting, there has been little that theoretically connects these results to the pre-processing domain. This paper proposes that achieving group fairness in downstream models can be formulated as finding the optimal design matrix in which to modify a response variable in a Randomized Response framework. We show that measures of group fairness can be directly controlled for with optimal model utility, proposing a pre-processing algorithm called FairRR that yields excellent downstream model utility and fairness.\n",
      "\n",
      "Completed Fairness, Group fairness, Pre-processing, Randomized response, Response variable, Machine learning models, Consequential decision-making, Optimal design matrix, Model utility, FairRR abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Advancements in high-throughput biomedical applications necessitate real-time, large field-of-view (FOV) imaging capabilities. Conventional lens-free imaging (LFI) systems, while addressing the limitations of physical lenses, have been constrained by dynamic, hard-to-model optical fields, resulting in a limited one-shot FOV of approximately 20 $mm^2$. This restriction has been a major bottleneck in applications like live-cell imaging and automation of microfluidic systems for biomedical research. Here, we present a deep-learning(DL)-based imaging framework -- GenLFI -- leveraging generative artificial intelligence (AI) for holographic image reconstruction. We demonstrate that GenLFI can achieve a real-time FOV over 550 $mm^2$, surpassing the current LFI system by more than 20-fold, and even larger than the world's largest confocal microscope by 1.76 times. The resolution is at the sub-pixel level of 5.52 $\\mu m$, without the need for a shifting light source. The unsupervised learning-based reconstruction does not require optical field modeling, making imaging dynamic 3D samples (e.g., droplet-based microfluidics and 3D cell models) in complex optical fields possible. This GenLFI framework unlocks the potential of LFI systems, offering a robust tool to tackle new frontiers in high-throughput biomedical applications such as drug discovery.\n",
      "\n",
      "Completed Lens-free, Imaging, Deep-learning, Holographic, Reconstruction, Field-of-view, Resolution, Unsupervised, Biomedical, Automation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We study how pricing affects the division of surplus among buyers in auctions for multiple units. Our equity objective may be important, e.g., for competition concerns in downstream markets, complementing the long-standing debate on revenue and efficiency. We study a canonical model of auctions for multiple indivisible units with unit demand buyers and valuations with a private and a common component and consider all pricing rules that are a mixture (i.e., a convex combination) of pay-as-bid and uniform pricing. We propose the winners' empirical variance (WEV), the expected empirical variance of surplus among the winners, as a metric for surplus equity. We show that, for a range of private-common value proportions, a strictly interior mix of pay-as-bid and uniform pricing minimizes WEV. From an equity perspective, auctions with a higher private value component benefit from more price discrimination, whereas only auctions with a sufficiently high common value justify a more uniform pricing rule. We provide a criterion under which strictly mixed pricing dominates uniform pricing, a partial ranking of different mixed pricing formats, and bounds on the WEV-minimizing pricing under the assumption of log-concave signal distributions. In numerical experiments, we further illustrate the WEV-minimal pricing as a function of the private-common-value mix.\n",
      "\n",
      "Completed surplus,equity,auction,multiple units,pricing,pay-as-bid,uniform pricing,winners' empirical variance,log-concave signal distributions,numerical experiments abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This work is addressing the Brain Magnetic Resonance Image Synthesis for Tumor Segmentation (BraSyn) challenge which was hosted as part of the Brain Tumor Segmentation challenge (BraTS) 2023. In this challenge researchers are invited to work on synthesizing a missing magnetic resonance image sequence given other available sequences to facilitate tumor segmentation pipelines trained on complete sets of image sequences. This problem can be addressed using deep learning in the framework of paired images-to-image translation. In this work, we proposed to investigate the effectiveness of a commonly-used deep learning framework such as Pix2Pix trained under supervision of different image-quality loss functions. Our results indicate that using different loss functions significantly affects the synthesis quality. We systematically study the impact of different loss functions in the multi-sequence MR image synthesis setting of the BraSyn challenge. Furthermore, we show how image synthesis performance can be optimized by beneficially combining different learning objectives.\n",
      "\n",
      "Completed BraSyn, Tumor, Segmentation, MRI, Image, Synthesis, Pix2Pix, Loss, Function, Optimization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We propose a novel early-terminating mesh refinement strategy using an integrated residual method to solve dynamic feasibility problems. As a generalization of direct collocation, the integrated residual method is used to approximate an infinite-dimensional problem into a sequence of finite-dimensional optimization subproblems. Each subproblem in the sequence is a finer approximation of the previous. It is shown that these subproblems need not be solved to a high precision; instead, an early termination procedure can determine when mesh refinement should be performed. The new refinement strategy, applied to an inverted pendulum swing-up problem, outperforms a conventional refinement method by up to a factor of three in function evaluations.\n",
      "\n",
      "Completed mesh, refinement, integrated, residual, method, dynamic, feasibility, problems, early, termination abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Autoencoders are powerful machine learning models used to compress information from multiple data sources. However, autoencoders, like all artificial neural networks, are often unidentifiable and uninterpretable. This research focuses on creating an identifiable and interpretable autoencoder that can be used to meld and combine climate data products. The proposed autoencoder utilizes a Bayesian statistical framework, allowing for probabilistic interpretations while also varying spatially to capture useful spatial patterns across the various data products. Constraints are placed on the autoencoder as it learns patterns in the data, creating an interpretable consensus that includes the important features from each input. We demonstrate the utility of the autoencoder by combining information from multiple precipitation products in High Mountain Asia.\n",
      "\n",
      "Completed autoencoders, identifiable, interpretable, Bayesian, statistical, probabilistic, constraints, consensus, important, features abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Eye-gaze tracking research offers significant promise in enhancing various healthcare-related tasks, above all in medical image analysis and interpretation. Eye tracking, a technology that monitors and records the movement of the eyes, provides valuable insights into human visual attention patterns. This technology can transform how healthcare professionals and medical specialists engage with and analyze diagnostic images, offering a more insightful and efficient approach to medical diagnostics. Hence, extracting meaningful features and insights from medical images by leveraging eye-gaze data improves our understanding of how radiologists and other medical experts monitor, interpret, and understand images for diagnostic purposes. Eye-tracking data, with intricate human visual attention patterns embedded, provides a bridge to integrating artificial intelligence (AI) development and human cognition. This integration allows novel methods to incorporate domain knowledge into machine learning (ML) and deep learning (DL) approaches to enhance their alignment with human-like perception and decision-making. Moreover, extensive collections of eye-tracking data have also enabled novel ML/DL methods to analyze human visual patterns, paving the way to a better understanding of human vision, attention, and cognition. This systematic review investigates eye-gaze tracking applications and methodologies for enhancing ML/DL algorithms for medical image analysis in depth.\n",
      "\n",
      "Completed Eye-gaze, Tracking, Healthcare, Medical-image, Interpretation, Diagnostics, Features, Insights, Artificial-intelligence, Human-cognition abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We study when low coordinate degree functions (LCDF) -- linear combinations of functions depending on small subsets of entries of a vector -- can hypothesis test between high-dimensional probability measures. These functions are a generalization, proposed in Hopkins' 2018 thesis but seldom studied since, of low degree polynomials (LDP), a class widely used in recent literature as a proxy for all efficient algorithms for tasks in statistics and optimization. Instead of the orthogonal polynomial decompositions used in LDP calculations, our analysis of LCDF is based on the Efron-Stein or ANOVA decomposition, making it much more broadly applicable. By way of illustration, we prove channel universality for the success of LCDF in testing for the presence of sufficiently \"dilute\" random signals through noisy channels: the efficacy of LCDF depends on the channel only through the scalar Fisher information for a class of channels including nearly arbitrary additive i.i.d. noise and nearly arbitrary exponential families. As applications, we extend lower bounds against LDP for spiked matrix and tensor models under additive Gaussian noise to lower bounds against LCDF under general noisy channels. We also give a simple and unified treatment of the effect of censoring models by erasing observations at random and of quantizing models by taking the sign of the observations. These results are the first computational lower bounds against any large class of algorithms for all of these models when the channel is not one of a few special cases, and thereby give the first substantial evidence for the universality of several statistical-to-computational gaps.\n",
      "\n",
      "Completed low, degree, functions, polynomials, Efron-Stein, ANOVA, universality, Gaussian, censoring, sign abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The goal in word spotting is to retrieve parts of document images which are relevant with respect to a certain user-defined query. The recent past has seen attribute-based Convolutional Neural Networks take over this field of research. As is common for other fields of computer vision, the CNNs used for this task are already considerably deep. The question that arises, however, is: How complex does a CNN have to be for word spotting? Are increasingly deeper models giving increasingly better results or does performance behave asymptotically for these architectures? On the other hand, can similar results be obtained with a much smaller CNN? The goal of this paper is to give an answer to these questions. Therefore, the recently successful TPP-PHOCNet will be compared to a Residual Network, a Densely Connected Convolutional Network and a LeNet architecture empirically. As will be seen in the evaluation, a complex model can be beneficial for word spotting on harder tasks such as the IAM Offline Database but gives no advantage for easier benchmarks such as the George Washington Database.\n",
      "\n",
      "Completed word, spotting, CNN, depth, architecture, complex, benchmark, comparison, TPP-PHOCNet, LeNet abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we propose a novel learning scheme called epoch-evolving Gaussian Process Guided Learning (GPGL), which aims at characterizing the correlation information between the batch-level distribution and the global data distribution. Such correlation information is encoded as context labels and needs renewal every epoch. With the guidance of the context label and ground truth label, GPGL scheme provides a more efficient optimization through updating the model parameters with a triangle consistency loss. Furthermore, our GPGL scheme can be further generalized and naturally applied to the current deep models, outperforming the existing batch-based state-of-the-art models on mainstream datasets (CIFAR-10, CIFAR-100, and Tiny-ImageNet) remarkably.\n",
      "\n",
      "Completed epoch, Gaussian, Process, Guided, Learning, context, label, triangle, consistency, loss abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "As a challenging problem, few-shot class-incremental learning (FSCIL) continually learns a sequence of tasks, confronting the dilemma between slow forgetting of old knowledge and fast adaptation to new knowledge. In this paper, we concentrate on this \"slow vs. fast\" (SvF) dilemma to determine which knowledge components to be updated in a slow fashion or a fast fashion, and thereby balance old-knowledge preservation and new-knowledge adaptation. We propose a multi-grained SvF learning strategy to cope with the SvF dilemma from two different grains: intra-space (within the same feature space) and inter-space (between two different feature spaces). The proposed strategy designs a novel frequency-aware regularization to boost the intra-space SvF capability, and meanwhile develops a new feature space composition operation to enhance the inter-space SvF learning performance. With the multi-grained SvF learning strategy, our method outperforms the state-of-the-art approaches by a large margin.\n",
      "\n",
      "Completed few-shot, class-incremental, learning, forgetting, adaptation, slow, fast, dilemma, multi-grained, regularization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We introduce a novel framework to track multiple objects in overhead camera videos for airport checkpoint security scenarios where targets correspond to passengers and their baggage items. We propose a self-supervised learning (SSL) technique to provide the model information about instance segmentation uncertainty from overhead images. Our SSL approach improves object detection by employing a test-time data augmentation and a regression-based, rotation-invariant pseudo-label refinement technique. Our pseudo-label generation method provides multiple geometrically transformed images as inputs to a convolutional neural network (CNN), regresses the augmented detections generated by the network to reduce localization errors, and then clusters them using the mean-shift algorithm. The self-supervised detector model is used in a single-camera tracking algorithm to generate temporal identifiers for the targets. Our method also incorporates a multiview trajectory association mechanism to maintain consistent temporal identifiers as passengers travel across camera views. An evaluation of detection, tracking, and association performances on videos obtained from multiple overhead cameras in a realistic airport checkpoint environment demonstrates the effectiveness of the proposed approach. Our results show that self-supervision improves object detection accuracy by up to 42% without increasing the inference time of the model. Our multicamera association method achieves up to 89% multiobject tracking accuracy with an average computation time of less than 15 ms.\n",
      "\n",
      "Completed tracking, self-supervised, airport, overhead, cameras, objects, passengers, baggage, detection, association abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Successful collaboration involves sharing information. However, parties may disagree on how the information they need to share should be used. We argue that many of these concerns reduce to 'the copy problem': once a bit of information is copied and shared, the sender can no longer control how the recipient uses it. From the perspective of each collaborator, this presents a dilemma that can inhibit collaboration. The copy problem is often amplified by three related problems which we term the bundling, edit, and recursive enforcement problems. We find that while the copy problem is not solvable, aspects of these amplifying problems have been addressed in a variety of disconnected fields. We observe that combining these efforts could improve the governability of information flows and thereby incentivise collaboration. We propose a five-part framework which groups these efforts into specific capabilities and offers a foundation for their integration into an overarching vision we call \"structured transparency\". We conclude by surveying an array of use-cases that illustrate the structured transparency principles and their related capabilities.\n",
      "\n",
      "Completed copy, problem, collaboration, sharing, information, dilemma, bundling, edit, enforcement, structured abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present a novel approach to denoising and inpainting problems for surface meshes. The purpose of these problems is to remove noise or fill in missing parts while preserving important features such as sharp edges. A discrete variant of the total variation of the unit normal vector field serves as a regularizing functional to achieve these goals. In order to solve the resulting problem, we use a version of the split Bregman (ADMM) iteration adapted to the problem. A new formulation of the total variation regularizer, as well as the use of an inexact Newton method for the shape optimization step, bring significant speed-up compared to earlier methods. Numerical examples are included, demonstrating the performance of our algorithm with some complex 3D geometries.\n",
      "\n",
      "Completed mesh, denoising, inpainting, total variation, unit normal, split Bregman, ADMM, Newton, shape optimization, 3D geometries abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Deep convolutional models often produce inadequate predictions for inputs foreign to the training distribution. Consequently, the problem of detecting outlier images has recently been receiving a lot of attention. Unlike most previous work, we address this problem in the dense prediction context in order to be able to locate outlier objects in front of in-distribution background. Our approach is based on two reasonable assumptions. First, we assume that the inlier dataset is related to some narrow application field (e.g.~road driving). Second, we assume that there exists a general-purpose dataset which is much more diverse than the inlier dataset (e.g.~ImageNet-1k). We consider pixels from the general-purpose dataset as noisy negative training samples since most (but not all) of them are outliers. We encourage the model to recognize borders between known and unknown by pasting jittered negative patches over inlier training images. Our experiments target two dense open-set recognition benchmarks (WildDash 1 and Fishyscapes) and one dense open-set recognition dataset (StreetHazard). Extensive performance evaluation indicates competitive potential of the proposed approach.\n",
      "\n",
      "Completed dense, open-set, recognition, outlier, prediction, detection, inlier, ImageNet, negativity, jittering abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Motivated by various data science applications including de-anonymizing user identities in social networks, we consider the graph alignment problem, where the goal is to identify the vertex/user correspondence between two correlated graphs. Existing work mostly recovers the correspondence by exploiting the user-user connections. However, in many real-world applications, additional information about the users, such as user profiles, might be publicly available. In this paper, we introduce the attributed graph alignment problem, where additional user information, referred to as attributes, is incorporated to assist graph alignment. We establish both the achievability and converse results on recovering vertex correspondence exactly, where the conditions match for certain parameter regimes. Our results span the full spectrum between models that only consider user-user connections and models where only attribute information is available.\n",
      "\n",
      "Completed graph, alignment, vertex, correspondence, attributed, graph, problem, attributes, user, profiles abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "As AI technologies increase in capability and ubiquity, AI accidents are becoming more common. Based on normal accident theory, high reliability theory, and open systems theory, we create a framework for understanding the risks associated with AI applications. In addition, we also use AI safety principles to quantify the unique risks of increased intelligence and human-like qualities in AI. Together, these two fields give a more complete picture of the risks of contemporary AI. By focusing on system properties near accidents instead of seeking a root cause of accidents, we identify where attention should be paid to safety for current generation AI systems.\n",
      "\n",
      "Completed accidents, AI, high reliability theory, normal accident theory, open systems theory, principles, quantitative analysis, risks, safety, systems abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Graph Neural Networks (GNNs) have been extensively used for mining graph-structured data with impressive performance. However, because these traditional GNNs do not distinguish among various downstream tasks, embeddings embedded by them are not always effective. Intuitively, paths in a graph imply different semantics for different downstream tasks. Inspired by this, we design a novel GNN solution, namely Customized Graph Neural Network with Path Reweighting (CustomGNN for short). Specifically, the proposed CustomGNN can automatically learn the high-level semantics for specific downstream tasks to highlight semantically relevant paths as well to filter out task-irrelevant noises in a graph. Furthermore, we empirically analyze the semantics learned by CustomGNN and demonstrate its ability to avoid the three inherent problems in traditional GNNs, i.e., over-smoothing, poor robustness, and overfitting. In experiments with the node classification task, CustomGNN achieves state-of-the-art accuracies on three standard graph datasets and four large graph datasets. The source code of the proposed CustomGNN is available at \\url{https://github.com/cjpcool/CustomGNN}.\n",
      "\n",
      "Completed Graph,Neural,Networks,Paths,Semantics,Reweighting,Overfitting,Robustness,Datasets,Accuracy abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "It is a challenging task to accurately perform semantic segmentation due to the complexity of real picture scenes. Many semantic segmentation methods based on traditional deep learning insufficiently captured the semantic and appearance information of images, which put limit on their generality and robustness for various application scenes. In this paper, we proposed a novel strategy that reformulated the popularly-used convolution operation to multi-layer convolutional sparse coding block to ease the aforementioned deficiency. This strategy can be possibly used to significantly improve the segmentation performance of any semantic segmentation model that involves convolutional operations. To prove the effectiveness of our idea, we chose the widely-used U-Net model for the demonstration purpose, and we designed CSC-Unet model series based on U-Net. Through extensive analysis and experiments, we provided credible evidence showing that the multi-layer convolutional sparse coding block enables semantic segmentation model to converge faster, can extract finer semantic and appearance information of images, and improve the ability to recover spatial detail information. The best CSC-Unet model significantly outperforms the results of the original U-Net on three public datasets with different scenarios, i.e., 87.14% vs. 84.71% on DeepCrack dataset, 68.91% vs. 67.09% on Nuclei dataset, and 53.68% vs. 48.82% on CamVid dataset, respectively.\n",
      "\n",
      "Completed semantic, segmentation, convolution, sparse, coding, deep, learning, multi-layer, U-Net, improvement abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "DNA-based storage is an emerging technology that enables digital information to be archived in DNA molecules. This method enjoys major advantages over magnetic and optical storage solutions such as exceptional information density, enhanced data durability, and negligible power consumption to maintain data integrity. To access the data, an information retrieval process is employed, where some of the main bottlenecks are the scalability and accuracy, which have a natural tradeoff between the two. Here we show a modular and holistic approach that combines Deep Neural Networks (DNN) trained on simulated data, Tensor-Product (TP) based Error-Correcting Codes (ECC), and a safety margin mechanism into a single coherent pipeline. We demonstrated our solution on 3.1MB of information using two different sequencing technologies. Our work improves upon the current leading solutions by up to x3200 increase in speed, 40% improvement in accuracy, and offers a code rate of 1.6 bits per base in a high noise regime. In a broader sense, our work shows a viable path to commercial DNA storage solutions hindered by current information retrieval processes.\n",
      "\n",
      "Completed DNA, storage, information, scalability, accuracy, DNN, ECC, safety, margin, pipeline abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Matrix decompositions are ubiquitous in machine learning, including applications in dimensionality reduction, data compression and deep learning algorithms. Typical solutions for matrix decompositions have polynomial complexity which significantly increases their computational cost and time. In this work, we leverage efficient processing operations that can be run in parallel on modern Graphical Processing Units (GPUs), predominant computing architecture used e.g. in deep learning, to reduce the computational burden of computing matrix decompositions. More specifically, we reformulate the randomized decomposition problem to incorporate fast matrix multiplication operations (BLAS-3) as building blocks. We show that this formulation, combined with fast random number generators, allows to fully exploit the potential of parallel processing implemented in GPUs. Our extensive evaluation confirms the superiority of this approach over the competing methods and we release the results of this research as a part of the official CUDA implementation (https://docs.nvidia.com/cuda/cusolver/index.html).\n",
      "\n",
      "Completed matrix, decompositions, machine, learning, dimensionality, reduction, compression, parallel, GPUs, BLAS-3 abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Propositional model enumeration, or All-SAT, is the task to record all models of a propositional formula. It is a key task in software and hardware verification, system engineering, and predicate abstraction, to mention a few. It also provides a means to convert a CNF formula into DNF, which is relevant in circuit design. While in some applications enumerating models multiple times causes no harm, in others avoiding repetitions is crucial. We therefore present two model enumeration algorithms, which adopt dual reasoning in order to shorten the found models. The first method enumerates pairwise contradicting models. Repetitions are avoided by the use of so-called blocking clauses, for which we provide a dual encoding. In our second approach we relax the uniqueness constraint. We present an adaptation of the standard conflict-driven clause learning procedure to support model enumeration without blocking clauses.Our procedures are expressed by means of a calculus and proofs of correctness are provided.\n",
      "\n",
      "Completed All-SAT, model enumeration, propositional formula, predicate abstraction, circuit design, dual reasoning, pairwise contradicting models, blocking clauses, conflict-driven clause learning, calculus abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "A Randomized Control Trial (RCT) is considered as the gold standard for evaluating the effect of any intervention or treatment. However, its feasibility is often hindered by ethical, economical, and legal considerations, making observational data a valuable alternative for drawing causal conclusions. Nevertheless, healthcare observational data presents a difficult challenge due to its high dimensionality, requiring careful consideration to ensure unbiased, reliable, and robust causal inferences. To overcome this challenge, in this study, we propose a novel two-stage feature selection technique called, Outcome Adaptive Elastic Net (OAENet), explicitly designed for making robust causal inference decisions using matching techniques. OAENet offers several key advantages over existing methods: superior performance on correlated and high-dimensional data compared to the existing methods and the ability to select specific sets of variables (including confounders and variables associated only with the outcome). This ensures robustness and facilitates an unbiased estimate of the causal effect. Numerical experiments on simulated data demonstrate that OAENet significantly outperforms state-of-the-art methods by either producing a higher-quality estimate or a comparable estimate in significantly less time. To illustrate the applicability of OAENet, we employ large-scale US healthcare data to estimate the effect of Opioid Use Disorder (OUD) on suicidal behavior. When compared to competing methods, OAENet closely aligns with existing literature on the relationship between OUD and suicidal behavior. Performance on both simulated and real-world data highlights that OAENet notably enhances the accuracy of estimating treatment effects or evaluating policy decision-making with causal inference.\n",
      "\n",
      "Completed Randomized, Control, Trial, Observational, Data, Feature, Selection, Causal, Inference, OAENet, Suicidal abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Modern visual systems have a wide range of potential applications in vision tasks for natural science research, such as aiding in species discovery, monitoring animals in the wild, and so on. However, real-world vision tasks may experience changes in environmental conditions, leading to shifts in how captured images are presented. To address this issue, we introduce Domain-Aware Continual Zero-Shot Learning (DACZSL), a task to recognize images of unseen categories in continuously changing domains. Accordingly, we propose a Domain-Invariant Network (DIN) to learn factorized features for shifting domains and improved textual representation for unseen classes. DIN continually learns a global shared network for domain-invariant and task-invariant features, and per-task private networks for task-specific features. Furthermore, we enhance the dual network with class-wise learnable prompts to improve class-level text representation, thereby improving zero-shot prediction of future unseen classes. To evaluate DACZSL, we introduce two benchmarks, DomainNet-CZSL and iWildCam-CZSL. Our results show that DIN significantly outperforms existing baselines by over 5% in harmonic accuracy and over 1% in backward transfer and achieves a new SoTA.\n",
      "\n",
      "Completed DACZSL, domain-aware, continual, zero-shot, learning, domain-invariant, network, features, representation, benchmarks abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Large-scale datasets are important for the development of deep learning models. Such datasets usually require a heavy workload of annotations, which are extremely time-consuming and expensive. To accelerate the annotation procedure, multiple annotators may be employed to label different subsets of the data. However, the inconsistency and bias among different annotators are harmful to the model training, especially for qualitative and subjective tasks.To address this challenge, in this paper, we propose a novel contrastive regression framework to address the disjoint annotations problem, where each sample is labeled by only one annotator and multiple annotators work on disjoint subsets of the data. To take account of both the intra-annotator consistency and inter-annotator inconsistency, two strategies are employed.Firstly, a contrastive-based loss is applied to learn the relative ranking among different samples of the same annotator, with the assumption that the ranking of samples from the same annotator is unanimous. Secondly, we apply the gradient reversal layer to learn robust representations that are invariant to different annotators. Experiments on the facial expression prediction task, as well as the image quality assessment task, verify the effectiveness of our proposed framework.\n",
      "\n",
      "Completed contrastive, regression, annotations, inconsistency, bias, ranking, representations, invariance, datasets, efficiency abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Graph alignment aims at finding the vertex correspondence between two correlated graphs, a task that frequently occurs in graph mining applications such as social network analysis. Attributed graph alignment is a variant of graph alignment, in which publicly available side information or attributes are exploited to assist graph alignment. Existing studies on attributed graph alignment focus on either theoretical performance without computational constraints or empirical performance of efficient algorithms. This motivates us to investigate efficient algorithms with theoretical performance guarantee. In this paper, we propose two polynomial-time algorithms that exactly recover the vertex correspondence with high probability. The feasible region of the proposed algorithms is near optimal compared to the information-theoretic limits. When specialized to the seeded graph alignment problem under the seeded Erd\\H{o}s--R\\'{e}nyi graph pair model, the proposed algorithms extends the best known feasible region for exact alignment by polynomial-time algorithms.\n",
      "\n",
      "Completed graph, alignment, attributed, theoretical, performance, efficient, polynomial, feasible, information, seeded abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In reaction to growing concerns about the potential harms of artificial intelligence (AI), societies have begun to demand more transparency about how AI models and systems are created and used. To address these concerns, several efforts have proposed documentation templates containing questions to be answered by model developers. These templates provide a useful starting point, but no single template can cover the needs of diverse documentation consumers. It is possible in principle, however, to create a repeatable methodology to generate truly useful documentation. Richards et al. [25] proposed such a methodology for identifying specific documentation needs and creating templates to address those needs. Although this is a promising proposal, it has not been evaluated.\n",
      "  This paper presents the first evaluation of this user-centered methodology in practice, reporting on the experiences of a team in the domain of AI for healthcare that adopted it to increase transparency for several AI models. The methodology was found to be usable by developers not trained in user-centered techniques, guiding them to creating a documentation template that addressed the specific needs of their consumers while still being reusable across different models and use cases. Analysis of the benefits and costs of this methodology are reviewed and suggestions for further improvement in both the methodology and supporting tools are summarized.\n",
      "\n",
      "Completed AI, transparency, documentation, user-centered, Richards, methodology, healthcare, developers, needs, benefits abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Designing spectral convolutional networks is a challenging problem in graph learning. ChebNet, one of the early attempts, approximates the spectral graph convolutions using Chebyshev polynomials. GCN simplifies ChebNet by utilizing only the first two Chebyshev polynomials while still outperforming it on real-world datasets. GPR-GNN and BernNet demonstrate that the Monomial and Bernstein bases also outperform the Chebyshev basis in terms of learning the spectral graph convolutions. Such conclusions are counter-intuitive in the field of approximation theory, where it is established that the Chebyshev polynomial achieves the optimum convergent rate for approximating a function.\n",
      "  In this paper, we revisit the problem of approximating the spectral graph convolutions with Chebyshev polynomials. We show that ChebNet's inferior performance is primarily due to illegal coefficients learnt by ChebNet approximating analytic filter functions, which leads to over-fitting. We then propose ChebNetII, a new GNN model based on Chebyshev interpolation, which enhances the original Chebyshev polynomial approximation while reducing the Runge phenomenon. We conducted an extensive experimental study to demonstrate that ChebNetII can learn arbitrary graph convolutions and achieve superior performance in both full- and semi-supervised node classification tasks. Most notably, we scale ChebNetII to a billion graph ogbn-papers100M, showing that spectral-based GNNs have superior performance. Our code is available at https://github.com/ivam-he/ChebNetII.\n",
      "\n",
      "Completed graph, learning, convolutional, networks, Chebyshev, polynomials, GCN, GPR-GNN, BernNet, ChebNetII abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Quantum based systems are a relatively new research area for that different modelling languages including process calculi are currently under development. Encodings are often used to compare process calculi. Quality criteria are used then to rule out trivial or meaningless encodings. In this new context of quantum based systems, it is necessary to analyse the applicability of these quality criteria and to potentially extend or adapt them. As a first step, we test the suitability of classical criteria for encodings between quantum based languages and discuss new criteria. Concretely, we present an encoding, from a language inspired by CQP into a language inspired by qCCS. We show that this encoding satisfies compositionality, name invariance (for channel and qubit names), operational correspondence, divergence reflection, success sensitiveness, and that it preserves the size of quantum registers. Then we show that there is no encoding from qCCS into CQP that is compositional, operationally corresponding, and success sensitive.\n",
      "\n",
      "Completed quantum, systems, encodings, quality, criteria, CQP, qCCS, compositionality, operational correspondence, success sensitiveness abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "As an important and challenging problem in vision-language tasks, referring expression comprehension (REC) generally requires a large amount of multi-grained information of visual and linguistic modalities to realize accurate reasoning. In addition, due to the diversity of visual scenes and the variation of linguistic expressions, some hard examples have much more abundant multi-grained information than others. How to aggregate multi-grained information from different modalities and extract abundant knowledge from hard examples is crucial in the REC task. To address aforementioned challenges, in this paper, we propose a Self-paced Multi-grained Cross-modal Interaction Modeling framework, which improves the language-to-vision localization ability through innovations in network structure and learning mechanism. Concretely, we design a transformer-based multi-grained cross-modal attention, which effectively utilizes the inherent multi-grained information in visual and linguistic encoders. Furthermore, considering the large variance of samples, we propose a self-paced sample informativeness learning to adaptively enhance the network learning for samples containing abundant multi-grained information. The proposed framework significantly outperforms state-of-the-art methods on widely used datasets, such as RefCOCO, RefCOCO+, RefCOCOg, and ReferItGame datasets, demonstrating the effectiveness of our method.\n",
      "\n",
      "Completed multi-grained, information, referring, expression, comprehension, visual, linguistic, transformer, learning, attention abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Multi-object tracking (MOT) aims to associate target objects across video frames in order to obtain entire moving trajectories. With the advancement of deep neural networks and the increasing demand for intelligent video analysis, MOT has gained significantly increased interest in the computer vision community. Embedding methods play an essential role in object location estimation and temporal identity association in MOT. Unlike other computer vision tasks, such as image classification, object detection, re-identification, and segmentation, embedding methods in MOT have large variations, and they have never been systematically analyzed and summarized. In this survey, we first conduct a comprehensive overview with in-depth analysis for embedding methods in MOT from seven different perspectives, including patch-level embedding, single-frame embedding, cross-frame joint embedding, correlation embedding, sequential embedding, tracklet embedding, and cross-track relational embedding. We further summarize the existing widely used MOT datasets and analyze the advantages of existing state-of-the-art methods according to their embedding strategies. Finally, some critical yet under-investigated areas and future research directions are discussed.\n",
      "\n",
      "Completed Multi-Object, Tracking, Embedding, Methods, Video, Frames, Correlation, Sequential, Tracklet, Relational abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This article introduces new multiplicative updates for nonnegative matrix factorization with the $\\beta$-divergence and sparse regularization of one of the two factors (say, the activation matrix). It is well known that the norm of the other factor (the dictionary matrix) needs to be controlled in order to avoid an ill-posed formulation. Standard practice consists in constraining the columns of the dictionary to have unit norm, which leads to a nontrivial optimization problem. Our approach leverages a reparametrization of the original problem into the optimization of an equivalent scale-invariant objective function. From there, we derive block-descent majorization-minimization algorithms that result in simple multiplicative updates for either $\\ell_{1}$-regularization or the more \"aggressive\" log-regularization. In contrast with other state-of-the-art methods, our algorithms are universal in the sense that they can be applied to any $\\beta$-divergence (i.e., any value of $\\beta$) and that they come with convergence guarantees. We report numerical comparisons with existing heuristic and Lagrangian methods using various datasets: face images, an audio spectrogram, hyperspectral data, and song play counts. We show that our methods obtain solutions of similar quality at convergence (similar objective values) but with significantly reduced CPU times.\n",
      "\n",
      "Completed multiplicative, updates, nonnegative, matrix, factorization, beta, regularization, equivalent,invariant, objective abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "PPSZ, for long time the fastest known algorithm for $k$-SAT, works by going through the variables of the input formula in random order; each variable is then set randomly to $0$ or $1$, unless the correct value can be inferred by an efficiently implementable rule (like small-width resolution; or being implied by a small set of clauses). We show that PPSZ performs exponentially better than previously known, for all $k \\geq 3$. For Unique-$3$-SAT we bound its running time by $O(1.306973^{n})$, which is somewhat better than the algorithm of Hansen, Kaplan, Zamir, and Zwick, which runs in time $O(1.306995^n)$. Before that, the best known upper bound for Unique-$3$-SAT was $O(1.3070319^n)$. All improvements are achieved without changing the original PPSZ. The core idea is to pretend that PPSZ does not process the variables in uniformly random order, but according to a carefully designed distribution. We write \"pretend\" since this can be done without any actual change to the algorithm.\n",
      "\n",
      "Completed PPSZ, k-SAT, random order, small-width resolution, Unique-3-SAT, Hansen, Kaplan, Zamir, Zwick, exponential improvement, carefully designed distribution abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we study differentially private point and confidence interval estimators for simple linear regression. Motivated by recent work that highlights the strong empirical performance of an algorithm based on robust statistics, DPTheilSen, we provide a rigorous, finite-sample analysis of its privacy and accuracy properties, offer guidance on setting hyperparameters, and show how to produce differentially private confidence intervals to accompany its point estimates.\n",
      "\n",
      "Completed differentially, private, point, confidence, interval, estimators, linear, regression, TheilSen, hyperparameters abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Having good knowledge of terrain information is essential for improving the performance of various downstream tasks on complex terrains, especially for the locomotion and navigation of legged robots. We present a novel framework for neural urban terrain reconstruction with uncertainty estimations. It generates dense robot-centric elevation maps online from sparse LiDAR observations. We design a novel pre-processing and point features representation approach that ensures high robustness and computational efficiency when integrating multiple point cloud frames. A Bayesian-GAN model then recovers the detailed terrain structures while simultaneously providing the pixel-wise reconstruction uncertainty. We evaluate the proposed pipeline through extensive simulation and real-world experiments. It demonstrates efficient terrain reconstruction with high quality and real-time performance on a mobile platform, which further benefits the downstream tasks of legged robots. (See https://kin-zhang.github.io/ndem/ for more details.)\n",
      "\n",
      "Completed terrain, reconstruction, uncertainty, neural, Bayesian-GAN, legged, robots, LiDAR, elevation, maps abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In minimum power network design problems we are given an undirected graph $G=(V,E)$ with edge costs $\\{c_e:e \\in E\\}$. The goal is to find an edge set $F\\subseteq E$ that satisfies a prescribed property of minimum power $p_c(F)=\\sum_{v \\in V} \\max \\{c_e: e \\in F \\mbox{ is incident to } v\\}$. In the Min-Power $k$ Edge Disjoint $st$-Paths problem $F$ should contains $k$ edge disjoint $st$-paths. The problem admits a $k$-approximation algorithm, and it was an open question whether it admits approximation ratio sublinear in $k$ even for unit costs. We give a $2\\sqrt{2k}$-approximation algorithm for general costs.\n",
      "\n",
      "Completed power, network, design, minimum, edge, disjoint, approximation, ratio, sublinear, unit abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper introduces SATformer, a novel Transformer-based approach for the Boolean Satisfiability (SAT) problem. Rather than solving the problem directly, SATformer approaches the problem from the opposite direction by focusing on unsatisfiability. Specifically, it models clause interactions to identify any unsatisfiable sub-problems. Using a graph neural network, we convert clauses into clause embeddings and employ a hierarchical Transformer-based model to understand clause correlation. SATformer is trained through a multi-task learning approach, using the single-bit satisfiability result and the minimal unsatisfiable core (MUC) for UNSAT problems as clause supervision. As an end-to-end learning-based satisfiability classifier, the performance of SATformer surpasses that of NeuroSAT significantly. Furthermore, we integrate the clause predictions made by SATformer into modern heuristic-based SAT solvers and validate our approach with a logic equivalence checking task. Experimental results show that our SATformer can decrease the runtime of existing solvers by an average of 21.33%.\n",
      "\n",
      "Completed SATformer, Transformer, Boolean, Satisfiability, Clause, Embedding, Unsatisfiability, Supervision, Classifier, Equivalence abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we explore the descriptive complexity theory of finite groups by examining the power of the second Ehrenfeucht-Fra\\\"iss\\'e bijective pebble game in Hella's (Ann. Pure Appl. Log., 1989) heirarchy. This is a Spoiler-Duplicator game in which Spoiler can place up to two pebbles each round. While it trivially solves graph isomorphism, it may be nontrivial for finite groups, and other ternary relational structures. We first provide a novel generalization of Weisfeiler-Leman (WL) coloring, which we call 2-ary WL. We then show that the 2-ary WL is equivalent to the second Ehrenfeucht-Fra\\\"iss\\'e bijective pebble game in Hella's heirarchy.\n",
      "  Our main result is that, in the pebble game characterization, only $O(1)$ pebbles and $O(1)$ rounds are sufficient to identify all groups without Abelian normal subgroups (a class of groups for which isomorphism testing is known to be in $\\mathsf{P}$; Babai, Codenotti, & Qiao, ICALP 2012). In particular, we show that within the first few rounds, Spoiler can force Duplicator to select an isomorphism between two such groups at each subsequent round. By Hella's results (\\emph{ibid.}), this is equivalent to saying that these groups are identified by formulas in first-order logic with generalized 2-ary quantifiers, using only $O(1)$ variables and $O(1)$ quantifier depth.\n",
      "\n",
      "Completed pebble game, finite groups, Ehrenfeucht-Fraisse, Weisfeiler-Leman coloring, Hella's hierarchy, binary WL, Abelian normal subgroups, isomorphism testing, first-order logic, generalized quantifiers abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Diffusion Models (DMs) have demonstrated state-of-the-art performance in content generation without requiring adversarial training. These models are trained using a two-step process. First, a forward - diffusion - process gradually adds noise to a datum (usually an image). Then, a backward - reverse diffusion - process gradually removes the noise to turn it into a sample of the target distribution being modelled. DMs are inspired by non-equilibrium thermodynamics and have inherent high computational complexity. Due to the frequent function evaluations and gradient calculations in high-dimensional spaces, these models incur considerable computational overhead during both training and inference stages. This can not only preclude the democratization of diffusion-based modelling, but also hinder the adaption of diffusion models in real-life applications. Not to mention, the efficiency of computational models is fast becoming a significant concern due to excessive energy consumption and environmental scares. These factors have led to multiple contributions in the literature that focus on devising computationally efficient DMs. In this review, we present the most recent advances in diffusion models for vision, specifically focusing on the important design aspects that affect the computational efficiency of DMs. In particular, we emphasize the recently proposed design choices that have led to more efficient DMs. Unlike the other recent reviews, which discuss diffusion models from a broad perspective, this survey is aimed at pushing this research direction forward by highlighting the design strategies in the literature that are resulting in practicable models for the broader research community. We also provide a future outlook of diffusion models in vision from their computational efficiency viewpoint.\n",
      "\n",
      "Completed Diffusion, Models, Forward, Reverse, Thermodynamics, Computational, Complexity, Efficiency, Design, Vision abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Self-supervised Learning (SSL) has been widely applied to learn image representations through exploiting unlabeled images. However, it has not been fully explored in the medical image analysis field. In this work, Saliency-guided Self-Supervised image Transformer (SSiT) is proposed for Diabetic Retinopathy (DR) grading from fundus images. We novelly introduce saliency maps into SSL, with a goal of guiding self-supervised pre-training with domain-specific prior knowledge. Specifically, two saliency-guided learning tasks are employed in SSiT: (1) Saliency-guided contrastive learning is conducted based on the momentum contrast, wherein fundus images' saliency maps are utilized to remove trivial patches from the input sequences of the momentum-updated key encoder. Thus, the key encoder is constrained to provide target representations focusing on salient regions, guiding the query encoder to capture salient features. (2) The query encoder is trained to predict the saliency segmentation, encouraging the preservation of fine-grained information in the learned representations. To assess our proposed method, four publicly-accessible fundus image datasets are adopted. One dataset is employed for pre-training, while the three others are used to evaluate the pre-trained models' performance on downstream DR grading. The proposed SSiT significantly outperforms other representative state-of-the-art SSL methods on all downstream datasets and under various evaluation settings. For example, SSiT achieves a Kappa score of 81.88% on the DDR dataset under fine-tuning evaluation, outperforming all other ViT-based SSL methods by at least 9.48%.\n",
      "\n",
      "Completed Self-Supervised, Learning, Transformer, Diabetic, Retinopathy, Saliency, Contrastive, Segmentation, Pre-training, Fine-tuning abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Channel Attention reigns supreme as an effective technique in the field of computer vision. However, the proposed channel attention by SENet suffers from information loss in feature learning caused by the use of Global Average Pooling (GAP) to represent channels as scalars. Thus, designing effective channel attention mechanisms requires finding a solution to enhance features preservation in modeling channel inter-dependencies. In this work, we utilize Wavelet transform compression as a solution to the channel representation problem. We first test wavelet transform as an Auto-Encoder model equipped with conventional channel attention module. Next, we test wavelet transform as a standalone channel compression method. We prove that global average pooling is equivalent to the recursive approximate Haar wavelet transform. With this proof, we generalize channel attention using Wavelet compression and name it WaveNet. Implementation of our method can be embedded within existing channel attention methods with a couple of lines of code. We test our proposed method using ImageNet dataset for image classification task. Our method outperforms the baseline SENet, and achieves the state-of-the-art results. Our code implementation is publicly available at https://github.com/hady1011/WaveNet-C.\n",
      "\n",
      "Completed Channel, Attention, Wavelet, Compression, Feature, Learning, Preservation, Inter-dependencies, ImageNet, Classification abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Automated verification has become an essential part in the security evaluation of cryptographic protocols. In this context privacy-type properties are often modelled by indistinguishability statements, expressed as behavioural equivalences in a process calculus. In this paper we contribute both to the theory and practice of this verification problem. We establish new complexity results for static equivalence, trace equivalence and labelled bisimilarity and provide a decision procedure for these equivalences in the case of a bounded number of protocol sessions. Our procedure is the first to decide trace equivalence and labelled bisimilarity exactly for a large variety of cryptographic primitives -- those that can be represented by a subterm convergent destructor rewrite system. We also implemented the procedure in a new tool, DeepSec. We showed through extensive experiments that it is significantly more efficient than other similar tools, while at the same time raises the scope of the protocols that can be analysed.\n",
      "\n",
      "Completed verification, privacy, indistinguishability, equivalence, complexity, trace, bisimilarity, decision procedure, primitives, implementation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Embodied Instruction Following (EIF) studies how autonomous mobile manipulation robots should be controlled to accomplish long-horizon tasks described by natural language instructions. While much research on EIF is conducted in simulators, the ultimate goal of the field is to deploy the agents in real life. This is one of the reasons why recent methods have moved away from training models end-to-end and take modular approaches, which do not need the costly expert operation data. However, as it is still in the early days of importing modular ideas to EIF, a search for modules effective in the EIF task is still far from a conclusion. In this paper, we propose to extend the modular design using knowledge obtained from two external sources. First, we show that embedding the physical constraints of the deployed robots into the module design is highly effective. Our design also allows the same modular system to work across robots of different configurations with minimal modifications. Second, we show that the landmark-based object search, previously implemented by a trained model requiring a dedicated set of data, can be replaced by an implementation that prompts pretrained large language models for landmark-object relationships, eliminating the need for collecting dedicated training data. Our proposed Prompter achieves 41.53\\% and 45.32\\% on the ALFRED benchmark with high-level instructions only and step-by-step instructions, respectively, significantly outperforming the previous state of the art by 5.46\\% and 9.91\\%.\n",
      "\n",
      "Completed autonomous, embodied, instruction, following, modular, natural, language, physical, constraints, ALFRED abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The prompt has become an effective linguistic tool for utilizing pre-trained language models. However, in few-shot scenarios, subtle changes in the prompt design always make the result widely different, and the prompt learning methods also make it easy to overfit the limited samples. To alleviate this, we explore utilizing suitable contrastive samples and multi-degree contrastive learning methods to improve the robustness of the prompt representation. Therefore, the proposed Consprompt combined with the prompt encoding network, contrastive sampling modules, and contrastive scoring modules, is introduced to realize differential contrastive learning. Our results exhibit state-of-the-art performance in different few-shot settings, and the ablation experiments also certify the effectiveness of utilizing multi-degree contrastive learning in the prompt-based fine-tuning process.\n",
      "\n",
      "Completed prompt, pre-trained language models, few-shot, prompt design, prompt learning, contrastive samples, contrastive learning, prompt representation, differential contrastive learning, ablation experiments abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Federated learning (FL) enables multiple clients to collaboratively train a global model without disclosing their data. Previous researches often require training the complete model parameters. However, the emergence of powerful pre-trained models makes it possible to achieve higher performance with fewer learnable parameters in FL. In this paper, we propose a federated adaptive prompt tuning algorithm, FedAPT, for multi-domain collaborative image classification with powerful foundation models, like CLIP. Compared with direct federated prompt tuning, our core idea is to adaptively unlock specific domain knowledge for each test sample in order to provide them with personalized prompts. To implement this idea, we design an adaptive prompt tuning module, which consists of a meta prompt, an adaptive network, and some keys. The server randomly generates a set of keys and assigns a unique key to each client. Then all clients cooperatively train the global adaptive network and meta prompt with the local datasets and the frozen keys. Ultimately, the global aggregation model can assign a personalized prompt to CLIP based on the domain features of each test sample. We perform extensive experiments on two multi-domain image classification datasets across two different settings -- supervised and unsupervised. The results show that FedAPT can achieve better performance with less than 10\\% of the number of parameters of the fully trained model, and the global model can perform well in diverse client domains simultaneously. The source code is available at \\url{https://github.com/leondada/FedAPT}.\n",
      "\n",
      "Completed Federated, learning, prompt, tuning, adaptation, image, classification, foundation, model, personalization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Ensuring that software performance does not degrade after a code change is paramount. A solution is to regularly execute software microbenchmarks, a performance testing technique similar to (functional) unit tests, which, however, often becomes infeasible due to extensive runtimes. To address that challenge, research has investigated regression testing techniques, such as test case prioritization (TCP), which reorder the execution within a microbenchmark suite to detect larger performance changes sooner. Such techniques are either designed for unit tests and perform sub-par on microbenchmarks or require complex performance models, drastically reducing their potential application. In this paper, we empirically evaluate single- and multi-objective search-based microbenchmark prioritization techniques to understand whether they are more effective and efficient than greedy, coverage-based techniques. For this, we devise three search objectives, i.e., coverage to maximize, coverage overlap to minimize, and historical performance change detection to maximize. We find that search algorithms (SAs) are only competitive with but do not outperform the best greedy, coverage-based baselines. However, a simple greedy technique utilizing solely the performance change history (without coverage information) is equally or more effective than the best coverage-based techniques while being considerably more efficient, with a runtime overhead of less than 1%. These results show that simple, non-coverage-based techniques are a better fit for microbenchmarks than complex coverage-based techniques.\n",
      "\n",
      "Completed Performance, Microbenchmarks, Regression, Test, Prioritization, Search, Greedy, Coverage, Effective, Efficient abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This article investigates the effect of explicitly adding auxiliary algebraic trajectory information to neural networks for dynamical systems. We draw inspiration from the field of differential-algebraic equations and differential equations on manifolds and implement related methods in residual neural networks, despite some fundamental scenario differences. Constraint or auxiliary information effects are incorporated through stabilization as well as projection methods, and we show when to use which method based on experiments involving simulations of multi-body pendulums and molecular dynamics scenarios. Several of our methods are easy to implement in existing code and have limited impact on training performance while giving significant boosts in terms of inference.\n",
      "\n",
      "Completed dynamical, systems, neural, networks, differential, algebraic, equations, manifolds, constraint, projection abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Data is a crucial infrastructure to how artificial intelligence (AI) systems learn. However, these systems to date have been largely model-centric, putting a premium on the model at the expense of the data quality. Data quality issues beset the performance of AI systems, particularly in downstream deployments and in real-world applications. Data-centric AI (DCAI) as an emerging concept brings data, its quality and its dynamism to the forefront in considerations of AI systems through an iterative and systematic approach. As one of the first overviews, this article brings together data-centric perspectives and concepts to outline the foundations of DCAI. It specifically formulates six guiding principles for researchers and practitioners and gives direction for future advancement of DCAI.\n",
      "\n",
      "Completed data, artificial intelligence, AI, data quality, model-centric, data-centric AI, DCAI, iterative, systematic, principles abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Long-form numerical reasoning in financial analysis aims to generate a reasoning program to calculate the correct answer for a given question. Previous work followed a retriever-generator framework, where the retriever selects key facts from a long-form document, and the generator generates a reasoning program based on retrieved facts. However, they treated all facts equally without considering the different contributions of facts with and without numbers. Meanwhile, the program consistency were ignored under supervised training, resulting in lower training accuracy and diversity. To solve these problems, we proposed APOLLO to improve the long-form numerical reasoning framework. For the retriever, we adopt a number-aware negative sampling strategy to enable the retriever to be more discriminative on key numerical facts. For the generator, we design consistency-based reinforcement learning and target program augmentation strategy based on the consistency of program execution results. Experimental results on the FinQA and ConvFinQA leaderboard verify the effectiveness of our proposed method, achieving the new state-of-the-art.\n",
      "\n",
      "Completed numerical, reasoning, financial, analysis, retriever, generator, consistency, learning, reinforcement, diversity abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Deep supervised models have an unprecedented capacity to absorb large quantities of training data. Hence, training on multiple datasets becomes a method of choice towards strong generalization in usual scenes and graceful performance degradation in edge cases. Unfortunately, different datasets often have incompatible labels. For instance, the Cityscapes road class subsumes all driving surfaces, while Vistas defines separate classes for road markings, manholes etc. Furthermore, many datasets have overlapping labels. For instance, pickups are labeled as trucks in VIPER, cars in Vistas, and vans in ADE20k. We address this challenge by considering labels as unions of universal visual concepts. This allows seamless and principled learning on multi-domain dataset collections without requiring any relabeling effort. Our method achieves competitive within-dataset and cross-dataset generalization, as well as ability to learn visual concepts which are not separately labeled in any of the training datasets. Experiments reveal competitive or state-of-the-art performance on two multi-domain dataset collections and on the WildDash 2 benchmark.\n",
      "\n",
      "Completed deep, supervised, models, multi-dataset, incompatible, overlapping, labels, universal, visual, concepts abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Previous weakly-supervised object localization (WSOL) methods aim to expand activation map discriminative areas to cover the whole objects, yet neglect two inherent challenges when relying solely on image-level labels. First, the ``entangled context'' issue arises from object-context co-occurrence (\\eg, fish and water), making the model inspection hard to distinguish object boundaries clearly. Second, the ``C-L dilemma'' issue results from the information decay caused by the pooling layers, which struggle to retain both the semantic information for precise classification and those essential details for accurate localization, leading to a trade-off in performance. In this paper, we propose a knowledge-guided causal intervention method, dubbed KG-CI-CAM, to address these two under-explored issues in one go. More specifically, we tackle the co-occurrence context confounder problem via causal intervention, which explores the causalities among image features, contexts, and categories to eliminate the biased object-context entanglement in the class activation maps. Based on the disentangled object feature, we introduce a multi-source knowledge guidance framework to strike a balance between absorbing classification knowledge and localization knowledge during model training. Extensive experiments conducted on several benchmark datasets demonstrate the effectiveness of KG-CI-CAM in learning distinct object boundaries amidst confounding contexts and mitigating the dilemma between classification and localization performance.\n",
      "\n",
      "Completed WSOL, Entangled Context, C-L Dilemma, Knowledge-Guided, Causal Intervention, KG-CI-CAM, Object Localization, Context Confounder, Classification, Localization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The quest for optimal operation in environments with unknowns and uncertainties is highly desirable but critically challenging across numerous fields. This paper develops a dual control framework for exploration and exploitation (DCEE) to solve an auto-optimisation problem in such complex settings. In general, there is a fundamental conflict between tracking an unknown optimal operational condition and parameter identification. The DCEE framework stands out by eliminating the need for additional perturbation signals, a common requirement in existing adaptive control methods. Instead, it inherently incorporates an exploration mechanism, actively probing the uncertain environment to diminish belief uncertainty. An ensemble based multi-estimator approach is developed to learn the environmental parameters and in the meanwhile quantify the estimation uncertainty in real time. The control action is devised with dual effects, which not only minimises the tracking error between the current state and the believed unknown optimal operational condition but also reduces belief uncertainty by proactively exploring the environment. Formal properties of the proposed DCEE framework like convergence are established. A numerical example is used to validate the effectiveness of the proposed DCEE. Simulation results for maximum power point tracking are provided to further demonstrate the potential of this new framework in real world applications.\n",
      "\n",
      "Completed exploration, exploitation, auto-optimisation, dual control, uncertainty, parameter identification, perturbation, multi-estimator, ensemble, real-time abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The learning rate is a critical hyperparameter for deep learning tasks since it determines the extent to which the model parameters are updated during the learning course. However, the choice of learning rates typically depends on empirical judgment, which may not result in satisfactory outcomes without intensive try-and-error experiments. In this study, we propose a novel learning rate adaptation scheme called QLABGrad. Without any user-specified hyperparameter, QLABGrad automatically determines the learning rate by optimizing the Quadratic Loss Approximation-Based (QLAB) function for a given gradient descent direction, where only one extra forward propagation is required. We theoretically prove the convergence of QLABGrad with a smooth Lipschitz condition on the loss function. Experiment results on multiple architectures, including MLP, CNN, and ResNet, on MNIST, CIFAR10, and ImageNet datasets, demonstrate that QLABGrad outperforms various competing schemes for deep learning.\n",
      "\n",
      "Completed learning, rate, adaptation, QLABGrad, hyperparameter, optimization, gradient, convergence, neural networks, datasets abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper addresses a cross-modal learning framework, where the objective is to enhance the performance of supervised learning in the primary modality using an unlabeled, unpaired secondary modality. Taking a probabilistic approach for missing information estimation, we show that the extra information contained in the secondary modality can be estimated via Nadaraya-Watson (NW) kernel regression, which can further be expressed as a kernelized cross-attention module (under linear transformation). Our results lay the foundations for introducing The Attention Patch (TAP), a simple neural network add-on that allows data-level knowledge transfer from the unlabeled modality. We provide extensive numerical simulations using four real-world datasets to show that TAP can provide statistically significant improvement in generalization across different domains and different neural network architectures, making use of seemingly unusable unlabeled cross-modal data.\n",
      "\n",
      "Completed Cross-modal, Learning, Framework, Performance, Supervised, Learning, Unlabeled, Unpaired, Kernelized, Attention abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Humans no doubt use language to communicate about their emotional experiences, but does language in turn help humans understand emotions, or is language just a vehicle of communication? This study used a form of artificial intelligence (AI) known as large language models (LLMs) to assess whether language-based representations of emotion causally contribute to the AI's ability to generate inferences about the emotional meaning of novel situations. Fourteen attributes of human emotion concept representation were found to be represented by the LLM's distinct artificial neuron populations. By manipulating these attribute-related neurons, we in turn demonstrated the role of emotion concept knowledge in generative emotion inference. The attribute-specific performance deterioration was related to the importance of different attributes in human mental space. Our findings provide a proof-in-concept that even a LLM can learn about emotions in the absence of sensory-motor representations and highlight the contribution of language-derived emotion-concept knowledge for emotion inference.\n",
      "\n",
      "Completed language, emotion, AI, representation, inference, concept, neuron, attribute, mental space, proof-of-concept abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "A finitary automaton group is a group generated by an invertible, deterministic finite-state letter-to-letter transducer whose only cycles are self-loops at an identity state. We show that, for this presentation of finite groups, the uniform word problem is coNP-complete. Here, the input consists of a finitary automaton together with a finite state sequence and the question is whether the sequence acts trivially on all input words. Additionally, we also show that the respective compressed word problem, where the state sequence is given as a straight-line program, is PSpace-complete. In both cases, we give a direct reduction from the satisfiability problem for (quantified) boolean formulae and we further show that the problems remain complete for their respective classes if we restrict the input alphabet of the automata to a binary one.\n",
      "\n",
      "Completed finitary, automaton, group, uniform, word, problem, coNP, complete, compressed, PSpace abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we introduce Tolerant Discrete Barrier States (T-DBaS), a novel safety-embedding technique for trajectory optimization with enhanced exploratory capabilities. The proposed approach generalizes the standard discrete barrier state (DBaS) method by accommodating temporary constraint violation during the optimization process while still approximating its safety guarantees. Consequently, the proposed approach eliminates the DBaS's safe nominal trajectories assumption, while enhancing its exploration effectiveness for escaping local minima. Towards applying T-DBaS to safety-critical autonomous robotics, we combine it with Differential Dynamic Programming (DDP), leading to the proposed safe trajectory optimization method T-DBaS-DDP, which inherits the convergence and scalability properties of the solver. The effectiveness of the T-DBaS algorithm is verified on differential drive robot and quadrotor simulations. In addition, we compare against the classical DBaS-DDP as well as Augmented-Lagrangian DDP (AL-DDP) in extensive numerical comparisons that demonstrate the proposed method's competitive advantages. Finally, the applicability of the proposed approach is verified through hardware experiments on the Georgia Tech Robotarium platform.\n",
      "\n",
      "Completed Tolerant, Discrete, Barrier, States, Trajectory, Optimization, Exploratory, Safety-Critical, Robotics, Differential, Dynamic, Programming abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Reinforcement learning (RL) is crucial for data science decision-making but suffers from sample inefficiency, particularly in real-world scenarios with costly physical interactions. This paper introduces a novel human-inspired framework to enhance RL algorithm sample efficiency. It achieves this by initially exposing the learning agent to simpler tasks that progressively increase in complexity, ultimately leading to the main task. This method requires no pre-training and involves learning simpler tasks for just one iteration. The resulting knowledge can facilitate various transfer learning approaches, such as value and policy transfer, without increasing computational complexity. It can be applied across different goals, environments, and RL algorithms, including value-based, policy-based, tabular, and deep RL methods. Experimental evaluations demonstrate the framework's effectiveness in enhancing sample efficiency, especially in challenging main tasks, demonstrated through both a simple Random Walk and more complex optimal control problems with constraints.\n",
      "\n",
      "Completed reinforcement learning, sample inefficiency, human-inspired framework, task progression, transfer learning, value transfer, policy transfer, tabular RL, deep RL, constrained optimal control abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present DiffuScene for indoor 3D scene synthesis based on a novel scene configuration denoising diffusion model. It generates 3D instance properties stored in an unordered object set and retrieves the most similar geometry for each object configuration, which is characterized as a concatenation of different attributes, including location, size, orientation, semantics, and geometry features. We introduce a diffusion network to synthesize a collection of 3D indoor objects by denoising a set of unordered object attributes. Unordered parametrization simplifies and eases the joint distribution approximation. The shape feature diffusion facilitates natural object placements, including symmetries. Our method enables many downstream applications, including scene completion, scene arrangement, and text-conditioned scene synthesis. Experiments on the 3D-FRONT dataset show that our method can synthesize more physically plausible and diverse indoor scenes than state-of-the-art methods. Extensive ablation studies verify the effectiveness of our design choice in scene diffusion models.\n",
      "\n",
      "Completed DiffuScene, scene synthesis, diffusion model, 3D instance properties, object configuration, denoising, scene completion, arrangement, text-conditioned synthesis, 3D-FRONT abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Large language models (LLMs) have made significant progress in NLP. However, their ability to memorize, represent, and leverage commonsense knowledge has been a well-known pain point. In this paper, we specifically focus on ChatGPT, a widely used and easily accessible LLM, and ask the following questions: (1) Can ChatGPT effectively answer commonsense questions? (2) Is ChatGPT aware of the underlying commonsense knowledge for answering a specific question? (3) Is ChatGPT knowledgeable in commonsense? (4) Can ChatGPT effectively leverage commonsense for answering questions? We conduct a series of experiments on 11 datasets to evaluate ChatGPT's commonsense abilities, including answering commonsense questions, identifying necessary knowledge, generating knowledge descriptions, and using knowledge descriptions to answer questions again. Experimental results show that: (1) ChatGPT can achieve good QA accuracies in commonsense tasks, while still struggling with certain domains of datasets. (2) ChatGPT is knowledgeable, and can accurately generate most of the commonsense knowledge using knowledge prompts. (3) Despite its knowledge, ChatGPT is an inexperienced commonsense problem solver, which cannot precisely identify the needed commonsense for answering a specific question. These findings raise the need to explore improved mechanisms for effectively incorporating commonsense into LLMs like ChatGPT, such as better instruction following and commonsense guidance.\n",
      "\n",
      "Completed ChatGPT, commonsense, knowledge, NLP, questions, datasets, accuracy, problem solving, LLMs, evaluation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recently, diffusion models have achieved great success in image synthesis. However, when it comes to the layout-to-image generation where an image often has a complex scene of multiple objects, how to make strong control over both the global layout map and each detailed object remains a challenging task. In this paper, we propose a diffusion model named LayoutDiffusion that can obtain higher generation quality and greater controllability than the previous works. To overcome the difficult multimodal fusion of image and layout, we propose to construct a structural image patch with region information and transform the patched image into a special layout to fuse with the normal layout in a unified form. Moreover, Layout Fusion Module (LFM) and Object-aware Cross Attention (OaCA) are proposed to model the relationship among multiple objects and designed to be object-aware and position-sensitive, allowing for precisely controlling the spatial related information. Extensive experiments show that our LayoutDiffusion outperforms the previous SOTA methods on FID, CAS by relatively 46.35%, 26.70% on COCO-stuff and 44.29%, 41.82% on VG. Code is available at https://github.com/ZGCTroy/LayoutDiffusion.\n",
      "\n",
      "Completed Diffusion models, Image synthesis, Layout-to-image generation, Controllability, LayoutDiffusion, Structural image patch, Layout Fusion Module (LFM), Object-aware Cross Attention (OaCA), FID, CAS abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper presents an algorithm for restoring AC power flow feasibility from solutions to simplified optimal power flow (OPF) problems, including convex relaxations, power flow approximations, and machine learning (ML) models. The proposed algorithm employs a state estimation-based post-processing technique in which voltage phasors, power injections, and line flows from solutions to relaxed, approximated, or ML-based OPF problems are treated similarly to noisy measurements in a state estimation algorithm. The algorithm leverages information from various quantities to obtain feasible voltage phasors and power injections that satisfy the AC power flow equations. Weight and bias parameters are computed offline using an adaptive stochastic gradient descent method. By automatically learning the trustworthiness of various outputs from simplified OPF problems, these parameters inform the online computations of the state estimation-based algorithm to both recover feasible solutions and characterize the performance of power flow approximations, relaxations, and ML models. Furthermore, the proposed algorithm can simultaneously utilize combined solutions from different relaxations, approximations, and ML models to enhance performance. Case studies demonstrate the effectiveness and scalability of the proposed algorithm, with solutions that are both AC power flow feasible and much closer to the true AC OPF solutions than alternative methods, often by several orders of magnitude in the squared two-norm loss function.\n",
      "\n",
      "Completed AC, power, flow, feasibility, OPF, convex, relaxation, approximation, machine, learning abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Black-box optimization (BBO) has a broad range of applications, including automatic machine learning, experimental design, and database knob tuning. However, users still face challenges when applying BBO methods to their problems at hand with existing software packages in terms of applicability, performance, and efficiency. This paper presents OpenBox, an open-source BBO toolkit with improved usability. It implements user-friendly inferfaces and visualization for users to define and manage their tasks. The modular design behind OpenBox facilitates its flexible deployment in existing systems. Experimental results demonstrate the effectiveness and efficiency of OpenBox over existing systems. The source code of OpenBox is available at https://github.com/PKU-DAIR/open-box.\n",
      "\n",
      "Completed Black-box optimization, Open-source, Toolkit, Usability, Interfaces, Visualization, Modular design, Efficiency, Effectiveness, OpenBox abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Quantum algorithms for tasks such as factorization, search, and simulation rely on control flow such as branching and iteration that depends on the value of data in superposition. High-level programming abstractions for control flow, such as switches, loops, and higher-order functions, are ubiquitous in classical languages. By contrast, many quantum languages do not provide high-level abstractions for control flow in superposition, and instead require the use of hardware-level logic gates to implement such control flow.\n",
      "  The reason for this gap is that whereas a classical computer supports control flow using a program counter that can depend on data, the typical architecture of a quantum computer does not provide a program counter that can depend on data in superposition. As a result, the complete set of control flow abstractions that can be correctly realized on a quantum computer has not yet been established.\n",
      "  In this work, we provide a complete characterization of the properties of control flow abstractions that are correctly realizable on a quantum computer. First, we prove that even on a quantum computer whose program counter exists in superposition, one cannot correctly realize control flow in quantum algorithms by lifting the classical conditional jump instruction to work in superposition. This theorem denies the ability to directly lift general abstractions for control flow such as the $\\lambda$-calculus from classical to quantum programming.\n",
      "  In response, we present the necessary and sufficient conditions for control flow to be correctly realizable on a quantum computer. We introduce the quantum control machine, an instruction set architecture featuring a conditional jump that is restricted to satisfy these conditions. We show how this design enables a developer to correctly express control flow in quantum algorithms using a program counter in place of logic gates.\n",
      "\n",
      "Completed quantum, algorithms, superposition, control, flow, languages, lambda-calculus, instruction, set, architecture abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Soft robots show compliance and have infinite degrees of freedom. Thanks to these properties, such robots can be leveraged for surgery, rehabilitation, biomimetics, unstructured environment exploring, and industrial grippers. In this case, they attract scholars from a variety of areas. However, nonlinearity and hysteresis effects also bring a burden to robot modeling. Moreover, following their flexibility and adaptation, soft robot control is more challenging than rigid robot control. In order to model and control soft robots, a large number of data-driven methods are utilized in pairs or separately. This review first briefly introduces two foundations for data-driven approaches, which are physical models and the Jacobian matrix, then summarizes three kinds of data-driven approaches, which are statistical method, neural network, and reinforcement learning. This review compares the modeling and controller features, e.g., model dynamics, data requirement, and target task, within and among these categories. Finally, we summarize the features of each method. A discussion about the advantages and limitations of the existing modeling and control approaches is presented, and we forecast the future of data-driven approaches in soft robots. A website (https://sites.google.com/view/23zcb) is built for this review and will be updated frequently.\n",
      "\n",
      "Completed data-driven, soft robots, nonlinearity, hysteresis, flexibility, adaptation, physical models, Jacobian matrix, neural network, reinforcement learning abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Weakly Supervised Semantic Segmentation (WSSS) techniques explore individual regularization strategies to refine Class Activation Maps (CAMs). In this work, we first analyze complementary WSSS techniques in the literature, their segmentation properties, and the conditions in which they are most effective. Based on these findings, we devise two new techniques: P-NOC and CCAM-H. In the first, we promote the conjoint training of two adversarial CAM generating networks: the generator, which progressively learns to erase regions containing class-specific features, and a discriminator, which is refined to gradually shift its attention to new class discriminant features. In the latter, we employ the high quality pseudo-segmentation priors produced by P-NOC to guide the learning to saliency information in a weakly supervised fashion. Finally, we employ both pseudo-segmentation priors and pseudo-saliency proposals in the random walk procedure, resulting in higher quality pseudo-semantic segmentation masks, and competitive results with the state of the art.\n",
      "\n",
      "Completed Weakly, Supervised, Semantic, Segmentation, Techniques, Class, Activation, Maps,\n",
      "Pseudo-Segmentation, Priors, Pseudo-Saliency abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Task-oriented dialogue (TOD) models have made significant progress in recent years. However, previous studies primarily focus on datasets written by annotators, which has resulted in a gap between academic research and real-world spoken conversation scenarios. While several small-scale spoken TOD datasets are proposed to address robustness issues such as ASR errors, they ignore the unique challenges in spoken conversation. To tackle the limitations, we introduce SpokenWOZ, a large-scale speech-text dataset for spoken TOD, containing 8 domains, 203k turns, 5.7k dialogues and 249 hours of audios from human-to-human spoken conversations. SpokenWOZ further incorporates common spoken characteristics such as word-by-word processing and reasoning in spoken language. Based on these characteristics, we present cross-turn slot and reasoning slot detection as new challenges. We conduct experiments on various baselines, including text-modal models, newly proposed dual-modal models, and LLMs, e.g., ChatGPT. The results show that the current models still have substantial room for improvement in spoken conversation, where the most advanced dialogue state tracker only achieves 25.65% in joint goal accuracy and the SOTA end-to-end model only correctly completes the user request in 52.1% of dialogues. The dataset, code, and leaderboard are available: https://spokenwoz.github.io/.\n",
      "\n",
      "Completed SpokenWOZ, speech-text, spoken TOD, human-to-human, word-by-word, reasoning, cross-turn slot, reasoning slot detection, dual-modal models, LLMs abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Estimating position bias is a well-known challenge in Learning to Rank (L2R). Click data in e-commerce applications, such as targeted advertisements and search engines, provides implicit but abundant feedback to improve personalized rankings. However, click data inherently includes various biases like position bias. Based on the position-based click model, Result Randomization and Regression Expectation-Maximization algorithm (REM) have been proposed to estimate position bias, but they require various paired observations of (item, position). In real-world scenarios of advertising, marketers frequently display advertisements in a fixed pre-determined order, which creates difficulties in estimation due to the limited availability of various pairs in the training data, resulting in a sparse dataset. We propose a variant of the REM that utilizes item embeddings to alleviate the sparsity of (item, position). Using a public dataset and internal carousel advertisement click dataset, we empirically show that item embedding with Latent Semantic Indexing (LSI) and Variational Auto-Encoder (VAE) improves the accuracy of position bias estimation and the estimated position bias enhances Learning to Rank performance. We also show that LSI is more effective as an embedding creation method for position bias estimation.\n",
      "\n",
      "Completed position bias, Learning to Rank, click data, e-commerce, item embedding, Result Randomization, Regression Expectation-Maximization, sparse dataset, Latent Semantic Indexing, Variational Auto-Encoder abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "One of the main challenges of the sign language recognition task is the difficulty of collecting a suitable dataset due to the gap between hard-of-hearing and hearing societies. In addition, the sign language in each country differs significantly, which obliges the creation of new data for each of them. This paper presents the Russian Sign Language (RSL) video dataset Slovo, produced using crowdsourcing platforms. The dataset contains 20,000 FullHD recordings, divided into 1,000 classes of isolated RSL gestures received by 194 signers. We also provide the entire dataset creation pipeline, from data collection to video annotation, with the following demo application. Several neural networks are trained and evaluated on the Slovo to demonstrate its teaching ability. Proposed data and pre-trained models are publicly available.\n",
      "\n",
      "Completed Sign, Language, Recognition, Dataset, Slovo, Crowdsourcing, Russian, Gestures, Neural, Networks abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Offline reinforcement learning (RL) allows agents to learn effective, return-maximizing policies from a static dataset. Three popular algorithms for offline RL are Conservative Q-Learning (CQL), Behavior Cloning (BC), and Decision Transformer (DT), from the class of Q-Learning, Imitation Learning, and Sequence Modeling respectively. A key open question is: which algorithm is preferred under what conditions? We study this question empirically by exploring the performance of these algorithms across the commonly used D4RL and Robomimic benchmarks. We design targeted experiments to understand their behavior concerning data suboptimality, task complexity, and stochasticity. Our key findings are: (1) DT requires more data than CQL to learn competitive policies but is more robust; (2) DT is a substantially better choice than both CQL and BC in sparse-reward and low-quality data settings; (3) DT and BC are preferable as task horizon increases, or when data is obtained from human demonstrators; and (4) CQL excels in situations characterized by the combination of high stochasticity and low data quality. We also investigate architectural choices and scaling trends for DT on Atari and D4RL and make design/scaling recommendations. We find that scaling the amount of data for DT by 5x gives a 2.5x average score improvement on Atari.\n",
      "\n",
      "Completed Offline, Reinforcement learning, Q-Learning, Imitation Learning, Sequence Modeling, D4RL, Robomimic, Data suboptimality, Task complexity, Stochasticity abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "A recent trend in explainable AI research has focused on surrogate modeling, where neural networks are approximated as simpler ML algorithms such as kernel machines. A second trend has been to utilize kernel functions in various explain-by-example or data attribution tasks. In this work, we combine these two trends to analyze approximate empirical neural tangent kernels (eNTK) for data attribution. Approximation is critical for eNTK analysis due to the high computational cost to compute the eNTK. We define new approximate eNTK and perform novel analysis on how well the resulting kernel machine surrogate models correlate with the underlying neural network. We introduce two new random projection variants of approximate eNTK which allow users to tune the time and memory complexity of their calculation. We conclude that kernel machines using approximate neural tangent kernel as the kernel function are effective surrogate models, with the introduced trace NTK the most consistent performer. Open source software allowing users to efficiently calculate kernel functions in the PyTorch framework is available (https://github.com/pnnl/projection\\_ntk).\n",
      "\n",
      "Completed explainable AI, surrogate modeling, kernel machines, data attribution, empirical neural tangent kernels, approximation, kernel function, random projection, time complexity, memory complexity abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We compare games under delayed control and delay games, two types of infinite games modelling asynchronicity in reactive synthesis. In games under delayed control both players suffer from partial informedness due to symmetrically delayed communication, while in delay games, the protagonist has to grant lookahead to the alter player. Our first main result, the interreducibility of the existence of sure winning strategies for the protagonist, allows to transfer known complexity results and bounds on the delay from delay games to games under delayed control, for which no such results had been known. We furthermore analyse existence of randomized strategies that win almost surely, where this correspondence between the two types of games breaks down. In this setting, some games surely won by the alter player in delay games can now be won almost surely by the protagonist in the corresponding game under delayed control, showing that it indeed makes a difference whether the protagonist has to grant lookahead or both players suffer from partial informedness. These results get even more pronounced when we finally address the quantitative goal of winning with a probability in $[0,1]$. We show that for any rational threshold $\\theta \\in [0,1]$ there is a game that can be won by the protagonist with exactly probability $\\theta$ under delayed control, while being surely won by alter in the delay game setting. All these findings refine our original result that games under delayed control are not determined.\n",
      "\n",
      "Completed delayed, control, delay, games, synthesis, informedness, lookahead, strategies, randomized, complexity abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "As an important and challenging problem in computer vision, PAnoramic Semantic Segmentation (PASS) gives complete scene perception based on an ultra-wide angle of view. Usually, prevalent PASS methods with 2D panoramic image input focus on solving image distortions but lack consideration of the 3D properties of original $360^{\\circ}$ data. Therefore, their performance will drop a lot when inputting panoramic images with the 3D disturbance. To be more robust to 3D disturbance, we propose our Spherical Geometry-Aware Transformer for PAnoramic Semantic Segmentation (SGAT4PASS), considering 3D spherical geometry knowledge. Specifically, a spherical geometry-aware framework is proposed for PASS. It includes three modules, i.e., spherical geometry-aware image projection, spherical deformable patch embedding, and a panorama-aware loss, which takes input images with 3D disturbance into account, adds a spherical geometry-aware constraint on the existing deformable patch embedding, and indicates the pixel density of original $360^{\\circ}$ data, respectively. Experimental results on Stanford2D3D Panoramic datasets show that SGAT4PASS significantly improves performance and robustness, with approximately a 2% increase in mIoU, and when small 3D disturbances occur in the data, the stability of our performance is improved by an order of magnitude. Our code and supplementary material are available at https://github.com/TencentARC/SGAT4PASS.\n",
      "\n",
      "Completed Panoramic, Segmentation, 3D, Disturbance, Spherical, Transformer, Geometry, Embedding, Loss, Stability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we propose LF-PGVIO, a Visual-Inertial-Odometry (VIO) framework for large Field-of-View (FoV) cameras with a negative plane using points and geodesic segments. The purpose of our research is to unleash the potential of point-line odometry with large-FoV omnidirectional cameras, even for cameras with negative-plane FoV. To achieve this, we propose an Omnidirectional Curve Segment Detection (OCSD) method combined with a camera model which is applicable to images with large distortions, such as panoramic annular images, fisheye images, and various panoramic images. The geodesic segment is sliced into multiple straight-line segments based on the radian and descriptors are extracted and recombined. Descriptor matching establishes the constraint relationship between 3D line segments in multiple frames. In our VIO system, line feature residual is also extended to support large-FoV cameras. Extensive evaluations on public datasets demonstrate the superior accuracy and robustness of LF-PGVIO compared to state-of-the-art methods. The source code will be made publicly available at https://github.com/flysoaryun/LF-PGVIO.\n",
      "\n",
      "Completed Visual-Inertial-Odometry, large-FoV, negative-plane, omnidirectional, geodesic, panoramic, descriptor matching, line feature residual, public datasets, source code abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper we propose a notion of pattern avoidance in binary trees that generalizes the avoidance of contiguous tree patterns studied by Rowland and non-contiguous tree patterns studied by Dairyko, Pudwell, Tyner, and Wynn. Specifically, we propose algorithms for generating different classes of binary trees that are characterized by avoiding one or more of these generalized patterns. This is achieved by applying the recent Hartung-Hoang-M\\\"utze-Williams generation framework, by encoding binary trees via permutations. In particular, we establish a one-to-one correspondence between tree patterns and certain mesh permutation patterns. We also conduct a systematic investigation of all tree patterns on at most 5 vertices, and we establish bijections between pattern-avoiding binary trees and other combinatorial objects, in particular pattern-avoiding lattice paths and set partitions.\n",
      "\n",
      "Completed binary, trees, pattern, avoidance, permutations, mesh, lattice, paths, set, partitions abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Knowledge Distillation (KD) is a promising technique for reducing the high computational demand of large language models (LLMs). However, previous KD methods are primarily applied to white-box classification models or training small models to imitate black-box model APIs like ChatGPT. How to effectively distill the knowledge of white-box LLMs into small models is still under-explored, which becomes more important with the prosperity of open-source LLMs. In this work, we propose a KD approach that distills LLMs into smaller language models. We first replace the forward Kullback-Leibler divergence (KLD) objective in the standard KD approaches with reverse KLD, which is more suitable for KD on generative language models, to prevent the student model from overestimating the low-probability regions of the teacher distribution. Then, we derive an effective optimization approach to learn this objective. The student models are named MiniLLM. Extensive experiments in the instruction-following setting show that MiniLLM generates more precise responses with higher overall quality, lower exposure bias, better calibration, and higher long-text generation performance than the baselines. Our method is scalable for different model families with 120M to 13B parameters. Our code, data, and model checkpoints can be found in https://github.com/microsoft/LMOps/tree/main/minillm.\n",
      "\n",
      "Completed knowledge distillation, large language models, white-box, black-box, reverse KLD, generative language models, optimization, MiniLLM, instruction-following, scalability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Partially observable Markov decision processes (POMDPs) have been widely applied in various real-world applications. However, existing theoretical results have shown that learning in POMDPs is intractable in the worst case, where the main challenge lies in the lack of latent state information. A key fundamental question here is: how much online state information (OSI) is sufficient to achieve tractability? In this paper, we establish a lower bound that reveals a surprising hardness result: unless we have full OSI, we need an exponentially scaling sample complexity to obtain an $\\epsilon$-optimal policy solution for POMDPs. Nonetheless, inspired by the insights in our lower-bound design, we identify important tractable subclasses of POMDPs, even with only partial OSI. In particular, for two subclasses of POMDPs with partial OSI, we provide new algorithms that are proved to be near-optimal by establishing new regret upper and lower bounds. Both our algorithm design and regret analysis involve non-trivial developments for joint OSI query and action control.\n",
      "\n",
      "Completed POMDPs, state information, tractability, lower bound, sample complexity, $\\epsilon$-optimal policy, near-optimal algorithms, regret upper bound, regret lower bound, joint query and action control abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Photometric stereo leverages variations in illumination conditions to reconstruct surface normals. Display photometric stereo, which employs a conventional monitor as an illumination source, has the potential to overcome limitations often encountered in bulky and difficult-to-use conventional setups. In this paper, we present differentiable display photometric stereo (DDPS), addressing an often overlooked challenge in display photometric stereo: the design of display patterns. Departing from using heuristic display patterns, DDPS learns the display patterns that yield accurate normal reconstruction for a target system in an end-to-end manner. To this end, we propose a differentiable framework that couples basis-illumination image formation with analytic photometric-stereo reconstruction. The differentiable framework facilitates the effective learning of display patterns via auto-differentiation. Also, for training supervision, we propose to use 3D printing for creating a real-world training dataset, enabling accurate reconstruction on the target real-world setup. Finally, we exploit that conventional LCD monitors emit polarized light, which allows for the optical separation of diffuse and specular reflections when combined with a polarization camera, leading to accurate normal reconstruction. Extensive evaluation of DDPS shows improved normal-reconstruction accuracy compared to heuristic patterns and demonstrates compelling properties such as robustness to pattern initialization, calibration errors, and simplifications in image formation and reconstruction.\n",
      "\n",
      "Completed photometric, stereo, display, patterns, differentiable, learning, 3D, printing, polarization, reconstruction abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Learning Granger causality from event sequences is a challenging but essential task across various applications. Most existing methods rely on the assumption that event sequences are independent and identically distributed (i.i.d.). However, this i.i.d. assumption is often violated due to the inherent dependencies among the event sequences. Fortunately, in practice, we find these dependencies can be modeled by a topological network, suggesting a potential solution to the non-i.i.d. problem by introducing the prior topological network into Granger causal discovery. This observation prompts us to tackle two ensuing challenges: 1) how to model the event sequences while incorporating both the prior topological network and the latent Granger causal structure, and 2) how to learn the Granger causal structure. To this end, we devise a unified topological neural Poisson auto-regressive model with two processes. In the generation process, we employ a variant of the neural Poisson process to model the event sequences, considering influences from both the topological network and the Granger causal structure. In the inference process, we formulate an amortized inference algorithm to infer the latent Granger causal structure. We encapsulate these two processes within a unified likelihood function, providing an end-to-end framework for this task. Experiments on simulated and real-world data demonstrate the effectiveness of our approach.\n",
      "\n",
      "Completed Granger, causality, event, sequences, topological, network, neural, Poisson, autoregressive, learning abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In the era of deep learning, federated learning (FL) presents a promising approach that allows multi-institutional data owners, or clients, to collaboratively train machine learning models without compromising data privacy. However, most existing FL approaches rely on a centralized server for global model aggregation, leading to a single point of failure. This makes the system vulnerable to malicious attacks when dealing with dishonest clients. In this work, we address this problem by proposing a secure and reliable FL system based on blockchain and distributed ledger technology. Our system incorporates a peer-to-peer voting mechanism and a reward-and-slash mechanism, which are powered by on-chain smart contracts, to detect and deter malicious behaviors. Both theoretical and empirical analyses are presented to demonstrate the effectiveness of the proposed approach, showing that our framework is robust against malicious client-side behaviors.\n",
      "\n",
      "Completed federated learning, blockchain, distributed ledger technology, peer-to-peer voting, reward-and-slash mechanism, smart contracts, malicious behavior detection, malicious client-side behaviors, robustness, privacy preservation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Modern language models can imitate complex patterns through few-shot learning, enabling them to complete challenging tasks without fine-tuning. However, imitation can also lead models to reproduce inaccuracies or harmful content if present in the context. We study harmful imitation through the lens of a model's internal representations, and identify two related phenomena: \"overthinking\" and \"false induction heads\". The first phenomenon, overthinking, appears when we decode predictions from intermediate layers, given correct vs. incorrect few-shot demonstrations. At early layers, both demonstrations induce similar model behavior, but the behavior diverges sharply at some \"critical layer\", after which the accuracy given incorrect demonstrations progressively decreases. The second phenomenon, false induction heads, are a possible mechanistic cause of overthinking: these are heads in late layers that attend to and copy false information from previous demonstrations, and whose ablation reduces overthinking. Beyond scientific understanding, our results suggest that studying intermediate model computations could be a promising avenue for understanding and guarding against harmful model behaviors.\n",
      "\n",
      "Completed Harmful, Imitation, Language, Models, Representations, Overthinking, False, Induction, Heads, Computation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "With recent advances in computing hardware and surges of deep-learning architectures, learning-based deep image registration methods have surpassed their traditional counterparts, in terms of metric performance and inference time. However, these methods focus on improving performance measurements such as Dice, resulting in less attention given to model behaviors that are equally desirable for registrations, especially for medical imaging. This paper investigates these behaviors for popular learning-based deep registrations under a sanity-checking microscope. We find that most existing registrations suffer from low inverse consistency and nondiscrimination of identical pairs due to overly optimized image similarities. To rectify these behaviors, we propose a novel regularization-based sanity-enforcer method that imposes two sanity checks on the deep model to reduce its inverse consistency errors and increase its discriminative power simultaneously. Moreover, we derive a set of theoretical guarantees for our sanity-checked image registration method, with experimental results supporting our theoretical findings and their effectiveness in increasing the sanity of models without sacrificing any performance. Our code and models are available at https://github.com/tuffr5/Saner-deep-registration.\n",
      "\n",
      "Completed Deep, registration, sanity, inverse consistency, nondiscrimination, regularization, theoretical guarantees, performance, medical imaging, microscope abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We view variational autoencoders (VAE) as decoder-encoder pairs, which map distributions in the data space to distributions in the latent space and vice versa. The standard learning approach for VAEs is the maximisation of the evidence lower bound (ELBO). It is asymmetric in that it aims at learning a latent variable model while using the encoder as an auxiliary means only. Moreover, it requires a closed form a-priori latent distribution. This limits its applicability in more complex scenarios, such as general semi-supervised learning and employing complex generative models as priors. We propose a Nash equilibrium learning approach, which is symmetric with respect to the encoder and decoder and allows learning VAEs in situations where both the data and the latent distributions are accessible only by sampling. The flexibility and simplicity of this approach allows its application to a wide range of learning scenarios and downstream tasks.\n",
      "\n",
      "Completed variational, autoencoders, decoder, encoder, data, latent, evidence, lower, bound, Nash, equilibrium abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "For decades, Simultaneous Ascending Auction (SAA) has been the most popular mechanism used for spectrum auctions. It has recently been employed by many countries for the allocation of 5G licences. Although SAA presents relatively simple rules, it induces a complex strategic game for which the optimal bidding strategy is unknown. Considering the fact that sometimes billions of euros are at stake in an SAA, establishing an efficient bidding strategy is crucial. In this work, we model the auction as a $n$-player simultaneous move game with complete information and propose the first efficient bidding algorithm that tackles simultaneously its four main strategic issues: the $\\textit{exposure problem}$, the $\\textit{own price effect}$, $\\textit{budget constraints}$ and the $\\textit{eligibility management problem}$. Our solution, called $SMS^\\alpha$, is based on Simultaneous Move Monte Carlo Tree Search (SM-MCTS) and relies on a new method for the prediction of closing prices. By introducing a new reward function in $SMS^\\alpha$, we give the possibility to bidders to define their own level of risk-aversion. Through extensive numerical experiments on instances of realistic size, we show that $SMS^\\alpha$ largely outperforms state-of-the-art algorithms, notably by achieving higher expected utility while taking less risks.\n",
      "\n",
      "Completed Simultaneous, Ascending, Auction, Optimal, Bidding, Strategy, Exposure, Problem, Budget, Constraints abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Deep models have achieved significant process on single image super-resolution (SISR) tasks, in particular large models with large kernel ($3\\times3$ or more). However, the heavy computational footprint of such models prevents their deployment in real-time, resource-constrained environments. Conversely, $1\\times1$ convolutions bring substantial computational efficiency, but struggle with aggregating local spatial representations, an essential capability to SISR models. In response to this dichotomy, we propose to harmonize the merits of both $3\\times3$ and $1\\times1$ kernels, and exploit a great potential for lightweight SISR tasks. Specifically, we propose a simple yet effective fully $1\\times1$ convolutional network, named Shift-Conv-based Network (SCNet). By incorporating a parameter-free spatial-shift operation, it equips the fully $1\\times1$ convolutional network with powerful representation capability while impressive computational efficiency. Extensive experiments demonstrate that SCNets, despite its fully $1\\times1$ convolutional structure, consistently matches or even surpasses the performance of existing lightweight SR models that employ regular convolutions. The code and pre-trained models can be found at https://github.com/Aitical/SCNet.\n",
      "\n",
      "Completed Lightweight, super-resolution, convolutional, efficient, kernel, spatial, representation, Shift-Conv, SCNet, 1x1 abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Learning to restore multiple image degradations within a single model is quite beneficial for real-world applications. Nevertheless, existing works typically concentrate on regarding each degradation independently, while their relationship has been less exploited to ensure the synergistic learning. To this end, we revisit the diverse degradations through the lens of singular value decomposition, with the observation that the decomposed singular vectors and singular values naturally undertake the different types of degradation information, dividing various restoration tasks into two groups, \\ie, singular vector dominated and singular value dominated. The above analysis renders a more unified perspective to ascribe the diverse degradations, compared to previous task-level independent learning. The dedicated optimization of degraded singular vectors and singular values inherently utilizes the potential relationship among diverse restoration tasks, attributing to the Decomposition Ascribed Synergistic Learning (DASL). Specifically, DASL comprises two effective operators, namely, Singular VEctor Operator (SVEO) and Singular VAlue Operator (SVAO), to favor the decomposed optimization, which can be lightly integrated into existing image restoration backbone. Moreover, the congruous decomposition loss has been devised for auxiliary. Extensive experiments on blended five image restoration tasks demonstrate the effectiveness of our method.\n",
      "\n",
      "Completed image restoration, synergistic learning, singular value decomposition, singular vectors, singular values, decomposed optimization, decomposition ascribed synergistic learning, singular vector operator, singular value operator, auxiliary congruous decomposition loss abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Steganography and steganalysis are two interrelated aspects of the field of information security. Steganography seeks to conceal communications, whereas steganalysis is aimed to either find them or even, if possible, recover the data they contain. Steganography and steganalysis have attracted a great deal of interest, particularly from law enforcement. Steganography is often used by cybercriminals and even terrorists to avoid being captured while in possession of incriminating evidence, even encrypted, since cryptography is prohibited or restricted in many countries. Therefore, knowledge of cutting-edge techniques to uncover concealed information is crucial in exposing illegal acts. Over the last few years, a number of strong and reliable steganography and steganalysis techniques have been introduced in the literature. This review paper provides a comprehensive overview of deep learning-based steganalysis techniques used to detect hidden information within digital media. The paper covers all types of cover in steganalysis, including image, audio, and video, and discusses the most commonly used deep learning techniques. In addition, the paper explores the use of more advanced deep learning techniques, such as deep transfer learning (DTL) and deep reinforcement learning (DRL), to enhance the performance of steganalysis systems. The paper provides a systematic review of recent research in the field, including data sets and evaluation metrics used in recent studies. It also presents a detailed analysis of DTL-based steganalysis approaches and their performance on different data sets. The review concludes with a discussion on the current state of deep learning-based steganalysis, challenges, and future research directions.\n",
      "\n",
      "Completed Steganography, Steganalysis, Information Security, Concealment, Recovery, Law Enforcement, Deep Learning, Digital Media, Data Sets, Transfer Learning abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The ability to cope with out-of-distribution (OOD) corruptions and adversarial attacks is crucial in real-world safety-demanding applications. In this study, we develop a general mechanism to increase neural network robustness based on focus analysis.\n",
      "  Recent studies have revealed the phenomenon of \\textit{Overfocusing}, which leads to a performance drop. When the network is primarily influenced by small input regions, it becomes less robust and prone to misclassify under noise and corruptions.\n",
      "  However, quantifying overfocusing is still vague and lacks clear definitions. Here, we provide a mathematical definition of \\textbf{focus}, \\textbf{overfocusing} and \\textbf{underfocusing}. The notions are general, but in this study, we specifically investigate the case of 3D point clouds.\n",
      "  We observe that corrupted sets result in a biased focus distribution compared to the clean training set.\n",
      "  We show that as focus distribution deviates from the one learned in the training phase - classification performance deteriorates.\n",
      "  We thus propose a parameter-free \\textbf{refocusing} algorithm that aims to unify all corruptions under the same distribution.\n",
      "  We validate our findings on a 3D zero-shot classification task, achieving SOTA in robust 3D classification on ModelNet-C dataset, and in adversarial defense against Shape-Invariant attack. Code is available in: https://github.com/yossilevii100/refocusing.\n",
      "\n",
      "Completed robustness, focus, overfocusing, underfocusing, corruptions, adversarial attacks, point clouds, refocusing, ModelNet-C, Shape-Invariant abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present a scalable method to build a high quality instruction following language model by automatically labelling human-written text with corresponding instructions. Our approach, named instruction backtranslation, starts with a language model finetuned on a small amount of seed data, and a given web corpus. The seed model is used to construct training examples by generating instruction prompts for web documents (self-augmentation), and then selecting high quality examples from among these candidates (self-curation). This data is then used to finetune a stronger model. Finetuning LLaMa on two iterations of our approach yields a model that outperforms all other LLaMa-based models on the Alpaca leaderboard not relying on distillation data, demonstrating highly effective self-alignment.\n",
      "\n",
      "Completed INSTRUCTION, BACKTRANSLATION, LANGUAGE, MODEL, FINETUNING, SEED, DATA, WEB, CORPUS, SELF-ALIGNMENT abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Equipping the rototranslation group $SE(2)$ with a sub-Riemannian structure inspired by the visual cortex V1, we propose algorithms for image inpainting and enhancement based on hypoelliptic diffusion. We innovate on previous implementations of the methods by Citti, Sarti, and Boscain et al., by proposing an alternative that prevents fading and is capable of producing sharper results in a procedure that we call WaxOn-WaxOff. We also exploit the sub-Riemannian structure to define a completely new unsharp filter using $SE(2)$, analogous to the classical unsharp filter for 2D image processing. We demonstrate our method on blood vessels enhancement in retinal scans.\n",
      "\n",
      "Completed sub-Riemannian, rototranslation, V1, inpainting, enhancement, hypoelliptic, diffusion, unsharp, filter, retinal abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Subsurface datasets inherently possess big data characteristics such as vast volume, diverse features, and high sampling speeds, further compounded by the curse of dimensionality from various physical, engineering, and geological inputs. Among the existing dimensionality reduction (DR) methods, nonlinear dimensionality reduction (NDR) methods, especially Metric-multidimensional scaling (MDS), are preferred for subsurface datasets due to their inherent complexity. While MDS retains intrinsic data structure and quantifies uncertainty, its limitations include unstabilized unique solutions invariant to Euclidean transformations and an absence of out-of-sample points (OOSP) extension. To enhance subsurface inferential and machine learning workflows, datasets must be transformed into stable, reduced-dimension representations that accommodate OOSP.\n",
      "  Our solution employs rigid transformations for a stabilized Euclidean invariant representation for LDS. By computing an MDS input dissimilarity matrix, and applying rigid transformations on multiple realizations, we ensure transformation invariance and integrate OOSP. This process leverages a convex hull algorithm and incorporates loss function and normalized stress for distortion quantification. We validate our approach with synthetic data, varying distance metrics, and real-world wells from the Duvernay Formation. Results confirm our method's efficacy in achieving consistent LDS representations. Furthermore, our proposed \"stress ratio\" (SR) metric provides insight into uncertainty, beneficial for model adjustments and inferential analysis. Consequently, our workflow promises enhanced repeatability and comparability in NDR for subsurface energy resource engineering and associated big data workflows.\n",
      "\n",
      "Completed Non-linear dimensionality reduction, Metric-multidimensional scaling, Subsurface datasets, Out-of-sample points, Stabilized representation, Rigid transformations, Dissimilarity matrix, Convex hull algorithm, Stress ratio, Repeatability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Autonomous agents have long been a prominent research focus in both academic and industry communities. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of LLM-based autonomous agents from a holistic perspective. More specifically, we first discuss the construction of LLM-based autonomous agents, for which we propose a unified framework that encompasses a majority of the previous work. Then, we present a comprehensive overview of the diverse applications of LLM-based autonomous agents in the fields of social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field. To keep track of this field and continuously update our survey, we maintain a repository of relevant references at https://github.com/Paitesanshi/LLM-Agent-Survey.\n",
      "\n",
      "Completed autonomous, agents, large, language, models, LLM, applications, evaluation, challenges, future, directions abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Given a square pencil $A+ \\lambda B$, where $A$ and $B$ are $n\\times n$ complex (resp. real) matrices, we consider the problem of finding the singular complex (resp. real) pencil nearest to it in the Frobenius distance. This problem is known to be very difficult, and the few algorithms available in the literature can only deal efficiently with pencils of very small size. We show that the problem is equivalent to minimizing a certain objective function $f$ over the Riemannian manifold $SU(n) \\times SU(n)$ (resp. $SO(n) \\times SO(n)$ if the nearest real singular pencil is sought), where $SU(n)$ denotes the special unitary group (resp. $SO(n)$ denotes the special orthogonal group). This novel perspective is based on the generalized Schur form of pencils, and yields competitive numerical methods, by pairing it with { algorithms} capable of doing optimization on { Riemannian manifolds. We propose one algorithm that directly minimizes the (almost everywhere, but not everywhere, differentiable) function $f$, as well as a smoothed alternative and a third algorithm that is smooth and can also solve the problem} of finding a nearest singular pencil with a specified minimal index. We provide numerical experiments that show that the resulting methods allow us to deal with pencils of much larger size than alternative techniques, yielding candidate minimizers of comparable or better quality. In the course of our analysis, we also obtain a number of new theoretical results related to the generalized Schur form of a (regular or singular) square pencil and to the minimal index of a singular square pencil whose nullity is $1$.\n",
      "\n",
      "Completed Frobenius, distance, singular, pencil, Riemannian, manifold, generalized, Schur, form, optimization, index abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Graph Neural Networks (GNNs) with equivariant properties have emerged as powerful tools for modeling complex dynamics of multi-object physical systems. However, their generalization ability is limited by the inadequate consideration of physical inductive biases: (1) Existing studies overlook the continuity of transitions among system states, opting to employ several discrete transformation layers to learn the direct mapping between two adjacent states; (2) Most models only account for first-order velocity information, despite the fact that many physical systems are governed by second-order motion laws. To incorporate these inductive biases, we propose the Second-order Equivariant Graph Neural Ordinary Differential Equation (SEGNO). Specifically, we show how the second-order continuity can be incorporated into GNNs while maintaining the equivariant property. Furthermore, we offer theoretical insights into SEGNO, highlighting that it can learn a unique trajectory between adjacent states, which is crucial for model generalization. Additionally, we prove that the discrepancy between this learned trajectory of SEGNO and the true trajectory is bounded. Extensive experiments on complex dynamical systems including molecular dynamics and motion capture demonstrate that our model yields a significant improvement over the state-of-the-art baselines.\n",
      "\n",
      "Completed Equivariant, Graph, Neural, Networks, Dynamics, Physical, Systems, Second-Order, Ordinary, Differential, Equation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Knowledge distillation (KD) has shown potential for learning compact models in dense object detection. However, the commonly used softmax-based distillation ignores the absolute classification scores for individual categories. Thus, the optimum of the distillation loss does not necessarily lead to the optimal student classification scores for dense object detectors. This cross-task protocol inconsistency is critical, especially for dense object detectors, since the foreground categories are extremely imbalanced. To address the issue of protocol differences between distillation and classification, we propose a novel distillation method with cross-task consistent protocols, tailored for the dense object detection. For classification distillation, we address the cross-task protocol inconsistency problem by formulating the classification logit maps in both teacher and student models as multiple binary-classification maps and applying a binary-classification distillation loss to each map. For localization distillation, we design an IoU-based Localization Distillation Loss that is free from specific network structures and can be compared with existing localization distillation losses. Our proposed method is simple but effective, and experimental results demonstrate its superiority over existing methods. Code is available at https://github.com/TinyTigerPan/BCKD.\n",
      "\n",
      "Completed knowledge, distillation, dense, object, detection, binary-classification, localization, IoU, consistent, cross-task abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In today's landscape, smartphones have evolved into hubs for hosting a multitude of deep learning models aimed at local execution. A key realization driving this work is the notable fragmentation among these models, characterized by varied architectures, operators, and implementations. This fragmentation imposes a significant burden on the comprehensive optimization of hardware, system settings, and algorithms.\n",
      "  Buoyed by the recent strides in large foundation models, this work introduces a pioneering paradigm for mobile AI: a collaborative management approach between the mobile OS and hardware, overseeing a foundational model capable of serving a broad spectrum of mobile AI tasks, if not all. This foundational model resides within the NPU and remains impervious to app or OS revisions, akin to firmware. Concurrently, each app contributes a concise, offline fine-tuned \"adapter\" tailored to distinct downstream tasks. From this concept emerges a concrete instantiation known as \\sys. It amalgamates a curated selection of publicly available Large Language Models (LLMs) and facilitates dynamic data flow. This concept's viability is substantiated through the creation of an exhaustive benchmark encompassing 38 mobile AI tasks spanning 50 datasets, including domains such as Computer Vision (CV), Natural Language Processing (NLP), audio, sensing, and multimodal inputs. Spanning this benchmark, \\sys unveils its impressive performance. It attains accuracy parity in 85\\% of tasks, demonstrates improved scalability in terms of storage and memory, and offers satisfactory inference speed on Commercial Off-The-Shelf (COTS) mobile devices fortified with NPU support. This stands in stark contrast to task-specific models tailored for individual applications.\n",
      "\n",
      "Completed mobile, AI, smartphones, fragmentation, optimization, foundation models, collaborative management, \\sys, benchmark, NPU abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The safe linear bandit problem is a version of the classical stochastic linear bandit problem where the learner's actions must satisfy an uncertain constraint at all rounds. Due its applicability to many real-world settings, this problem has received considerable attention in recent years. By leveraging a novel approach that we call directional optimism, we find that it is possible to achieve improved regret guarantees for both well-separated problem instances and action sets that are finite star convex sets. Furthermore, we propose a novel algorithm for this setting that improves on existing algorithms in terms of empirical performance, while enjoying matching regret guarantees. Lastly, we introduce a generalization of the safe linear bandit setting where the constraints are convex and adapt our algorithms and analyses to this setting by leveraging a novel convex-analysis based approach.\n",
      "\n",
      "Completed safe, linear, bandit, regret, directional, optimism, star, convex, convex-analysis abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Rapid advancements of large language models (LLMs) have enabled the processing, understanding, and generation of human-like text, with increasing integration into systems that touch our social sphere. Despite this success, these models can learn, perpetuate, and amplify harmful social biases. In this paper, we present a comprehensive survey of bias evaluation and mitigation techniques for LLMs. We first consolidate, formalize, and expand notions of social bias and fairness in natural language processing, defining distinct facets of harm and introducing several desiderata to operationalize fairness for LLMs. We then unify the literature by proposing three intuitive taxonomies, two for bias evaluation, namely metrics and datasets, and one for mitigation. Our first taxonomy of metrics for bias evaluation disambiguates the relationship between metrics and evaluation datasets, and organizes metrics by the different levels at which they operate in a model: embeddings, probabilities, and generated text. Our second taxonomy of datasets for bias evaluation categorizes datasets by their structure as counterfactual inputs or prompts, and identifies the targeted harms and social groups; we also release a consolidation of publicly-available datasets for improved access. Our third taxonomy of techniques for bias mitigation classifies methods by their intervention during pre-processing, in-training, intra-processing, and post-processing, with granular subcategories that elucidate research trends. Finally, we identify open problems and challenges for future work. Synthesizing a wide range of recent research, we aim to provide a clear guide of the existing literature that empowers researchers and practitioners to better understand and prevent the propagation of bias in LLMs.\n",
      "\n",
      "Completed bias, evaluation, mitigation, LLM, natural language processing, social, fairness, taxonomy, dataset, metric abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Training a high-performance deep neural network requires large amounts of data and computational resources. Protecting the intellectual property (IP) and commercial ownership of a deep model is challenging yet increasingly crucial. A major stream of watermarking strategies implants verifiable backdoor triggers by poisoning training samples, but these are often unrealistic due to data privacy and safety concerns and are vulnerable to minor model changes such as fine-tuning. To overcome these challenges, we propose a safe and robust backdoor-based watermark injection technique that leverages the diverse knowledge from a single out-of-distribution (OoD) image, which serves as a secret key for IP verification. The independence of training data makes it agnostic to third-party promises of IP security. We induce robustness via random perturbation of model parameters during watermark injection to defend against common watermark removal attacks, including fine-tuning, pruning, and model extraction. Our experimental results demonstrate that the proposed watermarking approach is not only time- and sample-efficient without training data, but also robust against the watermark removal attacks above.\n",
      "\n",
      "Completed deep,neural,network,watermark,backdoor,trigger,key,privacy,perturbation,extraction abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Using additional training data is known to improve the results, especially for medical image 3D segmentation where there is a lack of training material and the model needs to generalize well from few available data. However, the new data could have been acquired using other instruments and preprocessed such its distribution is significantly different from the original training data. Therefore, we study techniques which ameliorate domain shift during training so that the additional data becomes better usable for preprocessing and training together with the original data. Our results show that transforming the additional data using histogram matching has better results than using simple normalization.\n",
      "\n",
      "Completed medical, image, segmentation, training, data, domain, shift, preprocessing, normalization, histogram matching abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Vision Transformer (ViT) architectures are becoming increasingly popular and widely employed to tackle computer vision applications. Their main feature is the capacity to extract global information through the self-attention mechanism, outperforming earlier convolutional neural networks. However, ViT deployment and performance have grown steadily with their size, number of trainable parameters, and operations. Furthermore, self-attention's computational and memory cost quadratically increases with the image resolution. Generally speaking, it is challenging to employ these architectures in real-world applications due to many hardware and environmental restrictions, such as processing and computational capabilities. Therefore, this survey investigates the most efficient methodologies to ensure sub-optimal estimation performances. More in detail, four efficient categories will be analyzed: compact architecture, pruning, knowledge distillation, and quantization strategies. Moreover, a new metric called Efficient Error Rate has been introduced in order to normalize and compare models' features that affect hardware devices at inference time, such as the number of parameters, bits, FLOPs, and model size. Summarizing, this paper firstly mathematically defines the strategies used to make Vision Transformer efficient, describes and discusses state-of-the-art methodologies, and analyzes their performances over different application scenarios. Toward the end of this paper, we also discuss open challenges and promising research directions.\n",
      "\n",
      "Completed Vision, Transformer, Self-attention, Efficiency, Pruning, Knowledge distillation, Quantization, Efficient Error Rate, Hardware constraints, Performance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We consider an extension of the classical Total Store Order (TSO) semantics by expanding it to turn-based 2-player safety games. During her turn, a player can select any of the communicating processes and perform its next transition. We consider different formulations of the safety game problem depending on whether one player or both of them transfer messages from the process buffers to the shared memory. We give the complete decidability picture for all the possible alternatives.\n",
      "\n",
      "Completed TSO, safety, game, turn, transition, process, buffer, shared, memory, decidability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In the context of kernel machines, polynomial and Fourier features are commonly used to provide a nonlinear extension to linear models by mapping the data to a higher-dimensional space. Unless one considers the dual formulation of the learning problem, which renders exact large-scale learning unfeasible, the exponential increase of model parameters in the dimensionality of the data caused by their tensor-product structure prohibits to tackle high-dimensional problems. One of the possible approaches to circumvent this exponential scaling is to exploit the tensor structure present in the features by constraining the model weights to be an underparametrized tensor network. In this paper we quantize, i.e. further tensorize, polynomial and Fourier features. Based on this feature quantization we propose to quantize the associated model weights, yielding quantized models. We show that, for the same number of model parameters, the resulting quantized models have a higher bound on the VC-dimension as opposed to their non-quantized counterparts, at no additional computational cost while learning from identical features. We verify experimentally how this additional tensorization regularizes the learning problem by prioritizing the most salient features in the data and how it provides models with increased generalization capabilities. We finally benchmark our approach on large regression task, achieving state-of-the-art results on a laptop computer.\n",
      "\n",
      "Completed kernel, polynomial, Fourier, features, non-linear, tensor, network, quantization, regularization, benchmark abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We envision a system to continuously build and maintain a map based on earth-scale neural radiance fields (NeRF) using data collected from vehicles and drones in a lifelong learning manner. However, existing large-scale modeling by NeRF has problems in terms of scalability and maintainability when modeling earth-scale environments. Therefore, to address these problems, we propose a federated learning pipeline for large-scale modeling with NeRF. We tailor the model aggregation pipeline in federated learning for NeRF, thereby allowing local updates of NeRF. In the aggregation step, the accuracy of the clients' global pose is critical. Thus, we also propose global pose alignment to align the noisy global pose of clients before the aggregation step. In experiments, we show the effectiveness of the proposed pose alignment and the federated learning pipeline on the large-scale scene dataset, Mill19.\n",
      "\n",
      "Completed federated, learning, NeRF, earth-scale, radiance, fields, scalability, maintainability, pose, alignment, Mill19 abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recently, the underlying mechanism for successful deep learning (DL) was presented based on a quantitative method that measures the quality of a single filter in each layer of a DL model, particularly VGG-16 trained on CIFAR-10. This method exemplifies that each filter identifies small clusters of possible output labels, with additional noise selected as labels outside the clusters. This feature is progressively sharpened with each layer, resulting in an enhanced signal-to-noise ratio (SNR), which leads to an increase in the accuracy of the DL network. In this study, this mechanism is verified for VGG-16 and EfficientNet-B0 trained on the CIFAR-100 and ImageNet datasets, and the main results are as follows. First, the accuracy and SNR progressively increase with the layers. Second, for a given deep architecture, the maximal error rate increases approximately linearly with the number of output labels. Third, similar trends were obtained for dataset labels in the range [3, 1,000], thus supporting the universality of this mechanism. Understanding the performance of a single filter and its dominating features paves the way to highly dilute the deep architecture without affecting its overall accuracy, and this can be achieved by applying the filter's cluster connections (AFCC).\n",
      "\n",
      "Completed deep learning, filter quality, clusters, noise, VGG-16, EfficientNet-B0, SNR, accuracy, output labels, AFCC abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Automated Guided Vehicles (AGVs) are essential in various industries for their efficiency and adaptability. However, planning trajectories for AGVs in obstacle-dense, unstructured environments presents significant challenges due to the nonholonomic kinematics, abundant obstacles, and the scenario's nonconvex and constrained nature. To address this, we propose an efficient trajectory planning framework for AGVs by formulating the problem as an optimal control problem. Our framework utilizes the fast safe rectangular corridor (FSRC) algorithm to construct rectangular convex corridors, representing avoidance constraints as box constraints. This eliminates redundant obstacle influences and accelerates the solution speed. Additionally, we employ the Modified Visibility Graph algorithm to speed up path planning and a boundary discretization strategy to expedite FSRC construction. Experimental results demonstrate the effectiveness and superiority of our framework, particularly in computational efficiency. Compared to advanced frameworks, our framework achieves computational efficiency gains of 1 to 2 orders of magnitude. Notably, FSRC significantly outperforms other safe convex corridor-based methods regarding computational efficiency.\n",
      "\n",
      "Completed Automated, Guided, Vehicles, Trajectory, Planning, Obstacles, Optimal, Control, Convex, FSRC abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "To solve complex tasks, large language models (LLMs) often require multiple rounds of interactions with the user, sometimes assisted by external tools. However, current evaluation protocols often emphasize benchmark performance with single-turn exchanges, neglecting the nuanced interactions among the user, LLMs, and external tools, while also underestimating the importance of natural language feedback from users. These oversights contribute to discrepancies between research benchmark evaluations and real-world use cases. We introduce MINT, a benchmark that evaluates LLMs' ability to solve tasks with multi-turn interactions by (1) using tools and (2) leveraging natural language feedback. To ensure reproducibility, we provide an evaluation framework where LLMs can access tools by executing Python code and receive users' natural language feedback simulated by GPT-4. We repurpose a diverse set of established evaluation datasets focusing on reasoning, coding, and decision-making and carefully curate them into a compact subset for efficient evaluation. Our analysis of 20 open- and closed-source LLMs offers intriguing findings. (a) LLMs generally benefit from tools and language feedback, with performance gains (absolute, same below) of 1-8% for each turn of tool use and 2-17% with natural language feedback. (b) Better single-turn performance does not guarantee better multi-turn performance. (c) Surprisingly, on the LLMs evaluated, supervised instruction-finetuning (SIFT) and reinforcement learning from human feedback (RLHF) generally hurt multi-turn capabilities. We expect MINT can help measure progress and incentivize research in improving LLMs' capabilities in multi-turn interactions, especially for open-source communities where multi-turn human evaluation can be less accessible compared to commercial LLMs with a larger user base.\n",
      "\n",
      "Completed multi-turn, interactions, LLMs, tools, feedback, evaluation, MINT, reproducibility, datasets, SIFT, RLHF abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Single-view novel view synthesis (NVS), the task of generating images from new viewpoints based on a single reference image, is important but challenging in computer vision. Recent advancements in NVS have leveraged Denoising Diffusion Probabilistic Models (DDPMs) for their exceptional ability to produce high-fidelity images. However, current diffusion-based methods typically utilize camera pose matrices to globally and implicitly enforce 3D constraints, which can lead to inconsistencies in images generated from varying viewpoints, particularly in regions with complex textures and structures.\n",
      "  To address these limitations, we present Light Field Diffusion (LFD), a novel conditional diffusion-based approach that transcends the conventional reliance on camera pose matrices. Starting from the camera pose matrices, LFD transforms them into light field encoding, with the same shape as the reference image, to describe the direction of each ray. By integrating light field encoding with the reference image, our method imposes local pixel-wise constraints within the diffusion process, fostering enhanced view consistency. Our approach not only involves training image LFD on the ShapeNet Car dataset but also includes fine-tuning a pre-trained latent diffusion model on the Objaverse dataset. This enables our latent LFD model to exhibit remarkable zero-shot generalization capabilities across out-of-distribution datasets like RTMV as well as in-the-wild images. Experiments demonstrate that LFD not only produces high-fidelity images but also achieves superior 3D consistency in complex regions, outperforming existing novel view synthesis methods.\n",
      "\n",
      "Completed single-view, novel, view, synthesis, diffusion, probabilistic, models, light, field, generalization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The field of emotion recognition of conversation (ERC) has been focusing on separating sentence feature encoding and context modeling, lacking exploration in generative paradigms based on unified designs. In this study, we propose a novel approach,\n",
      "  \\textbf{InstructERC}, to reformulate the ERC task from a discriminative framework to a generative framework based on Large Language Models (LLMs).\n",
      "  InstructERC makes three significant contributions: (1) it introduces a simple yet effective retrieval template module, which helps the model explicitly integrate multi-granularity dialogue supervision information. (2) We introduce two additional emotion alignment tasks, namely speaker identification and emotion prediction tasks, to implicitly model the dialogue role relationships and future emotional tendencies in conversations. (3) Pioneeringly, we unify emotion labels across benchmarks through the feeling wheel to fit real application scenarios. InstructERC still perform impressively on this unified dataset. Our LLM-based plugin framework significantly outperforms all previous models and achieves comprehensive SOTA on three commonly used ERC datasets. Extensive analysis of parameter-efficient and data-scaling experiments provides empirical guidance for applying it in practical scenarios. Our code and aligned unified dataset (UIME) can be found in the Github link.\\footnote{You can find the offical realization in the Github link: https://github.com/LIN-SHANG/InstructERC}\n",
      "\n",
      "Completed generative, emotion, recognition, conversation, instructerc, retrieval template, emotion alignment, dialogue role, feeling wheel, unified dataset abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We analyse the conservatism and regret of distributionally robust (DR) stochastic model predictive control (SMPC) when using moment-based ambiguity sets for modeling unknown uncertainties. To quantify the conservatism, we compare the deterministic constraint tightening while taking a DR approach against the optimal tightening when the exact distributions of the stochastic uncertainties are known. Furthermore, we quantify the regret by comparing the performance when the distributions of the stochastic uncertainties are known and unknown. Analysing the accumulated sub-optimality of SMPC due to the lack of knowledge about the true distributions of the uncertainties marks the novel contribution of this work.\n",
      "\n",
      "Completed distributionally, robust, stochastic, model, predictive, control, conservatism, regret, uncertainty, sub-optimality abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Current unsupervised 2D-3D human pose estimation (HPE) methods do not work in multi-person scenarios due to perspective ambiguity in monocular images. Therefore, we present one of the first studies investigating the feasibility of unsupervised multi-person 2D-3D HPE from just 2D poses alone, focusing on reconstructing human interactions. To address the issue of perspective ambiguity, we expand upon prior work by predicting the cameras' elevation angle relative to the subjects' pelvis. This allows us to rotate the predicted poses to be level with the ground plane, while obtaining an estimate for the vertical offset in 3D between individuals. Our method involves independently lifting each subject's 2D pose to 3D, before combining them in a shared 3D coordinate system. The poses are then rotated and offset by the predicted elevation angle before being scaled. This by itself enables us to retrieve an accurate 3D reconstruction of their poses. We present our results on the CHI3D dataset, introducing its use for unsupervised 2D-3D pose estimation with three new quantitative metrics, and establishing a benchmark for future research.\n",
      "\n",
      "Completed unsupervised, 2D-3D, human, pose, estimation, multi-person, perspective, ambiguity, interaction, elevation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present ReCAT, a recursive composition augmented Transformer that is able to explicitly model hierarchical syntactic structures of raw texts without relying on gold trees during both learning and inference. Existing research along this line restricts data to follow a hierarchical tree structure and thus lacks inter-span communications. To overcome the problem, we propose a novel contextual inside-outside (CIO) layer that learns contextualized representations of spans through bottom-up and top-down passes, where a bottom-up pass forms representations of high-level spans by composing low-level spans, while a top-down pass combines information inside and outside a span. By stacking several CIO layers between the embedding layer and the attention layers in Transformer, the ReCAT model can perform both deep intra-span and deep inter-span interactions, and thus generate multi-grained representations fully contextualized with other spans. Moreover, the CIO layers can be jointly pre-trained with Transformers, making ReCAT enjoy scaling ability, strong performance, and interpretability at the same time. We conduct experiments on various sentence-level and span-level tasks. Evaluation results indicate that ReCAT can significantly outperform vanilla Transformer models on all span-level tasks and baselines that combine recursive networks with Transformers on natural language inference tasks. More interestingly, the hierarchical structures induced by ReCAT exhibit strong consistency with human-annotated syntactic trees, indicating good interpretability brought by the CIO layers.\n",
      "\n",
      "Completed ReCAT, Transformer, syntactic structures, hierarchical, Contextual Inside-Outside layer, intra-span interactions, inter-span interactions, multi-grained representations, interpretability, natural language inference abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We consider the two-pronged fork frame $F$ and the variety $\\mathbf{Eq}(B_F)$ generated by its dual closure algebra $B_F$. We describe the finite projective algebras in $\\mathbf{Eq}(B_F)$ and give a purely semantic proof that unification in $\\mathbf{Eq}(B_F)$ is finitary and not unitary.\n",
      "\n",
      "Completed Fork, frame, dual, closure, algebra, projective, unification, finitary, unitary, semantic abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Despite the success of deep learning for text and image data, tree-based ensemble models are still state-of-the-art for machine learning with heterogeneous tabular data. However, there is a significant need for tabular-specific gradient-based methods due to their high flexibility. In this paper, we propose $\\text{GRANDE}$, $\\text{GRA}$die$\\text{N}$t-Based $\\text{D}$ecision Tree $\\text{E}$nsembles, a novel approach for learning hard, axis-aligned decision tree ensembles using end-to-end gradient descent. GRANDE is based on a dense representation of tree ensembles, which affords to use backpropagation with a straight-through operator to jointly optimize all model parameters. Our method combines axis-aligned splits, which is a useful inductive bias for tabular data, with the flexibility of gradient-based optimization. Furthermore, we introduce an advanced instance-wise weighting that facilitates learning representations for both, simple and complex relations, within a single model. We conducted an extensive evaluation on a predefined benchmark with 19 classification datasets and demonstrate that our method outperforms existing gradient-boosting and deep learning frameworks on most datasets. The method is available under: https://github.com/s-marton/GRANDE\n",
      "\n",
      "Completed GRANDE, Gradient-Based, Decision Tree, Ensembles, Tabular, Dense Representation, Backpropagation, Inductive Bias, Instance-Wise Weighting, Benchmark abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper presents a novel framework for robust 3D object detection from point clouds via cross-modal hallucination. Our proposed approach is agnostic to either hallucination direction between LiDAR and 4D radar. We introduce multiple alignments on both spatial and feature levels to achieve simultaneous backbone refinement and hallucination generation. Specifically, spatial alignment is proposed to deal with the geometry discrepancy for better instance matching between LiDAR and radar. The feature alignment step further bridges the intrinsic attribute gap between the sensing modalities and stabilizes the training. The trained object detection models can deal with difficult detection cases better, even though only single-modal data is used as the input during the inference stage. Extensive experiments on the View-of-Delft (VoD) dataset show that our proposed method outperforms the state-of-the-art (SOTA) methods for both radar and LiDAR object detection while maintaining competitive efficiency in runtime. Code is available at https://github.com/DJNing/See_beyond_seeing.\n",
      "\n",
      "Completed cross-modal, hallucination, 3D, object, detection, point, clouds, View-of-Delft, VoD, backbone, refinement abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Many power system operation and planning problems use the DC power flow approximation to address computational challenges from the nonlinearity of the AC power flow equations. The DC power flow simplifies the AC power flow equations to a linear form that relates active power flows to phase angle differences across branches, parameterized by coefficients based on the branches' susceptances. Inspired by techniques for training machine learning models, this paper proposes an algorithm that seeks optimal coefficient and bias parameters to improve the DC power flow approximation's accuracy. Specifically, the proposed algorithm selects the coefficient and bias parameter values that minimize the discrepancy, across a specified set of operational scenarios, between the power flows given by the DC approximation and the power flows from the AC equations. Gradient-based optimization methods like Broyden-Fletcher-Goldfarb-Shanno (BFGS), Limited-Memory BFGS (L-BFGS), and Truncated Newton Conjugate-Gradient (TNC) enable solution of the proposed algorithm for large systems. After an off-line training phase, the optimized parameters are used to improve the accuracy of the DC power flow during on-line computations. Numerical results show several orders of magnitude improvements in accuracy relative to a hot-start DC power flow approximation across a range of test cases.\n",
      "\n",
      "Completed DC, power, flow, approximation, nonlinearity, optimization, coefficients, bias, gradient-based, accuracy abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "As the cost associated with fine-tuning Large Language Models (LLMs) continues to rise, recent research efforts have pivoted towards developing methodologies to edit implicit knowledge embedded within LLMs. Yet, there's still a dark cloud lingering overhead -- will knowledge editing trigger butterfly effect? since it is still unclear whether knowledge editing might introduce side effects that pose potential risks or not. This paper pioneers the investigation into the potential pitfalls associated with knowledge editing for LLMs. To achieve this, we introduce new benchmark datasets and propose innovative evaluation metrics. Our results underline two pivotal concerns: (1) Knowledge Conflict: Editing groups of facts that logically clash can magnify the inherent inconsistencies in LLMs-a facet neglected by previous methods. (2) Knowledge Distortion: Altering parameters with the aim of editing factual knowledge can irrevocably warp the innate knowledge structure of LLMs. Experimental results vividly demonstrate that knowledge editing might inadvertently cast a shadow of unintended consequences on LLMs, which warrant attention and efforts for future works. Code and data are available at https://github.com/zjunlp/PitfallsKnowledgeEditing.\n",
      "\n",
      "Completed Large Language Models, knowledge editing, butterfly effect, knowledge conflict, knowledge distortion, benchmark datasets, evaluation metrics, unintended consequences, potential risks, future works abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Effective out-of-distribution (OOD) detection is crucial for reliable machine learning models, yet most current methods are limited in practical use due to requirements like access to training data or intervention in training. We present a novel method for detecting OOD data in Transformers based on transformation smoothness between intermediate layers of a network (BLOOD), which is applicable to pre-trained models without access to training data. BLOOD utilizes the tendency of between-layer representation transformations of in-distribution (ID) data to be smoother than the corresponding transformations of OOD data, a property that we also demonstrate empirically. We evaluate BLOOD on several text classification tasks with Transformer networks and demonstrate that it outperforms methods with comparable resource requirements. Our analysis also suggests that when learning simpler tasks, OOD data transformations maintain their original sharpness, whereas sharpness increases with more complex tasks.\n",
      "\n",
      "Completed OOD, detection, Transformers, BLOOD, representation, transformation, smoothness, text, classification, sharpness abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Sharpness-aware minimization (SAM) reports improving domain generalization by reducing the loss surface curvature in the parameter space. However, generalization during fine-tuning is often more dependent on the transferability of representations in the function space. Trust-region methods (TR) target this goal by regularizing representation curvature to reduce catastrophic forgetting of pre-trained task-agnostic information while adopting task-specific skills. We consider unifying these strategies for low curvature in both parameter space and function space to improve out-of-domain (OOD) generalization. We propose Trust Region Aware Minimization (TRAM), a SAM algorithm fine-tuning for low parameter sharpness and smooth, informative representations preserving pre-trained structure. TRAM uses a trust region bound to inform the SAM adversarial neighborhood, introducing an awareness of function curvature within optimization for flatter minima. We empirically validate TRAM in vision (cross-dataset adaptation) and text (OOD language modeling, zero-shot cross-lingual transfer) tasks where robust domain transfer and representation generality are critical. TRAM outperforms SAM- and TR-based optimization across all tasks, notably surpassing competing methods for hard transfer between anticorrelated domains. TRAM establishes a novel standard in fine-tuning for domain-generalizable models with minimal additional computation over previous sharpness-aware methods.\n",
      "\n",
      "Completed Sharpness, Generalization, Parameter Space, Function Space, Trust-Region, Curvature, Representation Transfer, OOD, TRAM, Fine-Tuning abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Close Enough Traveling Salesman Problem (CETSP) is a well-known variant of TSP whereby the agent may complete its mission at any point within a target neighborhood. Heuristics based on overlapped neighborhoods, known as Steiner Zones (SZ), have gained attention in addressing CETSP. While SZs offer effective approximations to the original graph, their inherent overlap imposes constraints on search space, potentially conflicting with global optimization objectives. Here we show how such limitations can be converted into advantages in a Close Enough Orienteering Problem (CEOP) by aggregating prizes across overlapped neighborhoods. We further extend classic CEOP with Non-uniform Neighborhoods (CEOP-N) by introducing non-uniform costs for prize collection. To tackle CEOP and CEOP-N, we develop a new approach featuring a Randomized Steiner Zone Discretization (RSZD) scheme coupled with a hybrid algorithm based on Particle Swarm Optimization (PSO) and Ant Colony System (ACS), CRaSZe-AntS. The RSZD scheme identifies sub-regions for PSO exploration, and ACS determines the discrete visiting sequence. We evaluate the RSZD's discretization performance on CEOP instances derived from established CETSP instances and compare CRaSZe-AntS against the most relevant state-of-the-art heuristic focused on single-neighborhood optimization for CEOP instances. We also compare the performance of the interior search within SZs and the boundary search on individual neighborhoods in the context of CEOP-N. Our experimental results show that CRaSZe-AntS can yield comparable solution quality with significantly reduced computation time compared to the single neighborhood strategy, where we observe an average 140.44% increase in prize collection and a 55.18% reduction in algorithm execution time. CRaSZe-AntS is thus highly effective in solving emerging CEOP-N, examples of which include truck-and-drone delivery scenarios.\n",
      "\n",
      "Completed Close, Enough, Traveling, Salesman, Problem, Steiner, Zones, Non-uniform, Neighborhoods, Particle, Swarm abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Despite recent advancements in AI for robotics, grasping remains a partially solved challenge, hindered by the lack of benchmarks and reproducibility constraints. This paper introduces a vision-based grasping framework that can easily be transferred across multiple manipulators. Leveraging Quality-Diversity (QD) algorithms, the framework generates diverse repertoires of open-loop grasping trajectories, enhancing adaptability while maintaining a diversity of grasps. This framework addresses two main issues: the lack of an off-the-shelf vision module for detecting object pose and the generalization of QD trajectories to the whole robot operational space. The proposed solution combines multiple vision modules for 6DoF object detection and tracking while rigidly transforming QD-generated trajectories into the object frame. Experiments on a Franka Research 3 arm and a UR5 arm with a SIH Schunk hand demonstrate comparable performance when the real scene aligns with the simulation used for grasp generation. This work represents a significant stride toward building a reliable vision-based grasping module transferable to new platforms, while being adaptable to diverse scenarios without further training iterations.\n",
      "\n",
      "Completed grasping, robotics, vision, Quality-Diversity, adaptability, reproducibility, generalization, object detection, tracking, transferability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present Step-Back Prompting, a simple prompting technique that enables LLMs to do abstractions to derive high-level concepts and first principles from instances containing specific details. Using the concepts and principles to guide reasoning, LLMs significantly improve their abilities in following a correct reasoning path towards the solution. We conduct experiments of Step-Back Prompting with PaLM-2L, GPT-4 and Llama2-70B models, and observe substantial performance gains on various challenging reasoning-intensive tasks including STEM, Knowledge QA, and Multi-Hop Reasoning. For instance, Step-Back Prompting improves PaLM-2L performance on MMLU (Physics and Chemistry) by 7% and 11% respectively, TimeQA by 27%, and MuSiQue by 7%.\n",
      "\n",
      "Completed Step-Back, Prompting, Reasoning, LLMs, Concepts, Principles, STEM, Knowledge, Multi-Hop, Instances abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Federated Learning (FL) is a well-known paradigm of distributed machine learning on mobile and IoT devices, which preserves data privacy and optimizes communication efficiency. To avoid the single point of failure problem in FL, decentralized federated learning (DFL) has been proposed to use peer-to-peer communication for model aggregation, which has been considered an attractive solution for machine learning tasks on distributed personal devices. However, this process is vulnerable to attackers who share false models and data. If there exists a group of malicious clients, they might harm the performance of the model by carrying out a poisoning attack. In addition, in DFL, clients often lack the incentives to contribute their computing powers to do model training. In this paper, we proposed Blockchain-based Decentralized Federated Learning (BDFL), which leverages a blockchain for decentralized model verification and auditing. BDFL includes an auditor committee for model verification, an incentive mechanism to encourage the participation of clients, a reputation model to evaluate the trustworthiness of clients, and a protocol suite for dynamic network updates. Evaluation results show that, with the reputation mechanism, BDFL achieves fast model convergence and high accuracy on real datasets even if there exist 30\\% malicious clients in the system.\n",
      "\n",
      "Completed Federated, Learning, Decentralized, Blockchain, Model, Verification, Auditing, Incentive, Reputation, Network abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We introduce Bongard-OpenWorld, a new benchmark for evaluating real-world few-shot reasoning for machine vision. It originates from the classical Bongard Problems (BPs): Given two sets of images (positive and negative), the model needs to identify the set that query images belong to by inducing the visual concepts, which is exclusively depicted by images from the positive set. Our benchmark inherits the few-shot concept induction of the original BPs while adding the two novel layers of challenge: 1) open-world free-form concepts, as the visual concepts in Bongard-OpenWorld are unique compositions of terms from an open vocabulary, ranging from object categories to abstract visual attributes and commonsense factual knowledge; 2) real-world images, as opposed to the synthetic diagrams used by many counterparts. In our exploration, Bongard-OpenWorld already imposes a significant challenge to current few-shot reasoning algorithms. We further investigate to which extent the recently introduced Large Language Models (LLMs) and Vision-Language Models (VLMs) can solve our task, by directly probing VLMs, and combining VLMs and LLMs in an interactive reasoning scheme. We even conceived a neuro-symbolic reasoning approach that reconciles LLMs & VLMs with logical reasoning to emulate the human problem-solving process for Bongard Problems. However, none of these approaches manage to close the human-machine gap, as the best learner achieves 64% accuracy while human participants easily reach 91%. We hope Bongard-OpenWorld can help us better understand the limitations of current visual intelligence and facilitate future research on visual agents with stronger few-shot visual reasoning capabilities.\n",
      "\n",
      "Completed Bongard-OpenWorld, few-shot reasoning, open-world concepts, real-world images, Large Language Models, Vision-Language Models, neuro-symbolic reasoning, human problem-solving, visual intelligence, visual reasoning capabilities abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Fairness, especially group fairness, is an important consideration in the context of machine learning systems. The most commonly adopted group fairness-enhancing techniques are in-processing methods that rely on a mixture of a fairness objective (e.g., demographic parity) and a task-specific objective (e.g., cross-entropy) during the training process. However, when data arrives in an online fashion -- one instance at a time -- optimizing such fairness objectives poses several challenges. In particular, group fairness objectives are defined using expectations of predictions across different demographic groups. In the online setting, where the algorithm has access to a single instance at a time, estimating the group fairness objective requires additional storage and significantly more computation (e.g., forward/backward passes) than the task-specific objective at every time step. In this paper, we propose Aranyani, an ensemble of oblique decision trees, to make fair decisions in online settings. The hierarchical tree structure of Aranyani enables parameter isolation and allows us to efficiently compute the fairness gradients using aggregate statistics of previous decisions, eliminating the need for additional storage and forward/backward passes. We also present an efficient framework to train Aranyani and theoretically analyze several of its properties. We conduct empirical evaluations on 5 publicly available benchmarks (including vision and language datasets) to show that Aranyani achieves a better accuracy-fairness trade-off compared to baseline approaches.\n",
      "\n",
      "Completed Online, Fairness, In-processing, Decision Trees, Ensemble, Oblique, Gradient, Storage, Computation, Accuracy abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The quality of explanations for the predictions made by complex machine learning predictors is often measured using insertion and deletion metrics, which assess the faithfulness of the explanations, i.e., how accurately the explanations reflect the predictor's behavior. To improve the faithfulness, we propose insertion/deletion metric-aware explanation-based optimization (ID-ExpO), which optimizes differentiable predictors to improve both the insertion and deletion scores of the explanations while maintaining their predictive accuracy. Because the original insertion and deletion metrics are non-differentiable with respect to the explanations and directly unavailable for gradient-based optimization, we extend the metrics so that they are differentiable and use them to formalize insertion and deletion metric-based regularizers. Our experimental results on image and tabular datasets show that the deep neural network-based predictors that are fine-tuned using ID-ExpO enable popular post-hoc explainers to produce more faithful and easier-to-interpret explanations while maintaining high predictive accuracy. The code is available at https://github.com/yuyay/idexpo.\n",
      "\n",
      "Completed explainability, insertion, deletion, optimization, metric, faithfulness, gradient, differentiability, explainer, ID-ExpO abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Machine learning tasks are vulnerable to the quality of data used as input. Yet, it is often challenging for firms to obtain adequate datasets, with them being naturally distributed amongst owners, that in practice, may be competitors in a downstream market and reluctant to share information. Focusing on supervised learning for regression tasks, we develop a regression market to provide a monetary incentive for data sharing. Our proposed mechanism adopts a Bayesian framework, allowing us to consider a more general class of regression tasks. We present a thorough exploration of the market properties, and show that similar proposals in current literature expose the market agents to sizeable financial risks, which can be mitigated in our setup.\n",
      "\n",
      "Completed machine learning, regression, data sharing, monetary incentive, Bayesian framework, supervised learning, market properties, financial risks, competitors, downstream market abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this work, we present 3DCoMPaT$^{++}$, a multimodal 2D/3D dataset with 160 million rendered views of more than 10 million stylized 3D shapes carefully annotated at the part-instance level, alongside matching RGB point clouds, 3D textured meshes, depth maps, and segmentation masks. 3DCoMPaT$^{++}$ covers 41 shape categories, 275 fine-grained part categories, and 293 fine-grained material classes that can be compositionally applied to parts of 3D objects. We render a subset of one million stylized shapes from four equally spaced views as well as four randomized views, leading to a total of 160 million renderings. Parts are segmented at the instance level, with coarse-grained and fine-grained semantic levels. We introduce a new task, called Grounded CoMPaT Recognition (GCR), to collectively recognize and ground compositions of materials on parts of 3D objects. Additionally, we report the outcomes of a data challenge organized at CVPR2023, showcasing the winning method's utilization of a modified PointNet$^{++}$ model trained on 6D inputs, and exploring alternative techniques for GCR enhancement. We hope our work will help ease future research on compositional 3D Vision.\n",
      "\n",
      "Completed 3DCoMPaT++, dataset, multimodal, 2D/3D, shapes, annotations, instance level, GCR, PointNet++, compositional 3D Vision abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Pipelines, vital for fluid transport, pose an important yet challenging inspection task, particularly in small, flexible biological systems, that robots have yet to master. In this study, we explored the development of an innovative robot inspired by the ovipositor of parasitic wasps to navigate and inspect pipelines. The robot features a flexible locomotion system that adapts to different tube sizes and shapes through a mechanical inflation technique. The flexible locomotion system employs a reciprocating motion, in which groups of three sliders extend and retract in a cyclic fashion. In a proof-of-principle experiment, the robot locomotion efficiency demonstrated positive linear correlation (r=0.6434) with the diameter ratio (ratio of robot diameter to tube diameter). The robot showcased a remarkable ability to traverse tubes of different sizes, shapes and payloads with an average of (70%) locomotion efficiency across all testing conditions, at varying diameter ratios (0.7-1.5). Furthermore, the mechanical inflation mechanism displayed substantial load-carrying capacity, producing considerable holding force of (13 N), equivalent to carrying a payload of approximately (5.8 Kg) inclusive the robot weight. This novel soft robotic system shows promise for inspection and navigation within tubular confined spaces, particularly in scenarios requiring adaptability to different tube shapes, sizes, and load-carrying capacities. This novel design serves as a foundation for a new class of pipeline inspection robots that exhibit versatility across various pipeline environments, potentially including biological systems.\n",
      "\n",
      "Completed pipelines, inspection, ovipositor, flexible, locomotion, reciprocating, diameter ratio, load-carrying, soft robotics, adaptability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper targets to enhance the diffusion-based text-to-video generation by improving the two input prompts, including the noise and the text. Accommodated with this goal, we propose POS, a training-free Prompt Optimization Suite to boost text-to-video models. POS is motivated by two observations: (1) Video generation shows instability in terms of noise. Given the same text, different noises lead to videos that differ significantly in terms of both frame quality and temporal consistency. This observation implies that there exists an optimal noise matched to each textual input; To capture the potential noise, we propose an optimal noise approximator to approach the potential optimal noise. Particularly, the optimal noise approximator initially searches a video that closely relates to the text prompt and then inverts it into the noise space to serve as an improved noise prompt for the textual input. (2) Improving the text prompt via LLMs often causes semantic deviation. Many existing text-to-vision works have utilized LLMs to improve the text prompts for generation enhancement. However, existing methods often neglect the semantic alignment between the original text and the rewritten one. In response to this issue, we design a semantic-preserving rewriter to impose contraints in both rewritng and denoising phrases to preserve the semantic consistency. Extensive experiments on popular benchmarks show that our POS can improve the text-to-video models with a clear margin. The code will be open-sourced.\n",
      "\n",
      "Completed Text-to-video, Diffusion, Prompt Optimization Suite, Optimal Noise Approximator, Semantic-preserving Rewriter, Noise, Text Prompt, Instability, Semantic Alignment, Baseline abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Whisper is a multitask and multilingual speech model covering 99 languages. It yields commendable automatic speech recognition (ASR) results in a subset of its covered languages, but the model still underperforms on a non-negligible number of under-represented languages, a problem exacerbated in smaller model versions. In this work, we propose DistilWhisper, an approach able to bridge the performance gap in ASR for these languages while retaining the advantages of multitask and multilingual capabilities. Our approach involves two key strategies: lightweight modular ASR fine-tuning of whisper-small using language-specific experts, and knowledge distillation from whisper-large-v2. This dual approach allows us to effectively boost ASR performance while keeping the robustness inherited from the multitask and multilingual pre-training. Results demonstrate that our approach is more effective than standard fine-tuning or LoRA adapters, boosting performance in the targeted languages for both in- and out-of-domain test sets, while introducing only a negligible parameter overhead at inference.\n",
      "\n",
      "Completed Whisper, ASR, multilingual, under-represented languages, DistilWhisper, lightweight modular fine-tuning, language-specific experts, knowledge distillation, LoRA adapters, performance boost abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We introduce LOTUS, a continual imitation learning algorithm that empowers a physical robot to continuously and efficiently learn to solve new manipulation tasks throughout its lifespan. The core idea behind LOTUS is constructing an ever-growing skill library from a sequence of new tasks with a small number of human demonstrations. LOTUS starts with a continual skill discovery process using an open-vocabulary vision model, which extracts skills as recurring patterns presented in unsegmented demonstrations. Continual skill discovery updates existing skills to avoid catastrophic forgetting of previous tasks and adds new skills to solve novel tasks. LOTUS trains a meta-controller that flexibly composes various skills to tackle vision-based manipulation tasks in the lifelong learning process. Our comprehensive experiments show that LOTUS outperforms state-of-the-art baselines by over 11% in success rate, showing its superior knowledge transfer ability compared to prior methods. More results and videos can be found on the project website: https://ut-austin-rpl.github.io/Lotus/.\n",
      "\n",
      "Completed LOTUS, manipulation, lifelong learning, skill discovery, imitation learning, continual learning, meta-controller, skill library, knowledge transfer, open-vocabulary abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This work introduces a preference learning method that ensures adherence to given specifications, with an application to autonomous vehicles. Our approach incorporates the priority ordering of Signal Temporal Logic (STL) formulas describing traffic rules into a learning framework. By leveraging Parametric Weighted Signal Temporal Logic (PWSTL), we formulate the problem of safety-guaranteed preference learning based on pairwise comparisons and propose an approach to solve this learning problem. Our approach finds a feasible valuation for the weights of the given PWSTL formula such that, with these weights, preferred signals have weighted quantitative satisfaction measures greater than their non-preferred counterparts. The feasible valuation of weights given by our approach leads to a weighted STL formula that can be used in correct-and-custom-by-construction controller synthesis. We demonstrate the performance of our method with a pilot human subject study in two different simulated driving scenarios involving a stop sign and a pedestrian crossing. Our approach yields competitive results compared to existing preference learning methods in terms of capturing preferences and notably outperforms them when safety is considered.\n",
      "\n",
      "Completed preference, learning, autonomous, vehicles, Signal, Temporal, Logic, Parametric, Weighted, Signal, Temporal, Logic abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The relentless advancement of artificial intelligence (AI) and machine learning (ML) applications necessitates the development of specialized hardware accelerators capable of handling the increasing complexity and computational demands. Traditional computing architectures, based on the von Neumann model, are being outstripped by the requirements of contemporary AI/ML algorithms, leading to a surge in the creation of accelerators like the Graphcore Intelligence Processing Unit (IPU), Sambanova Reconfigurable Dataflow Unit (RDU), and enhanced GPU platforms. These hardware accelerators are characterized by their innovative data-flow architectures and other design optimizations that promise to deliver superior performance and energy efficiency for AI/ML tasks.\n",
      "  This research provides a preliminary evaluation and comparison of these commercial AI/ML accelerators, delving into their hardware and software design features to discern their strengths and unique capabilities. By conducting a series of benchmark evaluations on common DNN operators and other AI/ML workloads, we aim to illuminate the advantages of data-flow architectures over conventional processor designs and offer insights into the performance trade-offs of each platform. The findings from our study will serve as a valuable reference for the design and performance expectations of research prototypes, thereby facilitating the development of next-generation hardware accelerators tailored for the ever-evolving landscape of AI/ML applications. Through this analysis, we aspire to contribute to the broader understanding of current accelerator technologies and to provide guidance for future innovations in the field.\n",
      "\n",
      "Completed Artificial, Intelligence, Machine, Learning, Accelerators, Data-flow, Performance, Trade-offs, AI/ML, Architectures abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Overparameterized models have proven to be powerful tools for solving various machine learning tasks. However, overparameterization often leads to a substantial increase in computational and memory costs, which in turn requires extensive resources to train. In this work, we present a novel approach for compressing overparameterized models, developed through studying their learning dynamics. We observe that for many deep models, updates to the weight matrices occur within a low-dimensional invariant subspace. For deep linear models, we demonstrate that their principal components are fitted incrementally within a small subspace, and use these insights to propose a compression algorithm for deep linear networks that involve decreasing the width of their intermediate layers. We empirically evaluate the effectiveness of our compression technique on matrix recovery problems. Remarkably, by using an initialization that exploits the structure of the problem, we observe that our compressed network converges faster than the original network, consistently yielding smaller recovery errors. We substantiate this observation by developing a theory focused on deep matrix factorization. Finally, we empirically demonstrate how our compressed model has the potential to improve the utility of deep nonlinear models. Overall, our algorithm improves the training efficiency by more than 2x, without compromising generalization.\n",
      "\n",
      "Completed overparameterized, compression, learning, dynamics, subspace, deep, linear, width, matrix, recovery abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Answering questions within business and finance requires reasoning, precision, and a wide-breadth of technical knowledge. Together, these requirements make this domain difficult for large language models (LLMs). We introduce BizBench, a benchmark for evaluating models' ability to reason about realistic financial problems. BizBench comprises eight quantitative reasoning tasks, focusing on question-answering (QA) over financial data via program synthesis. We include three financially-themed code-generation tasks from newly collected and augmented QA data. Additionally, we isolate the reasoning capabilities required for financial QA: reading comprehension of financial text and tables for extracting intermediate values, and understanding financial concepts and formulas needed to calculate complex solutions. Collectively, these tasks evaluate a model's financial background knowledge, ability to parse financial documents, and capacity to solve problems with code. We conduct an in-depth evaluation of open-source and commercial LLMs, comparing and contrasting the behavior of code-focused and language-focused models. We demonstrate that the current bottleneck in performance is due to LLMs' limited business and financial understanding, highlighting the value of a challenging benchmark for quantitative reasoning within this domain.\n",
      "\n",
      "Completed BizBench, financial, reasoning, question-answering, code-generation, program synthesis, financial text, financial tables, financial concepts, financial formulas abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we propose two deep joint source and channel coding (DJSCC) structures with attention modules for the multi-input multi-output (MIMO) channel, including a serial structure and a parallel structure. With singular value decomposition (SVD)-based precoding scheme, the MIMO channel can be decomposed into various sub-channels, and the feature outputs will experience sub-channels with different channel qualities. In the serial structure, one single network is used at both the transmitter and the receiver to jointly process data streams of all MIMO subchannels, while data steams of different MIMO subchannels are processed independently via multiple sub-networks in the parallel structure. The attention modules in both serial and parallel architectures enable the system to adapt to varying channel qualities and adjust the quantity of information outputs in accordance with the channel qualities. Experimental results demonstrate the proposed DJSCC structures have improved image transmission performance, and reveal the phenomenon via non-parameter entropy estimation that the learned DJSCC transceivers tend to transmit more information over better sub-channels.\n",
      "\n",
      "Completed DJSCC, Attention, MIMO, Channel, SVD, Subchannels, Serial, Parallel, Entropy, Image abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This study focuses on a layered, experience-based, multi-modal contact planning framework for agile quadrupedal locomotion over a constrained rebar environment. To this end, our hierarchical planner incorporates locomotion-specific modules into the high-level contact sequence planner and solves kinodynamically-aware trajectory optimization as the low-level motion planner. Through quantitative analysis of the experience accumulation process and experimental validation of the kinodynamic feasibility of the generated locomotion trajectories, we demonstrate that the experience planning heuristic offers an effective way of providing candidate footholds for a legged contact planner. Additionally, we introduce a guiding torso path heuristic at the global planning level to enhance the navigation success rate in the presence of environmental obstacles. Our results indicate that the torso-path guided experience accumulation requires significantly fewer offline trials to successfully reach the goal compared to regular experience accumulation. Finally, our planning framework is validated in both dynamics simulations and real hardware implementations on a quadrupedal robot provided by Skymul Inc.\n",
      "\n",
      "Completed contact, planning, locomotion, quadrupedal, experience, multi-modal, layered, optimization, agility, constrained abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper addresses complex challenges in histopathological image analysis through three key contributions. Firstly, it introduces a fast patch selection method, FPS, for whole-slide image (WSI) analysis, significantly reducing computational cost while maintaining accuracy. Secondly, it presents PathDino, a lightweight histopathology feature extractor with a minimal configuration of five Transformer blocks and only 9 million parameters, markedly fewer than alternatives. Thirdly, it introduces a rotation-agnostic representation learning paradigm using self-supervised learning, effectively mitigating overfitting. We also show that our compact model outperforms existing state-of-the-art histopathology-specific vision transformers on 12 diverse datasets, including both internal datasets spanning four sites (breast, liver, skin, and colorectal) and seven public datasets (PANDA, CAMELYON16, BRACS, DigestPath, Kather, PanNuke, and WSSS4LUAD). Notably, even with a training dataset of 6 million histopathology patches from The Cancer Genome Atlas (TCGA), our approach demonstrates an average 8.5% improvement in patch-level majority vote performance. These contributions provide a robust framework for enhancing image analysis in digital pathology, rigorously validated through extensive evaluation. Project Page: https://kimialabmayo.github.io/PathDino-Page/\n",
      "\n",
      "Completed Fast, Patch, Selection, Histopathology, Image, Analysis, PathDino, Feature, Extractor, Transformer abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "While modeling people wearing tight-fitting clothing has made great strides in recent years, loose-fitting clothing remains a challenge. We propose a method that delivers realistic garment models from real-world images, regardless of garment shape or deformation. To this end, we introduce a fitting approach that utilizes shape and deformation priors learned from synthetic data to accurately capture garment shapes and deformations, including large ones. Not only does our approach recover the garment geometry accurately, it also yields models that can be directly used by downstream applications such as animation and simulation.\n",
      "\n",
      "Completed garment, modeling, loose-fitting, clothing, deformation, synthetic, data, geometry, animation, simulation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Indoor Positioning Systems (IPS) traditionally rely on odometry and building infrastructures like WiFi, often supplemented by building floor plans for increased accuracy. However, the limitation of floor plans in terms of availability and timeliness of updates challenges their wide applicability. In contrast, the proliferation of smartphones and WiFi-enabled robots has made crowdsourced radio maps - databases pairing locations with their corresponding Received Signal Strengths (RSS) - increasingly accessible. These radio maps not only provide WiFi fingerprint-location pairs but encode movement regularities akin to the constraints imposed by floor plans. This work investigates the possibility of leveraging these radio maps as a substitute for floor plans in multimodal IPS. We introduce a new framework to address the challenges of radio map inaccuracies and sparse coverage. Our proposed system integrates an uncertainty-aware neural network model for WiFi localization and a bespoken Bayesian fusion technique for optimal fusion. Extensive evaluations on multiple real-world sites indicate a significant performance enhancement, with results showing ~ 25% improvement over the best baseline\n",
      "\n",
      "Completed Indoor, Positioning, Systems, Crowdsourced, Radio, Maps, Localization, Uncertainty-Aware, Bayesian, Fusion abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "With the increasing availability of Foundation Models, federated tuning has garnered attention in the field of federated learning, utilizing data and computation resources from multiple clients to collaboratively fine-tune foundation models. However, in real-world federated scenarios, there often exist a multitude of heterogeneous clients with varying computation and communication resources, rendering them incapable of supporting the entire model fine-tuning process. In response to this challenge, we propose a novel federated tuning algorithm, FedRA. The implementation of FedRA is straightforward and can be seamlessly integrated into any transformer-based model without the need for further modification to the original model. Specifically, in each communication round, FedRA randomly generates an allocation matrix. For resource-constrained clients, it reorganizes a small number of layers from the original model based on the allocation matrix and fine-tunes using adapters. Subsequently, the server aggregates the updated adapter parameters from the clients according to the current allocation matrix into the corresponding layers of the original model. It is worth noting that FedRA also supports scenarios where none of the clients can support the entire global model, which is an impressive advantage. We conduct experiments on two large-scale image datasets, DomainNet and NICO++, under various non-iid settings. The results demonstrate that FedRA outperforms the compared methods significantly. The source code is available at \\url{https://github.com/leondada/FedRA}.\n",
      "\n",
      "Completed Federated, tuning, heterogeneity, computation, communication, resource, allocation, transformer, model, adapters abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Generalizable NeRF can directly synthesize novel views across new scenes, eliminating the need for scene-specific retraining in vanilla NeRF. A critical enabling factor in these approaches is the extraction of a generalizable 3D representation by aggregating source-view features. In this paper, we propose an Entangled View-Epipolar Information Aggregation method dubbed EVE-NeRF. Different from existing methods that consider cross-view and along-epipolar information independently, EVE-NeRF conducts the view-epipolar feature aggregation in an entangled manner by injecting the scene-invariant appearance continuity and geometry consistency priors to the aggregation process. Our approach effectively mitigates the potential lack of inherent geometric and appearance constraint resulting from one-dimensional interactions, thus further boosting the 3D representation generalizablity. EVE-NeRF attains state-of-the-art performance across various evaluation scenarios. Extensive experiments demonstate that, compared to prevailing single-dimensional aggregation, the entangled network excels in the accuracy of 3D scene geometry and appearance reconstruction. Our code is publicly available at https://github.com/tatakai1/EVENeRF.\n",
      "\n",
      "Completed Generalizable, NeRF, EVE-NeRF, Entanglement, View-epipolar, Aggregation, 3D, Representation, Geometry, Appearance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We prove error estimates for a finite element approximation of viscoelastic dynamics based on continuous Galerkin in space and time, both in energy norm and in $L^2$ norm. The proof is based on an error representation formula using a discrete dual problem and a stability estimate involving the kinetic, elastic, and viscoelastic energies. To set up the dual error analysis and to prove the basic stability estimates, it is natural to formulate the problem as a system involving evolution equations for the viscoelastic stress, the displacements, and the velocities. The equations for the viscoelastic stress can, however, be solved analytically in terms of the deviatoric strain velocity, and therefore, the viscoelastic stress can be eliminated from the system, resulting in a system for displacements and velocities.\n",
      "\n",
      "Completed finite, element, approximation, viscoelastic, dynamics, continuous, Galerkin, dual, stability, estimate abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The paper presents a numerical method for simulating flow and mechanics in fractured rock. The governing equations that couple the effects in the rock mass and in the fractures are obtained using the discrete fracture-matrix approach. The fracture flow is driven by the cubic law, and the contact conditions prevent fractures from self-penetration. A stable finite element discretization is proposed for the displacement-pressure-flux formulation. The resulting nonlinear algebraic system of equations and inequalities is decoupled using a robust iterative splitting into the linearized flow subproblem, and the quadratic programming problem for the mechanical part. The non-penetration conditions are solved by means of dualization and an optimal quadratic programming algorithm. The capability of the numerical scheme is demonstrated on a benchmark problem for tunnel excavation with hundreds of fractures in 3D. The paper's novelty consists in a combination of three crucial ingredients: (i) application of discrete fracture-matrix approach to poroelasticity, (ii) robust iterative splitting of resulting nonlinear algebraic system working for real-world 3D problems, and (iii) efficient solution of its mechanical quadratic programming part with a large number of fractures in mutual contact by means of own solvers implemented into an in-house software library.\n",
      "\n",
      "Completed discrete, fracture, matrix, flow, mechanics, fractured, rock, numerical, splitting, quadratic abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Image super-resolution (SR) methods typically model degradation to improve reconstruction accuracy in complex and unknown degradation scenarios. However, extracting degradation information from low-resolution images is challenging, which limits the model performance. To boost image SR performance, one feasible approach is to introduce additional priors. Inspired by advancements in multi-modal methods and text prompt image processing, we introduce text prompts to image SR to provide degradation priors. Specifically, we first design a text-image generation pipeline to integrate text into the SR dataset through the text degradation representation and degradation model. The text representation applies a discretization manner based on the binning method to describe the degradation abstractly. This method maintains the flexibility of the text and is user-friendly. Meanwhile, we propose the PromptSR to realize the text prompt SR. The PromptSR utilizes the pre-trained language model (e.g., T5 or CLIP) to enhance restoration. We train the model on the generated text-image dataset. Extensive experiments indicate that introducing text prompts into SR, yields excellent results on both synthetic and real-world images. Code is available at: https://github.com/zhengchen1999/PromptSR.\n",
      "\n",
      "Completed image, super-resolution, degradation, priors, text prompts, text degradation representation, binning method, PromptSR, pre-trained language model, synthetic images abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Increasing photovoltaic (PV) penetration in the distribution system can often lead to voltage violations. Mitigation of these violations requires reactive power intervention from PV inverters. However, the unbalanced nature of the distribution system leads to mixed effects on the voltages of nearby nodes for each inverter injecting or absorbing reactive power. In particular, reactive power absorption to reduce over-voltage in one phase can exacerbate over-voltage in a different phase. In this paper, the factors impacting the incremental and decremental voltage effects of reactive power intervention are analyzed in detail. The result of these effects on the distribution system performance is presented to highlight their significance and the need to factor them in for any coordinated voltage control algorithm.\n",
      "\n",
      "Completed Photovoltaic, penetration, voltage, violations, reactive, intervention, distribution, unbalanced, effects, voltage abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present Neural 3D Strokes, a novel technique to generate stylized images of a 3D scene at arbitrary novel views from multi-view 2D images. Different from existing methods which apply stylization to trained neural radiance fields at the voxel level, our approach draws inspiration from image-to-painting methods, simulating the progressive painting process of human artwork with vector strokes. We develop a palette of stylized 3D strokes from basic primitives and splines, and consider the 3D scene stylization task as a multi-view reconstruction process based on these 3D stroke primitives. Instead of directly searching for the parameters of these 3D strokes, which would be too costly, we introduce a differentiable renderer that allows optimizing stroke parameters using gradient descent, and propose a training scheme to alleviate the vanishing gradient issue. The extensive evaluation demonstrates that our approach effectively synthesizes 3D scenes with significant geometric and aesthetic stylization while maintaining a consistent appearance across different views. Our method can be further integrated with style loss and image-text contrastive models to extend its applications, including color transfer and text-driven 3D scene drawing. Results and code are available at http://buaavrcg.github.io/Neural3DStrokes.\n",
      "\n",
      "Completed Neural, 3D, Strokes, Stylization, Vector, Multi-View, Gradient, Differential, Renderer, Palette abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper does not present a novel method. Instead, it delves into an essential, yet must-know baseline in light of the latest advancements in Generative Artificial Intelligence (GenAI): the utilization of GPT-4 for visual understanding. Our study centers on the evaluation of GPT-4's linguistic and visual capabilities in zero-shot visual recognition tasks: Firstly, we explore the potential of its generated rich textual descriptions across various categories to enhance recognition performance without any training. Secondly, we evaluate GPT-4's visual proficiency in directly recognizing diverse visual content. We conducted extensive experiments to systematically evaluate GPT-4's performance across images, videos, and point clouds, using 16 benchmark datasets to measure top-1 and top-5 accuracy. Our findings show that GPT-4, enhanced with rich linguistic descriptions, significantly improves zero-shot recognition, offering an average top-1 accuracy increase of 7% across all datasets. GPT-4 excels in visual recognition, outshining OpenAI-CLIP's ViT-L and rivaling EVA-CLIP's ViT-E, particularly in video datasets HMDB-51 and UCF-101, where it leads by 22% and 9%, respectively. We hope this research contributes valuable data points and experience for future studies. We release our code at https://github.com/whwu95/GPT4Vis.\n",
      "\n",
      "Completed GPT-4, Generative AI, Visual Understanding, Zero-Shot Recognition, Benchmark Datasets, Top Accuracy, OpenAI-CLIP, EVA-CLIP, Code, GitHub abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Whole slide images are the foundation of digital pathology for the diagnosis and treatment of carcinomas. Writing pathology reports is laborious and error-prone for inexperienced pathologists. To reduce the workload and improve clinical automation, we investigate how to generate pathology reports given whole slide images. On the data end, we curated the largest WSI-text dataset (TCGA-PathoText). In specific, we collected nearly 10000 high-quality WSI-text pairs for visual-language models by recognizing and cleaning pathology reports which narrate diagnostic slides in TCGA. On the model end, we propose the multiple instance generative model (MI-Gen) which can produce pathology reports for gigapixel WSIs. We benchmark our model on the largest subset of TCGA-PathoText. Experimental results show our model can generate pathology reports which contain multiple clinical clues. Furthermore, WSI-text prediction can be seen as an approach of visual-language pre-training, which enables our model to be transferred to downstream diagnostic tasks like carcinoma grading and phenotyping. We observe that simple semantic extraction from the pathology reports can achieve the best performance (0.838 of F1 score) on BRCA subtyping without adding extra parameters or tricky fine-tuning. Our collected dataset and related code are available.\n",
      "\n",
      "Completed digital pathology, carcinoma, whole slide images, WSI-text, TCGA-PathoText, visual-language models, multiple instance generative model, MI-Gen, clinical clues, downstream diagnostic tasks abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Source-Free Domain Adaptation (SFDA) aims to adapt a source model for a target domain, with only access to unlabeled target training data and the source model pre-trained on a supervised source domain. Relying on pseudo labeling and/or auxiliary supervision, conventional methods are inevitably error-prone. To mitigate this limitation, in this work we for the first time explore the potentials of off-the-shelf vision-language (ViL) multimodal models (e.g.,CLIP) with rich whilst heterogeneous knowledge. We find that directly applying the ViL model to the target domain in a zero-shot fashion is unsatisfactory, as it is not specialized for this particular task but largely generic. To make it task specific, we propose a novel Distilling multimodal Foundation model(DIFO)approach. Specifically, DIFO alternates between two steps during adaptation: (i) Customizing the ViL model by maximizing the mutual information with the target model in a prompt learning manner, (ii) Distilling the knowledge of this customized ViL model to the target model. For more fine-grained and reliable distillation, we further introduce two effective regularization terms, namely most-likely category encouragement and predictive consistency. Extensive experiments show that DIFO significantly outperforms the state-of-the-art alternatives. Code is here\n",
      "\n",
      "Completed Source-Free, Domain, Adaptation, Vision-Language, Multimodal, Off-the-shelf, Prompt, Learning, Regularization, Distilling abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Decentralized coordination for multi-robot systems involves planning in challenging, high-dimensional spaces. The planning problem is particularly challenging in the presence of obstacles and different sources of uncertainty such as inaccurate dynamic models and sensor noise. In this paper, we introduce Stein Variational Belief Propagation (SVBP), a novel algorithm for performing inference over nonparametric marginal distributions of nodes in a graph. We apply SVBP to multi-robot coordination by modelling a robot swarm as a graphical model and performing inference for each robot. We demonstrate our algorithm on a simulated multi-robot perception task, and on a multi-robot planning task within a Model-Predictive Control (MPC) framework, on both simulated and real-world mobile robots. Our experiments show that SVBP represents multi-modal distributions better than sampling-based or Gaussian baselines, resulting in improved performance on perception and planning tasks. Furthermore, we show that SVBP's ability to represent diverse trajectories for decentralized multi-robot planning makes it less prone to deadlock scenarios than leading baselines.\n",
      "\n",
      "Completed multi-robot, coordination, inference, nonparametric, graphical model, SVBP, perception, planning, MPC, deadlock abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The security concerns surrounding Large Language Models (LLMs) have been extensively explored, yet the safety of Multimodal Large Language Models (MLLMs) remains understudied. In this paper, we observe that Multimodal Large Language Models (MLLMs) can be easily compromised by query-relevant images, as if the text query itself were malicious. To address this, we introduce MM-SafetyBench, a comprehensive framework designed for conducting safety-critical evaluations of MLLMs against such image-based manipulations. We have compiled a dataset comprising 13 scenarios, resulting in a total of 5,040 text-image pairs. Our analysis across 12 state-of-the-art models reveals that MLLMs are susceptible to breaches instigated by our approach, even when the equipped LLMs have been safety-aligned. In response, we propose a straightforward yet effective prompting strategy to enhance the resilience of MLLMs against these types of attacks. Our work underscores the need for a concerted effort to strengthen and enhance the safety measures of open-source MLLMs against potential malicious exploits. The resource is available at \\href{this https URL}{https://github.com/isXinLiu/MM-SafetyBench}.\n",
      "\n",
      "Completed safety, multimodal, large, language, models, attacks, prompting, strategies, resilience, open-source abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We show that the known list-decoding algorithms for univariate multiplicity and folded Reed-Solomon codes can be made to run in $\\tilde{O}(n)$ time. Univariate multiplicity codes and FRS codes are natural variants of Reed-Solomon codes that were discovered and studied for their applications to list decoding. It is known that for every $\\epsilon>0$, and rate $r \\in (0,1)$, there exist explicit families of these codes that have rate $r$ and can be list decoded from a $(1-r-\\epsilon)$ fraction of errors with constant list size in polynomial time (Guruswami & Wang (IEEE Trans. Inform. Theory 2013) and Kopparty, Ron-Zewi, Saraf & Wootters (SIAM J. Comput. 2023)). In this work, we present randomized algorithms that perform the above list-decoding tasks in $\\tilde{O}(n)$, where $n$ is the block-length of the code. Our algorithms have two main components. The first component builds upon the lattice-based approach of Alekhnovich (IEEE Trans. Inf. Theory 2005), who designed a $\\tilde{O}(n)$ time list-decoding algorithm for Reed-Solomon codes approaching the Johnson radius. As part of the second component, we design $\\tilde{O}(n)$ time algorithms for two natural algebraic problems: given a $(m+2)$-variate polynomial $Q(x,y_0,\\dots,y_m) = \\tilde{Q}(x) + \\sum_{i=0}^m Q_i(x)\\cdot y_i$ the first algorithm solves order-$m$ linear differential equations of the form $Q\\left(x, f(x), \\frac{df}{dx}, \\dots,\\frac{d^m f}{dx^m}\\right) \\equiv 0$ while the second solves functional equations of the form $Q\\left(x, f(x), f(\\gamma x), \\dots,f(\\gamma^m x)\\right) \\equiv 0$, where $m$ is an arbitrary constant and $\\gamma$ is a field element of sufficiently high order. These algorithms can be viewed as generalizations of classical $\\tilde{O}(n)$ time algorithms of Sieveking (Computing 1972) and Kung (Numer. Math. 1974) for computing the modular inverse of a power series, and might be of independent interest.\n",
      "\n",
      "Completed list-decoding, multiplicity-codes, folded-Reed-Solomon-codes, lattice-based-approach, linear-differential-equations, functional-equations, Sieveking, Kung, power-series, modular-inverse abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Hallucination, posed as a pervasive challenge of multi-modal large language models (MLLMs), has significantly impeded their real-world usage that demands precise judgment. Existing methods mitigate this issue with either training with specific designed data or inferencing with external knowledge from other sources, incurring inevitable additional costs. In this paper, we present OPERA, a novel MLLM decoding method grounded in an Over-trust Penalty and a Retrospection-Allocation strategy, serving as a nearly free lunch to alleviate the hallucination issue without additional data, knowledge, or training. Our approach begins with an interesting observation that, most hallucinations are closely tied to the knowledge aggregation patterns manifested in the self-attention matrix, i.e., MLLMs tend to generate new tokens by focusing on a few summary tokens, but not all the previous tokens. Such partial over-trust inclination results in the neglecting of image tokens and describes the image content with hallucination. Based on the observation, OPERA introduces a penalty term on the model logits during the beam-search decoding to mitigate the over-trust issue, along with a rollback strategy that retrospects the presence of summary tokens in the previously generated tokens, and re-allocate the token selection if necessary. With extensive experiments, OPERA shows significant hallucination-mitigating performance on different MLLMs and metrics, proving its effectiveness and generality. Our code is available at: https://github.com/shikiw/OPERA.\n",
      "\n",
      "Completed hallucination, MLLM, decoding, OPERA, penalty, retrospection, allocation, over-trust, attention, logits abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we propose an efficient and high-performance method for partially relevant video retrieval, which aims to retrieve long videos that contain at least one moment relevant to the input text query. The challenge lies in encoding dense frames using visual backbones. This requires models to handle the increased frames, resulting in significant computation costs for long videos. To mitigate the costs, previous studies use lightweight visual backbones, yielding sub-optimal retrieval performance due to their limited capabilities. However, it is undesirable to simply replace the backbones with high-performance large vision-and-language models (VLMs) due to their low efficiency. To address this dilemma, instead of dense frames, we focus on super images, which are created by rearranging the video frames in an $N \\times N$ grid layout. This reduces the number of visual encodings to $\\frac{1}{N^2}$ and mitigates the low efficiency of large VLMs. Based on this idea, we make two contributions. First, we explore whether VLMs generalize to super images in a zero-shot setting. To this end, we propose a method called query-attentive super image retrieval (QASIR), which attends to partial moments relevant to the input query. The zero-shot QASIR yields two discoveries: (1) it enables VLMs to generalize to super images and (2) the grid size $N$, image resolution, and VLM size are key trade-off parameters between performance and computation costs. Second, we introduce fine-tuning and hybrid QASIR that combines high- and low-efficiency models to strike a balance between performance and computation costs. This reveals two findings: (1) the fine-tuning QASIR enhances VLMs to learn super images effectively, and (2) the hybrid QASIR minimizes the performance drop of large VLMs while reducing the computation costs.\n",
      "\n",
      "Completed partially, relevant, video, retrieval, super, images, query-attentive, fine-tuning, hybrid, performance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Large language models (LLMs) such as ChatGPT have shown remarkable capabilities in code generation. Despite the great achievement, they rely on enormous training data to acquire a broad spectrum of open-domain knowledge. Besides, their evaluation revolves around open-domain benchmarks like HumanEval, which primarily consist of programming contests. Therefore, it is hard to fully characterize the intricacies and challenges associated with particular domains (e.g., web, game, and math). In this paper, we conduct an in-depth study of the LLMs in domain-specific code generation. Our results demonstrate that LLMs exhibit sub-optimal performance in generating domain-specific code, due to their limited proficiency in utilizing domain-specific libraries. We further observe that incorporating API knowledge as prompts can empower LLMs to generate more professional code. Based on these findings, we further investigate how to efficiently incorporate API knowledge into the code generation process. We experiment with three strategies for incorporating domain knowledge, namely, external knowledge inquirer, chain-of-thought prompting, and chain-of-thought fine-tuning. We refer to these strategies as a new code generation approach called DomCoder. Experimental results show that all strategies of DomCoder lead to improvement in the effectiveness of domain-specific code generation under certain settings. The results also show that there is still ample room for further improvement, based on which we suggest possible future works.\n",
      "\n",
      "Completed ChatGPT, code generation, large language models, domain-specific knowledge, API integration, DomCoder, external knowledge inquirer, chain-of-thought prompting, chain-of-thought fine-tuning, effectiveness abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present an approach to pose object recognition as next token prediction. The idea is to apply a language decoder that auto-regressively predicts the text tokens from image embeddings to form labels. To ground this prediction process in auto-regression, we customize a non-causal attention mask for the decoder, incorporating two key features: modeling tokens from different labels to be independent, and treating image tokens as a prefix. This masking mechanism inspires an efficient method - one-shot sampling - to simultaneously sample tokens of multiple labels in parallel and rank generated labels by their probabilities during inference. To further enhance the efficiency, we propose a simple strategy to construct a compact decoder by simply discarding the intermediate blocks of a pretrained language model. This approach yields a decoder that matches the full model's performance while being notably more efficient. The code is available at https://github.com/kaiyuyue/nxtp\n",
      "\n",
      "Completed pose, recognition, next, token, prediction, autoregressive, sampling, labels, efficiency, compact abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Given the widespread popularity of interactive AI models like ChatGPT, public opinion on emerging artificial intelligence generated content(AIGC) has been extensively debated. Pessimists believe that AIGC will replace humans in the future, and optimists think that it will further liberate productivity. Public emotions play a crucial role on social media platforms. They can provide valuable insights into the public's opinions, attitudes, and behaviors. There is a lack of research on the analysis of social group emotions triggered by AIGC content, and even more on the cross-platform differences of group emotions. This study fills the research gap by connecting the theory of group dynamics with emotions in social media. Specifically, we develop a scientific group emotion calculation and visualization system based on chains of communication. The system is capable of crawling data in real time and presenting the current state of group emotions in a fine-grained manner. We then analyze which group dynamic factors drive different public emotions towards nine AIGC products on the three most popular social media platforms in China. Finally, we obtain four main findings. First, Douyin is the only platform with negative group emotion on emerging AI technologies. Second, Weibo users prefer extreme emotions more than others. Third, the group emotion varies by education and age. It is negatively correlated with senior high school or lower and 25 or younger, and positively correlated with bachelor's degree or higher and 26-35. Fourth, the group emotion polarization increases with more posts without comments and celebrity publishers. By analyzing the key dynamic factors of group emotions to AIGC on various social media platforms, we can improve our products and services, develop more effective marketing strategies, and create more accurate and effective AI models to solve complex problems.\n",
      "\n",
      "Completed Social, Media, Platforms, Emotions, AIGC, Group, Dynamics, Weibo, Douyin, WeChat abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Research in decoding visual information from the brain, particularly through the non-invasive fMRI method, is rapidly progressing. The challenge arises from the limited data availability and the low signal-to-noise ratio of fMRI signals, leading to a low-precision task of fMRI-to-image retrieval. State-of-the-art MindEye remarkably improves fMRI-to-image retrieval performance by leveraging a deep MLP with a high parameter count orders of magnitude, i.e., a 996M MLP Backbone per subject, to align fMRI embeddings to the final hidden layer of CLIP's vision transformer. However, significant individual variations exist among subjects, even within identical experimental setups, mandating the training of subject-specific models. The substantial parameters pose significant challenges in deploying fMRI decoding on practical devices, especially with the necessitating of specific models for each subject. To this end, we propose Lite-Mind, a lightweight, efficient, and versatile brain representation network based on discrete Fourier transform, that efficiently aligns fMRI voxels to fine-grained information of CLIP. Our experiments demonstrate that Lite-Mind achieves an impressive 94.3% fMRI-to-image retrieval accuracy on the NSD dataset for Subject 1, with 98.7% fewer parameters than MindEye. Lite-Mind is also proven to be able to be migrated to smaller brain datasets and establishes a new state-of-the-art for zero-shot classification on the GOD dataset. The code is available at https://github.com/gongzix/Lite-Mind.\n",
      "\n",
      "Completed fMRI, decoding, MindEye, Lite-Mind, deep learning, parameter efficiency, discrete Fourier transform, fine-grained alignment, NSD dataset, GOD dataset abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The computational difficulties of large language model (LLM) inference remain a significant obstacle to their widespread deployment. The need for many applications to support long input sequences and process them in large batches typically causes token-generation to be bottlenecked by data-transfer. For this reason, we introduce SparQ Attention, a technique for increasing the inference throughput of LLMs by utilising memory bandwidth more efficiently within the attention layers, through selective fetching of the cached history. Our proposed technique can be applied directly to off-the-shelf LLMs during inference, without requiring any modification to the pre-training setup or additional fine-tuning. We show that SparQ Attention brings up to 8x savings in attention data-transfers without substantial drops in accuracy, by evaluating Llama 2, Mistral and Pythia models on a wide range of downstream tasks.\n",
      "\n",
      "Completed LLM, inference, bottleneck, data-transfer, SparQ Attention, attention, memory bandwidth, token-generation, pre-training, efficiency abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "3D generation has raised great attention in recent years. With the success of text-to-image diffusion models, the 2D-lifting technique becomes a promising route to controllable 3D generation. However, these methods tend to present inconsistent geometry, which is also known as the Janus problem. We observe that the problem is caused mainly by two aspects, i.e., viewpoint bias in 2D diffusion models and overfitting of the optimization objective. To address it, we propose a two-stage 2D-lifting framework, namely DreamControl, which optimizes coarse NeRF scenes as 3D self-prior and then generates fine-grained objects with control-based score distillation. Specifically, adaptive viewpoint sampling and boundary integrity metric are proposed to ensure the consistency of generated priors. The priors are then regarded as input conditions to maintain reasonable geometries, in which conditional LoRA and weighted score are further proposed to optimize detailed textures. DreamControl can generate high-quality 3D content in terms of both geometry consistency and texture fidelity. Moreover, our control-based optimization guidance is applicable to more downstream tasks, including user-guided generation and 3D animation. The project page is available at https://github.com/tyhuang0428/DreamControl.\n",
      "\n",
      "Completed 3D, generation, 2D-lifting, viewpoint, bias, overfitting, DreamControl, coarse, NeRF, LoRA abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Homogeneous binary function products are often encountered in the sub-universes modeled by databases, from genealogical trees to sports, from education to healthcare, etc. Their properties must be discovered and enforced by the software applications managing such data to guarantee plausibility. The (Elementary) Mathematical Data Model provides 18 dyadic-type homogeneous binary function product constraint types. MatBase, an intelligent data and knowledge base management system prototype, allows database designers to simply declare them by only clicking corresponding checkboxes and automatically generates code for enforcing them. This paper describes the algorithms that MatBase uses for enforcing all these 18 homogeneous binary function product constraint types, which may also be used by developers not having access to MatBase.\n",
      "\n",
      "Completed Homogeneous, Binary, Function, Products, Databases, Plausibility, Math, MatBase, Checkbox, Code abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In the past several years, the last-iterate convergence of the Stochastic Gradient Descent (SGD) algorithm has triggered people's interest due to its good performance in practice but lack of theoretical understanding. For Lipschitz convex functions, different works have established the optimal $O(\\log(1/\\delta)\\log T/\\sqrt{T})$ or $O(\\sqrt{\\log(1/\\delta)/T})$ high-probability convergence rates for the final iterate, where $T$ is the time horizon and $\\delta$ is the failure probability. However, to prove these bounds, all the existing works are either limited to compact domains or require almost surely bounded noises. It is natural to ask whether the last iterate of SGD can still guarantee the optimal convergence rate but without these two restrictive assumptions. Besides this important question, there are still lots of theoretical problems lacking an answer. For example, compared with the last-iterate convergence of SGD for non-smooth problems, only few results for smooth optimization have yet been developed. Additionally, the existing results are all limited to a non-composite objective and the standard Euclidean norm. It still remains unclear whether the last-iterate convergence can be provably extended to wider composite optimization and non-Euclidean norms. In this work, to address the issues mentioned above, we revisit the last-iterate convergence of stochastic gradient methods and provide the first unified way to prove the convergence rates both in expectation and in high probability to accommodate general domains, composite objectives, non-Euclidean norms, Lipschitz conditions, smoothness, and (strong) convexity simultaneously. Additionally, we extend our analysis to obtain the last-iterate convergence under heavy-tailed noises.\n",
      "\n",
      "Completed Stochastic, Gradient, Descent, Last-iterate, Convergence, Non-composite, Composite, Non-Euclidean, Smoothness, Convexity abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The key to performance optimization of a program is to decide correctly when a certain transformation should be applied by a compiler. This is an ideal opportunity to apply machine-learning models to speed up the tuning process; while this realization has been around since the late 90s, only recent advancements in ML enabled a practical application of ML to compilers as an end-to-end framework.\n",
      "  This paper presents ACPO: \\textbf{\\underline{A}}I-Enabled \\textbf{\\underline{C}}ompiler-driven \\textbf{\\underline{P}}rogram \\textbf{\\underline{O}}ptimization; a novel framework to provide LLVM with simple and comprehensive tools to benefit from employing ML models for different optimization passes. We first showcase the high-level view, class hierarchy, and functionalities of ACPO and subsequently, demonstrate a couple of use cases of ACPO by ML-enabling the Loop Unroll and Function Inlining passes and describe how ACPO can be leveraged to optimize other passes. Experimental results reveal that ACPO model for Loop Unroll is able to gain on average 4\\% compared to LLVM's O3 optimization when deployed on Polybench. Furthermore, by adding the Inliner model as well, ACPO is able to provide up to 4.5\\% and 2.4\\% on Polybench and Cbench compared with LLVM's O3 optimization, respectively.\n",
      "\n",
      "Completed AI, compiler, optimization, machine learning, LLVM, framework, ACPO, Loop Unroll, Function Inlining, performance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Generative AI (GenAI) systems offer unprecedented opportunities for transforming professional and personal work, yet present challenges around prompting, evaluating and relying on outputs, and optimizing workflows. We argue that metacognition$\\unicode{x2013}$the psychological ability to monitor and control one's thoughts and behavior$\\unicode{x2013}$offers a valuable lens to understand and design for these usability challenges. Drawing on research in psychology and cognitive science, and recent GenAI user studies, we illustrate how GenAI systems impose metacognitive demands on users, requiring a high degree of metacognitive monitoring and control. We propose these demands could be addressed by integrating metacognitive support strategies into GenAI systems, and by designing GenAI systems to reduce their metacognitive demand by targeting explainability and customizability. Metacognition offers a coherent framework for understanding the usability challenges posed by GenAI, and provides novel research and design directions to advance human-AI interaction.\n",
      "\n",
      "Completed Generative, AI, metacognition, usability, prompting, evaluation, workflows, explainability, customizability, user studies abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Prompt learning has emerged as an efficient alternative for fine-tuning foundational models, such as CLIP, for various downstream tasks. However, there is no work that provides a comprehensive explanation for the working mechanism of the multi-modal prompts. In this paper, we conduct a direct analysis of the multi-modal prompts by asking the following questions: $(i)$ How do the learned multi-modal prompts improve the recognition performance? $(ii)$ What do the multi-modal prompts learn? To answer these questions, we begin by isolating the component of the formula where the prompt influences the calculation of self-attention at each layer in two distinct ways, \\ie, $(1)$ introducing prompt embeddings makes the $[cls]$ token focus on foreground objects. $(2)$ the prompts learn a bias term during the update of token embeddings, allowing the model to adapt to the target domain. Subsequently, we conduct extensive visualization and statistical experiments on the eleven diverse downstream recognition datasets. From the experiments, we reveal that the learned prompts improve the performance mainly through the second way, which acts as the dataset bias to improve the recognition performance of the pre-trained model on the corresponding dataset. Meanwhile, we propose the bias tuning way to validate our finding. With a deeper understanding of the multi-modal prompt, we hope our work can inspire new and solid research in this direction.\n",
      "\n",
      "Completed prompt, learning, fine-tuning, multi-modal, recognition, self-attention, bias, visualization, dataset, tuning abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Synthesis of same-identity biometric iris images, both for existing and non-existing identities while preserving the identity across a wide range of pupil sizes, is complex due to intricate iris muscle constriction mechanism, requiring a precise model of iris non-linear texture deformations to be embedded into the synthesis pipeline. This paper presents the first method of fully data-driven, identity-preserving, pupil size-varying s ynthesis of iris images. This approach is capable of synthesizing images of irises with different pupil sizes representing non-existing identities as well as non-linearly deforming the texture of iris images of existing subjects given the segmentation mask of the target iris image. Iris recognition experiments suggest that the proposed deformation model not only preserves the identity when changing the pupil size but offers better similarity between same-identity iris samples with significant differences in pupil size, compared to state-of-the-art linear and non-linear (bio-mechanical-based) iris deformation models. Two immediate applications of the proposed approach are: (a) synthesis of, or enhancement of the existing biometric datasets for iris recognition, mimicking those acquired with iris sensors, and (b) helping forensic human experts in examining iris image pairs with significant differences in pupil dilation. Source codes and weights of the models are made available with the paper.\n",
      "\n",
      "Completed biometric, iris, synthesis, data-driven, identity-preserving, pupil, deformation, non-linear, recognition, forensic abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Alternating-time temporal logic (ATL$^*$) is a well-established framework for formal reasoning about multi-agent systems. However, while ATL$^*$ can reason about the strategic ability of agents (e.g., some coalition $A$ can ensure that a goal is reached eventually), we cannot compare multiple strategic interactions, nor can we require multiple agents to follow the same strategy. For example, we cannot state that coalition $A$ can reach a goal sooner (or more often) than some other coalition $A'$. In this paper, we propose HyperATLS$^*_S$, an extension of ATL$^*$ in which we can (1) compare the outcome of multiple strategic interactions w.r.t. a hyperproperty, i.e., a property that refers to multiple paths at the same time, and (2) enforce that some agents share the same strategy. We show that HyperATL$^*_S$ is a rich specification language that captures important AI-related properties that were out of reach of existing logics. We prove that model checking of HyperATL$^*_S$ on concurrent game structures is decidable. We implement our model-checking algorithm in a tool we call HyMASMC and evaluate it on a range of benchmarks.\n",
      "\n",
      "Completed ATL, HyperATLS, Multi-agent, Strategy, Hyperproperty, Comparability, Decidability, Model Checking, Concurrent Game Structures, HyMASMC abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Docker, a widely adopted tool for packaging and deploying applications leverages Dockerfiles to build images. However, creating an optimal Dockerfile can be challenging, often leading to \"Docker smells\" or deviations from best practices. This paper presents a study of the impact of 14 Docker smells on the size of Docker images.\n",
      "  To assess the size impact of Docker smells, we identified and repaired 16 145 Docker smells from 11 313 open-source Dockerfiles. We observe that the smells result in an average increase of 48.06 MB (4.6%) per smelly image. Depending on the smell type, the size increase can be up to 10%, and for some specific cases, the smells can represent 89% of the image size. Interestingly, the most impactful smells are related to package managers which are commonly encountered and are relatively easy to fix.\n",
      "  To collect the perspective of the developers regarding the size impact of the Docker smells, we submitted 34 pull requests that repair the smells and we reported their impact on the Docker image to the developers. 26/34 (76.5%) of the pull requests have been merged and they contribute to a saving of 3.46 GB (16.4%). The developer's comments demonstrate a positive interest in addressing those Docker smells even when the pull requests have been rejected\n",
      "\n",
      "Completed Docker, Dockerfiles, Docker smells, Image size, Size impact, Package managers, Pull requests, Developer feedback, Merged pull requests, Image savings abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Community detection is the problem of identifying natural divisions in networks. Efficient parallel algorithms for identifying such divisions is critical in a number of applications, where the size of datasets have reached significant scales. This technical report presents an optimized parallel implementation of Leiden, a high quality community detection method, for shared memory multicore systems. On a server equipped with dual 16-core Intel Xeon Gold 6226R processors, our Leiden implementation, which we term as GVE-Leiden, outperforms the original Leiden, igraph Leiden, and NetworKit Leiden by 436x, 104x, and 8.2x respectively - achieving a processing rate of 403 M edges/s on a 3.8 B edge graph. Compared to GVE-Louvain, our parallel Louvain implementation, GVE-Leiden achieves a total elimination of disconnected communities, with only a 13% increase in runtime. In addition, GVE-Leiden improves performance at an average rate of 1.6x for every doubling of threads.\n",
      "\n",
      "Completed Community, detection, Leiden, parallelization, multicore, high quality, GVE-Leiden, Louvain, outperform, elimination abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, we present a comprehensive evaluation to establish a robust and efficient framework for Lagrangian-based particle tracing using deep neural networks (DNNs). Han et al. (2021) first proposed a DNN-based approach to learn Lagrangian representations and demonstrated accurate particle tracing for an analytic 2D flow field. In this paper, we extend and build upon this prior work in significant ways. First, we evaluate the performance of DNN models to accurately trace particles in various settings, including 2D and 3D time-varying flow fields, flow fields from multiple applications, flow fields with varying complexity, as well as structured and unstructured input data. Second, we conduct an empirical study to inform best practices with respect to particle tracing model architectures, activation functions, and training data structures. Third, we conduct a comparative evaluation of prior techniques that employ flow maps as input for exploratory flow visualization. Specifically, we compare our extended model against its predecessor by Han et al. (2021), as well as the conventional approach that uses triangulation and Barycentric coordinate interpolation. Finally, we consider the integration and adaptation of our particle tracing model with different viewers. We provide an interactive web-based visualization interface by leveraging the efficiencies of our framework, and perform high-fidelity interactive visualization by integrating it with an OSPRay-based viewer. Overall, our experiments demonstrate that using a trained DNN model to predict new particle trajectories requires a low memory footprint and results in rapid inference. Following best practices for large 3D datasets, our deep learning approach using GPUs for inference is shown to require approximately 46 times less memory while being more than 400 times faster than the conventional methods.\n",
      "\n",
      "Completed Deep, Neural, Networks, Lagrangian, Particle, Tracing, Visualization, Triangulation, Barycentric, OSPRay abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Technical debt is a pervasive issue in software development, often arising from trade-offs made during development, which can impede software maintainability and hinder future development efforts. Self-admitted technical debt (SATD) refers to instances where developers explicitly acknowledge suboptimal code quality or design flaws in the codebase. Automated detection of SATD has emerged as a critical area of research, aiming to assist developers in identifying and addressing technical debt efficiently. However, the enormous variety of feature extraction approaches of NLP and algorithms employed in the literature often hinder researchers from trying to improve their performance. In light of this, this systematic literature review proposes a taxonomy of feature extraction techniques and ML/DL algorithms used in technical debt detection: its objective is to compare and benchmark their performance in the examined studies. We selected 53 articles that passed the quality evaluation of the systematic review. We then investigated in depth which feature extractions and algorithms were employed to identify technical debt in each software development activity. All approaches proposed in the analyzed studies were grouped into NLP, NLP+ML, and NLP+DL. This allows us to discuss the performance in three different ways. Overall, NLP+DL group consistently outperforms in precision and F1-score for all projects, and in all but one project for the recall metric. Regarding the feature extraction techniques, the PTE consistently achieves higher precision, recall, and F1-score for each project analyzed. Furthermore, TD types have been mappep to software development activities; this served to determine the best-performing feature extractions and algorithms for each development activity. Finally, based on the review results, we also identify implications that could be of concern to researchers and practitioners.\n",
      "\n",
      "Completed technical, debt, self-admitted, automated, detection, feature, extraction, machine, learning, NLP abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The prevalent use of commercial and open-source diffusion models (DMs) for text-to-image generation prompts risk mitigation to prevent undesired behaviors. Existing concept erasing methods in academia are all based on full parameter or specification-based fine-tuning, from which we observe the following issues: 1) Generation alternation towards erosion: Parameter drift during target elimination causes alternations and potential deformations across all generations, even eroding other concepts at varying degrees, which is more evident with multi-concept erased; 2) Transfer inability & deployment inefficiency: Previous model-specific erasure impedes the flexible combination of concepts and the training-free transfer towards other models, resulting in linear cost growth as the deployment scenarios increase. To achieve non-invasive, precise, customizable, and transferable elimination, we ground our erasing framework on one-dimensional adapters to erase multiple concepts from most DMs at once across versatile erasing applications. The concept-SemiPermeable structure is injected as a Membrane (SPM) into any DM to learn targeted erasing, and meantime the alteration and erosion phenomenon is effectively mitigated via a novel Latent Anchoring fine-tuning strategy. Once obtained, SPMs can be flexibly combined and plug-and-play for other DMs without specific re-tuning, enabling timely and efficient adaptation to diverse scenarios. During generation, our Facilitated Transport mechanism dynamically regulates the permeability of each SPM to respond to different input prompts, further minimizing the impact on other concepts. Quantitative and qualitative results across ~40 concepts, 7 DMs and 4 erasing applications have demonstrated the superior erasing of SPM. Our code and pre-tuned SPMs are available on the project page https://lyumengyao.github.io/projects/spm.\n",
      "\n",
      "Completed diffusion, models, text, image, generation, concept, erasing, transfer, adaptation, flexible abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Bayesian optimization is a principled optimization strategy for a black-box objective function. It shows its effectiveness in a wide variety of real-world applications such as scientific discovery and experimental design. In general, the performance of Bayesian optimization is reported through regret-based metrics such as instantaneous, simple, and cumulative regrets. These metrics only rely on function evaluations, so that they do not consider geometric relationships between query points and global solutions, or query points themselves. Notably, they cannot discriminate if multiple global solutions are successfully found. Moreover, they do not evaluate Bayesian optimization's abilities to exploit and explore a search space given. To tackle these issues, we propose four new geometric metrics, i.e., precision, recall, average degree, and average distance. These metrics allow us to compare Bayesian optimization algorithms considering the geometry of both query points and global optima, or query points. However, they are accompanied by an extra parameter, which needs to be carefully determined. We therefore devise the parameter-free forms of the respective metrics by integrating out the additional parameter. Finally, we empirically validate that our proposed metrics can provide more delicate interpretation of Bayesian optimization algorithms, on top of assessment via the conventional metrics.\n",
      "\n",
      "Completed Bayesian, optimization, metrics, precision, recall, average, degree, distance, search, space abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Utilizing massive web-scale datasets has led to unprecedented performance gains in machine learning models, but also imposes outlandish compute requirements for their training. In order to improve training and data efficiency, we here push the limits of pruning large-scale multimodal datasets for training CLIP-style models. Today's most effective pruning method on ImageNet clusters data samples into separate concepts according to their embedding and prunes away the most prototypical samples. We scale this approach to LAION and improve it by noting that the pruning rate should be concept-specific and adapted to the complexity of the concept. Using a simple and intuitive complexity measure, we are able to reduce the training cost to a quarter of regular training. By filtering from the LAION dataset, we find that training on a smaller set of high-quality data can lead to higher performance with significantly lower training costs. More specifically, we are able to outperform the LAION-trained OpenCLIP-ViT-B32 model on ImageNet zero-shot accuracy by 1.1p.p. while only using 27.7% of the data and training compute. Despite a strong reduction in training cost, we also see improvements on ImageNet dist. shifts, retrieval tasks and VTAB. On the DataComp Medium benchmark, we achieve a new state-of-the-art Imagehttps://info.arxiv.org/help/prep#commentsNet zero-shot accuracy and a competitive average zero-shot accuracy on 38 evaluation tasks.\n",
      "\n",
      "Completed CLIP, pruning, multimodal, LAION, ImageNet, complexity, training cost, data efficiency, performance, state-of-the-art abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Machine unlearning has become a pivotal task to erase the influence of data from a trained model. It adheres to recent data regulation standards and enhances the privacy and security of machine learning applications. In this work, we present a new machine unlearning approach Scissorhands. Initially, Scissorhands identifies the most pertinent parameters in the given model relative to the forgetting data via connection sensitivity. By reinitializing the most influential top-k percent of these parameters, a trimmed model for erasing the influence of the forgetting data is obtained. Subsequently, Scissorhands fine-tunes the trimmed model with a gradient projection-based approach, seeking parameters that preserve information on the remaining data while discarding information related to the forgetting data. Our experimental results, conducted across image classification and image generation tasks, demonstrate that Scissorhands, showcases competitive performance when compared to existing methods.\n",
      "\n",
      "Completed machine, unlearning, data regulation, privacy, security, Scissorhands, connection sensitivity, trimmed model, gradient projection, competitive performance abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Few-shot object detection (FSOD) aims at extending a generic detector for novel object detection with only a few training examples. It attracts great concerns recently due to the practical meanings. Meta-learning has been demonstrated to be an effective paradigm for this task. In general, methods based on meta-learning employ an additional support branch to encode novel examples (a.k.a. support images) into class prototypes, which are then fused with query branch to facilitate the model prediction. However, the class-level prototypes are difficult to precisely generate, and they also lack detailed information, leading to instability in performance.New methods are required to capture the distinctive local context for more robust novel object detection. To this end, we propose to distill the most representative support features into fine-grained prototypes. These prototypes are then assigned into query feature maps based on the matching results, modeling the detailed feature relations between two branches. This process is realized by our Fine-Grained Feature Aggregation (FFA) module. Moreover, in terms of high-level feature fusion, we propose Balanced Class-Agnostic Sampling (B-CAS) strategy and Non-Linear Fusion (NLF) module from differenct perspectives. They are complementary to each other and depict the high-level feature relations more effectively. Extensive experiments on PASCAL VOC and MS COCO benchmarks show that our method sets a new state-of-the-art performance in most settings. Our code is available at https://github.com/wangchen1801/FPD.\n",
      "\n",
      "Completed object, detection, meta-learning, prototypes, feature, aggregation, fusion, representation, sampling, optimization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Accurate estimation of the state of charge (SOC) and state of health (SOH) is crucial for the safe and reliable operation of batteries. Voltage measurement bias highly affects state estimation accuracy, especially in Lithium Iron Phosphate (LFP) batteries, which are susceptible due to their flat open-circuit voltage (OCV) curves. This work introduces a bias-compensated algorithm to reliably estimate the SOC and SOH of LFP batteries under the influence of voltage measurement bias. Specifically, SOC and SOH are estimated using the Dual Extended Kalman Filter (DEKF) in the high-slope SOC range, where voltage measurement bias effects are weak. Besides, the voltage measurement biases estimated in the low-slope SOC regions are compensated in the following joint estimation of SOC and SOH to enhance the state estimation accuracy further. Experimental results indicate that the proposed algorithm significantly outperforms the traditional method, which does not consider biases under different temperatures and aging conditions. Additionally, the bias-compensated algorithm can achieve low estimation errors of below 1.5% for SOC and 2% for SOH, even with a 30mV voltage measurement bias. Finally, even if the voltage measurement biases change in operation, the proposed algorithm can remain robust and keep the estimated errors of states around 2%.\n",
      "\n",
      "Completed Voltage, Measurement, Bias, State, Charge, Health, Lithium, Iron, Phosphate, Estimation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Cascading bandits have gained popularity in recent years due to their applicability to recommendation systems and online advertising. In the cascading bandit model, at each timestep, an agent recommends an ordered subset of items (called an item list) from a pool of items, each associated with an unknown attraction probability. Then, the user examines the list, and clicks the first attractive item (if any), and after that, the agent receives a reward. The goal of the agent is to maximize the expected cumulative reward. However, the prior literature on cascading bandits ignores the influences of user states (e.g., historical behaviors) on recommendations and the change of states as the session proceeds. Motivated by this fact, we propose a generalized cascading RL framework, which considers the impact of user states and state transition into decisions. In cascading RL, we need to select items not only with large attraction probabilities but also leading to good successor states. This imposes a huge computational challenge due to the combinatorial action space. To tackle this challenge, we delve into the properties of value functions, and design an oracle BestPerm to efficiently find the optimal item list. Equipped with BestPerm, we develop two algorithms CascadingVI and CascadingBPI, which are both computationally-efficient and sample-efficient, and provide near-optimal regret and sample complexity guarantees. Furthermore, we present experiments to show the improved computational and sample efficiencies of our algorithms compared to straightforward adaptations of existing RL algorithms in practice.\n",
      "\n",
      "Completed Cascading, bandits, recommendations, user states, state transition, value functions, BestPerm, CascadingVI, CascadingBPI, regret abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Ensuring stability of discrete-time (DT) linear parameter-varying (LPV) input-output (IO) models estimated via system identification methods is a challenging problem as known stability constraints can only be numerically verified, e.g., through solving Linear Matrix Inequalities. In this paper, an unconstrained DT-LPV-IO parameterization is developed which gives a stable model for any choice of model parameters. To achieve this, it is shown that all quadratically stable DT-LPV-IO models can be generated by a mapping of transformed coefficient functions that are constrained to the unit ball, i.e., a small-gain condition. The unit ball is then reparameterized through a Cayley transformation, resulting in an unconstrained parameterization of all quadratically stable DT-LPV-IO models. As a special case, an unconstrained parameterization of all stable DT linear time-invariant transfer functions is obtained. Identification using the stable DT-LPV-IO model with neural network coefficient functions is demonstrated on a simulation example of a position-varying mass-damper-spring system.\n",
      "\n",
      "Completed stable, discrete-time, linear parameter-varying, input-output, model, unit ball, Cayley transformation, system identification, neural network, mass-damper-spring system abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The generalization of decision-making agents encompasses two fundamental elements: learning from past experiences and reasoning in novel contexts. However, the predominant emphasis in most interactive environments is on learning, often at the expense of complexity in reasoning. In this paper, we introduce CivRealm, an environment inspired by the Civilization game. Civilization's profound alignment with human history and society necessitates sophisticated learning, while its ever-changing situations demand strong reasoning to generalize. Particularly, CivRealm sets up an imperfect-information general-sum game with a changing number of players; it presents a plethora of complex features, challenging the agent to deal with open-ended stochastic environments that require diplomacy and negotiation skills. Within CivRealm, we provide interfaces for two typical agent types: tensor-based agents that focus on learning, and language-based agents that emphasize reasoning. To catalyze further research, we present initial results for both paradigms. The canonical RL-based agents exhibit reasonable performance in mini-games, whereas both RL- and LLM-based agents struggle to make substantial progress in the full game. Overall, CivRealm stands as a unique learning and reasoning challenge for decision-making agents. The code is available at https://github.com/bigai-ai/civrealm.\n",
      "\n",
      "Completed CivRealm, Civilization, reasoning, learning, decision-making, language-based, negotiation, diplomacy, imperfect-information, general-sum abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Some reinforcement learning (RL) algorithms can stitch pieces of experience to solve a task never seen before during training. This oft-sought property is one of the few ways in which RL methods based on dynamic-programming differ from RL methods based on supervised-learning (SL). Yet, certain RL methods based on off-the-shelf SL algorithms achieve excellent results without an explicit mechanism for stitching; it remains unclear whether those methods forgo this important stitching property. This paper studies this question for the problems of achieving a target goal state and achieving a target return value. Our main result is to show that the stitching property corresponds to a form of combinatorial generalization: after training on a distribution of (state, goal) pairs, one would like to evaluate on (state, goal) pairs not seen together in the training data. Our analysis shows that this sort of generalization is different from i.i.d. generalization. This connection between stitching and generalisation reveals why we should not expect SL-based RL methods to perform stitching, even in the limit of large datasets and models. Based on this analysis, we construct new datasets to explicitly test for this property, revealing that SL-based methods lack this stitching property and hence fail to perform combinatorial generalization. Nonetheless, the connection between stitching and combinatorial generalisation also suggests a simple remedy for improving generalisation in SL: data augmentation. We propose a temporal data augmentation and demonstrate that adding it to SL-based methods enables them to successfully complete tasks not seen together during training. On a high level, this connection illustrates the importance of combinatorial generalization for data efficiency in time-series data beyond tasks beyond RL, like audio, video, or text.\n",
      "\n",
      "Completed reinforcement learning, stitching, supervised learning, combinatorial generalization, i.i.d. generalization, data augmentation, temporal data augmentation, data efficiency, time-series data, audio abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Language models, especially pre-trained large language models, have showcased remarkable abilities as few-shot in-context learners (ICL), adept at adapting to new tasks with just a few demonstrations in the input context. However, the model's ability to perform ICL is sensitive to the choice of the few-shot demonstrations. Instead of using a fixed set of demonstrations, one recent development is to retrieve demonstrations tailored to each input query. The implementation of demonstration retrieval is relatively straightforward, leveraging existing databases and retrieval systems. This not only improves the efficiency and scalability of the learning process but also has been shown to reduce biases inherent in manual example selection. In light of the encouraging results and growing research in ICL with retrieved demonstrations, we conduct an extensive review of studies in this area. In this survey, we discuss and compare different design choices for retrieval models, retrieval training procedures, and inference algorithms.\n",
      "\n",
      "Completed language, models, few-shot, in-context, learning, demonstrations, retrieval, databases, systems, review abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Symbols (or more broadly, non-natural language textual representations) such as numerical sequences, molecular formulas, and table delimiters widely exist, playing important roles in various tasks such as abstract reasoning, chemical property prediction, and table question answering. Despite the impressive natural language comprehension capabilities of large language models (LLMs), their reasoning abilities for symbols remain inadequate, which could attributed to the difference between symbol representations and general natural languages. We propose symbol-to-language (S2L), a tuning-free method that enables large language models to solve symbol-related problems with information expressed in natural language. Specifically, S2L first converts the symbols involved to language-based representations, which can be implemented by prompting LLMs or leveraging external tools, then these language-based representations are integrated into the original problem via direct substitution or concatenation, serving as useful input information for LLMs. We evaluate the S2L method using both API-based (GPT-4, ChatGPT) and open-source (OpenChat) models over eight symbol-related tasks, ranging from symbol-only abstract reasoning to sentiment analysis in social media. Experimental results show that S2L consistently leads to superior performance. For example, by employing S2L for GPT-4, there can be average significant improvements of +21.9% and +9.5% for subtasks in 1D-ARC and Dyck language, respectively. Codes and data are available at https://github.com/THUNLP-MT/symbol2language.\n",
      "\n",
      "Completed Symbols, language, reasoning, prediction, questioning, LLMs, S2L, conversion, concatenation, substitution abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This chapter focuses on gender-related errors in machine translation (MT) in the context of low-resource languages. We begin by explaining what low-resource languages are, examining the inseparable social and computational factors that create such linguistic hierarchies. We demonstrate through a case study of our mother tongue Bengali, a global language spoken by almost 300 million people but still classified as low-resource, how gender is assumed and inferred in translations to and from the high(est)-resource English when no such information is provided in source texts. We discuss the postcolonial and societal impacts of such errors leading to linguistic erasure and representational harms, and conclude by discussing potential solutions towards uplifting languages by providing them more agency in MT conversations.\n",
      "\n",
      "Completed machine translation, low-resource languages, gender errors, linguistic erasure, representational harm, social factors, computational factors, Bengali, postcolonialism, agency abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Traditional convolutional neural networks have a limited receptive field while transformer-based networks are mediocre in constructing long-term dependency from the perspective of computational complexity. Such the bottleneck poses a significant challenge when processing long sequences in video analysis tasks. Very recently, the state space models (SSMs) with efficient hardware-aware designs, famous by Mamba, have exhibited impressive achievements in long sequence modeling, which facilitates the development of deep neural networks on many vision tasks. To better capture available dynamic cues in video frames, this paper presents a generic Video Vision Mamba-based framework, dubbed as \\textbf{Vivim}, for medical video object segmentation tasks. Our Vivim can effectively compress the long-term spatiotemporal representation into sequences at varying scales by our designed Temporal Mamba Block. We also introduce a boundary-aware constraint to enhance the discriminative ability of Vivim on ambiguous lesions in medical images. Extensive experiments on thyroid segmentation in ultrasound videos and polyp segmentation in colonoscopy videos demonstrate the effectiveness and efficiency of our Vivim, superior to existing methods. The code is available at: https://github.com/scott-yjyang/Vivim.\n",
      "\n",
      "Completed Video, Vision, Mamba, Segmentation, Spatiotemporal, Transformer, Dependency, Sequence, Thyroid, Polyp abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The advances of deep learning (DL) have paved the way for automatic software vulnerability repair approaches, which effectively learn the mapping from the vulnerable code to the fixed code. Nevertheless, existing DL-based vulnerability repair methods face notable limitations: 1) they struggle to handle lengthy vulnerable code, 2) they treat code as natural language texts, neglecting its inherent structure, and 3) they do not tap into the valuable expert knowledge present in the expert system.\n",
      "  To address this, we propose VulMaster, a Transformer-based neural network model that excels at generating vulnerability repairs through data-centric innovation. Specifically, VulMaster introduces the utilization and combination of various types of input data, including complete vulnerable code of any size, vulnerable code structures, and expert knowledge from the CWE system. Additionally, VulMaster leverages the collaboration between two Large Language Models (LLMs), CodeT5 and ChatGPT: CodeT5 acts as the customizable backbone LLM, fine-tuned with the training data, while ChatGPT supplements by providing missing relevant inputs to CodeT5. We evaluated VulMaster on a real-world C/C++ vulnerability repair dataset comprising 1,754 projects with 5,800 vulnerable functions. The experimental results demonstrated that VulMaster exhibits substantial improvements compared to the learning-based state-of-the-art vulnerability repair approach. Specifically, VulMaster improves the EM, BLEU, and CodeBLEU scores from 10.2\\% to 20.0\\%, 21.3\\% to 29.3\\%, and 32.5\\% to 40.9\\%, respectively.\n",
      "\n",
      "Completed Vulnerability, Repair, Deep Learning, Transformer, VulMaster, Data-centric, Expert Knowledge, Large Language Models, CodeT5, ChatGPT abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recent decisions to discontinue access to social media APIs are having detrimental effects on Internet research and the field of computational social science as a whole. This lack of access to data has been dubbed the Post-API era of Internet research. Fortunately, popular search engines have the means to crawl, capture, and surface social media data on their Search Engine Results Pages (SERP) if provided the proper search query, and may provide a solution to this dilemma. In the present work we ask: does SERP provide a complete and unbiased sample of social media data? Is SERP a viable alternative to direct API-access? To answer these questions, we perform a comparative analysis between (Google) SERP results and nonsampled data from Reddit and Twitter/X. We find that SERP results are highly biased in favor of popular posts; against political, pornographic, and vulgar posts; are more positive in their sentiment; and have large topical gaps. Overall, we conclude that SERP is not a viable alternative to social media API access.\n",
      "\n",
      "Completed Internet, research, social media, API, search engines, SERP, data, bias, Reddit, Twitter abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Good arm identification (GAI) is a pure-exploration bandit problem in which a single learner outputs an arm as soon as it is identified as a good arm. A good arm is defined as an arm with an expected reward greater than or equal to a given threshold. This paper focuses on the GAI problem under a small threshold gap, which refers to the distance between the expected rewards of arms and the given threshold. We propose a new algorithm called lil'HDoC to significantly improve the total sample complexity of the HDoC algorithm. We demonstrate that the sample complexity of the first $\\lambda$ output arm in lil'HDoC is bounded by the original HDoC algorithm, except for one negligible term, when the distance between the expected reward and threshold is small. Extensive experiments confirm that our algorithm outperforms the state-of-the-art algorithms in both synthetic and real-world datasets.\n",
      "\n",
      "Completed bandit, exploration, good-arm, identification, HDoC, lil'HDoC, pure-exploration, sample-complexity, small-threshold-gap, reward abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Chromogenic RNAscope dye and haematoxylin staining of cancer tissue facilitates diagnosis of the cancer type and subsequent treatment, and fits well into existing pathology workflows. However, manual quantification of the RNAscope transcripts (dots), which signify gene expression, is prohibitively time consuming. In addition, there is a lack of verified supporting methods for quantification and analysis. This paper investigates the usefulness of grey level texture features for automatically segmenting and classifying the positions of RNAscope transcripts from breast cancer tissue. Feature analysis showed that a small set of grey level features, including Grey Level Dependence Matrix and Neighbouring Grey Tone Difference Matrix features, were well suited for the task. The automated method performed similarly to expert annotators at identifying the positions of RNAscope transcripts, with an F1-score of 0.571 compared to the expert inter-rater F1-score of 0.596. These results demonstrate the potential of grey level texture features for automated quantification of RNAscope in the pathology workflow.\n",
      "\n",
      "Completed RNAscope, cancer, diagnosis, transcript, segmentation, classification, grey level texture features, automation, pathologist, workflow abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Artificial intelligence (AI) in healthcare has significantly advanced intelligent medical treatment. However, traditional intelligent healthcare is limited by static data and unified standards, preventing full integration with individual situations and other challenges. Hence, a more professional and detailed intelligent healthcare method is needed for development. To this end, we propose an innovative framework named Heath-LLM, which combines large-scale feature extraction and medical knowledge trade-off scoring. Compared to traditional health management methods, our system has three main advantages. First, our system integrates health reports into a large model to provide detailed task information. Second, professional medical expertise is used to adjust the weighted scores of health characteristics. Third, we use a semi-automated feature extraction framework to enhance the analytical power of language models and incorporate expert insights to improve the accuracy of disease prediction. We have conducted disease prediction experiments on a large number of health reports to assess the effectiveness of Health-LLM. The results of the experiments indicate that the proposed system surpasses traditional methods and has the potential to revolutionize disease prediction and personalized health management. The code is available at https://github.com/jmyissb/HealthLLM.\n",
      "\n",
      "Completed Artificial, Intelligence, Healthcare, Health, LLM, Large-scale, Knowledge, Prediction, Personalized, Management abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper introduces AutoGCN, a generic Neural Architecture Search (NAS) algorithm for Human Activity Recognition (HAR) using Graph Convolution Networks (GCNs). HAR has gained attention due to advances in deep learning, increased data availability, and enhanced computational capabilities. At the same time, GCNs have shown promising results in modeling relationships between body key points in a skeletal graph. While domain experts often craft dataset-specific GCN-based methods, their applicability beyond this specific context is severely limited. AutoGCN seeks to address this limitation by simultaneously searching for the ideal hyperparameters and architecture combination within a versatile search space using a reinforcement controller while balancing optimal exploration and exploitation behavior with a knowledge reservoir during the search process. We conduct extensive experiments on two large-scale datasets focused on skeleton-based action recognition to assess the proposed algorithm's performance. Our experimental results underscore the effectiveness of AutoGCN in constructing optimal GCN architectures for HAR, outperforming conventional NAS and GCN methods, as well as random search. These findings highlight the significance of a diverse search space and an expressive input representation to enhance the network performance and generalizability.\n",
      "\n",
      "Completed AutoGCN, NAS, HAR, GCNs, Architecture Search, Reinforcement Learning, Knowledge Reservoir, Skeleton-Based Action Recognition, Optimization, Generalizability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In MRI studies, the aggregation of imaging data from multiple acquisition sites enhances sample size but may introduce site-related variabilities that hinder consistency in subsequent analyses. Deep learning methods for image translation have emerged as a solution for harmonizing MR images across sites. In this study, we introduce IGUANe (Image Generation with Unified Adversarial Networks), an original 3D model that leverages the strengths of domain translation and straightforward application of style transfer methods for multicenter brain MR image harmonization. IGUANe extends CycleGAN architecture by integrating an arbitrary number of domains for training through a many-to-one strategy. During inference, the model can be applied to any image, even from an unknown acquisition site, making it a universal generator for harmonization. Trained on a dataset comprising T1-weighted images from 11 different scanners, IGUANe was evaluated on data from unseen sites. The assessments included the transformation of MR images with traveling subjects, the preservation of pairwise distances between MR images within domains, the evolution of volumetric patterns related to age and Alzheimer$^\\prime$s disease (AD), and the performance in age regression and patient classification tasks. Comparisons with other harmonization and normalization methods suggest that IGUANe better preserves individual information in MR images and is more suitable for maintaining and reinforcing variabilities related to age and AD. Future studies may further assess IGUANe in other multicenter contexts, either using the same model or retraining it for applications to different image modalities.\n",
      "\n",
      "Completed IGUANE, MRI, multicenter, harmonization, image translation, domain translation, style transfer, age regression, patient classification, Alzheimer's disease abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Multi-view 3D object detection systems often struggle with generating precise predictions due to the challenges in estimating depth from images, increasing redundant and incorrect detections. Our paper presents Ray Denoising, an innovative method that enhances detection accuracy by strategically sampling along camera rays to construct hard negative examples. These examples, visually challenging to differentiate from true positives, compel the model to learn depth-aware features, thereby improving its capacity to distinguish between true and false positives. Ray Denoising is designed as a plug-and-play module, compatible with any DETR-style multi-view 3D detectors, and it only minimally increases training computational costs without affecting inference speed. Our comprehensive experiments, including detailed ablation studies, consistently demonstrate that Ray Denoising outperforms strong baselines across multiple datasets. It achieves a 1.9\\% improvement in mean Average Precision (mAP) over the state-of-the-art StreamPETR method on the NuScenes dataset. It shows significant performance gains on the Argoverse 2 dataset, highlighting its generalization capability. The code will be available at https://github.com/LiewFeng/RayDN.\n",
      "\n",
      "Completed Ray, Denoising, Depth, Detection, DETR, Sampling, Camera, Features, Negatives, mAP abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Foundation models, such as Large language Models (LLMs), have attracted significant amount of interest due to their large number of applications. Existing works show that appropriate prompt design, such as Chain-of-Thoughts, can unlock LLM's powerful capacity in diverse areas. However, when handling tasks involving repetitive sub-tasks and/or deceptive contents, such as arithmetic calculation and article-level fake news detection, existing prompting strategies either suffers from insufficient expressive power or intermediate errors triggered by hallucination. To make LLM more discerning to such intermediate errors, we propose to guide LLM with a Divide-and-Conquer program that simultaneously ensures superior expressive power and disentangles task decomposition, sub-task resolution, and resolution assembly process. Theoretic analysis reveals that our strategy can guide LLM to extend the expressive power of fixed-depth Transformer. Experiments indicate that our proposed method can achieve better performance than typical prompting strategies in tasks bothered by intermediate errors and deceptive contents, such as large integer multiplication, hallucination detection and misinformation detection.\n",
      "\n",
      "Completed Foundation, models, expressive, power, disentangled, decomposition, resolution, assembly, intermediate, errors abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In the absence of labeled target data, unsupervised domain adaptation approaches seek to align the marginal distributions of the source and target domains in order to train a classifier for the target. Unsupervised domain alignment procedures are category-agnostic and end up misaligning the categories. We address this problem by deploying a pretrained network to determine accurate labels for the target domain using a multi-stage pseudo-label refinement procedure. The filters are based on the confidence, distance (conformity), and consistency of the pseudo labels. Our results on multiple datasets demonstrate the effectiveness of our simple procedure in comparison with complex state-of-the-art techniques.\n",
      "\n",
      "Completed unsupervised, domain adaptation, target data, marginal distributions, category-agnostic, pseudo labels, multi-stage, confidence, distance, consistency abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Given a node-attributed graph, and a graph task (link prediction or node classification), can we tell if a graph neural network (GNN) will perform well? More specifically, do the graph structure and the node features carry enough usable information for the task? Our goals are (1) to develop a fast tool to measure how much information is in the graph structure and in the node features, and (2) to exploit the information to solve the task, if there is enough. We propose NetInfoF, a framework including NetInfoF_Probe and NetInfoF_Act, for the measurement and the exploitation of network usable information (NUI), respectively. Given a graph data, NetInfoF_Probe measures NUI without any model training, and NetInfoF_Act solves link prediction and node classification, while two modules share the same backbone. In summary, NetInfoF has following notable advantages: (a) General, handling both link prediction and node classification; (b) Principled, with theoretical guarantee and closed-form solution; (c) Effective, thanks to the proposed adjustment to node similarity; (d) Scalable, scaling linearly with the input size. In our carefully designed synthetic datasets, NetInfoF correctly identifies the ground truth of NUI and is the only method being robust to all graph scenarios. Applied on real-world datasets, NetInfoF wins in 11 out of 12 times on link prediction compared to general GNN baselines.\n",
      "\n",
      "Completed graph, structure, features, GNN, NUI, NetInfoF, NetInfoF_Probe, NetInfoF_Act, theoretical, synthetic abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "How can individuals exchange information to learn from each other despite their privacy needs and security concerns? For example, consider individuals deliberating a contentious topic and being concerned about divulging their private experiences. Preserving individual privacy and enabling efficient social learning are both important desiderata but seem fundamentally at odds with each other and very hard to reconcile. We do so by controlling information leakage using rigorous statistical guarantees that are based on differential privacy (DP). Our agents use log-linear rules to update their beliefs after communicating with their neighbors. Adding DP randomization noise to beliefs provides communicating agents with plausible deniability with regard to their private information and their network neighborhoods. We consider two learning environments one for distributed maximum-likelihood estimation given a finite number of private signals and another for online learning from an infinite, intermittent signal stream. Noisy information aggregation in the finite case leads to interesting tradeoffs between rejecting low-quality states and making sure all high-quality states are accepted in the algorithm output. Our results flesh out the nature of the trade-offs in both cases between the quality of the group decision outcomes, learning accuracy, communication cost, and the level of privacy protections that the agents are afforded.\n",
      "\n",
      "Completed differential, privacy, social, learning, information, quality, trade-offs, accuracy, communication, agents abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The increasing variety and quantity of tagged multimedia content on platforms such as TikTok provides an opportunity to advance computer vision modeling. We have curated a distinctive dataset of 283,582 unique video clips categorized under 386 hashtags relating to modern human actions. We release this dataset as a valuable resource for building domain-specific foundation models for human movement modeling tasks such as action recognition. To validate this dataset, which we name TikTokActions, we perform two sets of experiments. First, we pretrain the state-of-the-art VideoMAEv2 with a ViT-base backbone on TikTokActions subset, and then fine-tune and evaluate on popular datasets such as UCF101 and the HMDB51. We find that the performance of the model pre-trained using our Tik-Tok dataset is comparable to models trained on larger action recognition datasets (95.3% on UCF101 and 53.24% on HMDB51). Furthermore, our investigation into the relationship between pre-training dataset size and fine-tuning performance reveals that beyond a certain threshold, the incremental benefit of larger training sets diminishes. This work introduces a useful TikTok video dataset that is available for public use and provides insights into the marginal benefit of increasing pre-training dataset sizes for video-based foundation models.\n",
      "\n",
      "Completed TikTok, Multimedia, Dataset, HumanActions, FoundationModels, ActionRecognition, VideoMAE, UCF101, HMDB51, Pre-training abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Financial exchanges have recently shown an interest in migrating to the public cloud for scalability, elasticity, and cost savings. However, financial exchanges often have strict network requirements that can be difficult to meet on the cloud. Notably, market participants (MPs) trade based on market data about different activities in the market. Exchanges often use switch multicast to disseminate market data to MPs. However, if one MP receives market data earlier than another, that MP would have an unfair advantage. To prevent this, financial exchanges often equalize exchange-to-MP cable lengths to provide near-simultaneous reception of market data at MPs.\n",
      "  As a cloud tenant, however, building a fair multicast service is challenging because of the lack of switch support for multicast, high latency variance, and the lack of native mechanisms for simultaneous data delivery in the cloud. Jasper introduces a solution that creates an overlay multicast tree within a cloud region that minimizes latency and latency variations through hedging, leverages recent advancements in clock synchronization to achieve simultaneous delivery, and addresses various sources of latency through an optimized DPDK/eBPF implementation -- while scaling to a thousand receivers. Jasper outperforms a prior system, CloudEx, and a commercial multicast solution provided by Amazon Web Services.\n",
      "\n",
      "Completed financial exchanges, cloud, latency, multicast, fairness, hedging, clock synchronization, DPDK/eBPF, scalability, Amazon Web Services abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Generative adversarial networks (GANs) generate photorealistic faces that are often indistinguishable by humans from real faces. While biases in machine learning models are often assumed to be due to biases in training data, we find pathological internal color and luminance biases in the discriminator of a pre-trained StyleGAN3-r model that are not explicable by the training data. We also find that the discriminator systematically stratifies scores by both image- and face-level qualities and that this disproportionately affects images across gender, race, and other categories. We examine axes common in research on stereotyping in social psychology.\n",
      "\n",
      "Completed GANs, StyleGAN3-r, biases, color, luminance, discriminator, stereotyping, social psychology, image quality, face quality abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We introduce Clifford Group Equivariant Simplicial Message Passing Networks, a method for steerable E(n)-equivariant message passing on simplicial complexes. Our method integrates the expressivity of Clifford group-equivariant layers with simplicial message passing, which is topologically more intricate than regular graph message passing. Clifford algebras include higher-order objects such as bivectors and trivectors, which express geometric features (e.g., areas, volumes) derived from vectors. Using this knowledge, we represent simplex features through geometric products of their vertices. To achieve efficient simplicial message passing, we share the parameters of the message network across different dimensions. Additionally, we restrict the final message to an aggregation of the incoming messages from different dimensions, leading to what we term shared simplicial message passing. Experimental results show that our method is able to outperform both equivariant and simplicial graph neural networks on a variety of geometric tasks.\n",
      "\n",
      "Completed Clifford, Equivariant, Simplicial, Message, Passing, Networks, Geometric, Features, Shared, Dimensions, Aggregation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We marry diffusion policies and 3D scene representations for robot manipulation. Diffusion policies learn the action distribution conditioned on the robot and environment state using conditional diffusion models. They have recently shown to outperform both deterministic and alternative state-conditioned action distribution learning methods. 3D robot policies use 3D scene feature representations aggregated from a single or multiple camera views using sensed depth. They have shown to generalize better than their 2D counterparts across camera viewpoints. We unify these two lines of work and present 3D Diffuser Actor, a neural policy architecture that, given a language instruction, builds a 3D representation of the visual scene and conditions on it to iteratively denoise 3D rotations and translations for the robot's end-effector. At each denoising iteration, our model represents end-effector pose estimates as 3D scene tokens and predicts the 3D translation and rotation error for each of them, by featurizing them using 3D relative attention to other 3D visual and language tokens. 3D Diffuser Actor sets a new state-of-the-art on RLBench with an absolute performance gain of 16.3% over the current SOTA on a multi-view setup and an absolute gain of 13.1% on a single-view setup. On the CALVIN benchmark, it outperforms the current SOTA in the setting of zero-shot unseen scene generalization by being able to successfully run 0.2 more tasks, a 7% relative increase. It also works in the real world from a handful of demonstrations. We ablate our model's architectural design choices, such as 3D scene featurization and 3D relative attentions, and show they all help generalization. Our results suggest that 3D scene representations and powerful generative modeling are keys to efficient robot learning from demonstrations.\n",
      "\n",
      "Completed Diffusion, 3D, Scene, Representation, Manipulation, Robot, Actor, Attention, Generalization, Reinforcement abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Understanding how social norms vary across cultures can help us build culturally aligned NLP systems. We propose a culture agnostic approach to norm discovery, using moral emotions, shame and pride, to identify examples of normative expectations and extract corresponding social norms. We present the first cross cultural self-conscious emotions dataset, obtained from 5.4K Bollywood and Hollywood movies, along with over 10K extracted social norms. We validate our dataset using native speakers and demonstrate how our dataset reveals variations in social norms that align with the cultural dichotomy observed in these nations e.g., Bollywood movies emphasize shame due to deviation from social roles, and express pride in family honor, while Hollywood shames poverty and incompetence, and takes pride in ethical behavior. Notably, females are shamed more across both cultures and both cultures shame women for violating similar normative expectations.\n",
      "\n",
      "Completed social, norms, culture, emotions, pride, shame, NLP, datasets, Bollywood, Hollywood abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Retrieval Augmented Generation (RAG) has emerged as an effective solution for mitigating hallucinations in Large Language Models (LLMs). The retrieval stage in RAG typically involves a pre-trained embedding model, which converts queries and passages into vectors to capture their semantics. However, a standard pre-trained embedding model may exhibit sub-optimal performance when applied to specific domain knowledge, necessitating fine-tuning. This paper addresses scenarios where the embeddings are only available from a black-box model. We introduce Model augmented fine-tuning (Mafin) -- a novel approach for fine-tuning a black-box embedding model by augmenting it with a trainable embedding model. Our results demonstrate that Mafin significantly enhances the performance of the black-box embeddings by only requiring the training of a small augmented model. We validate the effectiveness of our method on both labeled and unlabeled datasets, illustrating its broad applicability and efficiency.\n",
      "\n",
      "Completed RAG, hallucinations, LLMs, embeddings, fine-tuning, black-box, Mafin, trainable, labeled, unlabeled abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Text-to-SQL, which involves translating natural language into Structured Query Language (SQL), is crucial for enabling broad access to structured databases without expert knowledge. However, designing models for such tasks is challenging due to numerous factors, including the presence of 'noise,' such as ambiguous questions and syntactical errors. This study provides an in-depth analysis of the distribution and types of noise in the widely used BIRD-Bench benchmark and the impact of noise on models. While BIRD-Bench was created to model dirty and noisy database values, it was not created to contain noise and errors in the questions and gold queries. We found that noise in questions and gold queries are prevalent in the dataset, with varying amounts across domains, and with an uneven distribution between noise types. The presence of incorrect gold SQL queries, which then generate incorrect gold answers, has a significant impact on the benchmark's reliability. Surprisingly, when evaluating models on corrected SQL queries, zero-shot baselines surpassed the performance of state-of-the-art prompting methods. We conclude that informative noise labels and reliable benchmarks are crucial to developing new Text-to-SQL methods that can handle varying types of noise.\n",
      "\n",
      "Completed Text-to-SQL, Noise, BIRD-Bench, Questions, Queries, Errors, Ambiguity, Prompts, Zero-shot, Benchmarks abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Automata operating on pairs of words were introduced as an alternative way of capturing acceptance of regular $\\omega$-languages. Families of DFAs and lasso automata operating on such pairs followed, giving rise to minimisation algorithms, a Myhill-Nerode theorem and language learning algorithms. Yet Kleene theorems for such a well-established class are still missing. We introduce rational lasso languages and expressions, show a Kleene theorem for lasso languages and explore the connection between rational lasso and $\\omega$-expressions, which yields a Kleene theorem for $\\omega$-languages with respect to saturated lasso automata. For one direction of the Kleene theorems, we also provide a Brzozowski construction for lasso automata from rational lasso expressions.\n",
      "\n",
      "Completed Automata, pairs, regular, $\\omega$-languages, DFAs, lasso automata, minimisation, Myhill-Nerode, Kleene theorems, Brzozowski construction abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We propose CounterCurate, a framework to comprehensively improve the visio-linguistic compositional reasoning capability for both contrastive and generative multimodal models. In particular, we identify two critical under-explored problems: the neglect of the physically grounded reasoning (counting and position understanding) and the potential of using highly capable text and image generation models for semantic counterfactual fine-tuning. Our work pioneers an approach that addresses these gaps. We first spotlight the near-chance performance of multimodal models like CLIP and LLaVA in physically grounded compositional reasoning. We then apply simple data augmentation using grounded image generation model GLIGEN to generate fine-tuning data, resulting in significant performance improvements: +33% and +37% for CLIP and LLaVA, respectively, on our newly curated Flickr30k-Positions benchmark. Moreover, we exploit the capabilities of high-performing text generation and image generation models, specifically GPT-4V and DALLE-3, to curate challenging semantic counterfactuals, thereby further enhancing compositional reasoning capabilities on benchmarks such as SugarCrepe, where CounterCurate outperforms GPT-4V.\n",
      "\n",
      "Completed CounterCurate, compositional reasoning, visio-linguistic, CLIP, LLaVA, grounded reasoning, semantic counterfactual, GLIGEN, GPT-4V, DALLE-3 abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This micro-paper describes a trick to speed up inference of transformers with RoPE (such as LLaMA, Mistral, PaLM, and Gemma). For these models, a large portion of the first transformer layer can be precomputed, which results in slightly lower latency and lower cost-per-token. Because this trick optimizes only one layer, the relative savings depend on the total number of layers. For example, the maximum savings for a model with only 4 layers (such as Whisper tiny) is limited to 25%, while a 32-layer model is limited to 3% savings. See https://github.com/OpenMachine-ai/transformer-tricks for code and more transformer tricks.\n",
      "\n",
      "Completed RoPE, transformer, inference, latency, cost-per-token, layers, precomputed, savings, Whisper, transformer-tricks abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We study the active few-shot fine-tuning of large neural networks to downstream tasks. We show that few-shot fine-tuning is an instance of a generalization of classical active learning, transductive active learning, and we propose ITL, short for information-based transductive learning, an approach which samples adaptively to maximize the information gained about specified downstream tasks. Under general regularity assumptions, we prove that ITL converges uniformly to the smallest possible uncertainty obtainable from the accessible data. To the best of our knowledge, we are the first to derive generalization bounds of this kind, and they may be of independent interest for active learning. We apply ITL to the few-shot fine-tuning of large neural networks and show that ITL substantially improves upon the state-of-the-art.\n",
      "\n",
      "Completed active, few-shot, fine-tuning, neural, networks, transductive, active learning, ITL, information, uncertainty abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Autonomous mobile robots must maintain safety, but should not sacrifice performance, leading to the classical reach-avoid problem. This paper seeks to compute trajectory plans for which a robot is guaranteed to reach a goal and avoid obstacles in the specific near-danger case that the obstacles and goal are near each other. The proposed method builds off of a common approach of using a simplified planning model to generate plans, which are then tracked using a high-fidelity tracking model and controller. Existing safe planning approaches use reachability analysis to overapproximate the error between these models, but this introduces additional numerical approximation error and thereby conservativeness that prevents goal-reaching. The present work instead proposes a Piecewise Affine Reach-avoid Computation (PARC) method to tightly approximate the reachable set of the planning model. With PARC, the main source of conservativeness is the model mismatch, which can be mitigated by careful controller and planning model design. The utility of this method is demonstrated through extensive numerical experiments in which PARC outperforms state-of-the-art reach-avoid methods in near-danger goal-reaching. Furthermore, in a simulated demonstration, PARC enables the generation of provably-safe extreme vehicle dynamics drift parking maneuvers.\n",
      "\n",
      "Completed reach-avoid, autonomous, robot, safety, obstacle, goal, PARC, approximation, control, vehicle abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We generalize active learning to address real-world settings where sampling is restricted to an accessible region of the domain, while prediction targets may lie outside this region. To this end, we propose ITL, short for information-based transductive learning, an approach which samples adaptively to maximize the information gained about specified prediction targets. We show, under general regularity assumptions, that ITL converges uniformly to the smallest possible uncertainty obtainable from the accessible data. We demonstrate ITL in two key applications: Few-shot fine-tuning of large neural networks and safe Bayesian optimization, and in both cases, ITL significantly outperforms the state-of-the-art.\n",
      "\n",
      "Completed active,  learning,  transductive,  information,  uncertainty,  optimization,  few-shot,  neural,  networks,  safe abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recent advances in instruction-tuned Large Vision-Language Models (LVLMs) have imbued the models with the ability to generate high-level, image-grounded explanations with ease. While such capability is largely attributed to the rich world knowledge contained within the Large Language Models (LLMs), our work reveals their shortcomings in fine-grained visual categorization (FGVC) across six different benchmark settings. Most recent state-of-the-art LVLMs like LLaVa-1.5, InstructBLIP and GPT-4V not only severely deteriorate in terms of classification performance, e.g., average drop of 65.58 in EM for Stanford Dogs for LLaVA-1.5, but also struggle to generate an accurate explanation with detailed attributes based on the concept that appears within an input image despite their capability to generate holistic image-level descriptions. In-depth analyses show that instruction-tuned LVLMs exhibit modality gap, showing discrepancy when given textual and visual inputs that correspond to the same concept, preventing the image modality from leveraging the rich parametric knowledge within the LLMs. In an effort to further the community's endeavor in this direction, we propose a multiple granularity attribute-centric evaluation benchmark, Finer, which aims to establish a ground to evaluate LVLMs' fine-grained visual comprehension ability and provide significantly improved explainability.\n",
      "\n",
      "Completed Large Vision-Language Model, Image-grounded Explanations, Fine-grained Visual Categorization, LLaVA-1.5, InstructBLIP, GPT-4V, Modality Gap, Attribute-centric Evaluation, Finer, Explainability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Preference-based Reinforcement Learning (PbRL) avoids the need for reward engineering by harnessing human preferences as the reward signal. However, current PbRL algorithms over-reliance on high-quality feedback from domain experts, which results in a lack of robustness. In this paper, we present RIME, a robust PbRL algorithm for effective reward learning from noisy preferences. Our method incorporates a sample selection-based discriminator to dynamically filter denoised preferences for robust training. To mitigate the accumulated error caused by incorrect selection, we propose to warm start the reward model, which additionally bridges the performance gap during transition from pre-training to online training in PbRL. Our experiments on robotic manipulation and locomotion tasks demonstrate that RIME significantly enhances the robustness of the current state-of-the-art PbRL method. Ablation studies further demonstrate that the warm start is crucial for both robustness and feedback-efficiency in limited-feedback cases.\n",
      "\n",
      "Completed Preference, Reinforcement, Learning, RIME, Robust, Reward, Denoising, Sample, Selection, Discrimination abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Mathematical formulas are the crystallization of human wisdom in exploring the laws of nature for thousands of years. Describing the complex laws of nature with a concise mathematical formula is a constant pursuit of scientists and a great challenge for artificial intelligence. This field is called symbolic regression. Symbolic regression was originally formulated as a combinatorial optimization problem, and GP and reinforcement learning algorithms were used to solve it. However, GP is sensitive to hyperparameters, and these two types of algorithms are inefficient. To solve this problem, researchers treat the mapping from data to expressions as a translation problem. And the corresponding large-scale pre-trained model is introduced. However, the data and expression skeletons do not have very clear word correspondences as the two languages do. Instead, they are more like two modalities (e.g., image and text). Therefore, in this paper, we proposed MMSR. The SR problem is solved as a pure multimodal problem, and contrastive learning is also introduced in the training process for modal alignment to facilitate later modal feature fusion. It is worth noting that in order to better promote the modal feature fusion, we adopt the strategy of training contrastive learning loss and other losses at the same time, which only needs one-step training, instead of training contrastive learning loss first and then training other losses. Because our experiments prove training together can make the feature extraction module and feature fusion module running-in better. Experimental results show that compared with multiple large-scale pre-training baselines, MMSR achieves the most advanced results on multiple mainstream datasets including SRBench.\n",
      "\n",
      "Completed Symbolic, Regression, Optimization, Machine Learning, Formula, Translation, Modalities, Contrastive Learning, Feature Fusion, Datasets abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "For U.S. presidential elections, most states use the so-called winner-take-all system, in which the state's presidential electors are awarded to the winning political party in the state after a popular vote phase, regardless of the actual margin of victory. Therefore, election campaigns are especially intense in states where there is no clear direction on which party will be the winning party. These states are often referred to as swing states. To measure the impact of such an election law on the campaigns, we analyze the Twitter activity surrounding the 2020 US preelection debate, with a particular focus on the spread of disinformation. We find that about 88% of the online traffic was associated with swing states. In addition, the sharing of links to unreliable news sources is significantly more prevalent in tweets associated with swing states: in this case, untrustworthy tweets are predominantly generated by automated accounts. Furthermore, we observe that the debate is mostly led by two main communities, one with a predominantly Republican affiliation and the other with accounts of different political orientations. Most of the disinformation comes from the former.\n",
      "\n",
      "Completed election, campaigns, swing states, Twitter, disinformation, online traffic, unreliable news, automated accounts, communities, Republican abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Large Language Model (LLM)-based agents have demonstrated remarkable effectiveness. However, their performance can be compromised in data science scenarios that require real-time data adjustment, expertise in optimization due to complex dependencies among various tasks, and the ability to identify logical errors for precise reasoning. In this study, we introduce the Data Interpreter, a solution designed to solve with code that emphasizes three pivotal techniques to augment problem-solving in data science: 1) dynamic planning with hierarchical graph structures for real-time data adaptability;2) tool integration dynamically to enhance code proficiency during execution, enriching the requisite expertise;3) logical inconsistency identification in feedback, and efficiency enhancement through experience recording. We evaluate the Data Interpreter on various data science and real-world tasks. Compared to open-source baselines, it demonstrated superior performance, exhibiting significant improvements in machine learning tasks, increasing from 0.86 to 0.95. Additionally, it showed a 26% increase in the MATH dataset and a remarkable 112% improvement in open-ended tasks. The solution will be released at https://github.com/geekan/MetaGPT.\n",
      "\n",
      "Completed Data, Interpreter, Large, Language, Model, Real-time, Optimization, Logical, Reasoning, Code abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Recent advancements in domain generalization (DG) for face anti-spoofing (FAS) have garnered considerable attention. Traditional methods have focused on designing learning objectives and additional modules to isolate domain-specific features while retaining domain-invariant characteristics in their representations. However, such approaches often lack guarantees of consistent maintenance of domain-invariant features or the complete removal of domain-specific features. Furthermore, most prior works of DG for FAS do not ensure convergence to a local flat minimum, which has been shown to be advantageous for DG. In this paper, we introduce GAC-FAS, a novel learning objective that encourages the model to converge towards an optimal flat minimum without necessitating additional learning modules. Unlike conventional sharpness-aware minimizers, GAC-FAS identifies ascending points for each domain and regulates the generalization gradient updates at these points to align coherently with empirical risk minimization (ERM) gradient updates. This unique approach specifically guides the model to be robust against domain shifts. We demonstrate the efficacy of GAC-FAS through rigorous testing on challenging cross-domain FAS datasets, where it establishes state-of-the-art performance. The code is available at https://github.com/leminhbinh0209/CVPR24-FAS.\n",
      "\n",
      "Completed Domain, Generalization, Face, Anti-Spoofing, Sharpness, Gradient, Flat, Minimum, GAC-FAS, ERM abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper presents WanJuan-CC, a safe and high-quality open-sourced English webtext dataset derived from Common Crawl data. The study addresses the challenges of constructing large-scale pre-training datasets for language models, which require vast amounts of high-quality data. A comprehensive process was designed to handle Common Crawl data, including extraction, heuristic rule filtering, fuzzy deduplication, content safety filtering, and data quality filtering. From approximately 68 billion original English documents, we obtained 2.22T Tokens of safe data and selected 1.0T Tokens of high-quality data as part of WanJuan-CC. We have open-sourced 100B Tokens from this dataset. The paper also provides statistical information related to data quality, enabling users to select appropriate data according to their needs. To evaluate the quality and utility of the dataset, we trained 1B-parameter and 3B-parameter models using WanJuan-CC and another dataset, RefinedWeb. Results show that WanJuan-CC performs better on validation datasets and downstream tasks.\n",
      "\n",
      "Completed WanJuan-CC, English, Webtext, Open-sourced, High-quality, Common Crawl, Language models, Data quality, RefinedWeb, Evaluation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper describes the 6th Affective Behavior Analysis in-the-wild (ABAW) Competition, which is part of the respective Workshop held in conjunction with IEEE CVPR 2024. The 6th ABAW Competition addresses contemporary challenges in understanding human emotions and behaviors, crucial for the development of human-centered technologies. In more detail, the Competition focuses on affect related benchmarking tasks and comprises of five sub-challenges: i) Valence-Arousal Estimation (the target is to estimate two continuous affect dimensions, valence and arousal), ii) Expression Recognition (the target is to recognise between the mutually exclusive classes of the 7 basic expressions and 'other'), iii) Action Unit Detection (the target is to detect 12 action units), iv) Compound Expression Recognition (the target is to recognise between the 7 mutually exclusive compound expression classes), and v) Emotional Mimicry Intensity Estimation (the target is to estimate six continuous emotion dimensions). In the paper, we present these Challenges, describe their respective datasets and challenge protocols (we outline the evaluation metrics) and present the baseline systems as well as their obtained performance. More information for the Competition can be found in: https://affective-behavior-analysis-in-the-wild.github.io/6th.\n",
      "\n",
      "Completed Affective, Behavior, Analysis, Competition, Workshop, Benchmarking, Sub-Challenges, Valence, Arousal, Mimicry abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Pre-routing timing prediction has been recently studied for evaluating the quality of a candidate cell placement in chip design. It involves directly estimating the timing metrics for both pin-level (slack, slew) and edge-level (net delay, cell delay), without time-consuming routing. However, it often suffers from signal decay and error accumulation due to the long timing paths in large-scale industrial circuits. To address these challenges, we propose a two-stage approach. First, we propose global circuit training to pre-train a graph auto-encoder that learns the global graph embedding from circuit netlist. Second, we use a novel node updating scheme for message passing on GCN, following the topological sorting sequence of the learned graph embedding and circuit graph. This scheme residually models the local time delay between two adjacent pins in the updating sequence, and extracts the lookup table information inside each cell via a new attention mechanism. To handle large-scale circuits efficiently, we introduce an order preserving partition scheme that reduces memory consumption while maintaining the topological dependencies. Experiments on 21 real world circuits achieve a new SOTA R2 of 0.93 for slack prediction, which is significantly surpasses 0.59 by previous SOTA method. Code will be available at: https://github.com/Thinklab-SJTU/EDA-AI.\n",
      "\n",
      "Completed timing, prediction, chip, design, graph, embedding, message, passing, order, preserving abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Deep reinforcement learning (DRL) algorithms require substantial samples and computational resources to achieve higher performance, which restricts their practical application and poses challenges for further development. Given the constraint of limited resources, it is essential to leverage existing computational work (e.g., learned policies, samples) to enhance sample efficiency and reduce the computational resource consumption of DRL algorithms. Previous works to leverage existing computational work require intrusive modifications to existing algorithms and models, designed specifically for specific algorithms, lacking flexibility and universality. In this paper, we present the Snapshot Reinforcement Learning (SnapshotRL) framework, which enhances sample efficiency by simply altering environments, without making any modifications to algorithms and models. By allowing student agents to choose states in teacher trajectories as the initial state to sample, SnapshotRL can effectively utilize teacher trajectories to assist student agents in training, allowing student agents to explore a larger state space at the early training phase. We propose a simple and effective SnapshotRL baseline algorithm, S3RL, which integrates well with existing DRL algorithms. Our experiments demonstrate that integrating S3RL with TD3, SAC, and PPO algorithms on the MuJoCo benchmark significantly improves sample efficiency and average return, without extra samples and additional computational resources.\n",
      "\n",
      "Completed reinforcement, learning, sample, efficiency, computational, resources, snapshot, environment, trajectory, state abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Efficiently solving unbalanced three-phase power flow in distribution grids is pivotal for grid analysis and simulation. There is a pressing need for scalable algorithms capable of handling large-scale unbalanced power grids that can provide accurate and fast solutions. To address this, deep learning techniques, especially Graph Neural Networks (GNNs), have emerged. However, existing literature primarily focuses on balanced networks, leaving a critical gap in supporting unbalanced three-phase power grids. This letter introduces PowerFlowMultiNet, a novel multigraph GNN framework explicitly designed for unbalanced three-phase power grids. The proposed approach models each phase separately in a multigraph representation, effectively capturing the inherent asymmetry in unbalanced grids. A graph embedding mechanism utilizing message passing is introduced to capture spatial dependencies within the power system network. PowerFlowMultiNet outperforms traditional methods and other deep learning approaches in terms of accuracy and computational speed. Rigorous testing reveals significantly lower error rates and a notable hundredfold increase in computational speed for large power networks compared to model-based methods.\n",
      "\n",
      "Completed power, grid, unbalanced, distribution, GNN, multigraph, deep learning, accuracy, scalability, speed abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Accurate load forecasting is crucial for energy management, infrastructure planning, and demand-supply balancing. Smart meter data availability has led to the demand for sensor-based load forecasting. Conventional ML allows training a single global model using data from multiple smart meters requiring data transfer to a central server, raising concerns for network requirements, privacy, and security. We propose a split learning-based framework for load forecasting to alleviate this issue. We split a deep neural network model into two parts, one for each Grid Station (GS) responsible for an entire neighbourhood's smart meters and the other for the Service Provider (SP). Instead of sharing their data, client smart meters use their respective GSs' model split for forward pass and only share their activations with the GS. Under this framework, each GS is responsible for training a personalized model split for their respective neighbourhoods, whereas the SP can train a single global or personalized model for each GS. Experiments show that the proposed models match or exceed a centrally trained model's performance and generalize well. Privacy is analyzed by assessing information leakage between data and shared activations of the GS model split. Additionally, differential privacy enhances local data privacy while examining its impact on performance. A transformer model is used as our base learner.\n",
      "\n",
      "Completed load forecasting, smart meters, sensor-based, split learning, deep neural network, Grid Station, Service Provider, personalized models, privacy, transformer model abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "A linear block code over a field can be derived from a unit scheme. Looking at codes as structures within a unit scheme greatly extends the availability of linear block and convolutional codes and allows the construction of the codes to required length, rate, distance and type. Properties of a code emanate from properties of the unit from which it was derived. Orthogonal units, units in group rings, Fourier/Vandermonde units and related units are used to construct and analyse linear block and convolutional codes and to construct these to predefined length, rate, distance and type. Self-dual, dual containing, quantum error-correcting and complementary dual linear block and convolutional codes are constructed.\n",
      "  Low density parity check linear block and convolutional codes are constructed using group rings and are constructed with no short cycles in the control matrix.\n",
      "  From a single unit, multiple codes of a required type are derivable.\n",
      "\n",
      "Completed Linear, block, codes, unit, scheme, distance, type, convolutional, group, Fourier abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Large language models (LLMs) frequently hallucinate and produce factual errors, yet our understanding of why they make these errors remains limited. In this study, we delve into the underlying mechanisms of LLM hallucinations from the perspective of inner representations, and discover a salient pattern associated with hallucinations: correct generations tend to have sharper context activations in the hidden states of the in-context tokens, compared to the incorrect ones. Leveraging this insight, we propose an entropy-based metric to quantify the ``sharpness'' among the in-context hidden states and incorporate it into the decoding process to formulate a constrained decoding approach. Experiments on various knowledge-seeking and hallucination benchmarks demonstrate our approach's consistent effectiveness, for example, achieving up to an 8.6 point improvement on TruthfulQA. We believe this study can improve our understanding of hallucinations and serve as a practical solution for hallucination mitigation.\n",
      "\n",
      "Completed LLMs, hallucinations, factual errors, inner representations, context activations, hidden states, entropy-based metric, sharpness, constrained decoding, performance improvement abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The transferability of deep neural networks (DNNs) has made significant progress in image and language processing. However, due to the heterogeneity among tables, such DNN bonus is still far from being well exploited on tabular data prediction (e.g., regression or classification tasks). Condensing knowledge from diverse domains, language models (LMs) possess the capability to comprehend feature names from various tables, potentially serving as versatile learners in transferring knowledge across distinct tables and diverse prediction tasks, but their discrete text representation space is inherently incompatible with numerical feature values in tables. In this paper, we present TP-BERTa, a specifically pre-trained LM for tabular data prediction. Concretely, a novel relative magnitude tokenization converts scalar numerical feature values to finely discrete, high-dimensional tokens, and an intra-feature attention approach integrates feature values with the corresponding feature names. Comprehensive experiments demonstrate that our pre-trained TP-BERTa leads the performance among tabular DNNs and is competitive with Gradient Boosted Decision Tree models in typical tabular data regime.\n",
      "\n",
      "Completed Language, Models, Tabular, Data, Prediction, Transferability, Features, Boosted, Decision, Tree abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Accurate and consistent methods for counting trees based on remote sensing data are needed to support sustainable forest management, assess climate change mitigation strategies, and build trust in tree carbon credits. Two-dimensional remote sensing imagery primarily shows overstory canopy, and it does not facilitate easy differentiation of individual trees in areas with a dense canopy and does not allow for easy separation of trees when the canopy is dense. We leverage the fusion of three-dimensional LiDAR measurements and 2D imagery to facilitate the accurate counting of trees. We compare a deep learning approach to counting trees in forests using 3D airborne LiDAR data and 2D imagery. The approach is compared with state-of-the-art algorithms, like operating on 3D point cloud and 2D imagery. We empirically evaluate the different methods on the NeonTreeCount data set, which we use to define a tree-counting benchmark. The experiments show that FuseCountNet yields more accurate tree counts.\n",
      "\n",
      "Completed Tree, counting, remote sensing, LiDAR, fusion, imagery, canopy, deep learning, benchmark, accuracy abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Learning a universal manipulation policy encompassing doors with diverse categories, geometries and mechanisms, is crucial for future embodied agents to effectively work in complex and broad real-world scenarios. Due to the limited datasets and unrealistic simulation environments, previous works fail to achieve good performance across various doors. In this work, we build a novel door manipulation environment reflecting different realistic door manipulation mechanisms, and further equip this environment with a large-scale door dataset covering 6 door categories with hundreds of door bodies and handles, making up thousands of different door instances. Additionally, to better emulate real-world scenarios, we introduce a mobile robot as the agent and use the partial and occluded point cloud as the observation, which are not considered in previous works while possessing significance for real-world implementations. To learn a universal policy over diverse doors, we propose a novel framework disentangling the whole manipulation process into three stages, and integrating them by training in the reversed order of inference. Extensive experiments validate the effectiveness of our designs and demonstrate our framework's strong performance. Code, data and videos are avaible on https://unidoormanip.github.io/.\n",
      "\n",
      "Completed unidoormanip, manipulation, policy, real-world, environment, dataset, mobile robot, partial point cloud, occluded point cloud, reversed order training abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper focuses on developing Pareto-optimal estimation and policy learning to identify the most effective treatment that maximizes the total reward from both short-term and long-term effects, which might conflict with each other. For example, a higher dosage of medication might increase the speed of a patient's recovery (short-term) but could also result in severe long-term side effects. Although recent works have investigated the problems about short-term or long-term effects or the both, how to trade-off between them to achieve optimal treatment remains an open challenge. Moreover, when multiple objectives are directly estimated using conventional causal representation learning, the optimization directions among various tasks can conflict as well. In this paper, we systematically investigate these issues and introduce a Pareto-Efficient algorithm, comprising Pareto-Optimal Estimation (POE) and Pareto-Optimal Policy Learning (POPL), to tackle them. POE incorporates a continuous Pareto module with representation balancing, enhancing estimation efficiency across multiple tasks. As for POPL, it involves deriving short-term and long-term outcomes linked with various treatment levels, facilitating an exploration of the Pareto frontier emanating from these outcomes. Results on both the synthetic and real-world datasets demonstrate the superiority of our method.\n",
      "\n",
      "Completed Pareto, optimization, estimation, policy learning, treatment, short-term, long-term, causal representation, efficiency, exploration abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Monte Carlo (MC) simulations play a pivotal role in diverse scientific and engineering domains, with applications ranging from nuclear physics to materials science. Harnessing the computational power of high-performance computing (HPC) systems, especially Graphics Processing Units (GPUs), has become essential for accelerating MC simulations. This paper focuses on the adaptation and optimization of the OpenMC neutron and photon transport Monte Carlo code for Intel GPUs, specifically the Intel Data Center Max 1100 GPU (codename Ponte Vecchio, PVC), through distributed OpenMP offloading. Building upon prior work by Tramm J.R., et al. (2022), which laid the groundwork for GPU adaptation, our study meticulously extends the OpenMC code's capabilities to Intel GPUs. We present a comprehensive benchmarking and scaling analysis, comparing performance on Intel MAX GPUs to state-of-the-art CPU execution (Intel Xeon Platinum 8480+ Processor, codename 4th generation Sapphire Rapids). The results demonstrate a remarkable acceleration factor compared to CPU execution, showcasing the GPU-adapted code's superiority over its CPU counterpart as computational load increases.\n",
      "\n",
      "Completed Monte Carlo, simulation, nuclear physics, materials science, high-performance computing, Graphics Processing Unit, Intel GPU, Ponte Vecchio, offloading, benchmarking abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "With the boom of e-commerce and web applications, recommender systems have become an important part of our daily lives, providing personalized recommendations based on the user's preferences. Although deep neural networks (DNNs) have made significant progress in improving recommendation systems by simulating the interaction between users and items and incorporating their textual information, these DNN-based approaches still have some limitations, such as the difficulty of effectively understanding users' interests and capturing textual information. It is not possible to generalize to different seen/unseen recommendation scenarios and reason about their predictions. At the same time, the emergence of large language models (LLMs), represented by ChatGPT and GPT-4, has revolutionized the fields of natural language processing (NLP) and artificial intelligence (AI) due to their superior capabilities in the basic tasks of language understanding and generation, and their impressive generalization and reasoning capabilities. As a result, recent research has sought to harness the power of LLM to improve recommendation systems. Given the rapid development of this research direction in the field of recommendation systems, there is an urgent need for a systematic review of existing LLM-driven recommendation systems for researchers and practitioners in related fields to gain insight into. More specifically, we first introduced a representative approach to learning user and item representations using LLM as a feature encoder. We then reviewed the latest advances in LLMs techniques for collaborative filtering enhanced recommendation systems from the three paradigms of pre-training, fine-tuning, and prompting. Finally, we had a comprehensive discussion on the future direction of this emerging field.\n",
      "\n",
      "Completed Recommendation, E-commerce, Web, Recommender, AI, NLP, LLM, ChatGPT, Collaborative, Filtering abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Personalized dialogue systems have gained significant attention in recent years for their ability to generate responses in alignment with different personas. However, most existing approaches rely on pre-defined personal profiles, which are not only time-consuming and labor-intensive to create but also lack flexibility. We propose In-Dialogue Learning (IDL), a fine-tuning framework that enhances the ability of pre-trained large language models to leverage dialogue history to characterize persona for completing personalized dialogue generation tasks without pre-defined profiles. Our experiments on three datasets demonstrate that IDL brings substantial improvements, with BLEU and ROUGE scores increasing by up to 200% and 247%, respectively. Additionally, the results of human evaluations further validate the efficacy of our proposed method.\n",
      "\n",
      "Completed personalized, dialogue, systems, personas, In-Dialogue Learning, fine-tuning, large language models, dialogue history, BLEU, ROUGE abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In the contemporary digital landscape, the continuous generation of extensive streaming data across diverse domains has become pervasive. Yet, a significant portion of this data remains unlabeled, posing a challenge in identifying infrequent events such as anomalies. This challenge is further amplified in non-stationary environments, where the performance of models can degrade over time due to concept drift. To address these challenges, this paper introduces a new method referred to as VAE4AS (Variational Autoencoder for Anomalous Sequences). VAE4AS integrates incremental learning with dual drift detection mechanisms, employing both a statistical test and a distance-based test. The anomaly detection is facilitated by a Variational Autoencoder. To gauge the effectiveness of VAE4AS, a comprehensive experimental study is conducted using real-world and synthetic datasets characterized by anomalous rates below 10\\% and recurrent drift. The results show that the proposed method surpasses both robust baselines and state-of-the-art techniques, providing compelling evidence for their efficacy in effectively addressing some of the challenges associated with anomalous sequence detection in non-stationary streaming data.\n",
      "\n",
      "Completed streaming, data, unlabeled, anomaly, detection, non-stationary, concept, drift, VAE, real-world abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This study proposes content and interaction analysis techniques for a large repository created from social media content. Though we have presented our study for a large platform dedicated to discussions around financial topics, the proposed methods are generic and applicable to all platforms. Along with an extension of topic extraction method using Latent Dirichlet Allocation, we propose a few measures to assess user participation, influence and topic affinities specifically. Our study also maps user-generated content to components of behavioral finance. While these types of information are usually gathered through surveys, it is obvious that large scale data analysis from social media can reveal many potentially unknown or rare insights. Characterising users based on their platform behavior to provide critical insights about how communities are formed and trust is established in these platforms using graphical analysis is also studied.\n",
      "\n",
      "Completed content, interaction, analysis, social, media, finance, topic, user, behavior, network abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "As an increasingly large number of people turn to platforms like Reddit, YouTube, Twitter, Instagram, etc. for financial advice, generating insights about the content generated and interactions taking place within these platforms have become a key research question. This study proposes content and interaction analysis techniques for a large repository created from social media content, where people interactions are centered around financial information exchange. We propose methods for content analysis that can generate human-interpretable insights using topic-centered clustering and multi-document abstractive summarization. We share details of insights generated from our experiments with a large repository of data gathered from subreddit for personal finance. We have also explored the use of ChatGPT and Vicuna for generating responses to queries and compared them with human responses. The methods proposed in this work are generic and applicable to all large social media platforms.\n",
      "\n",
      "Completed social, media, content, analysis, interaction, financial, advice, insights, clustering, summarization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Deep Learning models have been successfully utilized to extract clinically actionable insights from routinely available histology data. Generally, these models require annotations performed by clinicians, which are scarce and costly to generate. The emergence of self-supervised learning (SSL) methods remove this barrier, allowing for large-scale analyses on non-annotated data. However, recent SSL approaches apply increasingly expansive model architectures and larger datasets, causing the rapid escalation of data volumes, hardware prerequisites, and overall expenses, limiting access to these resources to few institutions. Therefore, we investigated the complexity of contrastive SSL in computational pathology in relation to classification performance with the utilization of consumer-grade hardware. Specifically, we analyzed the effects of adaptations in data volume, architecture, and algorithms on downstream classification tasks, emphasizing their impact on computational resources. We trained breast cancer foundation models on a large public patient cohort and validated them on various downstream classification tasks in a weakly supervised manner on two external public patient cohorts. Our experiments demonstrate that we can improve downstream classification performance whilst reducing SSL training duration by 90%. In summary, we propose a set of adaptations which enable the utilization of SSL in computational pathology in non-resource abundant environments.\n",
      "\n",
      "Completed Deep Learning, Self-Supervised Learning, Contrastive Learning, Computational Pathology, Data Augmentation, Efficient Models, Hardware Accessibility, Classification, Breast Cancer, Public Patient Cohorts abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present a novel method for efficiently producing semi-dense matches across images. Previous detector-free matcher LoFTR has shown remarkable matching capability in handling large-viewpoint change and texture-poor scenarios but suffers from low efficiency. We revisit its design choices and derive multiple improvements for both efficiency and accuracy. One key observation is that performing the transformer over the entire feature map is redundant due to shared local information, therefore we propose an aggregated attention mechanism with adaptive token selection for efficiency. Furthermore, we find spatial variance exists in LoFTR's fine correlation module, which is adverse to matching accuracy. A novel two-stage correlation layer is proposed to achieve accurate subpixel correspondences for accuracy improvement. Our efficiency optimized model is $\\sim 2.5\\times$ faster than LoFTR which can even surpass state-of-the-art efficient sparse matching pipeline SuperPoint + LightGlue. Moreover, extensive experiments show that our method can achieve higher accuracy compared with competitive semi-dense matchers, with considerable efficiency benefits. This opens up exciting prospects for large-scale or latency-sensitive applications such as image retrieval and 3D reconstruction. Project page: https://zju3dv.github.io/efficientloftr.\n",
      "\n",
      "Completed LoFTR, efficiency, accuracy, transformer, attention, token selection, correlation, subpixel, SuperPoint, LightGlue abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We propose an efficient solver for the privacy funnel (PF) method, leveraging its difference-of-convex (DC) structure. The proposed DC separation results in a closed-form update equation, which allows straightforward application to both known and unknown distribution settings. For known distribution case, we prove the convergence (local stationary points) of the proposed non-greedy solver, and empirically show that it outperforms the state-of-the-art approaches in characterizing the privacy-utility trade-off. The insights of our DC approach apply to unknown distribution settings where labeled empirical samples are available instead. Leveraging the insights, our alternating minimization solver satisfies the fundamental Markov relation of PF in contrast to previous variational inference-based solvers. Empirically, we evaluate the proposed solver with MNIST and Fashion-MNIST datasets. Our results show that under a comparable reconstruction quality, an adversary suffers from higher prediction error from clustering our compressed codes than that with the compared methods. Most importantly, our solver is independent to private information in inference phase contrary to the baselines.\n",
      "\n",
      "Completed privacy, funnel, difference-of-convex, closed-form, known, distribution, convergence, variational, inference, alternating, minimization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Large Language Models (LLM) have taken the front seat in most of the news since November 2022, when ChatGPT was introduced. After more than one year, one of the major reasons companies are resistant to adopting them is the limited confidence they have in the trustworthiness of those systems. In a study by (Baymard, 2023), ChatGPT-4 showed an 80.1% false-positive error rate in identifying usability issues on websites. A Jan. '24 study by JAMA Pediatrics found that ChatGPT has an accuracy rate of 17% percent when diagnosing pediatric medical cases (Barile et al., 2024). But then, what is \"trust\"? Trust is a relative, subject condition that can change based on culture, domain, individuals. And then, given a domain, how can the trustworthiness of a system be measured? In this paper, I present a systematic approach to measure trustworthiness based on a predefined ground truth, represented as a knowledge graph of the domain. The approach is a process with humans in the loop to validate the representation of the domain and to fine-tune the system.\n",
      "  Measuring the trustworthiness would be essential for all the entities operating in critical environments, such as healthcare, defense, finance, but it would be very relevant for all the users of LLMs.\n",
      "\n",
      "Completed Trustworthiness, Large Language Models, Reliability, Accuracy, Usability, Measurement, Knowledge Graph, Validation, Fine-Tuning, Critical Environments abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Formal methods for guaranteeing that a protocol satisfies a cryptographic security definition have advanced substantially, but such methods are still labor intensive and the need remains for an automated tool that can positively identify an insecure protocol. In this work, we demonstrate that property-based testing, \"run it a bunch of times and see if it breaks\", is effective for detecting security bugs in secure protocols. We specifically target Secure Multi-Party Computation (MPC), because formal methods targeting this security definition for bit-model implementations are particularly difficult. Using results from the literature for Probabilistic Programming Languages and statistical inference, we devise a test that can detect various flaws in a bit-level implementation of an MPC protocol. The test is grey-box; it requires only transcripts of randomness consumed by the protocol and of the inputs, outputs, and messages. It successfully detects several different mistakes and biases introduced into two different implementations of the classic GMW protocol. Applied to hundreds of randomly generated protocols, it identifies nearly all of them as insecure. We also include an analysis of the parameters of the test, and discussion of what makes detection of MPC (in)security difficult.\n",
      "\n",
      "Completed Formal, methods, security, property-based, testing, Secure, Multi-Party, Computation, grey-box, GMW, protocol abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "A diffusion interface two-phase magnetohydrodynamic model has been used for matched densities in our previous work [1,2], which may limit the applications of the model. In this work, we derive a thermodynamically consistent diffuse interface model for diffusion interface two-phase magnetohydrodynamic fluids with large density ratios by Onsager's variational principle and conservation law for the first time. The finite element method for spatial discretization and the first order semi-implicit scheme linked with convect splitting method for temporal discretization, is proposed to solve this new model. The mass conservation, unconditionally energy stability and convergence of the scheme can be proved. Then we derive the existence of weak solutions of governing system employing the above properties of the scheme and compactness method. Finally, we show some numerical results to test the effectiveness and well behavior of proposed scheme.\n",
      "\n",
      "Completed phase, magnetohydrodynamic, diffusion, variational, Onsager, weak, solutions, conservation, stability, convergence abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Aspect Sentiment Understanding (ASU) in interactive scenarios (e.g., Question-Answering and Dialogue) has attracted ever-more interest in recent years and achieved important progresses. However, existing studies on interactive ASU largely ignore the coreference issue for opinion targets (i.e., aspects), while this phenomenon is ubiquitous in interactive scenarios especially dialogues, limiting the ASU performance. Recently, large language models (LLMs) shows the powerful ability to integrate various NLP tasks with the chat paradigm. In this way, this paper proposes a new Chat-based Aspect Sentiment Understanding (ChatASU) task, aiming to explore LLMs' ability in understanding aspect sentiments in dialogue scenarios. Particularly, this ChatASU task introduces a sub-task, i.e., Aspect Chain Reasoning (ACR) task, to address the aspect coreference issue. On this basis, we propose a Trusted Self-reflexion Approach (TSA) with ChatGLM as backbone to ChatASU. Specifically, this TSA treats the ACR task as an auxiliary task to boost the performance of the primary ASU task, and further integrates trusted learning into reflexion mechanisms to alleviate the LLMs-intrinsic factual hallucination problem in TSA. Furthermore, a high-quality ChatASU dataset is annotated to evaluate TSA, and extensive experiments show that our proposed TSA can significantly outperform several state-of-the-art baselines, justifying the effectiveness of TSA to ChatASU and the importance of considering the coreference and hallucination issues in ChatASU.\n",
      "\n",
      "Completed Aspect, Sentiment, Understanding, Interactive, Coreference, Dialogue, Chat, ChatASU, ACR, TSA abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Dilated convolution, which expands the receptive field by inserting gaps between its consecutive elements, is widely employed in computer vision. In this study, we propose three strategies to improve individual phases of dilated convolution from the view of spectrum analysis. Departing from the conventional practice of fixing a global dilation rate as a hyperparameter, we introduce Frequency-Adaptive Dilated Convolution (FADC), which dynamically adjusts dilation rates spatially based on local frequency components. Subsequently, we design two plug-in modules to directly enhance effective bandwidth and receptive field size. The Adaptive Kernel (AdaKern) module decomposes convolution weights into low-frequency and high-frequency components, dynamically adjusting the ratio between these components on a per-channel basis. By increasing the high-frequency part of convolution weights, AdaKern captures more high-frequency components, thereby improving effective bandwidth. The Frequency Selection (FreqSelect) module optimally balances high- and low-frequency components in feature representations through spatially variant reweighting. It suppresses high frequencies in the background to encourage FADC to learn a larger dilation, thereby increasing the receptive field for an expanded scope. Extensive experiments on segmentation and object detection consistently validate the efficacy of our approach. The code is publicly available at \\url{https://github.com/Linwei-Chen/FADC}.\n",
      "\n",
      "Completed dilated,convolution,spectrum,analysis,frequency,adaptive,bandwidth,receptive,field,segmentation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We propose training fitted Q-iteration with log-loss (FQI-LOG) for batch reinforcement learning (RL). We show that the number of samples needed to learn a near-optimal policy with FQI-LOG scales with the accumulated cost of the optimal policy, which is zero in problems where acting optimally achieves the goal and incurs no cost. In doing so, we provide a general framework for proving $\\textit{small-cost}$ bounds, i.e. bounds that scale with the optimal achievable cost, in batch RL. Moreover, we empirically verify that FQI-LOG uses fewer samples than FQI trained with squared loss on problems where the optimal policy reliably achieves the goal.\n",
      "\n",
      "Completed Batch, reinforcement learning, Q-iteration, log-loss, optimal policy, near-optimal policy, sample complexity, small-cost bounds, squared loss, goal achievement abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Concurrent distributed systems are notoriously difficult to construct and reason about. Choreographic programming is a recent paradigm that describes a distributed system in a single global program called a choreography. Choreographies simplify reasoning about distributed systems and can ensure deadlock freedom by static analysis. In previous choreographic programming languages, each value is located at a single party, and the programmer is expected to insert special untyped \"select\" operations to ensure that all parties follow the same communication pattern.\n",
      "  We present He-Lambda-Small, a new choreographic programming language with Multiply Located Values. He-Lambda-Small allows multicasting to a set of parties, and the resulting value will be located at all of them. This approach enables a simple and elegant alternative to \"select\": He-Lambda-Small requires that the guard for a conditional be located at all of the relevant parties. In He-Lambda-Small, checking that a choreography is well-typed suffices to show that it is deadlock-free. We present several case studies that demonstrate the use of multiply-located values to concisely encode tricky communication patterns described in previous work without the use of \"select\" or redundant communication.\n",
      "\n",
      "Completed choreographic, programming, concurrent, distributed, systems, He-Lambda-Small, multiply, located, values, deadlock, freedom abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Vision-based tactile sensors have recently become popular due to their combination of low cost, very high spatial resolution, and ease of integration using widely available miniature cameras. The associated field of view and focal length, however, are difficult to package in a human-sized finger. In this paper we employ optical fiber bundles to achieve a form factor that, at 15 mm diameter, is smaller than an average human fingertip. The electronics and camera are also located remotely, further reducing package size. The sensor achieves a spatial resolution of 0.22 mm and a minimum force resolution 5 mN for normal and shear contact forces. With these attributes, the DIGIT Pinki sensor is suitable for applications such as robotic and teleoperated digital palpation. We demonstrate its utility for palpation of the prostate gland and show that it can achieve clinically relevant discrimination of prostate stiffness for phantom and ex vivo tissue.\n",
      "\n",
      "Completed vision, tactile, sensor, optical, fiber, bundle, small, palpation, prostate, stiffness abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Key-value (KV) caching has become the de-facto to accelerate generation speed for large language models (LLMs) inference. However, the growing cache demand with increasing sequence length has transformed LLM inference to be a memory bound problem, significantly constraining the system throughput. Existing methods rely on dropping unimportant tokens or quantizing all entries uniformly. Such methods, however, often incur high approximation errors to represent the compressed matrices. The autoregressive decoding process further compounds the error of each step, resulting in critical deviation in model generation and deterioration of performance. To tackle this challenge, we propose GEAR, an efficient KV cache compression framework that achieves near-lossless high-ratio compression. GEAR first applies quantization to majority of entries of similar magnitudes to ultra-low precision. It then employs a low rank matrix to approximate the quantization error, and a sparse matrix to remedy individual errors from outlier entries. By adeptly integrating three techniques, GEAR is able to fully exploit their synergistic potentials. Our experiments demonstrate that compared to alternatives, GEAR achieves near-lossless 4-bit KV cache compression with up to 2.38x throughput improvement, while reducing peak-memory size up to 2.29x. Our code is publicly available at https://github.com/HaoKang-Timmy/GEAR.\n",
      "\n",
      "Completed Key-value, KV, LLM, compression, quantization, approximation, autoregressive, GEAR, performance, throughput abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Worked examples, which present an explained code for solving typical programming problems are among the most popular types of learning content in programming classes. Most approaches and tools for presenting these examples to students are based on line-by-line explanations of the example code. However, instructors rarely have time to provide explanations for many examples typically used in a programming class. In this paper, we assess the feasibility of using LLMs to generate code explanations for passive and active example exploration systems. To achieve this goal, we compare the code explanations generated by chatGPT with the explanations generated by both experts and students.\n",
      "\n",
      "Completed Worked, examples, programming, problems, learning, explanations, LLMs, passive, active, exploration abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper presents hybrid numerical techniques for solving the Boltzmann transport equation formulated by means of low-order equations for angular moments of the angular flux. The moment equations are derived by the projection operator approach. The projected equations are closed exactly using a high-order transport solution. The low-order equations of the hybrid methods are approximated with a finite volume scheme of the second-order accuracy. Functionals defining the closures in the discretized low-order equations are calculated by Monte Carlo techniques. In this study, we analyze effects of statistical noise and discretization error on the accuracy of the hybrid transport solution.\n",
      "\n",
      "Completed Boltzmann, transport, equation, angular, moments, hybrid, numerical, Monte Carlo, statistical, discretization abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The diagnosis and monitoring of Castrate Resistant Prostate Cancer (CRPC) are crucial for cancer patients, but the current models (such as P-NET) have limitations in terms of parameter count, generalization, and cost. To address the issue, we develop a more accurate and efficient Prostate Cancer patient condition prediction model, named PR-NET. By compressing and optimizing the network structure of P-NET, the model complexity is reduced while maintaining high accuracy and interpretability. The PR-NET demonstrated superior performance in predicting prostate cancer patient outcomes, outshining P-NET and six other traditional models with a significant margin. In our rigorous evaluation, PR-NET not only achieved impressive average AUC and Recall scores of 0.94 and 0.83, respectively, on known data but also maintained robust generalizability on five unknown datasets with a higher average AUC of 0.73 and Recall of 0.72, compared to P-NET's 0.68 and 0.5. PR-NET's efficiency was evidenced by its shorter average training and inference times, and its gene-level analysis revealed 46 key genes, demonstrating its enhanced predictive power and efficiency in identifying critical biomarkers for prostate cancer. Future research can further expand its application domains and optimize the model's performance and reliability.\n",
      "\n",
      "Completed Prostate, Cancer, CRPC, PR-NET, P-NET, Prediction, Biomarkers, Efficiency, Interpretability, Generalizability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Acoustic-to-articulatory inversion (AAI) is to convert audio into articulator movements, such as ultrasound tongue imaging (UTI) data. An issue of existing AAI methods is only using the personalized acoustic information to derive the general patterns of tongue motions, and thus the quality of generated UTI data is limited. To address this issue, this paper proposes an audio-textual diffusion model for the UTI data generation task. In this model, the inherent acoustic characteristics of individuals related to the tongue motion details are encoded by using wav2vec 2.0, while the ASR transcriptions related to the universality of tongue motions are encoded by using BERT. UTI data are then generated by using a diffusion module. Experimental results showed that the proposed diffusion model could generate high-quality UTI data with clear tongue contour that is crucial for the linguistic analysis and clinical assessment. The project can be found on the website\\footnote{https://yangyudong2020.github.io/wav2uti/\n",
      "\n",
      "Completed acoustic, articulatory, inversion, ultrasound, tongue, imaging, audio, textual, diffusion, model abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Long-tail recognition is challenging because it requires the model to learn good representations from tail categories and address imbalances across all categories. In this paper, we propose a novel generative and fine-tuning framework, LTGC, to handle long-tail recognition via leveraging generated content. Firstly, inspired by the rich implicit knowledge in large-scale models (e.g., large language models, LLMs), LTGC leverages the power of these models to parse and reason over the original tail data to produce diverse tail-class content. We then propose several novel designs for LTGC to ensure the quality of the generated data and to efficiently fine-tune the model using both the generated and original data. The visualization demonstrates the effectiveness of the generation module in LTGC, which produces accurate and diverse tail data. Additionally, the experimental results demonstrate that our LTGC outperforms existing state-of-the-art methods on popular long-tailed benchmarks.\n",
      "\n",
      "Completed long-tail, recognition, generative, fine-tuning, LTGC, LLMs, visualization, generation, accuracy, benchmarks abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In the field of data mining and machine learning, commonly used classification models cannot effectively learn in unbalanced data. In order to balance the data distribution before model training, oversampling methods are often used to generate data for a small number of classes to solve the problem of classifying unbalanced data. Most of the classical oversampling methods are based on the SMOTE technique, which only focuses on the local information of the data, and therefore the generated data may have the problem of not being realistic enough. In the current oversampling methods based on generative networks, the methods based on GANs can capture the true distribution of data, but there is the problem of pattern collapse and training instability in training; in the oversampling methods based on denoising diffusion probability models, the neural network of the inverse diffusion process using the U-Net is not applicable to tabular data, and although the MLP can be used to replace the U-Net, the problem exists due to the simplicity of the structure and the poor effect of removing noise. problem of poor noise removal. In order to overcome the above problems, we propose a novel oversampling method SEMRes-DDPM.In the SEMRes-DDPM backward diffusion process, a new neural network structure SEMST-ResNet is used, which is suitable for tabular data and has good noise removal effect, and it can generate tabular data with higher quality. Experiments show that the SEMResNet network removes noise better than MLP; SEMRes-DDPM generates data distributions that are closer to the real data distributions than TabDDPM with CWGAN-GP; on 20 real unbalanced tabular datasets with 9 classification models, SEMRes-DDPM improves the quality of the generated tabular data in terms of three evaluation metrics (F1, G-mean, AUC) with better classification performance than other SOTA oversampling methods.\n",
      "\n",
      "Completed oversampling, unbalanced data, data mining, machine learning, SEMRes-DDPM, noise removal, tabular data, generative networks, classification, SEMST-ResNet abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The rigorous safety verification of control systems in critical applications is essential, given their increasing complexity and integration into everyday life. Simulation-based falsification approaches play a pivotal role in the safety verification of control systems, particularly within critical applications. These methods systematically explore the operational space of systems to identify configurations that result in violations of safety specifications. However, the effectiveness of traditional simulation-based falsification is frequently limited by the high dimensionality of the search space and the substantial computational resources required for exhaustive exploration. This paper presents BEACON, a novel framework that enhances the falsification process through a combination of Bayesian optimization and covariance matrix adaptation evolutionary strategy. By exploiting quantitative metrics to evaluate how closely a system adheres to safety specifications, BEACON advances the state-of-the-art in testing methodologies. It employs a model-based test point selection approach, designed to facilitate exploration across dynamically evolving search zones to efficiently uncover safety violations. Our findings demonstrate that BEACON not only locates a higher percentage of counterexamples compared to standalone BO but also achieves this with significantly fewer simulations than required by CMA-ES, highlighting its potential to optimize the verification process of control systems. This framework offers a promising direction for achieving thorough and resource-efficient safety evaluations, ensuring the reliability of control systems in critical applications.\n",
      "\n",
      "Completed safety, verification, control, systems, simulation, falsification, Bayesian, optimization, CMA-ES, BEACON abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Since coral reef ecosystems face threats from human activities and climate change, coral conservation programs are implemented worldwide. Monitoring coral health provides references for guiding conservation activities. However, current labor-intensive methods result in a backlog of unsorted images, highlighting the need for automated classification. Few studies have simultaneously utilized accurate annotations along with updated algorithms and datasets. This study aimed to create a dataset representing common coral conditions and associated stressors in the Indo-Pacific. Concurrently, it assessed existing classification algorithms and proposed a new multi-label method for automatically detecting coral conditions and extracting ecological information. A dataset containing over 20,000 high-resolution coral images of different health conditions and stressors was constructed based on the field survey. Seven representative deep learning architectures were tested on this dataset, and their performance was quantitatively evaluated using the F1 metric and the match ratio. Based on this evaluation, a new method utilizing the ensemble learning approach was proposed. The proposed method accurately classified coral conditions as healthy, compromised, dead, and rubble; it also identified corresponding stressors, including competition, disease, predation, and physical issues. This method can help develop the coral image archive, guide conservation activities, and provide references for decision-making for reef managers and conservationists. The proposed ensemble learning approach outperforms others on the dataset, showing State-Of-The-Art (SOTA) performance. Future research should improve its generalizability and accuracy to support global coral conservation efforts.\n",
      "\n",
      "Completed Coral, conservation, automated classification, Indo-Pacific, multi-label, deep learning, ensemble learning, ecological information, reef managers, SOTA abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The absence of openly accessible data and specialized foundation models is a major barrier for computational research in surgery. Toward this, (i) we open-source the largest dataset of general surgery videos to-date, consisting of 680 hours of surgical videos, including data from robotic and laparoscopic techniques across 28 procedures; (ii) we propose a technique for video pre-training a general surgery vision transformer (GSViT) on surgical videos based on forward video prediction that can run in real-time for surgical applications, toward which we open-source the code and weights of GSViT; (iii) we also release code and weights for procedure-specific fine-tuned versions of GSViT across 10 procedures; (iv) we demonstrate the performance of GSViT on the Cholec80 phase annotation task, displaying improved performance over state-of-the-art single frame predictors.\n",
      "\n",
      "Completed surgery, videos, dataset, GSViT, vision transformer, video prediction, real-time, fine-tuning, Cholec80, annotation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We introduce a new approach using computer vision to predict the land surface displacement from subsurface geometry images for Carbon Capture and Sequestration (CCS). CCS has been proved to be a key component for a carbon neutral society. However, scientists see there are challenges along the way including the high computational cost due to the large model scale and limitations to generalize a pre-trained model with complex physics. We tackle those challenges by training models directly from the subsurface geometry images. The goal is to understand the respons of land surface displacement due to carbon injection and utilize our trained models to inform decision making in CCS projects.\n",
      "  We implement multiple models (CNN, ResNet, and ResNetUNet) for static mechanics problem, which is a image prediction problem. Next, we use the LSTM and transformer for transient mechanics scenario, which is a video prediction problem. It shows ResNetUNet outperforms the others thanks to its architecture in static mechanics problem, and LSTM shows comparable performance to transformer in transient problem. This report proceeds by outlining our dataset in detail followed by model descriptions in method section. Result and discussion state the key learning, observations, and conclusion with future work rounds out the paper.\n",
      "\n",
      "Completed computer, vision, subsurface, geometry, images, Carbon, Capture, Sequestration, CCS, mechanics abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In recent years, video anomaly detection has been extensively investigated in both unsupervised and weakly supervised settings to alleviate costly temporal labeling. Despite significant progress, these methods still suffer from unsatisfactory results such as numerous false alarms, primarily due to the absence of precise temporal anomaly annotation. In this paper, we present a novel labeling paradigm, termed \"glance annotation\", to achieve a better balance between anomaly detection accuracy and annotation cost. Specifically, glance annotation is a random frame within each abnormal event, which can be easily accessed and is cost-effective. To assess its effectiveness, we manually annotate the glance annotations for two standard video anomaly detection datasets: UCF-Crime and XD-Violence. Additionally, we propose a customized GlanceVAD method, that leverages gaussian kernels as the basic unit to compose the temporal anomaly distribution, enabling the learning of diverse and robust anomaly representations from the glance annotations. Through comprehensive analysis and experiments, we verify that the proposed labeling paradigm can achieve an excellent trade-off between annotation cost and model performance. Extensive experimental results also demonstrate the effectiveness of our GlanceVAD approach, which significantly outperforms existing advanced unsupervised and weakly supervised methods. Code and annotations will be publicly available at https://github.com/pipixin321/GlanceVAD.\n",
      "\n",
      "Completed video, anomaly, detection, glance, annotation, unsupervised, weakly, supervised, gaussian, kernels abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Although automatically animating audio-driven talking heads has recently received growing interest, previous efforts have mainly concentrated on achieving lip synchronization with the audio, neglecting two crucial elements for generating expressive videos: emotion style and art style. In this paper, we present an innovative audio-driven talking face generation method called Style2Talker. It involves two stylized stages, namely Style-E and Style-A, which integrate text-controlled emotion style and picture-controlled art style into the final output. In order to prepare the scarce emotional text descriptions corresponding to the videos, we propose a labor-free paradigm that employs large-scale pretrained models to automatically annotate emotional text labels for existing audiovisual datasets. Incorporating the synthetic emotion texts, the Style-E stage utilizes a large-scale CLIP model to extract emotion representations, which are combined with the audio, serving as the condition for an efficient latent diffusion model designed to produce emotional motion coefficients of a 3DMM model. Moving on to the Style-A stage, we develop a coefficient-driven motion generator and an art-specific style path embedded in the well-known StyleGAN. This allows us to synthesize high-resolution artistically stylized talking head videos using the generated emotional motion coefficients and an art style source picture. Moreover, to better preserve image details and avoid artifacts, we provide StyleGAN with the multi-scale content features extracted from the identity image and refine its intermediate feature maps by the designed content encoder and refinement network, respectively. Extensive experimental results demonstrate our method outperforms existing state-of-the-art methods in terms of audio-lip synchronization and performance of both emotion style and art style.\n",
      "\n",
      "Completed Style2Talker, audio-driven, talking faces, emotion style, art style, CLIP, 3DMM, latent diffusion, StyleGAN, content features abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Generating emotional talking faces is a practical yet challenging endeavor. To create a lifelike avatar, we draw upon two critical insights from a human perspective: 1) The connection between audio and the non-deterministic facial dynamics, encompassing expressions, blinks, poses, should exhibit synchronous and one-to-many mapping. 2) Vibrant expressions are often accompanied by emotion-aware high-definition (HD) textures and finely detailed teeth. However, both aspects are frequently overlooked by existing methods. To this end, this paper proposes using normalizing Flow and Vector-Quantization modeling to produce emotional talking faces that satisfy both insights concurrently (FlowVQTalker). Specifically, we develop a flow-based coefficient generator that encodes the dynamics of facial emotion into a multi-emotion-class latent space represented as a mixture distribution. The generation process commences with random sampling from the modeled distribution, guided by the accompanying audio, enabling both lip-synchronization and the uncertain nonverbal facial cues generation. Furthermore, our designed vector-quantization image generator treats the creation of expressive facial images as a code query task, utilizing a learned codebook to provide rich, high-quality textures that enhance the emotional perception of the results. Extensive experiments are conducted to showcase the effectiveness of our approach.\n",
      "\n",
      "Completed talking, faces, audio, facial, dynamics, expressions, textures, teeth, FlowVQTalker, emotions abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Safe Multi-agent reinforcement learning (safe MARL) has increasingly gained attention in recent years, emphasizing the need for agents to not only optimize the global return but also adhere to safety requirements through behavioral constraints. Some recent work has integrated control theory with multi-agent reinforcement learning to address the challenge of ensuring safety. However, there have been only very limited applications of Model Predictive Control (MPC) methods in this domain, primarily due to the complex and implicit dynamics characteristic of multi-agent environments. To bridge this gap, we propose a novel method called Deep Learning-Based Model Predictive Control for Safe Multi-Agent Reinforcement Learning (DeepSafeMPC). The key insight of DeepSafeMPC is leveraging a entralized deep learning model to well predict environmental dynamics. Our method applies MARL principles to search for optimal solutions. Through the employment of MPC, the actions of agents can be restricted within safe states concurrently. We demonstrate the effectiveness of our approach using the Safe Multi-agent MuJoCo environment, showcasing significant advancements in addressing safety concerns in MARL.\n",
      "\n",
      "Completed Safe, MARL, Control, MPC, Multi-agent, Dynamics, Reinforcement, Learning, DeepSafeMPC, MuJoCo abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Despite the rapid development of large language models (LLMs) for the Korean language, there remains an obvious lack of benchmark datasets that test the requisite Korean cultural and linguistic knowledge. Because many existing Korean benchmark datasets are derived from the English counterparts through translation, they often overlook the different cultural contexts. For the few benchmark datasets that are sourced from Korean data capturing cultural knowledge, only narrow tasks such as bias and hate speech detection are offered. To address this gap, we introduce a benchmark of Cultural and Linguistic Intelligence in Korean (CLIcK), a dataset comprising 1,995 QA pairs. CLIcK sources its data from official Korean exams and textbooks, partitioning the questions into eleven categories under the two main categories of language and culture. For each instance in CLIcK, we provide fine-grained annotation of which cultural and linguistic knowledge is required to answer the question correctly. Using CLIcK, we test 13 language models to assess their performance. Our evaluation uncovers insights into their performances across the categories, as well as the diverse factors affecting their comprehension. CLIcK offers the first large-scale comprehensive Korean-centric analysis of LLMs' proficiency in Korean culture and language.\n",
      "\n",
      "Completed Korean, LLMs, Benchmark, Dataset, Cultural, Linguistic, Knowledge, CLIcK, Q&A, Proficiency abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper explores the problem of Generalist Anomaly Detection (GAD), aiming to train one single detection model that can generalize to detect anomalies in diverse datasets from different application domains without any further training on the target data. Some recent studies have shown that large pre-trained Visual-Language Models (VLMs) like CLIP have strong generalization capabilities on detecting industrial defects from various datasets, but their methods rely heavily on handcrafted text prompts about defects, making them difficult to generalize to anomalies in other applications, e.g., medical image anomalies or semantic anomalies in natural images. In this work, we propose to train a GAD model with few-shot normal images as sample prompts for AD on diverse datasets on the fly. To this end, we introduce a novel approach that learns an in-context residual learning model for GAD, termed InCTRL. It is trained on an auxiliary dataset to discriminate anomalies from normal samples based on a holistic evaluation of the residuals between query images and few-shot normal sample prompts. Regardless of the datasets, per definition of anomaly, larger residuals are expected for anomalies than normal samples, thereby enabling InCTRL to generalize across different domains without further training. Comprehensive experiments on nine AD datasets are performed to establish a GAD benchmark that encapsulate the detection of industrial defect anomalies, medical anomalies, and semantic anomalies in both one-vs-all and multi-class setting, on which InCTRL is the best performer and significantly outperforms state-of-the-art competing methods.\n",
      "\n",
      "Completed Generalist, Anomaly, Detection, Visual-Language, Models, Few-Shot, In-Context, Residual, Learning, Benchmark abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Mobility impairment caused by limb loss is a significant challenge faced by millions of individuals worldwide. The development of advanced assistive technologies, such as prosthetic devices, has the potential to greatly improve the quality of life for amputee patients. A critical component in the design of such technologies is the accurate prediction of reference joint motion for the missing limb. However, this task is hindered by the scarcity of joint motion data available for amputee patients, in contrast to the substantial quantity of data from able-bodied subjects. To overcome this, we leverage deep learning's reprogramming property to repurpose well-trained models for a new goal without altering the model parameters. With only data-level manipulation, we adapt models originally designed for able-bodied people to forecast joint motion in amputees. The findings in this study have significant implications for advancing assistive tech and amputee mobility.\n",
      "\n",
      "Completed Mobility impairment, limb loss, prosthetic devices, joint motion, amputees, data scarcity, deep learning, reprogramming, data-level manipulation, assistive technology abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Mastering autonomous drone landing on dynamic platforms presents formidable challenges due to unpredictable velocities and external disturbances caused by the wind, ground effect, turbines or propellers of the docking platform. This study introduces an advanced Deep Reinforcement Learning (DRL) agent, Lander:AI, designed to navigate and land on platforms in the presence of windy conditions, thereby enhancing drone autonomy and safety. Lander:AI is rigorously trained within the gym-pybullet-drone simulation, an environment that mirrors real-world complexities, including wind turbulence, to ensure the agent's robustness and adaptability.\n",
      "  The agent's capabilities were empirically validated with Crazyflie 2.1 drones across various test scenarios, encompassing both simulated environments and real-world conditions. The experimental results showcased Lander:AI's high-precision landing and its ability to adapt to moving platforms, even under wind-induced disturbances. Furthermore, the system performance was benchmarked against a baseline PID controller augmented with an Extended Kalman Filter, illustrating significant improvements in landing precision and error recovery. Lander:AI leverages bio-inspired learning to adapt to external forces like birds, enhancing drone adaptability without knowing force magnitudes.This research not only advances drone landing technologies, essential for inspection and emergency applications, but also highlights the potential of DRL in addressing intricate aerodynamic challenges.\n",
      "\n",
      "Completed DRL, drone, landing, dynamic platforms, wind, disturbances, Lander:AI, gym-pybullet-drone, Crazyflie, PID abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In real-world applications, dynamic scenarios require the models to possess the capability to learn new tasks continuously without forgetting the old knowledge. Experience-Replay methods store a subset of the old images for joint training. In the scenario of more strict privacy protection, storing the old images becomes infeasible, which leads to a more severe plasticity-stability dilemma and classifier bias. To meet the above challenges, we propose a new architecture, named continual expansion and absorption transformer~(CEAT). The model can learn the novel knowledge by extending the expanded-fusion layers in parallel with the frozen previous parameters. After the task ends, we losslessly absorb the extended parameters into the backbone to ensure that the number of parameters remains constant. To improve the learning ability of the model, we designed a novel prototype contrastive loss to reduce the overlap between old and new classes in the feature space. Besides, to address the classifier bias towards the new classes, we propose a novel approach to generate the pseudo-features to correct the classifier. We experiment with our methods on three standard Non-Exemplar Class-Incremental Learning~(NECIL) benchmarks. Extensive experiments demonstrate that our model gets a significant improvement compared with the previous works and achieves 5.38%, 5.20%, and 4.92% improvement on CIFAR-100, TinyImageNet, and ImageNet-Subset.\n",
      "\n",
      "Completed continual, expansion, absorption, transformer, plasticity, stability, contrastive, loss, pseudo-features, NECIL abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Compared to business-to-consumer (B2C) e-commerce systems, consumer-to-consumer (C2C) e-commerce platforms usually encounter the limited-stock problem, that is, a product can only be sold one time in a C2C system. This poses several unique challenges for click-through rate (CTR) prediction. Due to limited user interactions for each product (i.e. item), the corresponding item embedding in the CTR model may not easily converge. This makes the conventional sequence modeling based approaches cannot effectively utilize user history information since historical user behaviors contain a mixture of items with different volume of stocks. Particularly, the attention mechanism in a sequence model tends to assign higher score to products with more accumulated user interactions, making limited-stock products being ignored and contribute less to the final output. To this end, we propose the Meta-Split Network (MSNet) to split user history sequence regarding to the volume of stock for each product, and adopt differentiated modeling approaches for different sequences. As for the limited-stock products, a meta-learning approach is applied to address the problem of inconvergence, which is achieved by designing meta scaling and shifting networks with ID and side information. In addition, traditional approach can hardly update item embedding once the product is consumed. Thereby, we propose an auxiliary loss that makes the parameters updatable even when the product is no longer in distribution. To the best of our knowledge, this is the first solution addressing the recommendation of limited-stock product. Experimental results on the production dataset and online A/B testing demonstrate the effectiveness of our proposed method.\n",
      "\n",
      "Completed e-commerce, C2C, CTR, limited-stock, item embedding, sequence modeling, attention mechanism, meta-learning, auxiliary loss, recommendation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The Shallow Ice Approximation (SIA) model on strong form is commonly used for inferring the flow dynamics of grounded ice sheets. The solution to the SIA model is a closed-form expression for the velocity field. When that velocity field is used to advance the ice surface in time, the time steps have to take small values due to quadratic scaling in terms of the horizontal mesh size. In this paper we write the SIA model on weak form, and add in the Free Surface Stabilization Algorithm (FSSA) terms. We find numerically that the time step restriction scaling is improved from quadratic to linear, but only for large horizontal mesh sizes. We then extend the weak form by adding the initially neglected normal stress terms. This allows for a linear time step restriction across the whole range of the horizontal mesh sizes, leading to an improved efficiency. Theoretical analysis demonstrates that the inclusion of FSSA stabilization terms transitions the explicit time stepping treatment of second derivative surface terms to an implicit approach. Moreover, a computational cost analysis, combined with numerical results on stability and accuracy, advocates for preferring the SIA models written on weak form over the standard SIA model.\n",
      "\n",
      "Completed Shallow, Ice, Approximation, Weak, Form, Free, Surface, Stabilization, Algorithm, Stability, Accuracy abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper introduces a new data-driven, non-parametric method for image quality and aesthetics assessment, surpassing existing approaches and requiring no prompt engineering or fine-tuning. We eliminate the need for expressive textual embeddings by proposing efficient image anchors in the data. Through extensive evaluations of 7 state-of-the-art self-supervised models, our method demonstrates superior performance and robustness across various datasets and benchmarks. Notably, it achieves high agreement with human assessments even with limited data and shows high robustness to the nature of data and their pre-processing pipeline. Our contributions offer a streamlined solution for assessment of images while providing insights into the perception of visual information.\n",
      "\n",
      "Completed non-parametric, image, quality, aesthetics, assessment, data-driven, expressive, anchors, robustness, perception abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Large Language models (LLMs) have demonstrated impressive in-context learning (ICL) capabilities, where a LLM makes predictions for a given test input together with a few input-output pairs (demonstrations). Nevertheless, the inclusion of demonstrations leads to a quadratic increase in the computational overhead of the self-attention mechanism. Existing solutions attempt to distill lengthy demonstrations into compact vectors. However, they often require task-specific retraining or compromise LLM's in-context learning performance. To mitigate these challenges, we present Meta dEmonstratioN Distillation (MEND), where a language model learns to distill any lengthy demonstrations into vectors without retraining for a new downstream task. We exploit the knowledge distillation to enhance alignment between MEND and LLM, achieving both efficiency and effectiveness simultaneously. MEND is endowed with the meta-knowledge of distilling demonstrations through a two-stage training process, which includes meta-distillation pretraining and fine-tuning. Comprehensive evaluations across seven diverse ICL task partitions using decoder-only (GPT-2) and encoder-decoder (T5) attest to MEND's prowess. It not only matches but often outperforms the Vanilla ICL as well as other state-of-the-art distillation models, while significantly reducing the computational demands. This innovation promises enhanced scalability and efficiency for the practical deployment of large language models\n",
      "\n",
      "Completed Large, Language, Models, In-Context, Learning, Meta, Distillation, Pretraining, Fine-Tuning, Scalability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The diffusion-based text-to-image model harbors immense potential in transferring reference style. However, current encoder-based approaches significantly impair the text controllability of text-to-image models while transferring styles. In this paper, we introduce DEADiff to address this issue using the following two strategies: 1) a mechanism to decouple the style and semantics of reference images. The decoupled feature representations are first extracted by Q-Formers which are instructed by different text descriptions. Then they are injected into mutually exclusive subsets of cross-attention layers for better disentanglement. 2) A non-reconstructive learning method. The Q-Formers are trained using paired images rather than the identical target, in which the reference image and the ground-truth image are with the same style or semantics. We show that DEADiff attains the best visual stylization results and optimal balance between the text controllability inherent in the text-to-image model and style similarity to the reference image, as demonstrated both quantitatively and qualitatively. Our project page is https://tianhao-qi.github.io/DEADiff/.\n",
      "\n",
      "Completed DEADiff, text-to-image, style transfer, decoupling, Q-Formers, cross-attention, disentanglement, non-reconstructive learning, visual stylization, controllability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Addressing the dual challenges of local redundancy and global dependencies in video understanding, this work innovatively adapts the Mamba to the video domain. The proposed VideoMamba overcomes the limitations of existing 3D convolution neural networks and video transformers. Its linear-complexity operator enables efficient long-term modeling, which is crucial for high-resolution long video understanding. Extensive evaluations reveal VideoMamba's four core abilities: (1) Scalability in the visual domain without extensive dataset pretraining, thanks to a novel self-distillation technique; (2) Sensitivity for recognizing short-term actions even with fine-grained motion differences; (3) Superiority in long-term video understanding, showcasing significant advancements over traditional feature-based models; and (4) Compatibility with other modalities, demonstrating robustness in multi-modal contexts. Through these distinct advantages, VideoMamba sets a new benchmark for video understanding, offering a scalable and efficient solution for comprehensive video understanding. All the code and models are available at https://github.com/OpenGVLab/VideoMamba.\n",
      "\n",
      "Completed VideoMamba, video understanding, local redundancy, global dependencies, 3D convolution, video transformers, long-term modeling, self-distillation, multi-modal,benchmark abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Parameter space reduction has been proved to be a crucial tool to speed-up the execution of many numerical tasks such as optimization, inverse problems, sensitivity analysis, and surrogate models' design, especially when in presence of high-dimensional parametrized systems. In this work we propose a new method called local active subspaces (LAS), which explores the synergies of active subspaces with supervised clustering techniques in order to carry out a more efficient dimension reduction in the parameter space. The clustering is performed without losing the input-output relations by introducing a distance metric induced by the global active subspace. We present two possible clustering algorithms: K-medoids and a hierarchical top-down approach, which is able to impose a variety of subdivision criteria specifically tailored for parameter space reduction tasks. This method is particularly useful for the community working on surrogate modelling. Frequently, the parameter space presents subdomains where the objective function of interest varies less on average along different directions. So, it could be approximated more accurately if restricted to those subdomains and studied separately. We tested the new method over several numerical experiments of increasing complexity, we show how to deal with vectorial outputs, and how to classify the different regions with respect to the local active subspace dimension. Employing this classification technique as a preprocessing step in the parameter space, or output space in case of vectorial outputs, brings remarkable results for the purpose of surrogate modelling.\n",
      "\n",
      "Completed parameter, space, reduction, active, subspaces, clustering, surrogate, models, subdomains, dimension abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We study the problem of designing optimal learning and decision-making formulations when only historical data is available. Prior work typically commits to a particular class of data-driven formulation and subsequently tries to establish out-of-sample performance guarantees. We take here the opposite approach. We define first a sensible yard stick with which to measure the quality of any data-driven formulation and subsequently seek to find an optimal such formulation. Informally, any data-driven formulation can be seen to balance a measure of proximity of the estimated cost to the actual cost while guaranteeing a level of out-of-sample performance. Given an acceptable level of out-of-sample performance, we construct explicitly a data-driven formulation that is uniformly closer to the true cost than any other formulation enjoying the same out-of-sample performance. We show the existence of three distinct out-of-sample performance regimes (a superexponential regime, an exponential regime and a subexponential regime) between which the nature of the optimal data-driven formulation experiences a phase transition. The optimal data-driven formulations can be interpreted as a classically robust formulation in the superexponential regime, an entropic distributionally robust formulation in the exponential regime and finally a variance penalized formulation in the subexponential regime. This final observation unveils a surprising connection between these three, at first glance seemingly unrelated, data-driven formulations which until now remained hidden.\n",
      "\n",
      "Completed optimal, learning, decision-making, historical data, performance guarantees, out-of-sample performance, data-driven formulation, phase transition, variance penalized, entropic distributionally robust abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Geometric quantum mechanics, through its differential-geometric underpinning, provides additional tools of analysis and interpretation that bring quantum mechanics closer to classical mechanics: state spaces in both are equipped with symplectic geometry. This opens the door to revisiting foundational questions and issues, such as the nature of quantum entropy, from a geometric perspective. Central to this is the concept of geometric quantum state -- the probability measure on a system's space of pure states. This space's continuity leads us to introduce two analysis tools, inspired by Renyi's information theory, to characterize and quantify fundamental properties of geometric quantum states: the quantum information dimension that is the rate of geometric quantum state compression and the dimensional geometric entropy that monitors information stored in quantum states. We recount their classical definitions, information-theoretic meanings, and physical interpretations, and adapt them to quantum systems via the geometric approach. We then explicitly compute them in various examples and classes of quantum system. We conclude commenting on future directions for information in geometric quantum mechanics.\n",
      "\n",
      "Completed quantum, mechanics, geometry, entropy, information, dimension, state, space, pure, compression abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We propose an alternative approach to neural network training using the monotone vector field, an idea inspired by the seminal work of Juditsky and Nemirovski [Juditsky & Nemirovsky, 2019] developed originally to solve parameter estimation problems for generalized linear models (GLM) by reducing the original non-convex problem to a convex problem of solving a monotone variational inequality (VI). Our approach leads to computationally efficient procedures that converge fast and offer guarantee in some special cases, such as training a single-layer neural network or fine-tuning the last layer of the pre-trained model. Our approach can be used for more efficient fine-tuning of a pre-trained model while freezing the bottom layers, an essential step for deploying many machine learning models such as large language models (LLM). We demonstrate its applicability in training fully-connected (FC) neural networks, graph neural networks (GNN), and convolutional neural networks (CNN) and show the competitive or better performance of our approach compared to stochastic gradient descent methods on both synthetic and real network data prediction tasks regarding various performance metrics.\n",
      "\n",
      "Completed monotone vector field, neural network, training, Juditsky, Nemirovski, variational inequality, fine-tuning, large language models, graph neural networks, convolutional neural networks abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In this paper, a unified transformation method in learned image compression(LIC) is proposed from the perspective of modulation. Firstly, the quantization in LIC is considered as a generalized channel with additive uniform noise. Moreover, the LIC is interpreted as a particular communication system according to the consistency in structures and optimization objectives. Thus, the technology of communication systems can be applied to guide the design of modules in LIC. Furthermore, a unified transform method based on signal modulation (TSM) is defined. In the view of TSM, the existing transformation methods are mathematically reduced to a linear modulation. A series of transformation methods, e.g. TPM and TJM, are obtained by extending to nonlinear modulation. The experimental results on various datasets and backbone architectures verify that the effectiveness and robustness of the proposed method. More importantly, it further confirms the feasibility of guiding LIC design from a communication perspective. For example, when backbone architecture is hyperprior combining context model, our method achieves 3.52$\\%$ BD-rate reduction over GDN on Kodak dataset without increasing complexity.\n",
      "\n",
      "Completed image, compression, modulation, channel, noise, communication, signal, transformation, nonlinear, backbone abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Within the framework of Riehl-Shulman's synthetic $(\\infty,1)$-category theory, we present a theory of two-sided cartesian fibrations. Central results are several characterizations of the two-sidedness condition \\`{a} la Chevalley, Gray, Street, and Riehl-Verity, a two-sided Yoneda Lemma, as well as the proof of several closure properties.\n",
      "  Along the way, we also define and investigate a notion of fibered or sliced fibration which is used later to develop the two-sided case in a modular fashion. We also briefly discuss discrete two-sided cartesian fibrations in this setting, corresponding to $(\\infty,1)$-distributors.\n",
      "  The systematics of our definitions and results closely follows Riehl-Verity's $\\infty$-cosmos theory, but formulated internally to Riehl-Shulman's simplicial extension of homotopy type theory. All the constructions and proofs in this framework are by design invariant under homotopy equivalence. Semantically, the synthetic $(\\infty,1)$-categories correspond to internal $(\\infty,1)$-categories implemented as Rezk objects in an arbitrary given $(\\infty,1)$-topos.\n",
      "\n",
      "Completed cartesian, fibrations, two-sided, Yoneda, Chevalley, Gray, Street, cosmos, Riehl-Verity, Rezk abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present a novel adversarial distortion learning (ADL) for denoising two- and three-dimensional (2D/3D) biomedical image data. The proposed ADL consists of two auto-encoders: a denoiser and a discriminator. The denoiser removes noise from input data and the discriminator compares the denoised result to its noise-free counterpart. This process is repeated until the discriminator cannot differentiate the denoised data from the reference. Both the denoiser and the discriminator are built upon a proposed auto-encoder called Efficient-Unet. Efficient-Unet has a light architecture that uses the residual blocks and a novel pyramidal approach in the backbone to efficiently extract and re-use feature maps. During training, the textural information and contrast are controlled by two novel loss functions. The architecture of Efficient-Unet allows generalizing the proposed method to any sort of biomedical data. The 2D version of our network was trained on ImageNet and tested on biomedical datasets whose distribution is completely different from ImageNet; so, there is no need for re-training. Experimental results carried out on magnetic resonance imaging (MRI), dermatoscopy, electron microscopy and X-ray datasets show that the proposed method achieved the best on each benchmark. Our implementation and pre-trained models are available at https://github.com/mogvision/ADL.\n",
      "\n",
      "Completed adversarial, distortion, learning, denoising, biomedical, Efficient-Unet, residual, pyramidal, contrast, ImageNet abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Approximate integer programming is the following: For a convex body $K \\subseteq \\mathbb{R}^n$, either determine whether $K \\cap \\mathbb{Z}^n$ is empty, or find an integer point in the convex body scaled by $2$ from its center of gravity $c$. Approximate integer programming can be solved in time $2^{O(n)}$ while the fastest known methods for exact integer programming run in time $2^{O(n)} \\cdot n^n$. So far, there are no efficient methods for integer programming known that are based on approximate integer programming. Our main contribution are two such methods, each yielding novel complexity results.\n",
      "  First, we show that an integer point $x^* \\in (K \\cap \\mathbb{Z}^n)$ can be found in time $2^{O(n)}$, provided that the remainders of each component $x_i^* \\mod{\\ell}$ for some arbitrarily fixed $\\ell \\geq 5(n+1)$ of $x^*$ are given. The algorithm is based on a cutting-plane technique, iteratively halving the volume of the feasible set. The cutting planes are determined via approximate integer programming. Enumeration of the possible remainders gives a $2^{O(n)}n^n$ algorithm for general integer programming. This matches the current best bound of an algorithm by Dadush (2012) that is considerably more involved. Our algorithm also relies on a new asymmetric approximate Carath\\'eodory theorem that might be of interest on its own.\n",
      "  Our second method concerns integer programming problems in equation-standard form $Ax = b, 0 \\leq x \\leq u, \\, x \\in \\mathbb{Z}^n$ . Such a problem can be reduced to the solution of $\\prod_i O(\\log u_i +1)$ approximate integer programming problems. This implies, for example that knapsack or subset-sum problems with polynomial variable range $0 \\leq x_i \\leq p(n)$ can be solved in time $(\\log n)^{O(n)}$. For these problems, the best running time so far was $n^n \\cdot 2^{O(n)}$.\n",
      "\n",
      "Completed integer, programming, approximate, convex, volume, cutting, plane, Carathéodory, Knapsack, subset abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Diffusion models have shown a great ability at bridging the performance gap between predictive and generative approaches for speech enhancement. We have shown that they may even outperform their predictive counterparts for non-additive corruption types or when they are evaluated on mismatched conditions. However, diffusion models suffer from a high computational burden, mainly as they require to run a neural network for each reverse diffusion step, whereas predictive approaches only require one pass. As diffusion models are generative approaches they may also produce vocalizing and breathing artifacts in adverse conditions. In comparison, in such difficult scenarios, predictive models typically do not produce such artifacts but tend to distort the target speech instead, thereby degrading the speech quality. In this work, we present a stochastic regeneration approach where an estimate given by a predictive model is provided as a guide for further diffusion. We show that the proposed approach uses the predictive model to remove the vocalizing and breathing artifacts while producing very high quality samples thanks to the diffusion model, even in adverse conditions. We further show that this approach enables to use lighter sampling schemes with fewer diffusion steps without sacrificing quality, thus lifting the computational burden by an order of magnitude. Source code and audio examples are available online (https://uhh.de/inf-sp-storm).\n",
      "\n",
      "Completed diffusion, enhancement, predictive, generative, artifacts, stochastic, regeneration, guide, quality, computational abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present a computationally efficient algorithm that is suitable for graphic processing unit implementation. This algorithm enables the identification of all weak pseudo-manifolds that meet specific facet conditions, drawn from a given input set. We employ this approach to enumerate toric colorable seeds. Consequently, we achieve a comprehensive characterization of $(n-1)$-dimensional PL spheres with $n+4$ vertices that possess a maximal Buchstaber number.\n",
      "  A primary focus of this research is the fundamental categorization of non-singular complete toric varieties of Picard number $4$. This classification serves as a valuable tool for addressing questions related to toric manifolds of Picard number $4$. Notably, we have determined which of these manifolds satisfy equality within an inequality regarding the number of minimal components in their rational curve space. This addresses a question posed by Chen, Fu, and Hwang in 2014 for this specific case.\n",
      "\n",
      "Completed enumeration, manifolds, non-singular, toric, varieties, Buchstaber, classification, components, Picard, rational curves abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This study proposes an interpretable neural network-based non-proportional odds model (N$^3$POM) for ordinal regression. N$^3$POM is different from conventional approaches to ordinal regression with non-proportional models in several ways: (1) N$^3$POM is defined for both continuous and discrete responses, whereas standard methods typically treat the ordered continuous variables as if they are discrete, (2) instead of estimating response-dependent finite-dimensional coefficients of linear models from discrete responses as is done in conventional approaches, we train a non-linear neural network to serve as a coefficient function. Thanks to the neural network, N$^3$POM offers flexibility while preserving the interpretability of conventional ordinal regression. We establish a sufficient condition under which the predicted conditional cumulative probability locally satisfies the monotonicity constraint over a user-specified region in the covariate space. Additionally, we provide a monotonicity-preserving stochastic (MPS) algorithm for effectively training the neural network. We apply N$^3$POM to several real-world datasets.\n",
      "\n",
      "Completed ordinal regression, non-proportional odds, neural network, interpretability, monotonicity, sufficiency, conditional cumulative probability, region, covariate, MPS abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Synthetic data algorithms are widely employed in industries to generate artificial data for downstream learning tasks. While existing research primarily focuses on empirically evaluating utility of synthetic data, its theoretical understanding is largely lacking. This paper bridges the practice-theory gap by establishing relevant utility theory in a statistical learning framework. It considers two utility metrics: generalization and ranking of models trained on synthetic data. The former is defined as the generalization difference between models trained on synthetic and on real data. By deriving analytical bounds for this utility metric, we demonstrate that the synthetic feature distribution does not need to be similar as that of real data for ensuring comparable generalization of synthetic models, provided proper model specifications in downstream learning tasks. The latter utility metric studies the relative performance of models trained on synthetic data. In particular, we discover that the distribution of synthetic data is not necessarily similar as the real one to ensure consistent model comparison. Interestingly, consistent model comparison is still achievable even when synthetic responses are not well generated, as long as downstream models are separable by a generalization gap. Finally, extensive experiments on non-parametric models and deep neural networks have been conducted to validate these theoretical findings.\n",
      "\n",
      "Completed synthetic data, utility theory, generalization, ranking, model comparison, distribution, model specification, generalization gap, separable models, theoretical findings abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The problem of minimizing the sum of $n$ functions in $d$ dimensions is ubiquitous in machine learning and statistics. In many applications where the number of observations $n$ is large, it is necessary to use incremental or stochastic methods, as their per-iteration cost is independent of $n$. Of these, Quasi-Newton (QN) methods strike a balance between the per-iteration cost and the convergence rate. Specifically, they exhibit a superlinear rate with $O(d^2)$ cost in contrast to the linear rate of first-order methods with $O(d)$ cost and the quadratic rate of second-order methods with $O(d^3)$ cost. However, existing incremental methods have notable shortcomings: Incremental Quasi-Newton (IQN) only exhibits asymptotic superlinear convergence. In contrast, Incremental Greedy BFGS (IGS) offers explicit superlinear convergence but suffers from poor empirical performance and has a per-iteration cost of $O(d^3)$. To address these issues, we introduce the Sharpened Lazy Incremental Quasi-Newton Method (SLIQN) that achieves the best of both worlds: an explicit superlinear convergence rate, and superior empirical performance at a per-iteration $O(d^2)$ cost. SLIQN features two key changes: first, it incorporates a hybrid strategy of using both classic and greedy BFGS updates, allowing it to empirically outperform both IQN and IGS. Second, it employs a clever constant multiplicative factor along with a lazy propagation strategy, which enables it to have a cost of $O(d^2)$. Additionally, our experiments demonstrate the superiority of SLIQN over other incremental and stochastic Quasi-Newton variants and establish its competitiveness with second-order incremental methods.\n",
      "\n",
      "Completed Quasi-Newton, incremental, stochastic, superlinear, convergence, cost, greedy, empirical, lazy, hybrid abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The dynamic nature of proteins is crucial for determining their biological functions and properties, for which Monte Carlo (MC) and molecular dynamics (MD) simulations stand as predominant tools to study such phenomena. By utilizing empirically derived force fields, MC or MD simulations explore the conformational space through numerically evolving the system via Markov chain or Newtonian mechanics. However, the high-energy barrier of the force fields can hamper the exploration of both methods by the rare event, resulting in inadequately sampled ensemble without exhaustive running. Existing learning-based approaches perform direct sampling yet heavily rely on target-specific simulation data for training, which suffers from high data acquisition cost and poor generalizability. Inspired by simulated annealing, we propose Str2Str, a novel structure-to-structure translation framework capable of zero-shot conformation sampling with roto-translation equivariant property. Our method leverages an amortized denoising score matching objective trained on general crystal structures and has no reliance on simulation data during both training and inference. Experimental results across several benchmarking protein systems demonstrate that Str2Str outperforms previous state-of-the-art generative structure prediction models and can be orders of magnitude faster compared to long MD simulations. Our open-source implementation is available at https://github.com/lujiarui/Str2Str\n",
      "\n",
      "Completed Protein, conformation, sampling, simulation, Monte Carlo, molecular dynamics, force fields, learning-based, Str2Str, roto-translation abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Urn models for innovation have proven to capture fundamental empirical laws shared by several real-world processes. The so-called urn model with triggering includes, as particular cases, an urn representation of the two-parameter Poisson-Dirichlet process and the Dirichlet process, seminal in Bayesian non-parametric inference. In this work, we leverage this connection to introduce a novel approach for quantifying closeness between symbolic sequences and test it within the framework of the authorship attribution problem. The method demonstrates high accuracy when compared to other state-of-the-art methods in different scenarios, featuring a substantial gain in computational efficiency and theoretical transparency. Beyond the practical convenience, this work demonstrates how the recently established connection between urn models and non-parametric Bayesian inference can pave the way for designing more efficient inference methods. In particular, the hybrid approach that we propose allows us to relax the exchangeability hypothesis, which can be particularly relevant for systems exhibiting complex correlation patterns and non-stationary dynamics.\n",
      "\n",
      "Completed urn models, innovation, Bayesian, non-parametric, inference, authorship, attribution, symbolic sequences, efficiency, exchangeability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Multiple Instance Learning (MIL) is a weakly-supervised problem in which one label is assigned to the whole bag of instances. An important class of MIL models is instance-based, where we first classify instances and then aggregate those predictions to obtain a bag label. The most common MIL model is when we consider a bag as positive if at least one of its instances has a positive label. However, this reasoning does not hold in many real-life scenarios, where the positive bag label is often a consequence of a certain percentage of positive instances. To address this issue, we introduce a dedicated instance-based method called ProMIL, based on deep neural networks and Bernstein polynomial estimation. An important advantage of ProMIL is that it can automatically detect the optimal percentage level for decision-making. We show that ProMIL outperforms standard instance-based MIL in real-world medical applications. We make the code available.\n",
      "\n",
      "Completed Multiple,Instance,Learning,weakly-supervised,instance-based,positive,ProMIL,deep,neural,networks abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The development of successful artificial intelligence models for chest X-ray analysis relies on large, diverse datasets with high-quality annotations. While several databases of chest X-ray images have been released, most include disease diagnosis labels but lack detailed pixel-level anatomical segmentation labels. To address this gap, we introduce an extensive chest X-ray multi-center segmentation dataset with uniform and fine-grain anatomical annotations for images coming from five well-known publicly available databases: ChestX-ray8, Chexpert, MIMIC-CXR-JPG, Padchest, and VinDr-CXR, resulting in 657,566 segmentation masks. Our methodology utilizes the HybridGNet model to ensure consistent and high-quality segmentations across all datasets. Rigorous validation, including expert physician evaluation and automatic quality control, was conducted to validate the resulting masks. Additionally, we provide individualized quality indices per mask and an overall quality estimation per dataset. This dataset serves as a valuable resource for the broader scientific community, streamlining the development and assessment of innovative methodologies in chest X-ray analysis. The CheXmask dataset is publicly available at: https://physionet.org/content/chexmask-cxr-segmentation-data/\n",
      "\n",
      "Completed CheXmask, chest X-ray, segmentation, annotation, medical imaging, HybridGNet, quality control, dataset, artificial intelligence, radiology abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The aim of dynamic prediction is to provide individualized risk predictions over time, which are updated as new data become available. In pursuit of constructing a dynamic prediction model for a progressive eye disorder, age-related macular degeneration (AMD), we propose a time-dependent Cox survival neural network (tdCoxSNN) to predict its progression using longitudinal fundus images. tdCoxSNN builds upon the time-dependent Cox model by utilizing a neural network to capture the non-linear effect of time-dependent covariates on the survival outcome. Moreover, by concurrently integrating a convolutional neural network (CNN) with the survival network, tdCoxSNN can directly take longitudinal images as input. We evaluate and compare our proposed method with joint modeling and landmarking approaches through extensive simulations. We applied the proposed approach to two real datasets. One is a large AMD study, the Age-Related Eye Disease Study (AREDS), in which more than 50,000 fundus images were captured over a period of 12 years for more than 4,000 participants. Another is a public dataset of the primary biliary cirrhosis (PBC) disease, where multiple lab tests were longitudinally collected to predict the time-to-liver transplant. Our approach demonstrates commendable predictive performance in both simulation studies and the analysis of the two real datasets.\n",
      "\n",
      "Completed dynamic, prediction, Cox, survival, neural network, time-dependent, fundus images, convolutional neural network, AREDS, PBC abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The human brain remains continuously active, whether an individual is working or at rest. Mental activity is a daily process, and if the brain becomes excessively active, known as overload, it can adversely affect human health. Recently, advancements in early prediction of mental health conditions have emerged, aiming to prevent serious consequences and enhance the overall quality of life. Consequently, the estimation of mental status has garnered significant attention from diverse researchers due to its potential benefits. While various signals are employed to assess mental state, the electroencephalogram, containing extensive information about the brain, is widely utilized by researchers. In this paper, we categorize mental workload into three states (low, middle, and high) and estimate a continuum of mental workload levels. Our method leverages information from multiple spatial dimensions to achieve optimal results in mental estimation. For the time domain approach, we employ Temporal Convolutional Networks. In the frequency domain, we introduce a novel architecture based on combining residual blocks, termed the Multi-Dimensional Residual Block. The integration of these two domains yields significant results compared to individual estimates in each domain. Our approach achieved a 74.98% accuracy in the three-class classification, surpassing the provided data results at 69.00%. Specially, our method demonstrates efficacy in estimating continuous levels, evidenced by a corresponding Concordance Correlation Coefficient (CCC) result of 0.629. The combination of time and frequency domain analysis in our approach highlights the exciting potential to improve healthcare applications in the future.\n",
      "\n",
      "Completed mental, workload, estimation, electroencephalogram, time, frequency, temporal convolutional networks, multi-dimensional residual block, healthcare, Concordance Correlation Coefficient abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The conjugate gradient method is a crucial first-order optimization method that generally converges faster than the steepest descent method, and its computational cost is much lower than that of second-order methods. However, while various types of conjugate gradient methods have been studied in Euclidean spaces and on Riemannian manifolds, there is little study for those in distributed scenarios. This paper proposes a decentralized Riemannian conjugate gradient descent (DRCGD) method that aims at minimizing a global function over the Stiefel manifold. The optimization problem is distributed among a network of agents, where each agent is associated with a local function, and the communication between agents occurs over an undirected connected graph. Since the Stiefel manifold is a non-convex set, a global function is represented as a finite sum of possibly non-convex (but smooth) local functions. The proposed method is free from expensive Riemannian geometric operations such as retractions, exponential maps, and vector transports, thereby reducing the computational complexity required by each agent. To the best of our knowledge, DRCGD is the first decentralized Riemannian conjugate gradient algorithm to achieve global convergence over the Stiefel manifold.\n",
      "\n",
      "Completed distributed, Riemannian, conjugate, gradient, descent, Stiefel, manifold, decentralized, smooth, non-convex abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Magnetic resonance imaging (MRI) always suffers from long acquisition times. Parallel imaging (PI) is one solution to reduce scan time by periodically skipping certain K-space lines and then reconstructing high-quality images from undersampled measurements. Recently, implicit neural representation (INR) has emerged as a new deep learning method that represents an object as a continuous function of spatial coordinates, and this function is normally parameterized by a multilayer perceptron (MLP). In this paper, we propose a novel MRI PI reconstruction method based on INR, which represents the reconstructed fully-sampled images as the function of voxel coordinates and prior feature vectors of undersampled images to overcome the generalization problem of INR. Specifically, we introduce a scale-embedded encoder to produce scale-independent voxel-specific features from MR images with different undersampling scales and then concatenate with coordinate vectors to recover fully-sampled MR images, thus achieving multiple scale reconstructions. The performance of the proposed method was assessed by experimenting with publicly available MRI datasets and was compared with other reconstruction methods. Our quantitative evaluation demonstrates the superiority of the proposed method over alternative reconstruction methods.\n",
      "\n",
      "Completed MRI, PI, INR, MLP, voxels, coordinates, features, scale, encoder, reconstruction abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Our knowledge of the organisation of the human brain at the population-level is yet to translate into power to predict functional differences at the individual-level, limiting clinical applications, and casting doubt on the generalisability of inferred mechanisms. It remains unknown whether the difficulty arises from the absence of individuating biological patterns within the brain, or from limited power to access them with the models and compute at our disposal. Here we comprehensively investigate the resolvability of such patterns with data and compute at unprecedented scale. Across 23 810 unique participants from UK Biobank, we systematically evaluate the predictability of 25 individual biological characteristics, from all available combinations of structural and functional neuroimaging data. Over 4526 GPU hours of computation, we train, optimize, and evaluate out-of-sample 700 individual predictive models, including fully-connected feed-forward neural networks of demographic, psychological, serological, chronic disease, and functional connectivity characteristics, and both uni- and multi-modal 3D convolutional neural network models of macro- and micro-structural brain imaging. We find a marked discrepancy between the high predictability of sex (balanced accuracy 99.7%), age (mean absolute error 2.048 years, R2 0.859), and weight (mean absolute error 2.609Kg, R2 0.625), for which we set new state-of-the-art performance, and the surprisingly low predictability of other characteristics. Neither structural nor functional imaging predicted psychology better than the coincidence of chronic disease (p<0.05). Serology predicted chronic disease (p<0.05) and was best predicted by it (p<0.001), followed by structural neuroimaging (p<0.05). Our findings suggest either more informative imaging or more powerful models are needed to decipher individual level characteristics from the human brain.\n",
      "\n",
      "Completed Predictability, Brain, Computational, Demographics, Biological, Univariate, Multivariate, Neuroimaging, Prediction, Psychology abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We present CAFA-evaluator, a powerful Python program designed to evaluate the performance of prediction methods on targets with hierarchical concept dependencies. It generalizes multi-label evaluation to modern ontologies where the prediction targets are drawn from a directed acyclic graph and achieves high efficiency by leveraging matrix computation and topological sorting. The program requirements include a small number of standard Python libraries, making CAFA-evaluator easy to maintain. The code replicates the Critical Assessment of protein Function Annotation (CAFA) benchmarking, which evaluates predictions of the consistent subgraphs in Gene Ontology. Owing to its reliability and accuracy, the organizers have selected CAFA-evaluator as the official CAFA evaluation software.\n",
      "\n",
      "Completed CAFA-evaluator, Python, hierarchical, concept, dependencies, directed, acyclic, graph, topological, sorting abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Background: Missing data is a common challenge in mass spectrometry-based metabolomics, which can lead to biased and incomplete analyses. The integration of whole-genome sequencing (WGS) data with metabolomics data has emerged as a promising approach to enhance the accuracy of data imputation in metabolomics studies. Method: In this study, we propose a novel method that leverages the information from WGS data and reference metabolites to impute unknown metabolites. Our approach utilizes a multi-view variational autoencoder to jointly model the burden score, polygenetic risk score (PGS), and linkage disequilibrium (LD) pruned single nucleotide polymorphisms (SNPs) for feature extraction and missing metabolomics data imputation. By learning the latent representations of both omics data, our method can effectively impute missing metabolomics values based on genomic information. Results: We evaluate the performance of our method on empirical metabolomics datasets with missing values and demonstrate its superiority compared to conventional imputation techniques. Using 35 template metabolites derived burden scores, PGS and LD-pruned SNPs, the proposed methods achieved R^2-scores > 0.01 for 71.55% of metabolites. Conclusion: The integration of WGS data in metabolomics imputation not only improves data completeness but also enhances downstream analyses, paving the way for more comprehensive and accurate investigations of metabolic pathways and disease associations. Our findings offer valuable insights into the potential benefits of utilizing WGS data for metabolomics data imputation and underscore the importance of leveraging multi-modal data integration in precision medicine research.\n",
      "\n",
      "Completed missing, data, metabolomics, WGS, imputation, autoencoder, feature, extraction, genomic, information, integration abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper introduces a Bayesian framework designed to measure the degree of association between categorical random variables. The method is grounded in the formal definition of variable independence and is implemented using Markov Chain Monte Carlo (MCMC) techniques. Unlike commonly employed techniques in Association Rule Learning, this approach enables a clear and precise estimation of confidence intervals and the statistical significance of the measured degree of association. We applied the method to non-exclusive emotions identified by annotators in 4,613 tweets written in Portuguese. This analysis revealed pairs of emotions that exhibit associations and mutually opposed pairs. Moreover, the method identifies hierarchical relations between categories, a feature observed in our data, and is utilized to cluster emotions into basic-level groups.\n",
      "\n",
      "Completed Bayesian, Association, Categorical, Markov, Chain, Monte, Carlo, Statistical, Significance, Hierarchical, Clustering abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Molecular conformation optimization is crucial to computer-aided drug discovery and materials design. Traditional energy minimization techniques rely on iterative optimization methods that use molecular forces calculated by a physical simulator (oracle) as anti-gradients. However, this is a computationally expensive approach that requires many interactions with a physical simulator. One way to accelerate this procedure is to replace the physical simulator with a neural network. Despite recent progress in neural networks for molecular conformation energy prediction, such models are prone to distribution shift, leading to inaccurate energy minimization. We find that the quality of energy minimization with neural networks can be improved by providing optimization trajectories as additional training data. Still, it takes around $5 \\times 10^5$ additional conformations to match the physical simulator's optimization quality. In this work, we present the Gradual Optimization Learning Framework (GOLF) for energy minimization with neural networks that significantly reduces the required additional data. The framework consists of an efficient data-collecting scheme and an external optimizer. The external optimizer utilizes gradients from the energy prediction model to generate optimization trajectories, and the data-collecting scheme selects additional training data to be processed by the physical simulator. Our results demonstrate that the neural network trained with GOLF performs on par with the oracle on a benchmark of diverse drug-like molecules using $50$x less additional data.\n",
      "\n",
      "Completed Molecular, conformation, optimization, energy, minimization, neural, networks, trajectories, simulator, GOLF abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Ascertaining the collective viability of cells in different cell culture conditions has typically relied on averaging colorimetric indicators and is often reported out in simple binary readouts. Recent research has combined viability assessment techniques with image-based deep-learning models to automate the characterization of cellular properties. However, further development of viability measurements to assess the continuity of possible cellular states and responses to perturbation across cell culture conditions is needed. In this work, we demonstrate an image processing algorithm for quantifying cellular viability in 3D cultures without the need for assay-based indicators. We show that our algorithm performs similarly to a pair of human experts in whole-well images over a range of days and culture matrix compositions. To demonstrate potential utility, we perform a longitudinal study investigating the impact of a known therapeutic on pancreatic cancer spheroids. Using images taken with a high content imaging system, the algorithm successfully tracks viability at the individual spheroid and whole-well level. The method we propose reduces analysis time by 97% in comparison to the experts. Because the method is independent of the microscope or imaging system used, this approach lays the foundation for accelerating progress in and for improving the robustness and reproducibility of 3D culture analysis across biological and clinical research.\n",
      "\n",
      "Completed cell, viability, image processing, deep learning, 3D culture, spheroids, longitudinal study, pancreatic cancer, robustness, reproducibility abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Accurately simulating human opinion dynamics is crucial for understanding a variety of societal phenomena, including polarization and the spread of misinformation. However, the agent-based models (ABMs) commonly used for such simulations often over-simplify human behavior. We propose a new approach to simulating opinion dynamics based on populations of Large Language Models (LLMs). Our findings reveal a strong inherent bias in LLM agents towards producing accurate information, leading simulated agents to consensus in line with scientific reality. This bias limits their utility for understanding resistance to consensus views on issues like climate change. After inducing confirmation bias through prompt engineering, however, we observed opinion fragmentation in line with existing agent-based modeling and opinion dynamics research. These insights highlight the promise and limitations of LLM agents in this domain and suggest a path forward: refining LLMs with real-world discourse to better simulate the evolution of human beliefs.\n",
      "\n",
      "Completed opinion, dynamics, simulation, large, language, models, bias, consensus, polarization, confirmation, discourse abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Motivated by the great success of classical generative models in machine learning, enthusiastic exploration of their quantum version has recently started. To depart on this journey, it is important to develop a relevant metric to evaluate the quality of quantum generative models; in the classical case, one such example is the inception score. In this paper, we propose the quantum inception score, which relates the quality to the Holevo information of the quantum channel that classifies a given dataset. We prove that, under this proposed measure, the quantum generative models provide better quality than their classical counterparts because of the presence of quantum coherence, characterized by the resource theory of asymmetry, and entanglement. Furthermore, we harness the quantum fluctuation theorem to characterize the physical limitation of the quality of quantum generative models. Finally, we apply the quantum inception score to assess the quality of the one-dimensional spin chain model as a quantum generative model, with the quantum convolutional neural network as a quantum classifier, for the phase classification problem in the quantum many-body physics.\n",
      "\n",
      "Completed Quantum, Generative, Models, Inception, Score, Holevo, Information, Coherence, Entanglement, Fluctuation, Theorem abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Among the fundamental questions in computer science is that of the impact of synchronism/asynchronism on computations, which has been addressed in various fields of the discipline: in programming, in networking, in concurrence theory, in artificial learning, etc. In this paper, we tackle this question from a standpoint which mixes discrete dynamical system theory and computational complexity, by highlighting that the chosen way of making local computations can have a drastic influence on the performed global computation itself. To do so, we study how distinct update schedules may fundamentally change the asymptotic behaviors of finite dynamical systems, by analyzing in particular their limit cycle maximal period. For the message itself to be general and impacting enough, we choose to focus on a ``simple'' computational model which prevents underlying systems from having too many intrinsic degrees of freedom, namely elementary cellular automata. More precisely, for elementary cellular automata rules which are neither too simple nor too complex (the problem should be meaningless for both), we show that update schedule changes can lead to significant computational complexity jumps (from constant to superpolynomial ones) in terms of their temporal asymptotes.\n",
      "\n",
      "Completed computation, synchronism, asynchronism, complexity, dynamical systems, cellular automata, update schedules, limit cycles, computational model, asymptotes abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Histopathology plays a central role in clinical medicine and biomedical research. While artificial intelligence shows promising results on many pathological tasks, generalization and dealing with rare diseases, where training data is scarce, remains a challenge. Distilling knowledge from unlabelled data into a foundation model before learning from, potentially limited, labelled data provides a viable path to address these challenges. In this work, we extend the state of the art of foundation models for digital pathology whole slide images by semi-automated data curation and incorporating pathologist domain knowledge. Specifically, we combine computational and pathologist domain knowledge (1) to curate a diverse dataset of 133k slides corresponding to 1.2 billion image patches covering data from different fixation, staining, and scanning protocols as well as data from different indications and labs across the EU and US, (2) for grouping semantically similar slides and tissue patches, and (3) to augment the input images during training. We evaluate the resulting model on a set of public and internal benchmarks and show that although our foundation model is trained with an order of magnitude less slides, it performs on par or better than competing models. We expect that scaling our approach to more data and larger models will further increase its performance and capacity to deal with increasingly complex real world tasks in diagnostics and biomedical research.\n",
      "\n",
      "Completed histopathology, foundation models, digital pathology, semi-automated data curation, pathologist domain knowledge, dataset curation, data diversity, semantical grouping, image augmentation, benchmarking abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In practical scenarios involving the measurement of surface electromyography (sEMG) in muscles, particularly those areas near the heart, one of the primary sources of contamination is the presence of electrocardiogram (ECG) signals. To assess the quality of real-world sEMG data more effectively, this study proposes QASE-net, a new non-intrusive model that predicts the SNR of sEMG signals. QASE-net combines CNN-BLSTM with attention mechanisms and follows an end-to-end training strategy. Our experimental framework utilizes real-world sEMG and ECG data from two open-access databases, the Non-Invasive Adaptive Prosthetics Database and the MIT-BIH Normal Sinus Rhythm Database, respectively. The experimental results demonstrate the superiority of QASE-net over the previous assessment model, exhibiting significantly reduced prediction errors and notably higher linear correlations with the ground truth. These findings show the potential of QASE-net to substantially enhance the reliability and precision of sEMG quality assessment in practical applications.\n",
      "\n",
      "Completed sEMG, ECG, QASE-net, CNN-BLSTM, Attention, SNR, Databases, Ground truth, Reliability, Precision abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "WiFi-based human sensing has exhibited remarkable potential to analyze user behaviors in a non-intrusive and device-free manner, benefiting applications as diverse as smart homes and healthcare. However, most previous works focus on single-user sensing, which has limited practicability in scenarios involving multiple users. Although recent studies have begun to investigate WiFi-based multi-user sensing, there remains a lack of benchmark datasets to facilitate reproducible and comparable research. To bridge this gap, we present WiMANS, to our knowledge, the first dataset for multi-user sensing based on WiFi. WiMANS contains over 9.4 hours of dual-band WiFi Channel State Information (CSI), as well as synchronized videos, monitoring simultaneous activities of multiple users. We exploit WiMANS to benchmark the performance of state-of-the-art WiFi-based human sensing models and video-based models, posing new challenges and opportunities for future work. We believe WiMANS can push the boundaries of current studies and catalyze the research on WiFi-based multi-user sensing.\n",
      "\n",
      "Completed WiFi, human sensing, non-intrusive, device-free, multi-user sensing, benchmark, dataset, WiMANS, Channel State Information, video abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "In the era of Internet of Things, how to develop a smart sensor system with sustainable power supply, easy deployment and flexible use has become a difficult problem to be solved. The traditional power supply has problems such as frequent replacement or charging when in use, which limits the development of wearable devices. The contact-to-separate friction nanogenerator (TENG) was prepared by using polychotomy thy lene (PTFE) and aluminum (AI) foils. Human motion energy was collected by human body arrangement, and human motion posture was monitored according to the changes of output electrical signals. In 2012, Academician Wang Zhong lin and his team invented the triboelectric nanogenerator (TENG), which uses Maxwell displacement current as a driving force to directly convert mechanical stimuli into electrical signals, so it can be used as a self-driven sensor. Teng-based sensors have the advantages of simple structure and high instantaneous power density, which provides an important means for building intelligent sensor systems. At the same time, machine learning, as a technology with low cost, short development cycle, strong data processing ability and prediction ability, has a significant effect on the processing of a large number of electrical signals generated by TENG, and the combination with TENG sensors will promote the rapid development of intelligent sensor networks in the future. Therefore, this paper is based on the intelligent sound monitoring and recognition system of TENG, which has good sound recognition capability, and aims to evaluate the feasibility of the sound perception module architecture in ubiquitous sensor networks.\n",
      "\n",
      "Completed TENG, InternetThings, Nanogenerator, IntelligentSensor, SoundMonitoring, SoundRecognition, Triboelectric, MachineLearning, MaxwellDisplacementCurrent, UbiquitousSensorNetworks abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The protein dynamics are common and important for their biological functions and properties, the study of which usually involves time-consuming molecular dynamics (MD) simulations in silico. Recently, generative models has been leveraged as a surrogate sampler to obtain conformation ensembles with orders of magnitude faster and without requiring any simulation data (a \"zero-shot\" inference). However, being agnostic of the underlying energy landscape, the accuracy of such generative model may still be limited. In this work, we explore the few-shot setting of such pre-trained generative sampler which incorporates MD simulations in a tractable manner. Specifically, given a target protein of interest, we first acquire some seeding conformations from the pre-trained sampler followed by a number of physical simulations in parallel starting from these seeding samples. Then we fine-tuned the generative model using the simulation trajectories above to become a target-specific sampler. Experimental results demonstrated the superior performance of such few-shot conformation sampler at a tractable computational cost.\n",
      "\n",
      "Completed protein, dynamics, generative, model, zero-shot, inference, energy, landscape, few-shot, sampler abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Speech emotion recognition (SER) is a pivotal technology for human-computer interaction systems. However, 80.77% of SER papers yield results that cannot be reproduced. We develop EMO-SUPERB, short for EMOtion Speech Universal PERformance Benchmark, which aims to enhance open-source initiatives for SER. EMO-SUPERB includes a user-friendly codebase to leverage 15 state-of-the-art speech self-supervised learning models (SSLMs) for exhaustive evaluation across six open-source SER datasets. EMO-SUPERB streamlines result sharing via an online leaderboard, fostering collaboration within a community-driven benchmark and thereby enhancing the development of SER. On average, 2.58% of annotations are annotated using natural language. SER relies on classification models and is unable to process natural languages, leading to the discarding of these valuable annotations. We prompt ChatGPT to mimic annotators, comprehend natural language annotations, and subsequently re-label the data. By utilizing labels generated by ChatGPT, we consistently achieve an average relative gain of 3.08% across all settings.\n",
      "\n",
      "Completed Speech emotion recognition, EMO-SUPERB, benchmark, self-supervised learning, natural language, annotation, classification, ChatGPT, re-labeling, relative gain abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "We introduce SigNova, a new semi-supervised framework for detecting anomalies in streamed data. While our initial examples focus on detecting radio-frequency interference (RFI) in digitized signals within the field of radio astronomy, it is important to note that SigNova's applicability extends to any type of streamed data. The framework comprises three primary components. Firstly, we use the signature transform to extract a canonical collection of summary statistics from observational sequences. This allows us to represent variable-length visibility samples as finite-dimensional feature vectors. Secondly, each feature vector is assigned a novelty score, calculated as the Mahalanobis distance to its nearest neighbor in an RFI-free training set. By thresholding these scores we identify observation ranges that deviate from the expected behavior of RFI-free visibility samples without relying on stringent distributional assumptions. Thirdly, we integrate this anomaly detector with Pysegments, a segmentation algorithm, to localize consecutive observations contaminated with RFI, if any. This approach provides a compelling alternative to classical windowing techniques commonly used for RFI detection. Importantly, the complexity of our algorithm depends on the RFI pattern rather than on the size of the observation window. We demonstrate how SigNova improves the detection of various types of RFI (e.g., broadband and narrowband) in time-frequency visibility data. We validate our framework on the Murchison Widefield Array (MWA) telescope and simulated data and the Hydrogen Epoch of Reionization Array (HERA).\n",
      "\n",
      "Completed SigNova, semi-supervised, anomalies, streamed data, radio astronomy, signature transform, feature vectors, novelty score, Pysegments, windowing techniques abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "The right ventricular (RV) function deterioration strongly predicts clinical outcomes in numerous circumstances. To boost the clinical deployment of ensemble regression methods that quantify RV volumes using tabular data from the widely available two-dimensional echocardiography (2DE), we propose to complement the volume predictions with uncertainty scores. To this end, we employ an instance-based method which uses the learned tree structure to identify the nearest training samples to a target instance and then uses a number of distribution types to more flexibly model the output. The probabilistic and point-prediction performances of the proposed framework are evaluated on a relatively small-scale dataset, comprising 100 end-diastolic and end-systolic RV volumes. The reference values for point performance were obtained from MRI. The results demonstrate that our flexible approach yields improved probabilistic and point performances over other state-of-the-art methods. The appropriateness of the proposed framework is showcased by providing exemplar cases. The estimated uncertainty embodies both aleatoric and epistemic types. This work aligns with trustworthy artificial intelligence since it can be used to enhance the decision-making process and reduce risks. The feature importance scores of our framework can be exploited to reduce the number of required 2DE views which could enhance the proposed pipeline's clinical application.\n",
      "\n",
      "Completed RV, function, volumes, echocardiography, uncertainty, distribution, performances, feature, views, trustworthiness abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper considers the decentralized (discrete) optimal transport (D-OT) problem. In this setting, a network of agents seeks to design a transportation plan jointly, where the cost function is the sum of privately held costs for each agent. We reformulate the D-OT problem as a constraint-coupled optimization problem and propose a single-loop decentralized algorithm with an iteration complexity of O(1/{\\epsilon}) that matches existing centralized first-order approaches. Moreover, we propose the decentralized equitable optimal transport (DE-OT) problem. In DE-OT, in addition to cooperatively designing a transportation plan that minimizes transportation costs, agents seek to ensure equity in their individual costs. The iteration complexity of the proposed method to solve DE-OT is also O(1/{\\epsilon}). This rate improves existing centralized algorithms, where the best iteration complexity obtained is O(1/{\\epsilon}^2).\n",
      "\n",
      "Completed decentralized, optimal, transport, constraint-coupled, optimization, algorithm, scalable, equitable, transportation, costs abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Machine learning, particularly deep neural networks, has been widely utilized in high energy physics and has shown remarkable results in various applications. Moreover, the concept of machine learning has been extended to quantum computers, giving rise to a new research area known as quantum machine learning. In this paper, we propose a novel variational quantum circuit model, Quantum Complete Graph Neural Network (QCGNN), designed for learning complete graphs. We argue that QCGNN has a polynomial speedup against its classical counterpart, due to the property of quantum parallelism. In this paper, we study the application of QCGNN through the challenging jet discrimination, where the jets are represented with complete graphs. Subsequently, we conduct a comparative analysis with classical graph neural networks to establish a benchmark.\n",
      "\n",
      "Completed quantum, machine, learning, complete, graph, neural, network, variational, circuit, jet, discrimination abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Asynchronous Microphone array calibration is a prerequisite for most audition robot applications. In practice, the calibration requires estimating microphone positions, time offsets, clock drift rates, and sound event locations simultaneously. The existing method proposed Graph-based Simultaneous Localisation and Mapping (Graph-SLAM) utilizing common TDOA, time difference of arrival between two microphones (TDOA-M), and odometry measurement, however, it heavily depends on the initial value. In this paper, we propose a novel TDOA, time difference of arrival between adjacent sound events (TDOA-S), combine it with TDOA-M, called hybrid TDOA, and add odometry measurement to construct Graph-SLAM and use the Gauss-Newton (GN) method to solve. TDOA-S is simple and efficient because it eliminates time offset without generating new variables. Simulation and real-world experiment results consistently show that our method is independent of microphone number, insensitive to initial values, and has better calibration accuracy and stability under various TDOA noises. In addition, the simulation result demonstrates that our method has a lower Cram\\'er-Rao lower bound (CRLB) for microphone parameters, which explains the advantages of my method.\n",
      "\n",
      "Completed asynchronous, microphone, calibration, hybrid TDOA, Graph-SLAM, Gauss-Newton, initial value independence, robust, CRB, sound event abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Diffusion models have recently gained traction as a powerful class of deep generative priors, excelling in a wide range of image restoration tasks due to their exceptional ability to model data distributions. To solve image restoration problems, many existing techniques achieve data consistency by incorporating additional likelihood gradient steps into the reverse sampling process of diffusion models. However, the additional gradient steps pose a challenge for real-world practical applications as they incur a large computational overhead, thereby increasing inference time. They also present additional difficulties when using accelerated diffusion model samplers, as the number of data consistency steps is limited by the number of reverse sampling steps. In this work, we propose a novel diffusion-based image restoration solver that addresses these issues by decoupling the reverse process from the data consistency steps. Our method involves alternating between a reconstruction phase to maintain data consistency and a refinement phase that enforces the prior via diffusion purification. Our approach demonstrates versatility, making it highly adaptable for efficient problem-solving in latent space. Additionally, it reduces the necessity for numerous sampling steps through the integration of consistency models. The efficacy of our approach is validated through comprehensive experiments across various image restoration tasks, including image denoising, deblurring, inpainting, and super-resolution.\n",
      "\n",
      "Completed diffusion, image, restoration, likelihood, gradient, solver, decoupling, purification, versatility, consistency abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Computer-aided diagnosis (CAD) systems stand out as potent aids for physicians in identifying the novel Coronavirus Disease 2019 (COVID-19) through medical imaging modalities. In this paper, we showcase the integration and reliable and fast deployment of a state-of-the-art AI system designed to automatically analyze CT images, offering infection probability for the swift detection of COVID-19. The suggested system, comprising both classification and segmentation components, is anticipated to reduce physicians' detection time and enhance the overall efficiency of COVID-19 detection. We successfully surmounted various challenges, such as data discrepancy and anonymisation, testing the time-effectiveness of the model, and data security, enabling reliable and scalable deployment of the system on both cloud and edge environments. Additionally, our AI system assigns a probability of infection to each 3D CT scan and enhances explainability through anchor set similarity, facilitating timely confirmation and segregation of infected patients by physicians.\n",
      "\n",
      "Completed Computer-aided, Diagnosis, COVID-19, Medical, Imaging, AI, Classification, Segmentation, Probability, Explainability abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "This paper aims to develop and provide a rigorous treatment to the problem of entropy regularized fine-tuning in the context of continuous-time diffusion models, which was recently proposed by Uehara et al. (arXiv:2402.15194, 2024). The idea is to use stochastic control for sample generation, where the entropy regularizer is introduced to mitigate reward collapse. We also show how the analysis can be extended to fine-tuning involving a general $f$-divergence regularizer.\n",
      "\n",
      "Completed Entropy, Regularization, Fine-Tuning, Diffusion, Stochastic, Control, Sample, Generation, Mitigation, Reward abstracts ...\n",
      "Prompt: \n",
      "Provide a comma separated list of 10 words uniquely identifying this abstract. \n",
      "The words should only be unitary words.\n",
      "Do not use hyphenated words. \n",
      "Do not use phrases.\n",
      "\n",
      "Abstract: \n",
      "Multiple extended target tracking (ETT) has gained increasing attention due to the development of high-precision LiDAR and radar sensors in automotive applications. For LiDAR point cloud-based vehicle tracking, this paper presents a probabilistic measurement-region association (PMRA) ETT model, which can describe the complex measurement distribution by partitioning the target extent into different regions. The PMRA model overcomes the drawbacks of previous data-region association (DRA) models by eliminating the approximation error of constrained estimation and using continuous integrals to more reliably calculate the association probabilities. Furthermore, the PMRA model is integrated with the Poisson multi-Bernoulli mixture (PMBM) filter for tracking multiple vehicles. Simulation results illustrate the superior estimation accuracy of the proposed PMRA-PMBM filter in terms of both positions and extents of the vehicles comparing with PMBM filters using the gamma Gaussian inverse Wishart and DRA implementations.\n",
      "\n",
      "Completed extended, target, tracking, PMRA, ETT, LiDAR, radar, PMBM, vehicles, simulation abstracts ...\n"
     ]
    }
   ],
   "source": [
    "#df = daily_processing(\"../data/2024_03_08_cs.json\")\n",
    "df = pd.read_json(\"../data/2024_03_13_cs.json.gz\", orient=\"records\")\n",
    "abstracts = df[\"abstract\"].tolist()\n",
    "descriptive_words = get_descriptive_words_from_gemini(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_client = MistralClient(api_key=MISTRAL_API_KEY)\n",
    "\n",
    "\n",
    "def get_embeddings_from_mistral(input: list[str]) -> list[list[float]]:\n",
    "    embeddings_batch_response = mistral_client.embeddings(\n",
    "        model=\"mistral-embed\",\n",
    "        input=input,\n",
    "        )\n",
    "    return embeddings_batch_response\n",
    "\n",
    "\n",
    "def process_embedding_batches_with_mistral(input: list[str], batch_size: int) -> list[list[float]]:\n",
    "    embeddings = []\n",
    "    for i in range(0, len(input), batch_size):\n",
    "        batch = abstracts[i : i + batch_size]\n",
    "        batch_embedding = get_embeddings_from_mistral(batch)\n",
    "    embeddings.extend(batch_embedding)\n",
    "    return embeddings\n",
    "    \n",
    "\n",
    "def get_descriptive_words_from_mistral(input: list[str], model: str=\"open-mixtral-8x7b\") -> list[str]:\n",
    "    # open-mistral-7b\n",
    "    # open-mixtral-8x7b\n",
    "    # mistral-small-latest\n",
    "    # mistral-medium-latest\n",
    "    # mistral-large-latest\n",
    "\n",
    "    messages = [\n",
    "        ChatMessage(role=\"user\", content=input)\n",
    "    ]\n",
    "    chat_response = mistral_client.chat(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        # response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    return chat_response # [0].message.content\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "For each abstract in the list of <abstract_count> abstracts, provide <word_count> words that uniquely identify the abstract.\n",
    "\n",
    "List of abstracts: \n",
    "<list_of_abstracts>\n",
    "\n",
    "Return json data with exactly <abstract_count> records. \n",
    "Example response:\n",
    "{\n",
    "    \"abstract_1\": [<ten words>],\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "chunk = {f\"abstract_{i+1}\": sentence for i, sentence in enumerate(abstracts[0: 10])}\n",
    "\n",
    "prompt = prompt_template.replace(\"<abstract_count>\", str(10))\n",
    "prompt = prompt.replace(\"<word_count>\", str(10))\n",
    "prompt = prompt.replace(\"<list_of_abstracts>\", str(chunk))\n",
    "print(f\"Prompt: {prompt}\")\n",
    "\n",
    "\n",
    "# embeddings = get_embeddings_from_mistral([\"sentence one\", \"sentence two\"])\n",
    "#words = get_descriptive_words_from_mistral(prompt)\n",
    "#json.loads(words.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "novel2comic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
